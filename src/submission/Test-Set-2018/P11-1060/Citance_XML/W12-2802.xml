<PAPER>
	<S sid="0">Toward Learning Perceptually Grounded Word Meanings from Unaligned Parallel Data</S><ABSTRACT>
		<S sid="1" ssid="1">In order for robots to effectively understand natural language commands, they must be ableto acquire a large vocabulary of meaning rep resentations that can be mapped to perceptualfeatures in the external world.</S>
		<S sid="2" ssid="2">Previous ap proaches to learning these grounded meaning representations require detailed annotations at training time.</S>
		<S sid="3" ssid="3">In this paper, we present an approach which is capable of jointly learninga policy for following natural language com mands such as ?Pick up the tire pallet,?</S>
		<S sid="4" ssid="4">as well as a mapping between specific phrases in the language and aspects of the external world; for example the mapping between the words ?the tire pallet?</S>
		<S sid="5" ssid="5">and a specific object in the environment.</S>
		<S sid="6" ssid="6">We assume the action policy takes a parametric form that factors based on the structure of the language, based on the G3 framework and use stochastic gradient ascentto optimize policy parameters.</S>
		<S sid="7" ssid="7">Our prelimi nary evaluation demonstrates the effectivenessof the model on a corpus of ?pick up?</S>
		<S sid="8" ssid="8">com mands given to a robotic forklift by untrained users.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="9" ssid="9">In order for robots to robustly understand humanlanguage, they must have access to meaning rep resentations capable of mapping between symbols in the language and aspects of the external worldwhich are accessible via the robot?s perception sys tem.</S>
			<S sid="10" ssid="10">Previous approaches have represented word meanings as symbols in some specific symbolic language, either programmed by hand [Winograd, 1971, MacMahon et al, 2006] or learned [Matuszek et al, 2010, Chen and Mooney, 2011, Liang et al,2011, Branavan et al, 2009].</S>
			<S sid="11" ssid="11">Because word meanings are represented as symbols, rather than percep tually grounded features, the mapping between thesesymbols and the external world must still be de fined.</S>
			<S sid="12" ssid="12">Furthermore, the uncertainty of the mapping between constituents in the language and aspects of the external world cannot be explicitly represented by the model.</S>
			<S sid="13" ssid="13">Language grounding approaches, in contrast, map words in the language to groundings in the external world [Mavridis and Roy, 2006, Hsiao et al, 2008, Kollar et al, 2010, Tellex et al, 2011].</S>
			<S sid="14" ssid="14">Groundings are the specific physical concept that is referred to by the language and can be objects (e.g., a truck or a door), places (e.g., a particular location in theworld), paths (e.g., a trajectory through the environment), or events (e.g., a sequence of robot ac tions).</S>
			<S sid="15" ssid="15">This symbol grounding approach [Harnad, 1990] represents word meanings as functions whichtake as input a perceptual representation of a grounding and return whether it matches words in the lan guage.</S>
			<S sid="16" ssid="16">Recent work has demonstrated how to learn grounded word meanings from a parallel corpus of natural language commands paired with groundingsin the external world [Tellex et al, 2011].</S>
			<S sid="17" ssid="17">How ever, learning model parameters required that theparallel corpus be augmented with additional an notations specifying the alignment between specificphrases in the language and corresponding groundings in the external world.</S>
			<S sid="18" ssid="18">Figure 1 shows an ex ample command from the training set paired with these alignment annotations, represented as arrows 7pointing from each linguistic constituent to a corre sponding grounding.Our approach in this paper relaxes these annota tion requirements and learns perceptually grounded word meanings from an unaligned parallel corpusthat only provides supervision for the top-level action that corresponds to a natural language com mand.</S>
			<S sid="19" ssid="19">Our system takes as input a state/action space for the robot defining a space of possible groundingsand available actions in the external world.</S>
			<S sid="20" ssid="20">In addition it requires a corpus of natural language com mands paired with the correct action executed inthe environment.</S>
			<S sid="21" ssid="21">For example, an entry in the cor pus consists of a natural language command such as ?Pick up the tire pallet?</S>
			<S sid="22" ssid="22">given to a robotic forklift, paired with an action sequence of the robot as drives to the tire pallet, inserts its forks, and raises it off the ground, drives to the truck, and sets it down.</S>
			<S sid="23" ssid="23">To learn from an unaligned corpus, we derivea new training algorithm that combines the Generalized Grounding Graph (G3) framework introduced by Tellex et al [2011] with the policy gra dient method described by Branavan et al [2009].</S>
			<S sid="24" ssid="24">We assume a specific parametric form for the action policy that is defined by the linguistic structure of the natural language command.</S>
			<S sid="25" ssid="25">The system learns a policy parameters that maximize expected reward using stochastic gradient ascent.</S>
			<S sid="26" ssid="26">By factoring the policy according to the structure of language, we can propagate the error signal to each term, allowing thesystem to infer groundings for each linguistic constituent even without direct supervision.</S>
			<S sid="27" ssid="27">We eval uate our model using a corpus of natural languagecommands collected from untrained users on the in ternet, commanding the robot to pick up objects ordrive to locations in the environment.</S>
			<S sid="28" ssid="28">The evalua tion demonstrates that the model is able to predict both robot actions and noun phrase groundings with high accuracy, despite having no direct supervision for noun phrase groundings.</S>
	</SECTION>
	<SECTION title="Background. " number="2">
			<S sid="29" ssid="1">We briefly review the G3 framework, introduced byTellex et al [2011].</S>
			<S sid="30" ssid="2">In order for a robot to un derstand natural language, it must be able to map between words in the language and corresponding groundings in the external world.</S>
			<S sid="31" ssid="3">The aim is to find Figure 1: Sample entry from an aligned corpus, where mappings between phrases in the language and groundings in the external world are explicitly specified as arrows.</S>
			<S sid="32" ssid="4">Learning the meaning of ?thetruck?</S>
			<S sid="33" ssid="5">and ?the pallet?</S>
			<S sid="34" ssid="6">is challenging when align ment annotations are not known.</S>
			<S sid="35" ssid="7">?r1 ?Pick up?</S>
			<S sid="36" ssid="8">?1 = ?1 ?f2 ?the pallet.?</S>
			<S sid="37" ssid="9">?2 ?2 =Figure 2: Grounding graph for ?Pick up the tire pal let.</S>
			<S sid="38" ssid="10">8 the most probable groundings ?1 . . .</S>
			<S sid="39" ssid="11">?N given thelanguage ? and the robot?s model of the environ ment M : argmax ?1...?N p(?1 . . .</S>
			<S sid="40" ssid="12">?N |?,M) (1)M consists of the robot?s location, the loca tions, geometries, and perceptual tags of objects, and available actions the robot can take.</S>
			<S sid="41" ssid="13">For brevity, we omit M from future equations in this section.</S>
			<S sid="42" ssid="14">To learn this distribution, one standard approachis to factor it based on certain independence assump tions, then train models for each factor.</S>
			<S sid="43" ssid="15">Naturallanguage has a well-known compositional, hierar chical argument structure [Jackendoff, 1983], and apromising approach is to exploit this structure in order to factor the model.</S>
			<S sid="44" ssid="16">However, if we define a di rected model over these variables, we must assumea possibly arbitrary order to the conditional ?i factors.</S>
			<S sid="45" ssid="17">For example, for a phrase such as ?the tire pal let near the other skid,?</S>
			<S sid="46" ssid="18">we could factorize in either of the following ways: p(?tires, ?skid|?)</S>
			<S sid="47" ssid="19">= p(?skid|?tires,?)?</S>
			<S sid="48" ssid="20">p(?tires|?)</S>
			<S sid="49" ssid="21">(2) p(?tires, ?skid|?)</S>
			<S sid="50" ssid="22">= p(?tires|?skid,?)?</S>
			<S sid="51" ssid="23">p(?skid|?)</S>
			<S sid="52" ssid="24">(3) Depending on the order of factorization, we willneed different conditional probability tables that cor respond to the meanings of words in the language.</S>
			<S sid="53" ssid="25">To resolve this issue, another approach is to use Bayes?</S>
			<S sid="54" ssid="26">Rule to estimate the p(?|?1 . . .</S>
			<S sid="55" ssid="27">?N ), but thisapproach would require normalizing over all possi ble words in the language ?.</S>
			<S sid="56" ssid="28">Another alternative is to use an undirected model, but this approach is intractable because it requires normalizing over allpossible values of all ?i variables in the model, in cluding continuous attributes such as location and size.To address these problems, the G3 framework in troduced a correspondence vector ? to capture the dependency between ?1 . . .</S>
			<S sid="57" ssid="29">?N and ?.</S>
			<S sid="58" ssid="30">Each entryin ?i ? ?</S>
			<S sid="59" ssid="31">corresponds to whether linguistic con stituent ?i ? ?</S>
			<S sid="60" ssid="32">corresponds to grounding ?i. We assume that ?1 . . .</S>
			<S sid="61" ssid="33">?N are independent of ? unless?</S>
			<S sid="62" ssid="34">is known.</S>
			<S sid="63" ssid="35">Introducing ? enables factorization according to the structure of language with local nor malization at each factor over a space of just the two possible values for ?i. 2.1 Inference.</S>
			<S sid="64" ssid="36">In order to use the G3 framework for inference, wewant to infer the groundings ?1 . . .</S>
			<S sid="65" ssid="37">?N that maxi mize the distribution argmax ?1...?N p(?1 . . .</S>
			<S sid="66" ssid="38">?N |?,?)</S>
			<S sid="67" ssid="39">(4)which is equivalent to maximizing the joint distribu tion of all groundings ?1 . . .</S>
			<S sid="68" ssid="40">?N , ? and ?, argmax ?1...?N p(?1 . . .</S>
			<S sid="69" ssid="41">?N ,?,?).</S>
			<S sid="70" ssid="42">(5) We assume that ? and ?1 . . .</S>
			<S sid="71" ssid="43">?N are independent when ? is not known, yielding: argmax ?1...?N p(?|?, ?1 . . .</S>
			<S sid="72" ssid="44">?N )p(?)p(?1 . . .</S>
			<S sid="73" ssid="45">?N ) (6)This independence assumption may seem unintu itive, but it is justified because the correspondence variable ? breaks the dependency between ? and?1 . . .</S>
			<S sid="74" ssid="46">?N . If we do not know whether ?1 . . .</S>
			<S sid="75" ssid="47">?N cor respond to ?, we assume that the language does not tell us anything about the groundings.</S>
			<S sid="76" ssid="48">Finally, for simplicity, we assume that any object in the environment is equally likely to be referenced by the language, which amounts to a constant prior on ?1 . . .</S>
			<S sid="77" ssid="49">?N . In the future, we plan to incorporate models of attention and salience into this prior.</S>
			<S sid="78" ssid="50">We ignore p(?)</S>
			<S sid="79" ssid="51">since it does not depend on ?1 . . .</S>
			<S sid="80" ssid="52">?N , leading to: argmax ?1...?N p(?|?, ?1 . . .</S>
			<S sid="81" ssid="53">?N ) (7) To compute the maximum value of the objective in Equation 7, the system performs beam search over ?1 . . .</S>
			<S sid="82" ssid="54">?N , computing the probability of each assignment from Equation 7 to find the maximum probability assignment.</S>
			<S sid="83" ssid="55">Although we are using p(?|?, ?1 . . .</S>
			<S sid="84" ssid="56">?N ) as the objective function, ? is fixed, and the ?1 . . .</S>
			<S sid="85" ssid="57">?N are unknown.</S>
			<S sid="86" ssid="58">This approachis valid because, given our independence assumptions, p(?|?, ?1 . . .</S>
			<S sid="87" ssid="59">?N ) corresponds to the joint dis tribution over all the variables given in Equation 5.</S>
			<S sid="88" ssid="60">In order to perform beam search, we factor the model according to the hierarchical, compositional linguistic structure of the command: p(?|?, ?1 . . .</S>
			<S sid="89" ssid="61">?N ) = ? i p(?i|?i, ?i1 . . .</S>
			<S sid="90" ssid="62">?ik) (8) 9 This factorization can be represented graphically; we call the resulting graphical model the grounding graph for a natural language command.</S>
			<S sid="91" ssid="63">The directed model for the command ?Pick up the pallet?</S>
			<S sid="92" ssid="64">appears in Figure 2.</S>
			<S sid="93" ssid="65">The ? variables correspond to language;the ? variables correspond to groundings in the ex ternal world, and the ? variables are True if the groundings correspond to the language, and False otherwise.In the fully supervised case, we fit model param eters ? using an aligned parallel corpus of labeled positive and negative examples for each linguistic constituent.</S>
			<S sid="94" ssid="66">The G3 framework assumes a log-linearparametrization with feature functions fj and fea ture weights ?j : p(?|?, ?1 . . .</S>
			<S sid="95" ssid="67">?N ) = (9) ? i 1 Z exp( ? j ?jfj(?i,?i, ?i1 . . .</S>
			<S sid="96" ssid="68">?ik)) (10) This function is convex and can be optimized with gradient-based methods [McCallum, 2002].</S>
			<S sid="97" ssid="69">Features correspond to the degree to which each ? correctly grounds ?i. For a relation such as ?on,?a natural feature is whether the grounding corre sponding to the head noun phrase is supported by the grounding corresponding to the argument noun phrases.</S>
			<S sid="98" ssid="70">However, the feature supports(?i, ?j) alone is not enough to enable the model to learn that ?on?</S>
			<S sid="99" ssid="71">corresponds to supports(?i, ?j).</S>
			<S sid="100" ssid="72">Instead we need a feature that also takes into account the word ?on:?</S>
			<S sid="101" ssid="73">supports(?i, ?j) ?</S>
			<S sid="102" ssid="74">(?on?</S>
			<S sid="103" ssid="75">?i) (11)</S>
	</SECTION>
	<SECTION title="Approach. " number="3">
			<S sid="104" ssid="1">Our goal is to learn model parameters for the G3framework from an unaligned corpus of natural language commands paired with robot actions.</S>
			<S sid="105" ssid="2">Previ ously, the system learned model parameters ? usingan aligned corpus in which values for all grounding variables are known at training time, and anno tators provided both positive and negative examples for each factor.</S>
			<S sid="106" ssid="3">In this paper we describe how to relax this annotation requirement so that only the top-level action needs to be observed in order to train the model.</S>
			<S sid="107" ssid="4">It is easy and fast to collect datawith these annotations, whereas annotating the val ues of all the variables, including negative examples is time-consuming and error prone.</S>
			<S sid="108" ssid="5">Once we know the model parameters we can use existing inference to find groundings corresponding to word meanings, as in Equation 4.</S>
			<S sid="109" ssid="6">We are given a corpus of D training examples.Each example d consists of a natural language com mand ?d with an associated grounding graph with grounding variables ?d. Values for the grounding variables are not known, except for an observed value gda for the top-level action random variable, ? d a . Finally, an example has an associated environmental context or semantic map Md. Each environmentalcontext will have a different set of objects and avail able actions for the robot.</S>
			<S sid="110" ssid="7">For example, one trainingexample might contain a command given in an environment with a single tire pallet; another might con tain a command given in an environment with two box pallets and a truck.We define a sampling distribution to choose val ues for the ? variables in the model using the G3 framework with parameters ?: p(?d|?d,?d,Md,?)</S>
			<S sid="111" ssid="8">(12) Next, we define a reward function for choosing the correct grounding ga for a training example: r(?d, gda) = ? 1 if ?da = g d a ?1 otherwise (13)Here ?a is a grounding variable for the top-level ac tion corresponding to the command; it is one of the variables in the vector ?.</S>
			<S sid="112" ssid="9">Our aim is to find model parameters that maximize expected reward when drawing values for ?d from p(?d|?d,?d,Md,?)</S>
			<S sid="113" ssid="10">over the training set: argmax ? ?</S>
			<S sid="114" ssid="11">d Ep(?d|?d,?d,Md,?)r(?</S>
			<S sid="115" ssid="12">d, gda) (14) Expanding the expectation we have: argmax ? ?</S>
			<S sid="116" ssid="13">d d?</S>
			<S sid="117" ssid="14">r(?d, gda)p(?</S>
			<S sid="118" ssid="15">d|?d,?d,Md,?)</S>
			<S sid="119" ssid="16">(15)We use stochastic gradient descent to find model pa rameters that maximize reward.</S>
			<S sid="120" ssid="17">First, we take the 10 derivative of the expectation with respect to ?.</S>
			<S sid="121" ssid="18">(We drop the d subscripts for brevity.)</S>
			<S sid="122" ssid="19">??k Ep(?|?,?,M,?)r(?, ga) = ? ?</S>
			<S sid="123" ssid="20">r(?, ga) ? ??k p(?|?,?,M,?)</S>
			<S sid="124" ssid="21">(16) Focusing on the inner term, we expand it with Bayes?</S>
			<S sid="125" ssid="22">rule: ? ??k p(?|?,?,M,?)</S>
			<S sid="126" ssid="23">= ? ??k p(?|?,?,M,?)p(?|?,M,?)</S>
			<S sid="127" ssid="24">p(?|?,M,?)</S>
			<S sid="128" ssid="25">(17) We assume the priors do not depend on ?: p(?|M) p(?|?)</S>
			<S sid="129" ssid="26">??k p(?|?,?,M,?)</S>
			<S sid="130" ssid="27">(18)For brevity, we compress ?, ?, and M in the vari able X . Next, we take the partial derivative of thelikelihood of ?.</S>
			<S sid="131" ssid="28">First we assume each factor is inde pendent.</S>
			<S sid="132" ssid="29">??k p(?|X,?)</S>
			<S sid="133" ssid="30">= ? ??k ? i p(?i|X,?)</S>
			<S sid="134" ssid="31">(19) = ? i p(?i|X,?)?</S>
			<S sid="135" ssid="32">j ? ??k p(?j |X,?)</S>
			<S sid="136" ssid="33">p(?j |X,?)</S>
			<S sid="137" ssid="34">(20) Finally, we assume the distribution over ?j takes alog-linear form with feature functions fk and param eters ?k, as in the G3 framework.</S>
			<S sid="138" ssid="35">??k p(?j |X,?)</S>
			<S sid="139" ssid="36">= (21) p(?|X,?)?</S>
			<S sid="140" ssid="37">fk(?, X)?</S>
			<S sid="141" ssid="38">Ep(??|X,?)</S>
			<S sid="142" ssid="39">fk(?</S>
			<S sid="143" ssid="40">?, X) ? ?</S>
			<S sid="144" ssid="41">We substitute back into the overall expression for the partial derivative of the expectation: ? ??k Ep(?|X,?)r(?, ga) = Ep(?|X,?)r(?, ga)??</S>
			<S sid="145" ssid="42">j fk(?j , X)?</S>
			<S sid="146" ssid="43">Ep(??|X,?)</S>
			<S sid="147" ssid="44">fk(?</S>
			<S sid="148" ssid="45">?, X) ? ?</S>
			<S sid="149" ssid="46">(22) Input: 1: Initial values for parameters, ?0.</S>
			<S sid="150" ssid="47">2: Training dataset, D. 3: Number of iterations, T . 4: Step size, ?.</S>
			<S sid="151" ssid="48">5: 6: ??</S>
			<S sid="152" ssid="49">?0 7: for t ? T do 8: for d ? D do 9: ??</S>
			<S sid="153" ssid="50">???kEp(?d|?d,?d,Md,?)r(?</S>
			<S sid="154" ssid="51">d, gda) 10: end for 11: ??</S>
			<S sid="155" ssid="52">12: end for Output: Estimate of parameters ? Figure 3: Training algorithm.</S>
			<S sid="156" ssid="53">We approximate the expectation over ? with highly probable bindings for the ? and update thegradient incrementally for each example.</S>
			<S sid="157" ssid="54">The train ing algorithm is given in Figure 3.</S>
	</SECTION>
	<SECTION title="Results. " number="4">
			<S sid="158" ssid="1">We present preliminary results for the learning algo rithm using a corpus of natural language commands given to a robotic forklift.</S>
			<S sid="159" ssid="2">We collected a corpusof natural language commands paired with robot actions by showing annotators on Amazon Mechani cal Turk a video of the robot executing an action and asking them to describe in words they would use to command an expert human operator to carry out the commands in the video.</S>
			<S sid="160" ssid="3">Frames from a video in ourcorpus, together with commands for that video ap pear in Figure 4.</S>
			<S sid="161" ssid="4">Since commands often spannedmultiple parts of the video, we annotated the align ment between each top-level clause in the commandand the robot?s motion in the video.</S>
			<S sid="162" ssid="5">Our initial eval uation uses only commands from the corpus that contain the words ?pick up?</S>
			<S sid="163" ssid="6">due to scaling issues when running on the entire corpus.</S>
			<S sid="164" ssid="7">We report results using a random cost function as a baseline as well as the learned parameters on a training set and a held-out test set.</S>
			<S sid="165" ssid="8">Table 1 showsperformance on a training set using small environ ments (with one or two other objects) and a test set of small and large environments (with up to six other objects).</S>
			<S sid="166" ssid="9">11 (a) t=0 (b) t=20 (c) t=30 Pick up pallet with refridgerator [sic] and place on truck to the left.</S>
			<S sid="167" ssid="10">A distance away you should see a rectangular box.</S>
			<S sid="168" ssid="11">Approach it slowly and load it up onto your forklift.</S>
			<S sid="169" ssid="12">Slowly proceed to back out and then make a sharp turn and approach the truck.</S>
			<S sid="170" ssid="13">Raise your forklift and drop the rectangular box on the back of the truck.</S>
			<S sid="171" ssid="14">Go to the pallet with the refrigerator on it and pick it up.</S>
			<S sid="172" ssid="15">Move the pallet to the truck trailer.</S>
			<S sid="173" ssid="16">Place the pallet on the trailer.</S>
			<S sid="174" ssid="17">Pick up the pallet with the refrigerator and place it on the trailer.</S>
			<S sid="175" ssid="18">(d) Commands Figure 4: Frames from a video in our dataset, paired with natural language commands.</S>
			<S sid="176" ssid="19">As expected, on the training set the system learnsa good policy, since it is directly rewarded for act ing correctly.</S>
			<S sid="177" ssid="20">Because the environments are small, the chance of correctly grounding concrete nounphrases with a random cost function is high.</S>
			<S sid="178" ssid="21">How ever after training performance at grounding noun phrases increases to 92% even though the system had no access to alignment annotations for noun phrases at training time; it only observes reward based on whether it has acted correctly.</S>
			<S sid="179" ssid="22">Next, we report performance on a test set to assessgeneralization to novel commands given in novel environments.</S>
			<S sid="180" ssid="23">Since the test set includes larger environments with up to six objects, baseline perfor mance is lower.</S>
			<S sid="181" ssid="24">However the trained system is ableto achieve high performance at both inferring correct actions as well as correct object groundings, de spite having no access to a reward signal of any kind during inference.</S>
			<S sid="182" ssid="25">This result shows the system has learned general word meanings that apply in novel contexts not seen at training time.</S>
	</SECTION>
	<SECTION title="Related Work. " number="5">
			<S sid="183" ssid="1">Beginning with SHRDLU [Winograd, 1971], many systems have exploited the compositional structureof language to statically generate a plan correspond % Correct Actions Concrete Noun Phrases Before Training 31% 61% After Training 100% 92% (a) Training (small environments) % Correct Actions Concrete Noun Phrases Before Training 3% 26% After Training 84% 77% (b) Testing (small and large environments) Table 1: Results on the training set and test set.</S>
			<S sid="184" ssid="2">ing to a natural language command [Hsiao et al, 2008, MacMahon et al, 2006, Skubic et al, 2004, Dzifcak et al, 2009].</S>
			<S sid="185" ssid="3">Our work moves beyond this framework by defining a probabilistic graphicalmodel according to the structure of the natural lan guage command, inducing a distribution over plans and groundings.</S>
			<S sid="186" ssid="4">Models that learned word meanings [Tellex et al,2011, Kollar et al, 2010] require detailed alignment annotations between constituents in the language and objects, places, paths, or events in the external world.</S>
			<S sid="187" ssid="5">Previous approaches capable of learn ing from unaligned data [Vogel and Jurafsky, 2010, Branavan et al, 2009] used sequential models thatcould not capture the hierarchical structure of lan guage.</S>
			<S sid="188" ssid="6">Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meaningsare symbolic structures rather than patterns of fea tures in the external world.</S>
			<S sid="189" ssid="7">There has been a variety of work in transferringaction policies between a human and a robot.</S>
			<S sid="190" ssid="8">In imi tation learning, the goal is to create a system that canwatch a teacher perform an action, and then repro duce that action [Kruger et al, 2007, Chernova and Veloso, 2009, Schaal et al, 2003, Ekvall and Kragic, 2008].</S>
			<S sid="191" ssid="9">Rybski et al [2007] developed an imitation learning system that learns from a combination of imitation of the human teacher, as well as natural language input.</S>
			<S sid="192" ssid="10">Our work differs in that the systemmust infer an action from the natural language commands, rather than from watching the teacher per 12 form an action.</S>
			<S sid="193" ssid="11">The system is trained off-line, andthe task of the robot is to respond on-line to the nat ural language command.</S>
	</SECTION>
	<SECTION title="Conclusion. " number="6">
			<S sid="194" ssid="1">In this paper we described an approach for learningperceptually grounded word meanings from an un aligned parallel corpus of language paired with robotactions.</S>
			<S sid="195" ssid="2">The training algorithm jointly infers poli cies that correspond to natural language commands as well as alignments between noun phrases in the command and groundings in the external world.</S>
			<S sid="196" ssid="3">Inaddition, our approach learns grounded word mean ings or distributions corresponding to words in the language, that the system can use to follow novelcommands that it may have never encountered dur ing training.</S>
			<S sid="197" ssid="4">We presented a preliminary evaluation on a small corpus, demonstrating that the system isable to infer meanings for concrete noun phrases de spite having no direct supervision for these values.</S>
			<S sid="198" ssid="5">There are many directions for improvement.</S>
			<S sid="199" ssid="6">Weplan to train our system using a large dataset of language paired with robot actions in more complex en vironments, and on more than one robotic platform.</S>
			<S sid="200" ssid="7">Our approach points the way towards a framework that can learn a large vocabulary of general groundedword meanings, enabling systems that flexibly respond to a wide variety of natural language com mands given by untrained users.</S>
	</SECTION>
</PAPER>
