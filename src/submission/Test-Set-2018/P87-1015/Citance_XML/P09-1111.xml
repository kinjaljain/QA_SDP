<PAPER>
  <S sid="0">An Optimal-Time Binarization Algorithm for Linear Context-Free Rewriting Systems with Fan-Out Two</S>
  <ABSTRACT>
    <S sid="1" ssid="1">Linear context-free rewriting systems (LCFRSs) are grammar formalisms with the capability of modeling discontinuous constituents.</S>
    <S sid="2" ssid="2">Many applications use where the measure of the discontinuity of phrases) is not allowed be greater than We present an efficient algorithm for transforming LCFRS fan-out at most a binary form, whenever this is possible.</S>
    <S sid="3" ssid="3">This results in asymptotical run-time improvement for known parsing algorithms for this class.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="4" ssid="1">Since its early years, the computational linguistics field has devoted much effort to the development of formal systems for modeling the syntax of natural language.</S>
    <S sid="5" ssid="2">There has been a considerable interest in rewriting systems that enlarge the generative power of context-free grammars, still remaining far below the power of the class of contextsensitive grammars; see (Joshi et al., 1991) for discussion.</S>
    <S sid="6" ssid="3">Following this line, (Vijay-Shanker et al., 1987) have introduced a formalism called linear context-free rewriting systems (LCFRSs) that has received much attention in later years by the community.</S>
    <S sid="7" ssid="4">LCFRSs allow the derivation of tuples of strings,1 i.e., discontinuous phrases, that turn out to be very useful in modeling languages with relatively free word order.</S>
    <S sid="8" ssid="5">This feature has recently been used for mapping non-projective dependency grammars into discontinuous phrase structures (Kuhlmann and Satta, 2009).</S>
    <S sid="9" ssid="6">Furthermore, LCFRSs also implement so-called synchronous rewriting, up to some bounded degree, and have recently been exploited, in some syntactic variant, in syntax-based machine translation (Chiang, 2005; Melamed, 2003) as well as in the modeling of syntax-semantic interface (Nesson and Shieber, 2006).</S>
    <S sid="10" ssid="7">The maximum number f of tuple components that can be generated by an LCFRS G is called the fan-out of G, and the maximum number r of nonterminals in the right-hand side of a production is called the rank of G. As an example, contextfree grammars are LCFRSs with f = 1 and r given by the maximum length of a production right-hand side.</S>
    <S sid="11" ssid="8">Tree adjoining grammars (Joshi and Levy, 1977), or TAG for short, can be viewed as a special kind of LCFRS with f = 2, since each elementary tree generates two strings, and r given by the maximum number of adjunction sites in an elementary tree.</S>
    <S sid="12" ssid="9">Several parsing algorithms for LCFRS or equivalent formalisms are found in the literature; see for instance (Seki et al., 1991; Boullier, 2004; Burden and Ljungl&#168;of, 2005).</S>
    <S sid="13" ssid="10">All of these algorithms work in time O(JGJ &#183; JwJf'('+1)).</S>
    <S sid="14" ssid="11">Parsing time is then exponential in the input grammar size, since JGJ depends on both f and r. In the development of efficient algorithms for parsing based on LCFRS the crucial goal is therefore to optimize the term f &#183; (r + 1).</S>
    <S sid="15" ssid="12">In practical natural language processing applications the fan-out of the grammar is typically bounded by some small number.</S>
    <S sid="16" ssid="13">As an example, in the case of discontinuous parsing discussed above, we have f = 2 for most practical cases.</S>
    <S sid="17" ssid="14">On the contrary, LCFRS productions with a relatively large number of nonterminals are usually observed in real data.</S>
    <S sid="18" ssid="15">The reduction of the rank of a LCFRS, called binarization, is a process very similar to the reduction of a context-free grammar into Chomsky normal form.</S>
    <S sid="19" ssid="16">While in the special case of CFG and TAG this can always be achieved, binarization of an LCFRS requires, in the general case, an increase in the fan-out of the grammar much larger than the achieved reduction in the rank.</S>
    <S sid="20" ssid="17">Worst cases and some lower bounds have been discussed in (Rambow and Satta, 1999; Satta, 1998).</S>
    <S sid="21" ssid="18">Nonetheless, in many cases of interest binarization of an LCFRS can be carried out without any extra increase in the fan-out.</S>
    <S sid="22" ssid="19">As an example, in the case where f = 2, binarization of a LCFRS would result in parsing time of O(|G |&#183; |w|6).</S>
    <S sid="23" ssid="20">With the motivation of parsing efficiency, much research has been recently devoted to the design of efficient algorithms for rank reduction, in cases in which this can be carried out at no extra increase in the fan-out.</S>
    <S sid="24" ssid="21">(G&#180;omez-Rodriguez et al., 2009) reports a general binarization algorithm for LCFRS.</S>
    <S sid="25" ssid="22">In the case where f = 2, this algorithm works in time O(|p|7), where p is the input production.</S>
    <S sid="26" ssid="23">A more efficient algorithm is presented in (Kuhlmann and Satta, 2009), working in time O(|p|) in case of f = 2.</S>
    <S sid="27" ssid="24">However, this algorithm works for a restricted typology of productions, and does not cover all cases in which some binarization is possible.</S>
    <S sid="28" ssid="25">Other linear time algorithms for rank reduction are found in the literature (Zhang et al., 2008), but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2.</S>
    <S sid="29" ssid="26">In this paper we focus our attention on LCFRS with a fan-out of two.</S>
    <S sid="30" ssid="27">We improve upon all of the above mentioned results, by providing an algorithm that computes a binarization of an LCFRS production in all cases in which this is possible and works in time O(|p|).</S>
    <S sid="31" ssid="28">This is an optimal result in terms of time complexity, since O(|p|) is also the size of any output binarization of an LCFRS production.</S>
  </SECTION>
  <SECTION title="2 Linear context-free rewriting systems" number="2">
    <S sid="32" ssid="1">We briefly summarize here the terminology and notation that we adopt for LCFRS; for detailed definitions, see (Vijay-Shanker et al., 1987).</S>
    <S sid="33" ssid="2">We denote the set of non-negative integers by N. For i, j &#8712; N, the interval {k  |i &#8804; k &#8804; j} is denoted by [i, j].</S>
    <S sid="34" ssid="3">We write [i] as a shorthand for [1, i].</S>
    <S sid="35" ssid="4">For an alphabet V , we write V &#8727; for the set of all (finite) strings over V .</S>
    <S sid="36" ssid="5">As already mentioned in Section 1, linear context-free rewriting systems generate tuples of strings over some finite alphabet.</S>
    <S sid="37" ssid="6">This is done by associating each production p of a grammar with a function g that rearranges the string components in the tuples generated by the nonterminals in p&#8217;s right-hand side, possibly adding some alphabet symbols.</S>
    <S sid="38" ssid="7">Let V be some finite alphabet.</S>
    <S sid="39" ssid="8">For natural numbers r &#8805; 0 and f, f1,... , fr &#8805; 1, consider a function g : (V &#8727;)f, &#215; &#183; &#183; &#183; &#215; (V &#8727;)fr &#8594; (V &#8727;)f defined by an equation of the form g(hx1,1, ... , x1,f,i, ... , hxr,1, ..., xr,fri) = ~&#945;, where &#945;~ = h&#945;1, ... , &#945;fi is an f-tuple of strings over g&#8217;s argument variables and symbols in V .</S>
    <S sid="40" ssid="9">We say that g is linear, non-erasing if &#945;~ contains exactly one occurrence of each argument variable.</S>
    <S sid="41" ssid="10">We call r and f the rank and the fan-out of g, respectively, and write r(g) and f(g) to denote these quantities.</S>
    <S sid="42" ssid="11">A linear context-free rewriting system (LCFRS) is a tuple G = (VN, VT, P, S), where VN and VT are finite, disjoint alphabets of nonterminal and terminal symbols, respectively.</S>
    <S sid="43" ssid="12">Each A &#8712; VN is associated with a value f(A), called its fan-out.</S>
    <S sid="44" ssid="13">The nonterminal S is the start symbol, with f(S) = 1.</S>
    <S sid="45" ssid="14">Finally, P is a set of productions of the form where A, A1, ... , Ar(g) &#8712; VN, and g : (VT&#8727;)f(A,) &#215; &#183; &#183; &#183; &#215; (VT&#8727;)f(Ar&#65533;9&#65533;) &#8594; (VT&#8727;)f(A) is a linear, nonerasing function.</S>
    <S sid="46" ssid="15">A production p of G can be used to transform a sequence of r(g) string tuples generated by the nonterminals A1, ... , Ar(g) into a tuple of f(A) strings generated by A.</S>
    <S sid="47" ssid="16">The values r(g) and f(g) are called the rank and fan-out of p, respectively, written r(p) and f(p).</S>
    <S sid="48" ssid="17">The rank and fan-out of G, written r(G) and f(G), respectively, are the maximum rank and fan-out among all of G&#8217;s productions.</S>
    <S sid="49" ssid="18">Given that f(S) = 1, S generates a set of strings, defining the language of G. Example 1 Consider the LCFRS G defined by the productions We have f(S) = 1, f(A) = f(G) = 2, r(p3) = 0 and r(p1) = r(p2) = r(G) = 1.</S>
    <S sid="50" ssid="19">G generates the string language {anbncndn  |n &#8712; N}.</S>
    <S sid="51" ssid="20">For instance, the string a3b3c3d3 is generated by means of the following bottom-up process.</S>
    <S sid="52" ssid="21">First, the tuple h&#949;, &#949;i is generated by A through p3.</S>
    <S sid="53" ssid="22">We then iterate three times the application of p2 to h&#949;, &#949;i, resulting in the tuple ha3b3, c3d3i.</S>
    <S sid="54" ssid="23">Finally, the tuple (string) ha3b3c3d3i is generated by S through application of p1.</S>
    <S sid="55" ssid="24">&#10065;</S>
  </SECTION>
  <SECTION title="3 Position sets and binarizations" number="3">
    <S sid="56" ssid="1">Throughout this section we assume an LCFRS production p : A &#8594; g(A1,..., Ar) with g defined through a tuple &#945;~ as in section 2.</S>
    <S sid="57" ssid="2">We also assume that the fan-out of A and the fan-out of each Ai are all bounded by two.</S>
    <S sid="58" ssid="3">We introduce here a specialized representation for p. Let $ be a fresh symbol that does not occur in p. We define the characteristic string of p as the string where each &#945;'j is obtained from &#945;j by removing all the occurrences of symbols in VT.</S>
    <S sid="59" ssid="4">Consider now some occurrence Ai of a nonterminal symbol in the right-hand side of p. We define the position set of Ai, written XAz, as the set of all non-negative integers j &#8712; [|&#963;N(p)|] such that the j-th symbol in &#963;N(p) is a variable of the form xi,h for some h. Example 2 Let p : A &#8594; g(A1, A2, A3), where g(hx1,1, x1,2i, hx2,1i, hx3,1, x3,2i) = &#945;~ with In other words, we are decomposing X into the union of k intervals, with k as small as possible.</S>
    <S sid="60" ssid="5">It is easy to see that this decomposition is always unique.</S>
    <S sid="61" ssid="6">We call set E = {i1, i2, ... , i2k} the endpoint set associated with X, and we call k the fan-out of X, written f(X).</S>
    <S sid="62" ssid="7">Throughout this paper, we will represent p as the collection of all the position sets associated with the occurrences of nonterminals in its right-hand side.</S>
    <S sid="63" ssid="8">Let X1 and X2 be two disjoint position sets (i.e., X1 &#8745; X2 = &#8709;), with f(X1) = k1 and f(X2) = k2 and with associated endpoint sets E1 and E2, respectively.</S>
    <S sid="64" ssid="9">We define the merge of X1 and X2 as the set X1 &#8746; X2.</S>
    <S sid="65" ssid="10">We extend the position set and end-point set terminology to these merge sets as well.</S>
    <S sid="66" ssid="11">It is easy to check that the endpoint set associated to position set X1 &#8746; X2 is (E1 &#8746;E2)\(E1 &#8745;E2).</S>
    <S sid="67" ssid="12">We say that X1 and X2 are 2-combinable if f(X1 &#8746; X2) &#8804; 2.</S>
    <S sid="68" ssid="13">We also say that X1 and X2 are adjacent, written X1 &#8596; X2, if f(X1 &#8746; X2) &#8804; max(k1, k2).</S>
    <S sid="69" ssid="14">It is not difficult to see that X1 &#8596; X2 if and only if X1 and X2 are disjoint and |E1 &#8745; E2 |&#8805; min(k1, k2).</S>
    <S sid="70" ssid="15">Note also that X1 &#8596; X2 always implies that X1 and X2 are 2-combinable (but not the other way around).</S>
    <S sid="71" ssid="16">Let X be a collection of mutually disjoint position sets.</S>
    <S sid="72" ssid="17">A reduction of X is the process of merging two position sets X1, X2 &#8712; X, resulting in a new collection X' = (X \{X1, X2})&#8746;{X1&#8746;X2}.</S>
    <S sid="73" ssid="18">The reduction is 2-feasible if X1 and X2 are 2combinable.</S>
    <S sid="74" ssid="19">A binarization of X is a sequence of reductions resulting in a new collection with two or fewer position sets.</S>
    <S sid="75" ssid="20">The binarization is 2-feasible if all of the involved reductions are 2feasible.</S>
    <S sid="76" ssid="21">Finally, we say that X is 2-feasible if there exists at least one 2-feasible binarization for X.</S>
    <S sid="77" ssid="22">As an important remark, we observe that when a collection X represents the position sets of all the nonterminals in the right-hand side of a production p with r(p) &gt; 2, then a 2-feasible reduction merging XAz, XA3 &#8712; X can be interpreted as follows.</S>
    <S sid="78" ssid="23">We replace p by means of a new production p' obtained from p by substituting Ai and Aj with a fresh nonterminal symbol B, so that r(p') = r(p) &#8722; 1.</S>
    <S sid="79" ssid="24">Furthermore, we create a new production p'' with Ai and Aj in its right-hand side, such that f(p'') = f(B) &#8804; 2 and r(p'') = 2.</S>
    <S sid="80" ssid="25">Productions p' and p'' together are equivalent to p, but we have now achieved a local reduction in rank of one unit.</S>
    <S sid="81" ssid="26">Example 3 Let p be defined as in example 2 and let X = {XA1, XA2, XA3}.</S>
    <S sid="82" ssid="27">We have that XA1 and XA2 are 2-combinable, and their merge is the new position set X = XA1 &#8746; XA2 = {1, 2, 3}.</S>
    <S sid="83" ssid="28">This merge corresponds to a 2-feasible reduction of X resulting in X' = {X, XA3}.</S>
    <S sid="84" ssid="29">Such a reduction corresponds to the construction of a new production p' : A &#8594; g'(B, A3) with g'(hx1,1i, hx3,1, x3,2i) = hx1,1, x3,1bx3,2i ; and a new production p00 : B &#8594; g00(A1, A2) with sets, since the merging operation is commutative), and we define a function hD1&#8594;D2 : 2IN &#8594; 2IN as follows: It is easy to see that X is 2-feasible if and only if there exists a binarization of p that does not increase its fan-out.</S>
    <S sid="85" ssid="30">Example 4 It has been shown in (Rambow and Satta, 1999) that binarization of an LCFRS G with f(G) = 2 and r(G) = 3 is always possible without increasing the fan-out, and that if r(G) &#8805; 4 then this is no longer true.</S>
    <S sid="86" ssid="31">Consider the LCFRS production p : A &#8594; g(A1, A2, A3, A4), with g(hx1,1, x1,2i, hx2,1, x2,2i, hx3,1, x3,2i, hx4,1, x4,2i) = a,a= hx1,1x2,1x3,1x4,1, x2,2x4,2x1,2x3,2i.</S>
    <S sid="87" ssid="32">It is not difficult to see that replacing any set of two or three nonterminals in p&#8217;s right-hand side forces the creation of a fresh nonterminal of fan-out larger than two.</S>
    <S sid="88" ssid="33">&#10065; The binarization algorithm presented in this paper proceeds by representing each LCFRS production p as a collection of disjoint position sets, and then finding a 2-feasible binarization of p. This binarization is computed deterministically, by an iterative process that greedily chooses merges corresponding to pairs of adjacent position sets.</S>
    <S sid="89" ssid="34">The key idea behind the algorithm is based on a theorem that guarantees that any merge of adjacent sets preserves the property of 2-feasibility: Theorem 1 Let X be a 2-feasible collection ofposition sets.</S>
    <S sid="90" ssid="35">The reduction of X by merging any two adjacent position sets D1, D2 &#8712; X results in a new collection X0 which is 2-feasible.</S>
    <S sid="91" ssid="36">To prove Theorem 1 we consider that, since X is 2-feasible, there must exist at least one 2-feasible binarization for X.</S>
    <S sid="92" ssid="37">We can write this binarization Q as a sequence of reductions, where each reduction is characterized by a pair of position sets (X1, X2) which are merged into X1 &#8746; X2, in such a way that both each of the initial sets and the result of the merge have fan-out at most 2.</S>
    <S sid="93" ssid="38">We will show that, under these conditions, for every pair of adjacent position sets D1 and D2, there exists a binarization that starts with the reduction merging D1 with D2.</S>
    <S sid="94" ssid="39">Without loss of generality, we assume that f(D1) &#8804; f(D2) (if this inequality does not hold we can always swap the names of the two position der, and for each reduction o merging (X1, X2), if X1 =6 D1 and X2 =6 D1, we append a reduction o0 merging (hD1&#8594;D2(X1), hD1&#8594;D2(X2)) to Q0.</S>
    <S sid="95" ssid="40">We will now prove that, if Q is a 2-feasible binarization, then Q0 is also a 2-feasible binarization.</S>
    <S sid="96" ssid="41">To prove this, it suffices to show the following:2 To prove (i) we note that by construction of Q0, if an operand of a merging operation in Q0 is not one of the original position sets in X, then it must be an hD1&#8594;D2(X) for some X that appears as an operand of a merging operation in Q.</S>
    <S sid="97" ssid="42">Since the binarization Q is itself valid, this X must be either one of the position sets in X, or the result of a previous merge in the binarization Q.</S>
    <S sid="98" ssid="43">So we divide the proof into two cases: in two different reductions, but this easily follows from the fact that hD1&#8212;.D2(X) = hD1-.D2(Y ) if and only if X U D1 = Y U D1.</S>
    <S sid="99" ssid="44">Thus, two reductions in ,Q can only produce conflicting reductions in ,Q' if they merge two position sets differing only by D1, but in this case, one of the reductions must merge D1 so it does not produce any reduction in 3. a corresponding operation in Q0.</S>
    <S sid="100" ssid="45">If X equals D2, then hD1&#8594;D2(X) is D1 U D2, which is the result of the first merging operation in Q0.</S>
    <S sid="101" ssid="46">Finally, if X is one of the position sets in X, and not D1 or D2, then hD1&#8594;D2(X) = X, so our operand is also one of the position sets in X.</S>
    <S sid="102" ssid="47">To prove (ii), we show that, under the assumptions of the theorem, the function hD1&#8594;D2 preserves 2-combinability.</S>
    <S sid="103" ssid="48">Since two position sets of fan-out &lt; 2 are 2-combinable if and only if they are disjoint and the fan-out of their union is at most 2, it suffices to show that, for every X, X1, X2 unions of one or more sets of X, having fan-out &lt; 2, such that X1 =&#65533; D1, X2 =&#65533; D1 and X =&#65533; D1; If X1 and X2 do not contain D1 or D2, or if one of the two unions X1 or X2 contains D1 UD2, properties (a) and (b) are trivial, since the function hD1&#8594;D2 behaves as the identity function in these cases.</S>
    <S sid="104" ssid="49">It remains to show that (a) and (b) are true in the following cases: &#8226; X1 contains D1 but not D2, and X2 does not contain D1 or D2: 3Except if one of the operands of the operation o was D1.</S>
    <S sid="105" ssid="50">But in this case, if we call the other operand Z, then we have that X = D1 U Z.</S>
    <S sid="106" ssid="51">If Z contains D2, then X = D1 U Z = hD1-.D2(X) = hD1-.D2(Z), so we apply this same reasoning with hD1-.D2(Z) where we cannot fall into this case, since there can be only one merge operation in Q that uses D1 as an operand.</S>
    <S sid="107" ssid="52">If Z does not contain D2, then we have that hD1-.D2(X) = X \ D1 = Z = hD1-.D2(Z), so we can do the same.</S>
    <S sid="108" ssid="53">In this case, if X1 and X2 are disjoint, we can write X1 = Y1UD1, such that Y1, X2, D1 are pairwise disjoint.</S>
    <S sid="109" ssid="54">By definition, we have that hD1&#8594;D2(X1) = Y1, and hD1&#8594;D2(X2) = X2, which are disjoint, so (a) holds.</S>
    <S sid="110" ssid="55">Property (b) also holds because, with these expressions for X1 and X2, we can calculate hD1&#8594;D2(X1 U X2) = Y1 U X2 = hD1&#8594;D2(X1) U hD1&#8594;D2(X2).</S>
    <S sid="111" ssid="56">&#8226; X1 contains D2 but not D1, X2 does not contain D1 or D2: In this case, if X1 and X2 are disjoint, we can write X1 = Y1 U D2, such that Y1, X2, D1, D2 are pairwise disjoint.</S>
    <S sid="112" ssid="57">By definition, hD1&#8594;D2(X1) = Y1 U D2 U D1, and hD1&#8594;D2(X2) = X2, which are disjoint, so (a) holds.</S>
    <S sid="113" ssid="58">In this case, if X1 and X2 are disjoint, we can write X1 = Y1 UD1 and X2 = Y2 UD2, such that Y1, Y2, D1, D2 are pairwise disjoint.</S>
    <S sid="114" ssid="59">By definition, we know that hD1&#8594;D2(X1) = Y1, and hD1&#8594;D2(X2) = Y2 U D1 U D2, which are disjoint, so (a) holds.</S>
    <S sid="115" ssid="60">Finally, property (b) also holds in this case, since hD1&#8594;D2(X1 U X2) = Y1 U X2 U D2 U D1 = hD1&#8594;D2(X1) U hD1&#8594;D2(X2).</S>
    <S sid="116" ssid="61">This concludes the proof of (a) and (b).</S>
    <S sid="117" ssid="62">To prove (c), we consider a position set X, union of one or more sets of X, with fan-out &lt; 2 and such that X =&#65533; D1.</S>
    <S sid="118" ssid="63">First of all, we observe that if X does not contain D1 or D2, or if it contains D1 U D2, (c) is trivial, because the function hD1&#8594;D2 behaves as the identity function in this case.</S>
    <S sid="119" ssid="64">So it remains to prove (c) in the cases where X contains D1 but not D2, and where X contains D2 but not D1.</S>
    <S sid="120" ssid="65">In any of these two cases, if we call E(Y ) the endpoint set associated with an arbitrary position set Y , we can make the following observations: of D1 and D2, we know that the endpoints where D1 is adjacent to D2 must also be endpoints of X, so that E(D1) &#8745; E(D2) &#8838; E(X).</S>
    <S sid="121" ssid="66">Therefore, E(X)\(E(D1)&#8745;E(D2)) can contain at most 4 &#8722; f(D1) endpoints.</S>
    <S sid="122" ssid="67">Now, in the case where X contains D1 but not D2, we know that hD1,D2(X) = X \D1.</S>
    <S sid="123" ssid="68">We calculate abound for the fan-out of X\D1 as follows: we observe that all the endpoints in E(X \ D1) must be either endpoints of X or endpoints of D1, since E(X) = (E(X \ D1) &#8746; E(D1)) \ (E(X \ D1) &#8745; E(D1)), so every position that is in E(X \ D1) but not in E(D1) must be in E(X).</S>
    <S sid="124" ssid="69">But we also observe that E(X \ D1) cannot contain any of the endpoints where D1 is adjacent to D2 (i.e., the members of E(D1) &#8745; E(D2)), since X \ D1 does not contain D1 or D2.</S>
    <S sid="125" ssid="70">Thus, we can say that any endpoint of X \ D1 is either a member of E(D1) \ (E(D1) &#8745; E(D2)), or a member of E(X) \ (E(D1) &#8745; E(D2)).</S>
    <S sid="126" ssid="71">Thus, the number of endpoints in E(X \ D1) cannot exceed the sum of the number of endpoints in these two sets, which, according to the reasonings above, is at most 4 &#8722; f(D1) + f(D1) = 4.</S>
    <S sid="127" ssid="72">Since E(X \ D1) cannot contain more than 4 endpoints, we conclude that the fan-out of X \ D1 is at most 2, so the function hD1,D2 preserves the property of position sets having fan-out &#8804; 2 in this case.</S>
    <S sid="128" ssid="73">In the other case, where X contains D2 but not D1, we follow a similar reasoning: in this case, hD1,D2(X) = X &#8746; D1.</S>
    <S sid="129" ssid="74">To bound the fan-out of X &#8746; D1, we observe that all the endpoints in E(X &#8746; D1) must be either in E(X) or in E(D1), since E(X &#8746; D1) = (E(X) &#8746; E(D1)) \ (E(X) &#8745; E(D1)).</S>
    <S sid="130" ssid="75">But we also know that E(X &#8746; D1) cannot contain any of the endpoints where D1 is adjacent to D2 (i.e., the members of E(D1) &#8745; E(D2)), since X &#8746; D1 contains both D1 and D2.</S>
    <S sid="131" ssid="76">Thus, we can say that any endpoint of X &#8746; D1 is either a member of E(D1)\(E(D1)&#8745;E(D2)), or a member of E(X) \ (E(D1) &#8745; E(D2)).</S>
    <S sid="132" ssid="77">Reasoning as in the previous case, we conclude that the fan-out of X &#8746; D1 is at most 2, so the function hD1,D2 also preserves the property of position sets having fan-out &#8804; 2 in this case.</S>
    <S sid="133" ssid="78">This concludes the proof of Theorem 1.</S>
  </SECTION>
  <SECTION title="4 Binarization algorithm" number="4">
    <S sid="134" ssid="1">Let p : A &#8594; g(A1, ... , A,(p)) be a production with r(p) &gt; 2 from some LCFRS with fan-out not greater than 2.</S>
    <S sid="135" ssid="2">Recall from Subsection 3.1 that each occurrence of nonterminal AZ in the righthand side of p is represented as a position set XAz.</S>
    <S sid="136" ssid="3">The specification of an algorithm for finding a 2feasible binarization of p is reported in Figure 1.</S>
    <S sid="137" ssid="4">The algorithm uses an agenda A as a working set, where all position sets that still need to be processed are stored.</S>
    <S sid="138" ssid="5">A is initialized with the position sets XAz, 1 &#8804; i &#8804; r(p).</S>
    <S sid="139" ssid="6">At each step in the algorithm, the size of A represents the maximum rank among all productions that can be obtained from the reductions that have been chosen so far in the binarization process.</S>
    <S sid="140" ssid="7">The algorithm also uses a list R, initialized as the empty list, where all reductions that are attempted in the binarization process are appended.</S>
    <S sid="141" ssid="8">At each iteration, the algorithm performs a reduction by arbitrarily choosing a pair of adjacent endpoint sets from the agenda and by merging them.</S>
    <S sid="142" ssid="9">As already discussed in Subsection 3.1, this corresponds to some specific transformation of the input production p that preserves its generative capacity and that decreases its rank by one unit.</S>
    <S sid="143" ssid="10">We stop the iterations of the algorithm when we reach a state in which there are no more than two position sets in the agenda.</S>
    <S sid="144" ssid="11">This means that the binarization process has come to an end with the reduction of p to a set of productions equivalent to p and with rank and fan-out at most 2.</S>
    <S sid="145" ssid="12">This set of productions can be easily constructed from the output list R. We also stop the iterations in case no adjacent pair of position sets can be found in the agenda.</S>
    <S sid="146" ssid="13">If the agenda has more than two position sets, this means that no binarization has been found and the algorithm returns a failure.</S>
    <S sid="147" ssid="14">To prove the correctness of the algorithm in Figure 1, we need to show that it produces a 2-feasible binarization of the given production p whenever such a binarization exists.</S>
    <S sid="148" ssid="15">This is established by the following theorem: always finds a 2-feasible binarization of X.</S>
    <S sid="149" ssid="16">In order to prove this, the loop invariant is that X is a 2-feasible set, and that the union of all position sets in X has fan-out &lt; 2: reductions can never change the union of all sets in X, and Theorem 1 guarantees us that every change to the state of X maintains 2-feasibility.</S>
    <S sid="150" ssid="17">We also know that the algorithm eventually finishes, because every iteration reduces the amount of position sets in X by 1; and the looping condition will not hold when the number of sets gets to be 1.</S>
    <S sid="151" ssid="18">So it only remains to prove that the loop is only exited if X contains at most two position sets.</S>
    <S sid="152" ssid="19">If we show this, we know that the sequence of reductions produced by this procedure is a 2-feasible binarization.</S>
    <S sid="153" ssid="20">Since the loop is exited when X is 2feasible but it contains no pair of adjacent position sets, it suffices to show the following: Proposition 1 Let X be a 2-feasible collection of position sets, such that the union of all the sets in X is a position set with fan-out &lt; 2.</S>
    <S sid="154" ssid="21">If X has more than two elements, then it contains at least a pair of adjacent position sets.</S>
    <S sid="155" ssid="22">&#10065; Let X be a 2-feasible collection of more than two position sets.</S>
    <S sid="156" ssid="23">Since X is 2-feasible, we know that there must be a 2-feasible binarization of X.</S>
    <S sid="157" ssid="24">Suppose that Q is such a binarization, and let D1 and D2 be the two position sets that are merged in the first reduction of 0.</S>
    <S sid="158" ssid="25">Since Q is 2-feasible, D1 and D2 must be 2-combinable.</S>
    <S sid="159" ssid="26">If D1 and D2 are adjacent, our proposition is true.</S>
    <S sid="160" ssid="27">If they are not adjacent, then, in order to be 2combinable, the fan-out of both position sets must be 1: if any of them had fan-out 2, their union would need to have fan-out &gt; 2 for D1 and D2 not to be adjacent, and thus they would not be 2combinable.</S>
    <S sid="161" ssid="28">Since D1 and D2 have fan-out 1 and are not adjacent, their sets of endpoints are of the form {b1, b2} and {c1, c2}, and they are disjoint.</S>
    <S sid="162" ssid="29">If we call EX the set of endpoints corresponding to the union of all the position sets in X and ED1D2 = {b1, b2, c1, c2}, we can show that at least one of the endpoints in ED1D2 does not appear in EX, since we know that EX can have at most 4 elements (as the union has fan-out &lt; 2) and that it cannot equal ED1D2 because this would mean that X = {D1, D2}, and by hypothesis X has more than two position sets.</S>
    <S sid="163" ssid="30">If we call this endpoint x, this means that there must be a position set D3 in X, different from D1 and D2, that has x as one of its endpoints.</S>
    <S sid="164" ssid="31">Since D1 and D2 have fan-out 1, this implies that D3 must be adjacent either to D1 or to D2, so we conclude the proof.</S>
    <S sid="165" ssid="32">We now turn to the computational analysis of the algorithm in Figure 1.</S>
    <S sid="166" ssid="33">We define the length of an LCFRS production p, written 1pl, as the sum of the length of all strings &#945;j in &#945;&#65533; in the definition of the linear, non-erasing function associated with p. Since we are dealing with LCFRS of fan-out at most two, we easily derive that 1p&#65533; = O(r(p)).</S>
    <S sid="167" ssid="34">In the implementation of the algorithm it is convenient to represent each position set by means of the corresponding endpoint set.</S>
    <S sid="168" ssid="35">Since at any time in the computation we are only processing position sets with fan-out not greater than two, each endpoint set will contain at most four integers.</S>
    <S sid="169" ssid="36">The for-loop at lines 4 and 5 in the algorithm can be easily implemented through a left-to-right scan of the characteristic string QN(p), detecting the endpoint sets associated with each position set XAi.</S>
    <S sid="170" ssid="37">This can be done in constant time for each XAz, and thus in linear time in |p|.</S>
    <S sid="171" ssid="38">At each iteration of the while-loop at lines 6 to 10 we have that A is reduced in size by one unit.</S>
    <S sid="172" ssid="39">This means that the number of iterations is bounded by r(p).</S>
    <S sid="173" ssid="40">We will show below that each iteration of this loop can be executed in constant time.</S>
    <S sid="174" ssid="41">We can therefore conclude that our binarization algorithm runs in optimal time O(|p|).</S>
    <S sid="175" ssid="42">In order to run in constant time each single iteration of the while-loop at lines 6 to 10, we need to perform some additional bookkeeping.</S>
    <S sid="176" ssid="43">We use two arrays Ve and Va, whose elements are indexed by the endpoints associated with characteristic string UN(p), that is, integers i E [0, |UN(p)|].</S>
    <S sid="177" ssid="44">For each endpoint i, Ve[i] stores all the endpoint sets that share endpoint i.</S>
    <S sid="178" ssid="45">Since each endpoint can be shared by at most two endpoint sets, such a data structure has size O(|p|).</S>
    <S sid="179" ssid="46">If there exists some position set X in A with leftmost endpoint i, then Va[i] stores all the position sets (represented as endpoint sets) that are adjacent to X.</S>
    <S sid="180" ssid="47">Since each position set can be adjacent to at most four other position sets, such a data structure has size O(|p|).</S>
    <S sid="181" ssid="48">Finally, we assume we can go back and forth between position sets in the agenda and their leftmost endpoints.</S>
    <S sid="182" ssid="49">We maintain arrays Ve and Va through the following simple procedures.</S>
    <S sid="183" ssid="50">&#8226; Whenever a new position set X is added to A, for each endpoint i of X we add X to Ve[i].</S>
    <S sid="184" ssid="51">We also check whether any position set in Ve[i] other than X is adjacent to X, and add these position sets to Va[il], where il is the leftmost end point of X.</S>
    <S sid="185" ssid="52">It is easy to see that, for any position set X which is added/removed from A, each of the above procedures can be executed in constant time.</S>
    <S sid="186" ssid="53">We maintain a set Z of integer numbers i E [0, |UN(p)|] such that i E Z if and only if Va[i] is not empty.</S>
    <S sid="187" ssid="54">Then at each iteration of the while-loop at lines 6 to 10 we pick up some index in Z and retrieve at Va[i] some pair X, X' such that X H X'.</S>
    <S sid="188" ssid="55">Since X, X' are represented by means of endpoint sets, we can compute the endpoint set of X UX' in constant time.</S>
    <S sid="189" ssid="56">Removal of X, X' and addition of X UX' in our data structures Ve and Va is then performed in constant time, as described above.</S>
    <S sid="190" ssid="57">This proves our claim that each single iteration of the while loop can be executed in constant time.</S>
  </SECTION>
  <SECTION title="5 Discussion" number="5">
    <S sid="191" ssid="1">We have presented an algorithm for the binarization of a LCFRS with fan-out 2 that does not increase the fan-out, and have discussed how this can be applied to improve parsing efficiency in several practical applications.</S>
    <S sid="192" ssid="2">In the algorithm of Figure 1, we can modify line 14 to return R even in case of failure.</S>
    <S sid="193" ssid="3">If we do this, when a binarization with fan-out &lt; 2 does not exist the algorithm will still provide us with a list of reductions that can be converted into a set of productions equivalent to p with fan-out at most 2 and rank bounded by some rb, with 2 &lt; rb &lt; r(p).</S>
    <S sid="194" ssid="4">In case rb &lt; r(p), we are not guaranteed to have achieved an optimal reduction in the rank, but we can still obtain an asymptotic improvement in parsing time if we use the new productions obtained in the transformation.</S>
    <S sid="195" ssid="5">Our algorithm has optimal time complexity, since it works in linear time with respect to the input production length.</S>
    <S sid="196" ssid="6">It still needs to be investigated whether the proposed technique, based on determinization of the choice of the reduction, can also be used for finding binarizations for LCFRS with fan-out larger than two, again without increasing the fan-out.</S>
    <S sid="197" ssid="7">However, it seems unlikely that this can still be done in linear time, since the problem of binarization for LCFRS in general, i.e., without any bound on the fan-out, might not be solvable in polynomial time.</S>
    <S sid="198" ssid="8">This is still an open problem; see (G&#180;omez-Rodr&#180;&#305;guez et al., 2009) for discussion.</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="6">
    <S sid="199" ssid="1">The first author has been supported by Ministerio de Educaci&#180;on y Ciencia and FEDER (HUM200766607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR and Rede Galega de Procesamento da Linguaxe e Recuperaci&#180;on de Informaci&#180;on).</S>
    <S sid="200" ssid="2">The second author has been partially supported by MIUR under project PRIN No.</S>
    <S sid="201" ssid="3">2007TJNZRE 002.</S>
  </SECTION>
</PAPER>
