<PAPER>
  <S sid="0">Relation Extraction with Relation Topics</S>
  <ABSTRACT>
    <S sid="1" ssid="1">This paper describes a novel approach to the semantic relation detection problem.</S>
    <S sid="2" ssid="2">Instead of relying only on the training instances for a new relation, we leverage the knowledge learned from previously trained relation detectors.</S>
    <S sid="3" ssid="3">Specifically, we detect a new semantic relation by projecting the new relation&#8217;s training instances onto a lower dimension topic space constructed from existing relation detectors through a three step process.</S>
    <S sid="4" ssid="4">First, we construct a large relation repository of more than 7,000 relations from Wikipedia.</S>
    <S sid="5" ssid="5">Second, we construct a set of non-redundant relation topics defined at multiple scales from the relation repository to characterize the existing relations.</S>
    <S sid="6" ssid="6">Similar to the topics defined over words, each relation topic is an interpretable multinomial distribution over the existing relations.</S>
    <S sid="7" ssid="7">Third, we integrate the relation topics in a kernel function, and use it together with SVM to construct detectors for new relations.</S>
    <S sid="8" ssid="8">The experimental results on Wikipedia and ACE data have confirmed that backgroundknowledge-based topics generated from the Wikipedia relation repository can significantly improve the performance over the state-of-theart relation detection approaches.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="9" ssid="1">Detecting semantic relations in text is very useful in both information retrieval and question answering because it enables knowledge bases to be leveraged to score passages and retrieve candidate answers.</S>
    <S sid="10" ssid="2">To extract semantic relations from text, three types of approaches have been applied.</S>
    <S sid="11" ssid="3">Rule-based methods (Miller et al., 2000) employ a number of linguistic rules to capture relation patterns.</S>
    <S sid="12" ssid="4">Featurebased methods (Kambhatla, 2004; Zhao and Grishman, 2005) transform relation instances into a large amount of linguistic features like lexical, syntactic and semantic features, and capture the similarity between these feature vectors.</S>
    <S sid="13" ssid="5">Recent results mainly rely on kernel-based approaches.</S>
    <S sid="14" ssid="6">Many of them focus on using tree kernels to learn parse tree structure related features (Collins and Duffy, 2001; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005).</S>
    <S sid="15" ssid="7">Other researchers study how different approaches can be combined to improve the extraction performance.</S>
    <S sid="16" ssid="8">For example, by combining tree kernels and convolution string kernels, (Zhang et al., 2006) achieved the state of the art performance on ACE (ACE, 2004), which is a benchmark dataset for relation extraction.</S>
    <S sid="17" ssid="9">Although a large set of relations have been identified, adapting the knowledge extracted from these relations for new semantic relations is still a challenging task.</S>
    <S sid="18" ssid="10">Most of the work on domain adaptation of relation detection has focused on how to create detectors from ground up with as little training data as possible through techniques such as bootstrapping (Etzioni et al., 2005).</S>
    <S sid="19" ssid="11">We take a different approach, focusing on how the knowledge extracted from the existing relations can be reused to help build detectors for new relations.</S>
    <S sid="20" ssid="12">We believe by reusing knowledge one can build a more cost effective relation detector, but there are several challenges associated with reusing knowledge.</S>
    <S sid="21" ssid="13">The first challenge to address in this approach is how to construct a relation repository that has sufficient coverage.</S>
    <S sid="22" ssid="14">In this paper, we introduce a method that automatically extracts the knowledge characterizing more than 7,000 relations from Wikipedia.</S>
    <S sid="23" ssid="15">Wikipedia is comprehensive, containing a diverse body of content with significant depth and grows rapidly.</S>
    <S sid="24" ssid="16">Wikipedia&#8217;s infoboxes are particularly interesting for relation extraction.</S>
    <S sid="25" ssid="17">They are short, manually-created, and often have a relational summary of an article: a set of attribute/value pairs describing the article&#8217;s subject.</S>
    <S sid="26" ssid="18">Another challenge is how to deal with overlap of relations in the repository.</S>
    <S sid="27" ssid="19">For example, Wikipedia authors may make up a name when a new relation is needed without checking if a similar relation has already been created.</S>
    <S sid="28" ssid="20">This leads to relation duplication.</S>
    <S sid="29" ssid="21">We refine the relation repository based on an unsupervised multiscale analysis of the correlations between existing relations.</S>
    <S sid="30" ssid="22">This method is parameter free, and able to produce a set of non-redundant relation topics defined at multiple scales.</S>
    <S sid="31" ssid="23">Similar to the topics defined over words (Blei et al., 2003), we define relation topics as multinomial distributions over the existing relations.</S>
    <S sid="32" ssid="24">The relation topics extracted in our approach are interpretable, orthonormal to each other, and can be used as basis relations to re-represent the new relation instances.</S>
    <S sid="33" ssid="25">The third challenge is how to use the relation topics for a relation detector.</S>
    <S sid="34" ssid="26">We map relation instances in the new domains to the relation topic space, resulting in a set of new features characterizing the relationship between the relation instances and existing relations.</S>
    <S sid="35" ssid="27">By doing so, background knowledge from the existing relations can be introduced into the new relations, which overcomes the limitations of the existing approaches when the training data is not sufficient.</S>
    <S sid="36" ssid="28">Our work fits in to a class of relation extraction research based on &#8220;distant supervision&#8221;, which studies how knowledge and resources external to the target domain can be used to improve relation extraction.</S>
    <S sid="37" ssid="29">(Mintz et al., 2009; Jiang, 2009; Chan and Roth, 2010).</S>
    <S sid="38" ssid="30">One distinction between our approach and other existing approaches is that we represent the knowledge from distant supervision using automatically constructed topics.</S>
    <S sid="39" ssid="31">When we test on new instances, we do not need to search against the knowledge base.</S>
    <S sid="40" ssid="32">In addition, our topics also model the indirect relationship between relations.</S>
    <S sid="41" ssid="33">Such information cannot be directly found from the knowledge base.</S>
    <S sid="42" ssid="34">The contributions of this paper are three-fold.</S>
    <S sid="43" ssid="35">Firstly, we extract a large amount of training data for more than 7,000 semantic relations from Wikipedia (Wikipedia, 2011) and DBpedia (Auer et al., 2007).</S>
    <S sid="44" ssid="36">A key part of this step is how we handle noisy data with little human effort.</S>
    <S sid="45" ssid="37">Secondly, we present an unsupervised way to construct a set of relation topics at multiple scales.</S>
    <S sid="46" ssid="38">This step is parameter free, and results in a nonredundant, multiscale relation topic space.</S>
    <S sid="47" ssid="39">Thirdly, we design a new kernel for relation detection by integrating the relation topics into the relation detector construction.</S>
    <S sid="48" ssid="40">The experimental results on Wikipedia and ACE data (ACE, 2004) have confirmed that background-knowledge-based features generated from the Wikipedia relation repository can significantly improve the performance over the state-of-the-art relation detection approaches.</S>
  </SECTION>
  <SECTION title="2 Extracting Relations from Wikipedia" number="2">
    <S sid="49" ssid="1">Our training data is from two parts: relation instances from DBpedia (extracted from Wikipedia infoboxes), and sentences describing the relations from the corresponding Wikipedia pages.</S>
    <S sid="50" ssid="2">Since our relations correspond to Wikipedia infobox properties, we use an approach similar to that described in (Hoffmann et al., 2010) to collect positive training data instances.</S>
    <S sid="51" ssid="3">We assume that a Wikipedia page containing a particular infobox property is likely to express the same relation in the text of the page.</S>
    <S sid="52" ssid="4">We further assume that the relation is most likely expressed in the first sentence on the page which mentions the arguments of the relation.</S>
    <S sid="53" ssid="5">For example, the Wikipedia page for &#8220;Albert Einstein&#8221; contains an infobox property &#8220;alma mater&#8221; with value &#8220;University of Zurich&#8221;, and the first sentence mentioning the arguments is the following: &#8220;Einstein was awarded a PhD by the University of Zurich&#8221;, which expresses the relation.</S>
    <S sid="54" ssid="6">When looking for relation arguments on the page, we go beyond (sub)string matching, and use link information to match entities which may have different surface forms.</S>
    <S sid="55" ssid="7">Using this technique, we are able to collect a large amount of positive training instances of DBpedia relations.</S>
    <S sid="56" ssid="8">To get precise type information for the arguments of a DBpedia relation, we use the DBpedia knowledge base (Auer et al., 2007) and the associated YAGO type system (Suchanek et al., 2007).</S>
    <S sid="57" ssid="9">Note that for every Wikipedia page, there is a corresponding DBpedia entry which has captured the infobox-properties as RDF triples.</S>
    <S sid="58" ssid="10">Some of the triples include type information, where the subject of the triple is a Wikipedia entity, and the object is a YAGO type for the entity.</S>
    <S sid="59" ssid="11">For example, the DBpedia entry for the entity &#8220;Albert Einstein&#8221; includes YAGO types such as Scientist, Philosopher, Violinist etc.</S>
    <S sid="60" ssid="12">These YAGO types are also linked to appropriate WordNet concepts, providing for accurate sense disambiguation.</S>
    <S sid="61" ssid="13">Thus, for any entity argument of a relation we are learning, we obtain sense-disambiguated type information (including super-types, sub-types, siblings etc.</S>
    <S sid="62" ssid="14">), which become useful generalization features in the relation detection model.</S>
    <S sid="63" ssid="15">Given a common noun, we can also retrieve its type information by checking against WordNet (Fellbaum, 1998).</S>
    <S sid="64" ssid="16">We use a set of rules together with their popularities (occurrence count) to characterize a relation.</S>
    <S sid="65" ssid="17">A rule representing the relations between two arguments has five components (ordered): arguments type, argument2 type, noun, preposition and verb.</S>
    <S sid="66" ssid="18">A rule example of ActiveYearsEndDate relation (about the year that a person retired) is: person100007846|year115203791|-|in|retire.</S>
    <S sid="67" ssid="19">In this example, arguments type is person100007846, argument2 type is year115203791, both of which are from YAGO type system.</S>
    <S sid="68" ssid="20">The key words connecting these two arguments are in (preposition) and retire (verb).</S>
    <S sid="69" ssid="21">This rule does not have a noun, so we use a &#8216;-&#8217; to take the position of noun.</S>
    <S sid="70" ssid="22">The same relation can be represented in many different ways.</S>
    <S sid="71" ssid="23">Another rule example characterizing the same relation is person100007846|year115203791|retirement|-|announce.</S>
    <S sid="72" ssid="24">This paper only considers three types of words: noun, verb and preposition.</S>
    <S sid="73" ssid="25">It is straightforward to expand or simplify the rules by including more or removing some word types.</S>
    <S sid="74" ssid="26">The keywords are extracted from the shortest path on the dependency tree between the two arguments.</S>
    <S sid="75" ssid="27">A dependency tree (Figure 1) represents grammatical relations between words in a sentence.</S>
    <S sid="76" ssid="28">We used a slot grammar parser (McCord, 1995) to generate the parse tree of each sentence.</S>
    <S sid="77" ssid="29">Note that there could be multiple paths between two arguments in the tree.</S>
    <S sid="78" ssid="30">We only take the shortest path into consideration.</S>
    <S sid="79" ssid="31">The popularity value corresponding to each rule represents how many times this rule applies to the given relation in the given data.</S>
    <S sid="80" ssid="32">Multiple rules can be constructed from one relation instance, if multiple argument types are associated with the instance, or multiple nouns, prepositions or verbs are in the dependency path.</S>
    <S sid="81" ssid="33">To find a sentence on the Wikipedia page that is likely to express a relation in its infobox, we consider the first sentence on the page that mentions both arguments of the relation.</S>
    <S sid="82" ssid="34">This heuristic approach returns reasonably good results, but brings in about 20% noise in the form of false positives, which is a concern when building an accurate statistical relation detector.</S>
    <S sid="83" ssid="35">To address this issue, we have developed a two-step technique to automatically remove some of the noisy data.</S>
    <S sid="84" ssid="36">In the first step, we extract popular argument types and keywords for each DBpedia relation from the given data, and then use the combinations of those types and words to create initial rules.</S>
    <S sid="85" ssid="37">Many of the argument types and keywords introduced by the noisy data are often not very popular, so they can be filtered out in the first step.</S>
    <S sid="86" ssid="38">Not all initial rules make sense.</S>
    <S sid="87" ssid="39">In the second step, we check each rule against the training data to see if that rule really exists in the training data or not.</S>
    <S sid="88" ssid="40">If it does not exist, we filter it out.</S>
    <S sid="89" ssid="41">If a sentence does not have a single rule passing the above procedure, that sentence will be removed.</S>
    <S sid="90" ssid="42">Using the above techniques, we collect examples characterizing 7,628 DBpedia relations.</S>
  </SECTION>
  <SECTION title="3 Learning Multiscale Relation Topics" number="3">
    <S sid="91" ssid="1">An extra step extracting knowledge from the raw data is needed for two reasons: Firstly, many DBpedia relations are inter-related.</S>
    <S sid="92" ssid="2">For example, some DBpedia relations have a subclass relationship, e.g.</S>
    <S sid="93" ssid="3">&#8220;AcademyAward&#8221; and &#8220;Award&#8221;; others overlap in their scope and use, e.g., &#8220;Composer&#8221; and &#8220;Artist&#8221;; while some are equivalent, e.g., &#8220;DateOfBirth&#8221; and &#8220;BirthDate&#8221;.</S>
    <S sid="94" ssid="4">Secondly, a fairly large amount of the noisy labels are still in the training data.</S>
    <S sid="95" ssid="5">To reveal the intrinsic structure of the current DBpedia relation space and filter out noise, we carried out a correlation analysis of relations in the training data, resulting in a relation topic space.</S>
    <S sid="96" ssid="6">Each relation topic is a multinomial distribution over the existing relations.</S>
    <S sid="97" ssid="7">We adapted diffusion wavelets (Coifman and Maggioni, 2006) for this task.</S>
    <S sid="98" ssid="8">Compared to the other well-known topic extraction methods like LDA (Blei et al., 2003) and LSI (Deerwester et al., 1990), diffusion wavelets can efficiently extract a hierarchy of interpretable topics without any user input parameter (Wang and Mahadevan, 2009).</S>
    <S sid="99" ssid="9">The diffusion wavelets algorithm constructs a compressed representation of the dyadic powers of a square matrix by representing the associated matrices at each scale not in terms of the original (unit vector) basis, but rather using a set of custom generated bases (Coifman and Maggioni, 2006).</S>
    <S sid="100" ssid="10">Figure 2 summarizes the procedure to generate diffusion wavelets.</S>
    <S sid="101" ssid="11">Given a matrix T, the QR (a modified QR decomposition) subroutine decomposes T into an orthogonal matrix Q and a triangular matrix R such that T Pz&#65533; QR, where |Ti,k &#8722; (QR)i,k |&lt; e for any i and k. Columns in Q are orthonormal basis functions spanning the column space of T at the finest scale.</S>
    <S sid="102" ssid="12">RQ is the new representation of T with sentations of the input matrix at different scales.</S>
    <S sid="103" ssid="13">QR is a modified QR decomposition.</S>
    <S sid="104" ssid="14">J is the max step number (this is optional, since the algorithm automatically terminates when it reaches a matrix of size 1 x 1).</S>
    <S sid="105" ssid="15">The notation [T]&#966;b &#966;a denotes matrix T whose column space is represented using basis &#57739;b at scale b, and row space is represented using basis &#57739;a at scale a.</S>
    <S sid="106" ssid="16">The notation [&#57739;b]&#966;a denotes basis &#57739;b represented on the basis &#57739;a.</S>
    <S sid="107" ssid="17">At an arbitrary scale j, we have pj basis functions, and length of each function is lj.</S>
    <S sid="108" ssid="18">The number of pj is determined by the intrinsic structure of the given dataset in QR routine.</S>
    <S sid="109" ssid="19">[T]&#966;b is a pb x la matrix, and [&#57739;b]&#966;a is an la x pb matrix. &#966;a respect to the space spanned by the columns of Q (this result is based on the matrix invariant subspace theory).</S>
    <S sid="110" ssid="20">At an arbitrary level j, DWT learns the basis functions from T2' using QR.</S>
    <S sid="111" ssid="21">Compared to the number of basis functions spanning T2'&#8217;s original column space, we usually get fewer basis functions, since some high frequency information (corresponding to the &#8220;noise&#8221; at that level) can be filtered out.</S>
    <S sid="112" ssid="22">DWT then computes T2'+1 using the low frequency representation of T23 and the procedure repeats.</S>
    <S sid="113" ssid="23">Assume we have M relations, and the ith of them is characterized by mi &lt;rule, popularity&gt; pairs.</S>
    <S sid="114" ssid="24">We use s(a, b) to represent the similarity between the ath and bth relations.</S>
    <S sid="115" ssid="25">To compute s(a, b), we first normalize the popularities for each relation, and then look for the rules that are shared by both relation a and b.</S>
    <S sid="116" ssid="26">We use the product of corresponding popularity values to represent the similarity score between two relations with respect to each common rule. s(a, b) is set to the sum of such scores over all common rules.</S>
    <S sid="117" ssid="27">The relation-relation correlation matrix S is constructed as follows: We have more than 200, 000 argument types, tens of thousands of distinct nouns, prepositions, and verbs, so we potentially have trillions of distinct rules.</S>
    <S sid="118" ssid="28">One rule may appear in multiple relations.</S>
    <S sid="119" ssid="29">The more rules two relations share, the more related two relations should be.</S>
    <S sid="120" ssid="30">The rules shared across different relations offer us a novel way to model the correlations between different relations, and further allow us to create relation topics.</S>
    <S sid="121" ssid="31">The rules can also be simplified.</S>
    <S sid="122" ssid="32">For example, we may treat argument1, argument2, noun, preposition and verb separately.</S>
    <S sid="123" ssid="33">This results in simple rules that only involve in one argument type or word.</S>
    <S sid="124" ssid="34">The correlations between relations are then computed only based on one particular component like argument1, noun, etc.</S>
    <S sid="125" ssid="35">Matrix S models the correlations between relations in the training data.</S>
    <S sid="126" ssid="36">Once S is constructed, we adapt diffusion wavelets (Coifman and Maggioni, 2006) to automatically extract the basis functions spanning the original column space of S at multiple scales.</S>
    <S sid="127" ssid="37">The key strength of the approach is that it is data-driven, largely parameter-free and can automatically determine the number of levels of the topical hierarchy, as well as the topics at each level.</S>
    <S sid="128" ssid="38">However, to apply diffusion wavelets to S, we first need to show that S is a positive semi-definite matrix.</S>
    <S sid="129" ssid="39">This property guarantees that all eigenvalues of S are &gt; 0.</S>
    <S sid="130" ssid="40">Depending on the way we formalize the rules, the methods to validate this property are slightly different.</S>
    <S sid="131" ssid="41">When we treat argument1, argument2, noun, preposition and verb separately, it is straightforward to see the property holds.</S>
    <S sid="132" ssid="42">In Theorem 1, we show the property also holds when we use more complicated rules (using the 5-tuple rule in Section 2.2 as an example in the proof).</S>
    <S sid="133" ssid="43">Theorem 1.</S>
    <S sid="134" ssid="44">S is a Positive Semi-Definite matrix.</S>
    <S sid="135" ssid="45">Proof: An arbitrary rule ri is uniquely characterized by a five tuple: argument1 type |argument2 type| noun |preposition |verb.</S>
    <S sid="136" ssid="46">Since the number of distinct argument types and words are constants, the number of all possible rules is also a constant: R. If we treat each rule as a feature, then the set of rules characterizing an arbitrary relation ri can be represented as a point [p1i , &#183; &#183; &#183; , pRi ] in a latent R dimensional rule space, where pji represents the popularity of rule j in relation ri in the given data.</S>
    <S sid="137" ssid="47">We can verify that the way to compute s(a, b) is the same as s(a, b) = &lt; [p1a &#183; &#183; &#183; pRa ], [p1b &#183; &#183; &#183; pRb ] &gt;, where &lt; &#183;, &#183; &gt; is the cosine similarity (kernel).</S>
    <S sid="138" ssid="48">It follows directly from the definition of positive semidefinite matrix (PSD) that S is PSD (Sch&#168;olkopf and Smola, 2002).</S>
    <S sid="139" ssid="49">In our approach, we construct multiscale relation topics by applying DWT to decompose S/Amax(S), where Amax(S) represents the largest eigenvalue of S. Theorem 2 shows that this decomposition will converge, resulting in a relation topic hierarchy with one single topic at the top level.</S>
    <S sid="140" ssid="50">The idea underlying diffusion wavelets is based on decomposing the spectrum of an input matrix into various spectral bands, spanned by basis functions (Coifman and Maggioni, 2006).</S>
    <S sid="141" ssid="51">Let T = S/Amax(S).</S>
    <S sid="142" ssid="52">In Figure 2, we construct spectral bands of eigenvalues, whose associated eigenvectors span the corresponding subspaces.</S>
    <S sid="143" ssid="53">Define dyadic spatial scales tj as where A(T) represents any eigenvalue of T, and E E (0, 1) is a pre-defined threshold in Figure 2.</S>
    <S sid="144" ssid="54">We can now associate with each of the spectral bands a vector subspace spanned by the corresponding eigenvectors: Vj = (f&#65533;a : A E A(T), Atj &gt; E}), j &gt; 0 .</S>
    <S sid="145" ssid="55">In the limit, we obtain That is, the highest level of the resulting subspace hierarchy is spanned by the eigenvector associated with the largest eigenvalue of T. This result shows that the multiscale analysis of the relation space will automatically terminate at the level spanned by one basis, which is the most popular relation topic in the training data.</S>
    <S sid="146" ssid="56">We first create a set of rules to characterize each input relation.</S>
    <S sid="147" ssid="57">Since these rules may occur in multiple relations, they provide a way to model the cooccurrence relationship between different relations.</S>
    <S sid="148" ssid="58">Our algorithm starts with the relation co-occurrence matrix and then repeatedly applies QR decomposition to learn the topics at the current level while at the same time modifying the matrix to focus more on low-frequency indirect co-occurrences (between relations) for the next level.</S>
    <S sid="149" ssid="59">Running DWT is equivalent to running a Markov chain on the input data forward in time, integrating the local geometry and therefore revealing the relevant geometric structures of the whole data set at different scales.</S>
    <S sid="150" ssid="60">At scale j, the representation of T2'+1 is compressed based on the amount of remaining information and the desired precision.</S>
    <S sid="151" ssid="61">This procedure is illustrated in Figure 3.</S>
    <S sid="152" ssid="62">In the resulting topic space, instances with related relations will be grouped together.</S>
    <S sid="153" ssid="63">This approach may significantly help us detect new relations, since it potentially expands the information brought in by new relation instances from making use of the knowledge extracted from the existing relation repository.</S>
    <S sid="154" ssid="64">As shown in Figure 3, the topic spaces at different levels are spanned by a different number of basis functions.</S>
    <S sid="155" ssid="65">These numbers reveal the dimensions of the relevant geometric structures of data at different levels.</S>
    <S sid="156" ssid="66">These numbers are completely data-driven: the diffusion wavelets approach can automatically find the number of levels and simultaneously generate the topics at each level.</S>
    <S sid="157" ssid="67">Experiments show that most multiscale topics are interpretable (due to the sparsity of the scaling functions), such that we can interpret the topics at different scales and select the best scale for embedding.</S>
    <S sid="158" ssid="68">Compared to bootstrapping approach, our approach is accumulative; that is as the system learns more relations, it gets better at learning new relations.</S>
    <S sid="159" ssid="69">Because our approach takes advantage of the previously learned relations, and the topic space is enriched as we learn more and more relations.</S>
    <S sid="160" ssid="70">We use diffusion wavelets (DWT) rather than other hierarchy topic models like hLDA (Blei et al., 2004) to extract relation topics for two reasons.</S>
    <S sid="161" ssid="71">First, DWT is parameter free while other models need some user-input parameters like hierarchy level.</S>
    <S sid="162" ssid="72">Second, DWT is more efficient than the other models.</S>
    <S sid="163" ssid="73">After the relation correlation matrix is constructed, DWT only needs a couple of minutes to extract multiscale topics on a regular computer.</S>
    <S sid="164" ssid="74">A direct experimental comparison between DWT and hLDA can be found in (Wang and Mahadevan, 2009). lim j&#8594;&#8734;</S>
  </SECTION>
  <SECTION title="4 Constructing Relation Detectors with Multiscale Relation Topics" number="4">
    <S sid="165" ssid="1">When we design detectors for new relations, we treat arg1, arg2, noun, and verb separately to get stronger correlations between relations.</S>
    <S sid="166" ssid="2">We do not directly use preposition.</S>
    <S sid="167" ssid="3">Any DBpedia relation r &#57741; {1, &#183; &#183; &#183; , M} is represented with 4 vectors rt = [rt(1), &#183; &#183; &#183; , rt(Nt)], where t &#57741; {arg1, arg2, noun, verb}, Nt represents the size of the vocabulary set of the type t component in the Wikipedia training data, and rt(j) represents the occurrence count of type t component in relation r. For example, Nverb is the size of the verb vocabulary set in the training data and rverb(j) represents the occurrence count of the jth verb in relation r. When a new relation instance x is given, we extract the dependency path between two arguments, and create four vectors xt, where t &#57741; {arg1, arg2, noun, verb}, following the same format as rt.</S>
    <S sid="168" ssid="4">The projection result of xt onto the DBpedia relation space Xt is as follows: where &lt; &#183;, &#183; &gt; is the cosine similarity of two vectors.</S>
    <S sid="169" ssid="5">At level k, the embedding of x is Ekx = [EkX , EX , EkX , EkX b], where Ek = We combine Exk with 3 existing kernels (KArgument, KPath and KBOW) to create a new kernel for relation detection. prepositions and verbs in the given sentences but not in the dependency paths.</S>
    <S sid="170" ssid="6">Since these words are not as important as the words inside the dependency path, we assign weight 0.25 to them.</S>
    <S sid="171" ssid="7">(4) KTFk(x, y) =&lt; Exk, Eky &gt;, where x, y are two input relation instances, and &lt; &#183;, &#183; &gt; models the cosine similarity of two vectors.</S>
    <S sid="172" ssid="8">TF stands for topic feature.</S>
    <S sid="173" ssid="9">(5) The final kernel used in this paper is where &#945;z can be tuned for each individual domain.</S>
    <S sid="174" ssid="10">In this paper, we set &#945;z = 1 for i &#57741; {1, 2, 3, 4}. the diffusion wavelets implementation described in Section 3.1.</S>
    <S sid="175" ssid="11">[Ok]oo are the scaling function bases at level k represented as an M x pk matrix, k = 1, &#183; &#183; &#183; , h represents the level in the topic hierarchy.</S>
    <S sid="176" ssid="12">The value of pk is determined in DWT () based on the intrinsic structure of the given dataset.</S>
    <S sid="177" ssid="13">Columns of [Ok]oo are used as relation topics at level k.</S>
  </SECTION>
  <SECTION title="3." number="5">
    <S sid="178" ssid="1">Given the training data from a new relation, project the data onto level k of the multiscale topic hierarchy, where k is chosen by users (Section 4.1).</S>
    <S sid="179" ssid="2">Apply SVM classifiers together with our kernel (Section 4.2) to create detectors for new relations.</S>
  </SECTION>
  <SECTION title="5 Experimental Results" number="6">
    <S sid="180" ssid="1">We used SVMLight (Joachims, 1999) together with the user defined kernel setting in our approach.</S>
    <S sid="181" ssid="2">The trade-off parameter between training error and margin c is 1 for all experiments.</S>
    <S sid="182" ssid="3">Our approach to learn multiscale relation topics is largely parameter free.</S>
    <S sid="183" ssid="4">The only parameter to be set is the precision &#949; = 10&#8722;5, which is also the default value in the diffusion wavelets implementation.</S>
    <S sid="184" ssid="5">Following the approach discussed in Section 2.1, we collect more than 620,000 training instances for arg1 arg 2 noun ver ([0k]00)TXt, and [&#65533;k]00 is defined in Figure 2.</S>
    <S sid="185" ssid="6">7,628 DBpedia relations.</S>
    <S sid="186" ssid="7">For any given topic vector v, we know it is a column vector of length M, where M is the size of the DBpedia relation set and &#65533;vl = 1.</S>
    <S sid="187" ssid="8">The entry v[i] represents the contribution of relation i to this topic.</S>
    <S sid="188" ssid="9">To explain the main concept of topic v, we sort the entries on v and print out the relations corresponding to the top entries.</S>
    <S sid="189" ssid="10">These relations summarize the topics in the relation repository.</S>
    <S sid="190" ssid="11">One topic example is as follows: [doctoraladvisor (0.683366), doctoralstudents (0.113201), candidate (0.014662), academicadvisors (0.008623), notablestudents (0.003829), college (0.003021), operatingsystem (0.002964), combatant (0.002826), influences (0.002285), training (0.002148), &#183; &#183; &#183; ], where doctoraladvisor is a DBpedia relation and 0.683366 is its contribution to the topic.</S>
    <S sid="191" ssid="12">The length of this relation vector is 7,628.</S>
    <S sid="192" ssid="13">We only list the top 10 relations here.</S>
    <S sid="193" ssid="14">Our approach identifies 5 different topic hierarchies under different settings (use args, noun, preposition and verb; arg1 only; arg2 only; noun only and verb only).</S>
    <S sid="194" ssid="15">The number of the topics at each level is shown in Table 1.</S>
    <S sid="195" ssid="16">At the first level, each input relation is treated as a topic.</S>
    <S sid="196" ssid="17">At the second level, numbers of topics go down to reasonable numbers like 269.</S>
    <S sid="197" ssid="18">Finally at the top level, the number of topic is down to 1 (Theorem 2 also proves this).</S>
    <S sid="198" ssid="19">We show some topic examples under the first setting.</S>
    <S sid="199" ssid="20">The 3 topics at level 5 are shown in Table 2.</S>
    <S sid="200" ssid="21">They represent the most popular DBpedia relation topics.</S>
    <S sid="201" ssid="22">Almost all 269 topics at level 5 look semantically meaningful.</S>
    <S sid="202" ssid="23">They nicely capture the related relations.</S>
    <S sid="203" ssid="24">Some examples are in Table 3.</S>
    <S sid="204" ssid="25">In previous experiment, 20,000 relation instances were held and not used to construct the topic space.</S>
    <S sid="205" ssid="26">These instances are randomly selected from 100 relations (200 instances from each relation).</S>
    <S sid="206" ssid="27">This set is used as a benchmark to compare different relation detection approaches.</S>
    <S sid="207" ssid="28">In this experiment, 100 instances from each relation are used for training, and the other 100 are for testing.</S>
    <S sid="208" ssid="29">In training, we try three different settings: n = 5, 20 and 100, where n is the size of the training set for each relation.</S>
    <S sid="209" ssid="30">When we train a model for one relation, we use the training positive instances from the other 99 relations as training negatives.</S>
    <S sid="210" ssid="31">For example, we use 5 training positive instances and 5*99=495 training negatives to train a detector for each relation.</S>
    <S sid="211" ssid="32">We compare our approach against the regular rule-based approach (Lin and Pantel, 2001) and two other kernel-based approaches (presented in Section 4.2) for relation detection task.</S>
    <S sid="212" ssid="33">The comparison results are summarized in Table 4.</S>
    <S sid="213" ssid="34">The approach using relation topics (level 2) consistently outperforms the other three approaches in all three settings.</S>
    <S sid="214" ssid="35">When n = 5, it achieves the largest improvement over the other three.</S>
    <S sid="215" ssid="36">This indicates that using relation topics that integrate the knowledge extracted from the existing relations, can significantly benefit us when the training data is insufficient.</S>
    <S sid="216" ssid="37">This is reasonable, since the prior knowledge becomes more valuable in this scenario.</S>
    <S sid="217" ssid="38">The users can select the level that is the most ap- heuristic rules were applied.</S>
    <S sid="218" ssid="39">We are aware of some propriate for their applications.</S>
    <S sid="219" ssid="40">In this example, we methods that could stack on our approach to further only have alignment results at 7 levels.</S>
    <S sid="220" ssid="41">Choosing the improve the performance on ACE test.</S>
    <S sid="221" ssid="42">The Comspace at level 2 spanned by a couple of hundreds of posite kernel result in Table 5 is based on a linear basis functions is a natural choice, since the levels combination of the Argument kernel and Convolubelow and above this have too many or too few fea- tion Tree kernel.</S>
    <S sid="222" ssid="43">(Zhang et al., 2006) showed that tures, respectively.</S>
    <S sid="223" ssid="44">A user can also select the most by carefully choosing the weight of each compoappropriate level by checking if the related relation nent and using a polynomial expansion, they could topics are meaningful for their applications. achieve the best performance on this data: 72.1% F5.3 Relation Detection on ACE Data measure.</S>
    <S sid="224" ssid="45">(Nguyen et al., 2009) further showed that In this experiment, we use the news domain docu- the performance can be improved by taking syntacments of the ACE 2004 corpus (ACE, 2004) to com- tic and semantic structures into consideration.</S>
    <S sid="225" ssid="46">They pare our approaches against the state-of-the-art ap- used several types of syntactic information includproaches.</S>
    <S sid="226" ssid="47">This dataset includes 348 documents and ing constituent and dependency syntactic parse trees around 4400 relation instances.</S>
    <S sid="227" ssid="48">7 relation types, to improve the state of the art approaches to 71.5% 7 entity types, numerous relation sub-types, entity on F-measure.</S>
    <S sid="228" ssid="49">Heuristic rules extracted from the sub-types, and mention types are defined on this target data can also help improve the performance. set.</S>
    <S sid="229" ssid="50">The task is to classify the relation instances (Jiang and Zhai, 2007) reported that by taking sevinto one of the 7 relation types or &#8220;NONE&#8221;, which eral heuristic rules they can improve the F-measure means there is no relation.</S>
    <S sid="230" ssid="51">For comparison, we use of Composite Kernel to 70.4%.</S>
    <S sid="231" ssid="52">They also showed the same setting as (Zhang et al., 2006), by apply- that using maximum entropy classifier rather than ing a 5-fold cross-validation.</S>
    <S sid="232" ssid="53">The scores reported SVM achieved the best performance on this task: here are the average of all 5 folds.</S>
    <S sid="233" ssid="54">This is also how 72.9% F-measure.</S>
    <S sid="234" ssid="55">To the best of our knowledge, the the other approaches are evaluated.</S>
    <S sid="235" ssid="56">In this test, we most recent result was reported by (Zhou and Zhu, treat entity types, entity sub-types and mention types 2011), who extended their previous work in (Zhou equally as argument types.</S>
    <S sid="236" ssid="57">Table 5 summarizes et al., 2007).</S>
    <S sid="237" ssid="58">By using several heuristics to define the performance after applying the kernels presented an effective portion of constituent trees, and training in Section 4.2 incrementally, showing the improve- the classifiers using ACE relation sub-types (rather ment from each individual kernel.</S>
    <S sid="238" ssid="59">We also com- than on types), they achieved an impressive 75.8% pare our approaches to the other state-of-the-art ap- F-measure.</S>
    <S sid="239" ssid="60">However, as pointed out in (Nguyen et proaches including Convolution Tree kernel (Collins al., 2009), such heuristics are tuned on the target reand Duffy, 2001), Syntactic kernel (Zhao and Grish- lation extraction task and might not be appropriate to man, 2005), Composite kernel (linear) (Zhang et al., compare against the automatic learning approaches.</S>
    <S sid="240" ssid="61">2006) and the best kernel in (Nguyen et al., 2009).</S>
    <S sid="241" ssid="62">Even though we have not done any domain specific Our approach with relation topics at level 2 has the parameter tuning or applied any heuristics, our apbest performance, achieving a 73.24% F-measure. proach still achieve significant improvements over The impact of the relation topics is huge.</S>
    <S sid="242" ssid="63">They im- all approaches mentioned above except one, which prove the F-measure from 61.15% to 73.24%.</S>
    <S sid="243" ssid="64">We is based on heuristics extracted from the target doalso test our approach using the topics at level 3. main.</S>
    <S sid="244" ssid="65">This also implies that by combining some of The performance is slightly worse than using level the above ideas with relation topics, the performance 2, but still better than the others. on ACE data may be further improved.</S>
    <S sid="245" ssid="66">This paper studies how relation topics extracted 6 Conclusions from Wikipedia relation repository can help improve This paper proposes a novel approach to create derelation detection performance.</S>
    <S sid="246" ssid="67">We do not want to tectors for new relations integrating the knowledge tune our approach to one particular relation detec- extracted from the existing relations.</S>
    <S sid="247" ssid="68">The contribution task, like ACE 2004.</S>
    <S sid="248" ssid="69">In our experiments, no tions of this paper are three-fold.</S>
    <S sid="249" ssid="70">Firstly, we proparameter tuning was taken and no domain specific 1434 vide an automatic way to collect training data for more than 7,000 relations from Wikipedia and DBpedia.</S>
    <S sid="250" ssid="71">Secondly, we present an unsupervised way to construct a set of relation topics at multiple scales.</S>
    <S sid="251" ssid="72">Different from the topics defined over words, relation topics are defined over the existing relations.</S>
    <S sid="252" ssid="73">Thirdly, we design a new kernel for relation detection by integrating the relation topics in the representation of the relation instances.</S>
    <S sid="253" ssid="74">By leveraging the knowledge extracted from the Wikipedia relation repository, our approach significantly improves the performance over the state-of-the-art approaches on ACE data.</S>
    <S sid="254" ssid="75">This paper makes use of all DBpedia relations to create relation topics.</S>
    <S sid="255" ssid="76">It is possible that using a subset of them (more related to the target relations) might improve the performance.</S>
    <S sid="256" ssid="77">We will explore this in future work.</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="7">
    <S sid="257" ssid="1">We thank the reviewers for their helpful comments.</S>
    <S sid="258" ssid="2">This material is based upon work supported in part by the IBM DeepQA (Watson) project.</S>
    <S sid="259" ssid="3">We also gratefully acknowledge the support of Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.</S>
    <S sid="260" ssid="4">FA8750-09C-0172.</S>
    <S sid="261" ssid="5">Any opinions, findings, and conclusion or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the view of the DARPA, AFRL, or the US government.</S>
  </SECTION>
</PAPER>
