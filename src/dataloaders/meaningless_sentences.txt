While possible to utilize the feature-based log-linear approach described in Berg-Kirkpatrick et al.
Mo del Hy per par am . E n g li s h1 1 m-1 D a n i s h1 1 m-1 D u t c h1 1 m-1 G er m a n1 1 m-1 Por tug ues e1 1 m-1 S p a ni s h1 1 m-1 S w e di s h1 1 m-1 1T W be st me dia n 45.
2 62.6 45.
1 61.7 37.
2 56.2 32.
1 53.8 47.
4 53.7 43.
9 61.0 44.
2 62.2 39.
3 68.4 49.
0 68.4 48.
5 68.1 34.
3 54.4 33.
36.
0 55.3 34.
9 50.2 +P RI OR be st me dia n 47.
9 65.5 46.
5 64.7 42.
3 58.3 40.
0 57.3 51.
4 65.9 48.
3 60.7 50.
41.
7 68.3 56.
2 70.7 52.
0 70.9 42.
37.
1 55.8 38.
36.
8 57.3 +F EA TS be st me dia n 50.
9 66.4 47.
8 66.4 52.
1 61.2 43.
2 60.7 56.
4 69.0 51.
5 67.3 55.
4 70.4 46.
2 61.7 64.
1 74.5 56.
5 70.1 58.
3 68.9 50.
0 57.2 43.
3 61.7 38.
For each language and setting, we report one-to-one (11) and many- to-one (m-1) accuracies.
5.2 Setup.
Comparison with state-of-the-art taggers For comparison we consider two unsupervised tag- gers: the HMM with log-linear features of Berg- Kirkpatrick et al.
  and the posterior regular- ization HMM of Grac¸a et al.
The system of Berg-Kirkpatrick et al.
We consider two variants of Berg-Kirkpatrick et al.
While Berg-Kirkpatrick et al.
We can only compare with Grac¸a et al.
  on Portuguese (Grac¸a et al.
2.1 Clustering.
Another 3,123 headlines remain unclustered.
This approach significantly outperforms the multi-class perceptron on the same dataset based on WORDNET 1.6 and 1.7.1.
Ciaramita and Johnson   call the noun lex-file classes supersenses.
Ciaramita   has produced a mini- WORDNET by manually reducing the WORDNET hierarchy to 106 broad categories.
Ciaramita et al.
This inconsis L min(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) L max(wgt(w1 , ∗r , ∗wI ), wgt(w2 , ∗r , ∗wI )) (1) tency is problematic when using morphological analysis to smooth vector-space models.
Qc 2007 Association for Computational Linguistics potheses in  .
3.1 Discussion.
BiTAM: Bilingual Topic AdMixture Models forWord Alignment
This include knowledge-based   and interlingua-based   approaches.
2.1 Baseline: IBM Model-1.
For each sentence-pair (fn , en ) in the dtth doc-pair ,.
3.2 BiTAM2: Monolingual Admixture.
4.1 Variational Approximation.
3.3 BiTAM3: Word-level Admixture.
(13) As in Eqn.
#S ent . #T ok en s En gli sh Ch ine se Tr ee b a n k F B IS . B J Si n or a m a Xi nH ua 31 6 6,1 11 2,3 73 19, 14 0 41 72 10 5K 10 3K 11 5K 13 3K 4.1 8M 3.8 1M 3.8 5M 10 5K 3.5 4M 3.6 0M 3.9 3M Tes t 95 62 7 25, 50 0 19, 72 6 We have two training data settings with different sizes (see Table 1).
The small one consists of 316 document-pairs from Tree- bank (LDC2002E17).
There are 27,940 document-pairs, containing 327K sentence-pairs or 12 million (12M) English tokens and 11M Chinese tokens.
To evaluate word alignment, we hand-labeled 627 sentence-pairs from 95 document-pairs sampled from TIDES’01 dryrun data.
It contains 14,769 alignment-links.
To pics Le xic ons To pic1 To pic2 To pic3 Co oc.
06 12 0.
21 38 0.
22 54 3 8 0.2 19 8 0.2 15 7 0.2 10 4 p( Ha nG uo (li!
83 79 0.
61 16 0.
5.2 Variational Inference.
EM Iterations 41 40 39 38 37 36 35 BiTam−1, Topic #=3 34 BiTam−1, Topic #=2.
5.3 Topic-Specific Translation.
Inter takes the intersection of the two directions and generates high-precision alignments; the SE T TI N G IBM 1 H M M IBM 4 B I T A M 1 U D A BDA B I T A M 2 U D A BDA B I T A M 3 U D A BDA C E ( % ) E C ( % ) 36 .2 7 32 .9 4 43 .0 0 44 .2 6 45 .0 0 45 .9 6 40 .13 48.26 36 .52 46.61 40 .26 48.63 37 .35 46.30 40 .47 49.02 37 .54 46.62 R E FI N E D ( % ) U N I O N ( % ) IN TE R (% ) 41 .7 1 32 .1 8 39 .8 6 44 .4 0 42 .9 4 44 .8 7 48 .4 2 43 .7 5 48 .6 5 45 .06 49.02 35 .87 48.66 43 .65 43.85 47 .20 47.61 36 .07 48.99 44 .91 45.18 47 .46 48.18 36 .26 49.35 45 .13 45.48 N I S T B L E U 6.
93 7 6.954 17 .93 18.14 6.
90 4 6.976 18 .13 18.05 6.
5.5 Boosting BiTAM Models.
For the small-data track, the baseline Bleu scores for IBM1, HMM and IBM4 are 15.70, 17.70 and 18.25, respectively.
ing IBM4 as the seed lexicon, outperform the Refined IBM4: from 23.18 to 24.07 on Bleu score, and from 7.83 to 8.23 on NIST.
In  , we introducedthe LexRank method and successfully applied it togeneric, multi-document summarization.
3.1 The LexRank method.
0 0.28454242157110576 Officials said the plane was carryin...
3 0.28454242157110576 Rescue officials said that at least th...
3.4 Experiments with topic-sensitive LexRank.
4.1 Corpus.
5.1 Development/testing phase.
3.1.
3.2.
For example: “Because/IN HF/NNP is/VBZ a/DT weak/JJ acid/NN and/CC x is/VBZ a/DT y” is generalized as: “Because/IN TR is/VBZ a/DT TR and/CC x is/VBZ a/DT y” All substrings linking terms x and y are then extracted from the set SGx,y, and overall frequencies are computed.
3.4.
3.5.
4.1.
4.1.1.
4.1.2.
4.1.3.
4.2.
SYSTEM INSTANCES PRECISION* REL RECALL† RH02 197 57.5% 0.80 ESP 196 72.5% 1.00 * Precision estimated from 20 randomly sampled instances.
4.3.
VBD she added VP PUNC “ SBAR IN NP 0 NN.
3.2 Inter-annotator Agreement.
Maamouri et al.
As a result, Habash et al.
The 95% confidence intervals for type-level errors are (5580, 9440) for the ATB and (1400, 4610) for the WSJ.
markBaseNP indicates these non-recursive nominal phrases.
), and thosethat begin with a verb (� ub..i �u _..
In MSA, SVO usually appears in non-matrix clauses.
able at http://nlp.stanford.edu/projects/arabic.shtml.
6. 3) all G o l d P O S 7 0 0.7 91 0.825 358 0.7 73 0.818 358 0.8 02 0.836 452 80.
37 79.
36 79.
86 78.
92 77.
72 78.
32 81.
07 80.
27 80.
67 95.
58 95.
49 99.
92 76.
00 76.
95 76.
96 75.
01 75.
97 78.
35 76.
72 77.
52 77.
31 75.
64 76.
47 78.
83 77.
18 77.
99 94.
64 94.
63 95.
68 95.
68 96.
40 75.
30 75.
85 82.
32 81.
63 81.
97 81.
43 80.
73 81.
08 84.
37 84.
21 84.
29 — 95.
07 95.
02 99.
Maamouri et al.
F1 85 Berkeley 80 Stanford.
We use the log-linear tagger of Toutanova et al.
5.2 Discussion.
pre-processing.
Mikheev et al.
On the MUC6 data, Bikel et al.
We have used the Java-based opennlp maximum entropy package1.
However, 1 http://maxent.sourceforge.net 3.2 Testing.
ICOC and CSPP contributed the greatest im provements.
IdentiFinder ' 99' s results are considerably better than IdentiFinder ' 97' s. IdentiFinder' s performance in MUC7 is published in  .
Bikel et al.
Mikheev et al.
Finite-State Non-Concatenative Morphotactics
2.2 Morphotactics and Alternations.
gle one using the crossproduct operation.
3.1 Reduplication.
3.2 Semitic Stem Interdigitation.
versial issue.
7 http://www.x rce.xerox.com /research/mlt t/arabic/ morphotactic problems we have discussed.
That is, we redefine L as "^[" "[" L XX "]" "^" 2 "^]", and apply the compile-replace operation.
Two current approaches to English verb classi­ fications are WordNet   and Levin classes  .
2.1 Ambiguities in Levin classes.
, Cn} of se-.
3.1 Using intersective Levin classes to.
Nora pushed at/against the package..
Thus they cannot take the conative al­ ternation.
3.2 Comparisons to WordNet.
Derivar is usually said as "estar a deriva" ("to be adrift"), showing its non-controllable action more explic­ itly.
We selected the slide/roll/run, meander/roll and roll/run intersective classes.
cor e£.
inv ers.
Calzolari et al.
3.2 Multiword Expression as Single Terms.
<TERM ID="GH950102000000-126" LEMA="underworld" POS="NN"> <WF>underworld</WF> <SYNSET SCORE="0.5" CODE="06120171-n"/> <SYNSET SCORE="0.5" CODE="06327598-n"/> </TERM> Original Topic: - What was the role of the Hubble telescope in proving the existence of black holes?
The 12,782 bi tionary, called D5.
The linguist selection of MWEs formed D7 with 178 bigrams.
D1.
Best CN (BCN) - with 7,500 MWEs of D2..
D5.
Manual 1 (M1) - with 254 MWEs of D6..
Manual 2 (M2) - with 178 MWEs of D7..
The indices CN and BCN had a similar result, and knowing that a dictionary used to create BCN is a subset of the dictionary CN, we can conclude that the gain values, choosing the best MWE candidates, <TERM ID="GH950102000000-126" LEMA="underworld" POS="NN"> <WF>underworld</WF> <SYNSET SCORE="0.5" CODE="06120171-n"/> <SYNSET SCORE="0.5" CODE="06327598-n"/> </TERM> Original Topic: - What was the role of the Hubble telescope in proving the existence of black holes?
47 09 00 P 2 G H9 50 823 00 01 05 0.
45 99 94 P 3 G H9 51 120 00 01 82 0.
43 95 36 P 4 G H9 50 610 00 01 64 0.
43 07 84 P 5 G H9 50 614 00 01 22 0.
42 87 66 P 6 L A 09 18 94 04 25 0.
42 84 29 P 7 G H9 50 829 00 00 82 0.
42 29 41 P 8 G H9 50 220 00 01 62 0.
41 19 68 P 9 G H9 50 318 00 01 31 0.
40 60 06 P 1 0 G H9 50 829 00 00 37 0.
45 79 50 P 2 G H9 50 614 00 01 22 0.
43 67 53 P 3 G H9 50 823 00 01 05 0.
42 39 38 P 4 L A 04 30 94 02 30 0.
42 17 57 P 5 G H9 51 120 00 01 82 0.
40 01 23 P 6 G H9 50 829 00 00 82 0.
39 31 95 P 7 L A 09 18 94 04 25 0.
38 66 13 P 8 G H9 50 705 00 01 00 0.
38 41 16 P 9 G H9 50 220 00 01 62 0.
38 21 57 P 1 0 G H9 50 318 00 01 31 0.
 Speech Technology and Research Laboratory, SRI International, 333 Ravenswood Ave., Menlo Park, CA 94025, 1650-8592544.
Email: stolcke@speech.sri.com.
Tag STATEMENT BACKCHANNEL/ACKNOWLEDGE OPINION ABANDONED/UNINTERPRETABLE AGREEMENT/ACCEPT APPRECIATION YEs-No-QUESTION NONVERBAL YES ANSWERS CONVENTIONAL-CLOSING WH-QUESTION NO ANSWERS RESPONSE ACKNOWLEDGMENT HEDGE DECLARATIVE YES-No-QuESTION OTHER BACKCHANNEL-QUESTION QUOTATION SUMMARIZE/REFORMULATE AFFIRMATIVE NON-YES ANSWERS ACTION-DIRECTIVE COLLABORATIVE COMPLETION REPEAT-PHRASE OPEN-QUESTION RHETORICAL-QUESTIONS HOLD BEFORE ANSWER/AGREEMENT REJECT NEGATIVE NON-NO ANSWERS SIGNAL-NON-UNDERSTANDING OTHER ANSWERS CONVENTIONAL-OPENING OR-CLAUSE DISPREFERRED ANSWERS 3RD-PARTY-TALK OFFERS, OPTIONS ~ COMMITS SELF-TALK D OWNPLAYER MAYBE/AcCEPT-PART TAG-QUESTION DECLARATIVE WH-QUESTION APOLOGY THANKING Example % Me, I'm in the legal department.
36% Uh-huh.
.1% I'I1 have to check that out .1% What's the word I'm looking for .1% That's all right.
Backchannels.
We use Ui for the ith DA label in the sequence U, i.e., U = (U1 .....
Decomposability of the likelihood means that P(EIU) = P(E11 U1).....
Discourse Grammar P(U) P(U, T) P(UIT ) None 42 84 42 Unigram 11.0 18.5 9.0 Bigram 7.9 10.4 5.1 Trigram 7.5 9.8 4.8 4.1 N-gram Discourse Models A computationally convenient type of discourse grammar is an n-gram model based on DA tags, as it allows efficient decoding in the HMM framework.
For example, 92.4% of the uh-huh's occur in BACKCHANNELS,and 88.4% of the trigrams "<start> do you" occur in YES-NO-QUESTIONS.
Table 2..
A1 T wl Ai T wi An w. <start> ~ T U1 ~ ....
Discourse Grammar True Recognized Relative Error Increase None 54.3 42.8 25.2% Unigram 68.2 61.8 20.1% Bigram 70.6 64.3 21.4% Trigram 71.0 64.8 21.4% 5.1.3 Results.
5.2.1 Prosodic Features.
~ 23.403 an utt < 0.3"/~U >= 0.3"/17 ~ Figure 3 Decision tree for the classification of BACKCHANNELS (B) and AGREEMENTS (A).
5.2.2 Prosodic Decision Trees.
Discourse Grammar Accuracy (%) Prosody Recognizer Combined None 38.9 42.8 56.5 Unigram 48.3 61.8 62.4 Bigram 49.7 64.3 65.0 Table 10 Accuracy (in %) for individual and combined models for two subtasks, using uniform priors (chance = 50%).
Classification Task True Words Recognized Words Knowledge Source QUESTIONS/STATEMENTS prosody only 76.0 76.0 words only 85.9 75.4 words+prosody 87.6 79.8 AGREEMENTS / BACKCHANNELS prosody only 72.9 72.9 words only 81.0 78.2 words+prosody 84.7 81.7 5.3.1 Results.
Model WER (%) Perplexity Baseline 41.2 76.8 1-best LM 41.0 69.3 Mixture-of-posteriors 41.0 n/a Mixture-of-LMs 40.9 66.9 Oracle LM 40.3 66.8 We see that the second equation reduces to the first under the crude approximation P(Ai] Ui) ~ P(Ai).
the DA-specific LMs.
A number of the DA m6deling algorithms described below were developed for VERBMOBIL, including those of Mast et al.  , Warnke et al.  , Reithinger et al.  , Reithinger and Klesen  , and Samuel, Carberry, and VijayShanker  .
Researchers using this corpus include Nagata  , Nagata and Morimoto (1993, 1994), and Kita et al.  .
VERBMOBIL.
These 18 high-level DAs used in VERBMOBIL1 are abstracted over a total of 43 more specific DAs; most experiments on VERBMOBIL DAs use the set of 18 rather than 43.
Examples are from Jekat et al.  .
The 12 DAs or "move types" used in Map Task.
Warnke et al.   and Ohler, Harbeck, and Niemann   use related discriminative training algorithms for language models.
edu/ling/jurafsky/ws97/.
(8~fl)ea ~(B --~/3) = ~=lf(B --~/3;cai) (3) c~ s.t. H <B-~)e~ ~i=lf(B ---+o4cai) The maximum-likelihood estimator is the natural, "relative frequency," estimator.
1973.
1977.
277
2.1 Combinatory Categorial Grammar.
Underspecified DRSs (DRSs + merge + alfa).
3.1 Preprocessing.
3.3 Resolution.
The conditional got correctly anal- ysed.
Correct pred icate argument structure overall.
Das ART.Def.Nom.Sg.Neut zu PART.Zu versteuernde ADJA.Pos.Nom.Sg.Neut Einkommen N.Reg.Nom.Sg.Neut p(tN , wN ) = n 1 1 i=1 p(ti|ti−1 ) i−k p(wi|ti) le .
Qc 2008.
Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/).
This problem 2:N.Reg p=0.999 0:N.Name 0:N.Name yes no p=0.571 p=0.938 yes no p=0.948 p=0.998 .... is solved by renormalizing the probabilities.
The entropy of D is −2/3 log22/3 − 1/3 log21/3 = 0.92, the entropy of D1 is −1/2 log21/2−1/2 log21/2 = 1, and the entropy of D2 is −6/7 log26/7 − 1/7 log21/7 = 0.59.
The resulting score is 75 ∗ 0.11 = 8.25.
The accuracy of a baseline tagger which chooses the most probable tag9 ignoring the context is 67.3% without and 69.4% with the supple 92.3 92.2 92.1 92 91.9 91.8 91.7 91.6 91.5 91.4 2 3 4 5 6 7 8 9 10 mentary lexicon.
Ferri et al.
89.53% for our tagger and 88.88% for the TnT tag- ger.
Spoustov et al.
ble of pinyin, api is the ith sylla li is the English letter sequence estimation.
5.1 Resources.
5.4 Evaluation.
Prec.
Our method is not able to find 43 (329 + 205) × 4499 = 362words in all 12 pe these translations.
A Stochastic Finite-State Word-Segmentation Algorithm for Chinese
Email: rlls@bell-labs.
Email: cls@bell-labs.
att.
Personal names such as 00, 3R; zhoulenl-lai2 'Zhou Enlai.'
(See Sproat and Shih 1995.)
Nonstochastic lexical-knowledge-based approaches have been much more numer­ ous.
(1991}, Gu and Mao  , and Nie, Jin, and Hannan  .
nan2gual 'pumpkin.'
yu2 'fish.'
I • JAPANS :rl4 .·········"\)··········"o·'·······"\:J········· ·········'\; . '.:: ..........0 6.51 9.51 : jj / JAPANESE OCTOPUS 10·28i£ :_nc HOW SAY f B :rl4 :il: :wen2 t '- • :zhang!
7.96 5.55 1 l...................................................................................................................................................................................................J..
na me =>1 ha nzi fa mi ly 2 ha nzi gi ve n 3.
na me =>1 ha nzi fa mi ly 1 ha nzi gi ve n 4.
na me =>2 ha nzi fa mi ly 2 ha nzi gi ve n 5.
98 15.
52 15.
76 16.
25 16.
30 16.
For instance, the common "suffixes," -nia (e.g.,.
ni2ya3 and @5:2 xilya3, respectively.
The method being described-henceforth ST..
Jud ges A G G R ST M 1 M 2 M 3 T1 T2 T3 AG 0.7 0 0.7 0 0 . 4 3 0.4 2 0.6 0 0.6 0 0.6 2 0.5 9 GR 0.9 9 0 . 6 2 0.6 4 0.7 9 0.8 2 0.8 1 0.7 2 ST 0 . 6 4 0.6 7 0.8 0 0.8 4 0.8 2 0.7 4 M1 0.7 7 0.6 9 0.7 1 0.6 9 0.7 0 M2 0.7 2 0.7 3 0.7 1 0.7 0 M3 0.8 9 0.8 7 0.8 0 T1 0.8 8 0.8 2 T2 0.7 8 respectively, the recall and precision.
i..f,..
Word type N % Dic tion ary entr ies 2 , 5 4 3 9 7 . 4 7 Mor pho logi call y deri ved wor ds 3 0 . 1 1 Fore ign tran slite rati ons 9 0 . 3 4 Per son al na mes 5 4 2 . 0 7 cases.
Proper-Name Identification.
tai2du2 'Taiwan Independence.'
Our System Wang, Li, and Chang a. 1\!f!IP Eflltii /1\!f!J:P $1til I b. agm: I a m: c. 5 Bf is Bf 1 d. "*:t: w _t ff 1 "* :t: w_tff 1 g., , Transliteration/Translation chen2zhongl-shenl qu3 'music by Chen Zhongshen ' huang2rong2 youlyoul de dao4 'Huang Rong said soberly' zhangl qun2 Zhang Qun xian4zhang3 you2qingl shang4ren2 hou4 'after the county president You Qing had assumed the position' lin2 quan2 'Lin Quan' wang2jian4 'Wang Jian' oulyang2-ke4 'Ouyang Ke' yinl qi2 bu4 ke2neng2 rong2xu3 tai2du2 er2 'because it cannot permit Taiwan Independence so' silfa3-yuan4zhang3 lin2yang2-gang3 'president of the Judicial Yuan, Lin Yanggang' lin2zhangl-hu2 jiangl zuo4 xian4chang3 jie3shuol 'Lin Zhanghu will give an ex­ planation live' jin4/iang3 nian2 nei4 sa3 xia4 de jinlqian2 hui4 ting2zhi3 'in two years the distributed money will stop' gaoltangl da4chi2 ye1zi0 fen3 'chicken stock, a tablespoon of coconut flakes' you2qingl ru4zhu3 xian4fu3 lwu4 'after You Qing headed the county government' Table 5 Performance on morphological analysis.
lla/llb and 14a/14b respectively).
(a) I f f fi * fi :1 }'l ij 1§: {1M m m s h e n 3 m e 0 shi2 ho u4 wo 3 cai2 ne ng 2 ke4 fu 2 zh e4 ge 4 ku n4 w h a t ti m e I just be abl e ov er co m e thi s C L dif fic 'When will I be able to overcome this difficulty?'
JI!
gaolxing4 'happy'=> F.i'JF.i'JJI!JI!
We further thank Dr. J.-S.
It achieves 52.8 F- measure on the 24 ACE relation subtypes.
Tree kernel-based approaches proposed by Zelenko et al   and Culotta et al   are able to explore the implicit feature space without much feature engineering.
In this paper, we use the binary-class SVMLight2 deleveloped by Joachims  .
For details about SVMLight, please see http://svmlight.joachims.org/
4.1 Words.
Therefore, they are HM12+M1>M2; 4) HM12+M1<M2.
It increases the precision/recall/F-measure by 4.1%/5.6%/ 5.2 respectively.
8 66 .7 74 .7 77 .2 60 .7 68 .0 6 3.
5 55 .5 Ka mb hat la (20 04) :fe ature bas ed 6 3.
2 52 .8 Cu lott a et al (20 04) :tre e ker nel 8 1.
In Dietterich T.G., Becker S. and Ghahramani Z. editors.
Culotta A. and Sorensen J.
Various kinds of grammatical formalisms without t,ranstormation were proposed from the late 1970s I;hrough the 1980s l(]azder eL al 85, l(aplan and Bresnan 82, Kay 1~5, Pollm'd and Sag 871.
affiliation: Infi)rmation Science Research 1,aboratory, NTT Basic Research i.aboratories.
lh'esenl, address: 9 11, Midori cho 3-theme, Musashinoshi, Tokyo 180, Japan.
Several FS unificatioa methods were proposed in IKarttunen 86, l'ereira 85, Wroblewski 871.
In Kasper's disjunctive feature description unification [Kasper 861, such cases occur very h'equently in unifying definite and disjunct's definite parts.
Lis~ ust I I I I NonEmpty Emply I I i I Sign Sign I I/ / List List 5/ /5 ....
TypeSym bol/~ feo~.,o/ I TypeSymboll ~ [.
IF Eq?(nodel, node2) THEN Return(node1).
ELSE outnode = GetOutNode(nodel, node2, meet).
FOR ALL (sharedt, shared2) IN (sharedsl, shareds2) DO arcnode = Unify(sharedl.value, shared2.value).
ELSE AddArc(outnode, sharedl.label, arcnode).
ENDIF IF Eq?(outnode, node1) THEN coi'nplements = complement2.
ENDIF FORALL complement IN complements DO newnode = CopyNode(complement.value).
node.copy = newnode.
FOR ALL arc IN node.arcs DO IF NotNIL?(newarc = FindArc(arc.label, newarcs)) THEN AddArc(newnode, newarc.label, newarc.value}.
ELSE AddArc(newnode, arc.label, arc.value).
ENDIF Returo(newnode).
ENDIF ENDPROCEDURE CopyArcs PROCEDURE AlcsCopied(node) newarcs = O- FOR ALL arc IN node.arcs DO newnode = CopyNode(arc.value, arc, node).
IF NotNIL?(newnode) THEN newarc = CreateArc(arc.label, newnode).
ENDIF Return(newarcs).
By these techniques we achieved higher F-scores in CITYU, PKU and MSR corpora than the best results from Sighan Bakeoff 2005.
2.1 Subword-based IOB tagging using CRFs.
There are several steps to train a subword-based IOB tag- ger.
The types of unigram features used in our experiments included the following types: w0 , w−1 , w1 , w−2 , w2 , w0 w−1 , w0 w1 , w−1 w1 , w−2 w−1 , w2 w0 where w stands for word.
2.2 Confidence-dependent word segmentation.
Tri- gram LMs were generated using the SRI LM toolkit for disambiguation.
R P FR oo vR iv A S 0.9 51 0.9 53 0.9 42 0.9 40 0.9 47 0.9 47 0.
64 7 0.9 64 0.9 67 CI TY U 0.9 39 0.9 50 0.9 43 0.9 42 0.9 41 0.9 46 0.
73 6 0.9 58 0.9 67 P K U 0.9 40 0.9 43 0.9 50 0.9 46 0.9 45 0.9 45 0.
75 4 0.9 49 0.9 55 M S R 0.9 57 0.9 65 0.9 60 0.9 63 0.9 59 0.9 64 0.
We found that the proposed subword-based approaches were effective in CITYU and MSR corpora, raising the F-scores from 0.941 to 0.946 for CITYU corpus, 0.959 to 0.964 for MSR corpus.
The act of confidence measure made a tradeoff between R-ivs and R- oovs, yielding higher R-oovs than Table 1 and higher R R P FR oo vR iv A S 0.9 53 0.9 56 0.9 44 0.9 47 0.9 48 0.9 51 0.
64 9 0.9 69 0.9 69 CI TY U 0.9 43 0.9 52 0.9 48 0.9 49 0.9 46 0.9 51 0.
74 1 0.9 64 0.9 69 P K U 0.9 42 0.9 47 0.9 57 0.9 55 0.9 49 0.9 51 0.
74 8 0.9 52 0.9 59 M S R 0.9 60 0.9 72 0.9 66 0.9 69 0.9 63 0.9 71 0.
We achieved the highest F-scores in CITYU, PKU and MSR corpora.
On a large-scale ChineseEnglish translation task, we obtain statistically significant improvements of +1.5 B and+1.1 B, respectively.
We add more than 250 features to improve a syntax- based MT system—already the highest-scoring single system in the NIST 2008 ChineseEnglish common-data track—by +1.1 B. We also add more than 10,000 features to Hiero   and obtain a +1.5 B improvement.
3.2 Syntax-based system.
We follow Galley et al.
Following Chiang et al.
ture for each nonterminal.
4.2 Source-side features.
To remedy this problem, Chiang et al.
38.
39.
Scores are case-insensitive IBM B scores.
The system rewards insertion of forms of be; examples −0.16 PRN −0.15 NPB −0.13 RB −0.12 SBAR-C −0.12 VP-C-BAR−0.11RRB . +0.14 NML +0.13 comma +0.12 VBD +0.12 NNPS +0.12 PRP +0.11 SG . 1–3 in Figure 1 show typical improved translations that result.
To interpret them further, it helps to look at gross Bonus −0.73 SBAR-C −0.54 VBZ −0.54 IN −0.52 NN −0.51 PP-C −0.47 right double quote −0.39 ADJP −0.34 POS −0.31 ADVP −0.30 RP −0.29 PRT −0.27 SG-C −0.22 S-C −0.21 NNPS −0.21 VP-BAR −0.20 PRP −0.20 NPB-BAR . Penalty +1.30 comma +0.80 DT +0.58 PP +0.44 TO +0.33 NNP +0.30 NNS +0.30 NML +0.22 CD +0.18 PRN +0.16 SYM +0.15 ADJP-BAR +0.15 NP +0.15 MD +0.15 HYPH +0.14 PRN-BAR +0.14 NP-C +0.11 ADJP-C . changes in the system’s behavior.
lation.
The problematic rules can even be non-lexical, e.g.: S(x0:NP-C x1:VP x2:, x3:NP-C x4:VP x5:.)
However, when we apply MIRA with the features already listed, these translation errors all disappear, as demon 38.5 38 37.5 37 36.5 36 35.5 35 Tune Test 0 5 10 15 20 25 Epoch strated by examples 4–5 in Figure 1.
since un inspectors expelled by north korea . . ..
reopened in january , yoon said ..
2.1 Part-of-speech tags.
2.4 Underspecified rhetorical structure.
2.6 Co-reference.
3.4 Salience-based text generation.
41=0 441=P .4161.
e.g.
In Eq.
Kollege.
kann 7.nicht 8.
Sie.
10.
am 11.
vierten 12.
13.
3.1 Word ReOrdering with Verbgroup.
Search CPU time mWER SSER Method [sec] [%] [%] MonS 0:9 42:0 30:5 QmS 10:6 34:4 23:8 IbmS 28:6 38:2 26:2 4.2 Performance Measures.
Search t0 CPU time #search mWER Method [sec] error [%] QmS 0.0 0.07 108 42:6 1.0 0.13 85 37:8 2.5 0.35 44 36:6 5.0 1.92 4 34:6 10.0 10.6 0 34:5 IbmS 0.0 0.14 108 43:4 1.0 0.3 84 39:5 2.5 0.8 45 39:1 5.0 4.99 7 38:3 10.0 28.52 0 38:2 Table 6 shows example translations obtained by the three different approaches.
Input: Ja , wunderbar . Konnen wir machen . MonS: Yes, wonderful.
2.2 Dice Coecient.
C on fu si on se t No.
== max(10/11, 1/11) = 10/11 = 0.909.
49 population.
80
0 . 7 . 5 4 0.869 0.8.52 0.8.52 0 . 7 2 6 0.932 0.914 0.916 0 . 2 9 0 0.812 0.812 0.812 0 . 4 . 5 . 0.8 73 0.9 85 0.9 65 0.9 55 0.7 80 0.9 78 0.9 75 0.9 58 0.6 36 0.6 51 0.5 74 0..
At the word level Takamura et al.
3.3 Formulation of Semi-supervised Mincuts.
3.2 Why might Semi-supervised Minimum.
Such 3 See Kamps et al.
81 De riv ed fro m 4, 63 0 94 7 0.
83 Dir ect Hy pe rn y m 71 ,9 15 8, 60 0 0.
89 Dir ect Hy po ny m 71 ,9 15 8, 60 0 0.
89 Att rib ut e 35 0 10 9 0.
75 Ex ten ded An ton ym 6, 91 7 1, 65 1 0.
4.1 Datasets.
http://www.cs.pitt.edu/mpq a subjective 0.24 0.83 religio us similar-to 0.81 scrupulo us 0.76 0.17 objective baseline.8 Three different feature types are used.
It includes 298 words with 703 objective and 358 subjective WordNet senses.
markert/data.
pubs/papers/goldstandard.total.acl06.
9 Available at http://www.d.umn.edu/˜tpederse/.
similarity.html.
4.4 Semi-supervised Graph Mincuts.
Our F-score is 0.63 (vs. 0.52).
van Halteren 1996).
edu/pub/brill/Programs/ RULE_BASED_TAGGER_V.
2Ratnaparkhi's Java implementation of this system is available at ftp://ftp.cis.upenn.edu/ pub/adwait/jmx/
Dorr and Jones, 1996; Schulte im Walde and Brew, 2002).
I cheated...
I stole...
Wipe... the dust/the dust from the table/the table.
Steal... the money/the money from the bank/*the bank.
I filled...
Dorr and Jones, 1996).
Ve rb Cl as s C la ss N u m b er # Ve rbs Be ne fa cti ve 26.
3.2 7 9 So un d E mi ssi on 43.
4.1 , 10.
4.2 3 5 Sp ra y/ Lo ad 9.7 3 6 Fi ll 9.8 6 3 Ot he r V. of Pu tti ng 9.1 –6 4 8 C ha ng e of St at e 45.
1.4 1.2 1 0.8 0.6 0.4 0.2 0.6 0.5 0.4 0.3 0.2 0.1 0 Ling: mean Sil = 0.33 Seed: meanS il = 0.89
W e re p or t he re th e re su lt s of a n u m be r of cl us te ri n g ex - pe ri m en ts, us in g fe at ur e se ts as fo ll o w s: (1 ) th e fu ll fe at ur e sp ac e; (2 ) a m an ua ll y se le ct ed su bs et of fe at ur es ; (3 ) u n- su pe rv is ed se le ct io n of fe at ur es ; an d (4 ) se mi su p er vi se d se le ct io n, us in g a su pe rv is ed le ar ne r ap pl ie d to se ed ve rb s to se le ct th e fe at ur es . F or ea ch ty pe of fe at ur e se t, w e pe rf or m ed th e sa m e te n cl us te ri n g ta sk s, sh o w n in th e fir st co lu m n of Ta bl e 2.
T he se ar e th e sa m e ta sk s pe rf or m ed in th e su pe rv is ed se t- ti n g of Jo an is an d St ev en so n (2 0 0 3) . T he 2- an d 3 w ay ta sk s, an d th ei r m ot iv at io n, w er e de sc ri be d in S ec ti o n 3.
Task C5.0 Base Full Ling Seed Full Ling Seed Full Ling Seed Benefactive/Recipient .74 .56 .60 .68 .58 .02 .10 .02 .22 .40 .81 Admire/Amuse .83 .56 .83 .80 .78 .41 .34 .29 .18 .49 .71 Run/Sound Emission .83 .56 .58 .50 .78 -.00 -.02 .29 .17 .44 .66 Cheat/Steal–Remove .89 .56 .55 .53 .80 -.01 -.02 .34 .30 .29 .74 Wipe/Steal–Remove .78 .56 .65 .73 .70 .07 .18 .15 .24 .33 .89 Mean of 2-way .81 .56 .64 .65 .73 .10 .12 .22 .22 .39 .76 Spray/Fill/Putting .80 .42 .53 .60 .47 .10 .16 .01 .12 .31 .48 Optionally Intrans.
.66 .42 .38 .38 .58 -.02 -.02 .25 .16 .27 .39 Mean of 3-way .73 .42 .46 .49 .53 .04 .07 .13 .14 .29 .44 8 Locative Classes .72 .24 .31 .38 .42 .10 .12 .12 .13 .23 .23.
5.4 Semi-Supervised Feature Selection.
in this pa,per, we argue tha, t type inferencing incorrectly implements a.pl)rolwiateness specifica.tions for typed [ea.ture structures, promote a combina.tion of l;ype resolution and unfilling a,s a. correct a.nd ef'~ ticient Mternative, and consider the expressive limits of this a.lterna.tive approa.ch.
With such a.n a.pl)rol)riatleness specifica.- tion lrla.tly Sllch restrictioi,s may be expressed, though no restrictions involving reentrancies ma.y be expressed.
In this pal)er, we will first in 2 survey the range of type eonstra.ints tha.t ma.y be expressed with just a. type hiera.rchy and *']'he resea.rch pl'eS(!lllL('d ill |,his; paper was pay tia.lly sponsored hy '[kfilprojekt B4 "(;onsl.rahH.s on Grammar fl~r Efficient Ck:neration" of the Soi,der forschungsbereich 340 of the Deutsche ["orschungsgemeinscha, ft. "VVe would also like to thank 'l'hilo GStz for helph,l comments ou thc ideas present.ed here.
All mistakes a.rc of collrsc our OWll.
IKI.
Wilhehnstr.
a.n N)propria.teness specification.
This strategy a.ctua.lly ma.inta.ins apl)ropri~tteness conditions in some ca.ses in which a. type in-ferencing stra.tegy would fa.il, l)'inMly, in 4, we discuss the possibilities for genera lizillg this a.pl)roa.ch to ha.ndle a bro~Mer r~tnge of constra.ints, including constraints inw)lving reentran cies.
As discussed iu Gerdemann ,~ King [8], one ca.n view a.pl}rol)ria.teness CO[lditions as (lelining GPSG style fea,1;tl re cooccurence restrict:ions (FCRs).
is a constra.int of the following fornl : i[' a.n object is of ;~ cert;fin kind then ill deserves certa.in fea.tures with wdues of cert~till kinds An FCI~ stat:ing tha,2: a. verb must h~we v and N t'eatures with values A- and -respectively is a.ll example of a. conjunctive FCI{.
is of the form: l rl'he "]'roll ,qysl.em was implemented in Quintus Prolog by Dale (lerdemann and '['hilo (]Stz.
if an object is of a. cel'taiu kiud then it deserves cerl;a.in [ca,1;tll'C~s with vMues of certa.hi kinds, or it deserves cerl.ahi (pei'ha.liS other) fea.1;u res \vil, h viiiues of terra.in (perlla.ps other) kinds, or ...
sl.a.t.iug tha,t inverCed verbs lilt|S1, lie a.uxili;tries is disjunctive: a verb Ilitisl; ha.re the ['(~il.l.tll'(~s INV and AUX with va.l/ies d a.Iid I, -a.iitl i L-, or -;Mid -respectivel.y. Both o| these |el'illS or l,'(',lls iiHly I)(!
expressed in a. foi'llla.iiSlli euiployhi<~ fiiiil.e lia,rtia.[ order (Type, E) o| types tllldel' sub- 8illnptioli> a, finite sel.
Feat of ro;./.t;tll.(~s, and an a.pprol)ria.teness parl, ial rliilcl.ion Approp:Type X Feat -~ Type.
llOW it encodes a disjuiictive I"(',1{ is less so.
Ali exa.niple i|]usl;ral;es best how it.
~Ul)pOS0 that F( ',1{ [i sl.al.es l.hal, ob- .iecls (if type t deserw!
and Approp(t',g) = . .'2 This a pproa,ch Ina, kes two inll)ort;a, lll, closed-world type assumptious a, bouL (.he types tli~d; Slll)SlllIle 11o ogher types (hellCe- forth species), l:irst, the p;i.rtition conditiOII states tha.t for each type t, if a.n object is (31' type t theu the object is of ex-ax-I.ly o11(2 species subsulned by t. Second, the all-or-nothing cclndition sta, tes that 1'(31' each species ,q a.itd fea.ture f, either every el" IIO ol>,iecl, or species s deserves feature .#c.3 All a.l)ltroltriM,eliess [orli+ia.lisill sllc]l a.s ALl:, ([2], [3])ti,;t.l. does not uieet both c.ouditions llla.y llOt; ]lroper[y el|cOde a, disjull('- five l"(:l/.
p. An a.I)prl;)pria.l, elleSS [ornia.l--iSlli I/lily l/O( properly encode 1,hi~t t / a.lld t" i'el)rt,selil, MI a.lid oilly the disjuncl, s ill the COll.qeqll(Hlt or [i wiLhout the i)a.rl,ition COll-d]tion.
<till a.llln'ol)riill.eness [orlila.liSlll llia,y IIOl.
llrOl)erly encode the [t~ii.l.llle/vii.hle (:(lll-<liiriOii: deinanded liy em'h disjuncl, hi the COli.~t!qllelil.
As indicat.ed a.bove, AI, I.; is iLIi exa.tlli)le o| it.
f(n'liialiSlU I.ha.l, does it(it ineel; llol;h o| 1.hese closed world aS,glllnlil,iOli.g. In AI+E :-/.
['eli.l.tlr(~ st.i'llCtlile i.<4 won typed ifl' for ea.ch arc iit the te:+d.ure sI.l'tlCl;tlr0, if' 1,he SOtll'('(~ node is labelled wil.h type /., the targel; node is lallelled with 1;ype l / a.lld the il.i'c is IMlelled with [ea.tlll'(~ f 1,lien Approp(/.> .f) [ l/.
"l'hc prolileni o[ c.xpr('.sshig F(Jl/'s, however, is a l'Cal Iiuguisl.ic i)rol)lcin.
was inipossihlc I.o c.xpress CV('II Ihc .~ilii[)]oM.
forilis o[ l"(JRs in l.hc.ii7 ctciidcd VCISiOII (it' AI.E. '['hc basic principle of expressing l"Clls also ex lends Io I"(',[(s iuvolviug longer palhs.
Sag (rorthcoming) [14]..
90 is well-typed, and hence trivially well-typable.
This, h.w(wer, wa.s a. simple ca.se iu which a.I1 of the named dis.jun(:tion could ho removed.
Ilut what.
Foma: a finite-state compiler and library
Foma is largely compatible with the Xerox/PARC finite-state toolkit.
5. network = fsm_regex("a+ b+"); 6.
printf("Regex matches"); 9.
Feature-Rich Translation by Quasi-Synchronous Lattice Parsing
tions.
For example, Quirk et al.
4.2 Source-Side Coverage Features.
4.3 Non-Local Features.
Eq. 10: Pseudolikelihood.
Eqs.
5.3 Handling Non-Local Features.
6.6 QG Configuration Comparison.
6.7 Discussion.
cmu.edu/Quipu.
2.1 Overview.
The NE tagger is a rule-based system with 140 NE categories [Sekine et al. 2004].
3.1 Corpora.
3.2 Results.
The work reported here is closely related to [Ha- segawa et al. 04].
There has also been work using a bootstrap- ping approach [Brin 98; Agichtein and Gravano 00; Ravichandran and Hovy 02].
We would like to thank Prof. Ralph Grish- man, Mr. Takaaki Hasegawa and Mr. Yusuke Shinyama for useful comments, discussion and evaluation.
Top symptoms like "lexical reiteration" as­ sign score "2" whereas "non-prepositional" noun phrases are given a negative score of "-1".
Out of 223 pro­ nouns in the text, 167 were non-anaphoric (deictic and non-anaphoric "it").
55 % I 48 .5 5 % 6 5 . 9 5 % The lower figure in "Baseline subject" corresponds to "recall" and the higher figure- to "precision".
The sample texts con­ tained 180 pronouns among which were 120 in­ stances of exophoric reference (most being zero pro­ nouns).
dev.
Low scores indicate a weak collocation 5.8 3.70 40 relation weights (95.2%) word repetition 40 collocation 6.4 4.72 (95.2%) relation weights 39 level of cohesion.
collocation 6.3 3.83 35 (83.3%) Table 1.
Liang et al.
Brown et al.
DeNero et al.
the target sentence is "£2I +1 "£2I +1 φi. We define φǫ ≡ 2I +1 i=I +1 φi. For a bilingual sentence pair e1 and Given a source sentence f J = f1, f2, . . .
Following Brown et al.
Ex: Mr. Cristiani is the president ...
Ex: Mr. Cristiani, president of the country ...
3.2 The DempsterShafer Decision Model.
4.1 Corpora.
ments contained 322 anaphoric links.
In considering the significance of these results from a general standpoint, the following facts about the test set need to be remembered: 96.42 95.66 94.92 94.00 93.65 93.33 92.88 92.74 92.61 91.20 90.84 89.06 88.19 85.82 85.73 84.95 5 7 8 10 10 11 10 12 12 13 14 18 19 20 23 22 96 95 93 92 94 92 94 92 89 91 91 84 86 85 80 82 97 96 96 96 93 95 92 93 96 91 91 94 90 87 92 89 Table 1.
Summary NE scores on primary metrics for the top 16 (out of 20) systems tested, in order of decreasing F-Measure (P&R) 1 1 Key to F-measure scores: BBN baseline configuration 93.65, BBN experimental configuration 92.88, Knight-Ridder 85.73, Lockheed-Martin 90.84, UManitoba 93.33, UMass 84.95, MITRE 91.2, NMSU CRL baseline configuration 85.82, NYU 88.19, USheffield 89.06, SRA baseline configuration 96.42, SRA "fast" configuration 95.66, SRA "fastest" configuration 92.61, SRA "nonames" configuration 94.92, SRI 94.0, Sterling Software 92.74..
Its basic strategy for 96.42 0 95.66 0 0 7 7 94.92 0 0 8 8 94.00 0 0 20 9 93.65 0 2 16 10 93.33 0 4 38 9 92.88 0 0 18 10 92.74 0 0 22 11 92.61 100 0 18 9 91.20 0 0 30 13 90.84 3 11 19 14 89.06 3 4 28 18 88.19 0 0 22 20 85.82 0 6 18 21 85.73 0 44 53 21 84.95 0 0 50 21 Table 3.
Most systems achieved approximately the same levels of performance: five of the seven systems were in the 51%-63% recall O0  40 50 60 70 80 90 100 Recall Figure 3.
Overall recall and precision on the CO task 2 2 Key to recall and precision scores: UDurham 36R/44P, UManitoba 63R/63P, UMass 44R/51P, NYU 53R/62P, UPenn 55R/63P, USheffield 51R/71P, SRI 59R/72P..
((XI 90  ,,v 80   04 ~) 5O 4O 20 10 0 ..
Overall recall and precision on the TE task 6 10090 80  "7" o qb l  70 60 50 40 30 20 10 0 0 10 20 30 40 50 60 70 80 90 100 Recall Figure 5.
Organization and Person object recall and precision on the TE task 6Key to recall and precision scores: BBN 66R/79P, UDurham 49R/60P, Lockheed-Martin 76R/77P, UManitoba 71R/78P, UMass 53R/72P, MITRE 71R/85P, NYU 62R/83P, USheffield 66R/74P, SRA baseline configuration 75R/86P, SRA "noref" configuration 74R/87P, SRI 74R/76P, Sterling Software 72R/83P.
432 8o I ,o l II ii 40 3o 2o ,~ 10- type name alias country locale descriptor ORGANIZATION Slot= Figure 6.
The approximate 5050 split between relevant and nonrelevant texts was Template Level (Doc_Nr) JCCESSION_EVE/~ (Post, Vacancy_Reason) In_and_Out r IN_AND_OUT " Succession Org (New_Status, On_the_Job, Rel Other_Org) j IO Template Element Level PERSON ORGANIZATION 1ame, Per_Alias, (Org_Name, Org_Alias, Org_Descriptor, Per_Title) ~Q0rg_Type, Org_Locale, Org_Country) Figure 7.
Management Succession Template Structure intentional and is comparable to the richness of the MUC3 "TST2" test set and the MUC4 "TST4" test set.
MUC6 56.40 MUC5 EJV 52.75 MUC5 JJV 60.07 MUC5 EME 49.18 MUC5 JME 56.31 Table 4.
He will be succeeded by Mr. Dooner, 45.
7Key to recall and precision scores: BBN 50R/59P, UDurham 33R/34P, Lockheed-Martin 43R/64P, UManitoba 39R/62P, UMass 36R/46P, NYU 47R/70P, USheffield 37R/73P, SRA baseline configuration 47R/62P, SRA "precision" configuration 32R/66P, SRA "recall" configuration 58R/46P, SRI 44R/61P.
The alignment in Figure 2 includes the cepts thei and 016 the7, but not the cepts of6 thei or the7.
Then the left-hand side of Equation (15) is t10 tzo t30 t10 t20 t31 +&quot; +41 t21 t30 tll t21 t31, and the right-hand side is (tip +t11)(t20 ±t21)(t30 +t31)• It is routine to verify that these are the same.
As before we exclude multi-word cepts.
Finally, in (De les promesses, de les promesses!
The orthography for the French sentence in the second example is Voyez les profits qu'ils ont realises and in the third example is Des promesses, des promesses!
Thus, we have translations like (II fait signe que oui I He is nodding), (11 fait un signe de la tete I He is nodding), (II fait un signe de tete affirmatif I He is nodding), or (II hoche la tete affirmativement I He is nodding).
It generates eni, de3, the comma, de16, and dela. f t(f I e) 0 n(0 I e) le 0.497 1 0.746 la 0.207 0 0.254 les 0.155 l' 0.086 ce 0.018 cette 0.011 Translation and fertility probabilities for the. f t(f l e) 0 n(0 I e) agriculteurs 0.442 2 0.731 les 0.418 1 0.228 cultivateurs 0.046 0 0.039 producteurs 0.021 Translation and fertility probabilities for farmers.
In our experiments, grow-diag outperforms both one-tomany and many-to-one for both MaxMatch and CharBased.
With this setting, MaxMatch is 0.46 BLEU point better than CharBased (29.62 to 29.16) on MT03.
Table 3 shows that the feature-based segmenter CRF-basic outperforms the lexicon-based MaxMatch by 5.9% relative F measure.
We call the 4label extension CRF-Lex-NR.
Acknowledgements: The authors thank Andrew Hogue, Raj Krishnan and Deepak Ravichandran for insightful discussions about this work.
Many algorithms have been proposed for measuring the attributional similarity between two words (Lesk 1969; Resnik 1995; Landauer and Dumais 1997; Jiang and Conrath 1997; Lin 1998b; Turney 2001; Budanitsky and Hirst 2001; Banerjee and Pedersen 2003).
On the same 600 noun-modifier pairs, the VSM had accuracies of 27.8% (30-class) and 45.7% (5-class)  .
Algorithms for measuring attributional similarity can be lexicon-based  , corpus-based (Lesk 1969; Landauer and Dumais 1997; Lin 1998a; Turney 2001), or a hybrid of the two  .
The precision was 120/(120 + 224) and the recall was 120/(120 + 224 + 30).
Turney et al.   combined 13 independent modules to answer SAT questions.
SVD improves both document-query attributional similarity measures   and word–word attributional similarity measures  .
The evaluation used 600 hand-labeled noun-modifier pairs from Nastase and Szpakowicz  .
Turney et al.   combine 13 independent modules to answer SAT questions.
.�F denotes the Frobenius norm  .
10.
12.
Turney and Littman   used 64 manually generated patterns, whereas LRA uses 4,000 automatically generated patterns.
The following experiments use the 600 labeled noun-modifier pairs of Nastase and Szpakowicz  .
Thanks to Vivi Nastase and Stan Szpakowicz for sharing their 600 classified noun-modifier phrases.
spectively.
Word-level alignments were obtained using GIZA++  .
IP=, IP+, VP= and VP+), and NP_ (tying weights of NP= and NP+; see Section 3).
Thus the disjunctions of a formula can be put into the form (uconji Adi sj 11 A ...Adisji.)
Each OR-node represents a disjunction.
Let new-def = UNIFY-DGS (f.definite, g.definite).
Let desc = a feature-description with: desc.definite = new-def, desc.indefinite = tindefinite U g.indefinite.
Let new-desc = CHECK-INDEF (desc, new-def).
Function CHECK-DISJ (disj, cond) Returns disjunction: where disj is a disjunction of feature-descriptions, and cond is a DG. gorithm.
C08 is a grammar containing 98 disjunctions, 2Consider, 23&quot; i:.
N00014-91-1634.
Definition 8 Two subtrees T1, T2 interleave, if there are nodes l1, r1 E T1 and l2, r2 E T2 such that l1 < l2 < r1 < r2.
Both Graph 3a and Graph 3b are well-nested.
Graph 3c is not well-nested.
4.1.4 Position.
4.1.5 Voice.
335-342.
I am also indebted to Vance Gledhill, Mike Johnson, Philip Resnik, Richard Sproat, Wilco ter Stal, Lucy Vanderwende and Wobcke.
2.1.1 Recoverability.
314 Mitchell P. Marcus et al.
sing/VB be/VB do/VB have/VB sings/VBZ is/VBZ does/VBZ has/VBZ sang/VBD was/VBD did/VBD had/VBD singing/VBG being/VBG doing/VBG having/VBG sung/VBN been/VBN done/VBN had/VBN A second example of lexical recoverability concerns those words that can precede articles in noun phrases.
2.1.2 Consistency.
2.1.4 Indeterminacy.
2.2 The POS Tagset The Penn Treebank tagset is given in Table 2.
316 Mitchell P. Marcus et al.
DT Determiner 27.
FW Foreign word 29.
VBG Verb, gerund/present 6.
IN Preposition/subordinating participle conjunction 30.
JJ Adjective 31.
VBP Verb, non-3rd ps.
JJR Adjective, comparative 32.
VBZ Verb, 3rd ps.
JJS Adjective, superlative 33.
WDT wh-determiner 10.
WP wh-pronoun 11.
WP$ Possessive wh-pronoun 12.
WRB wh-adverb 13.
NNS Noun, plural 37.
NNP Proper noun, singular 38.
NNPS Proper noun, plural 39.. Sentence-final punctuation 16.
PDT Predeterminer 40. , Comma 17.
POS Possessive nding 41. : Colon, semi-colon 18.
PRP Personal pronoun 42.
RB Adverb 44. "
RBR Adverb, comparative 45.
RBS Adverb, superlative 46. "
SYM Symbol (mathematical or scientific) 48. "
Thus, childrens is tagged "children/NNS s/POS," and wont is tagged "wo-/MD nt/RB."
317 Computational Linguistics Volume 19, Number 2 Battle-tested/NNP industrial/JJ managers/NNS here/RB always/RB buck/VB up/IN nervous/JJ newcomers/NNS with/IN the/DT tale/NN of/IN the/DT first/JJ of/IN their/PP$ countrymen/NNS to/TO visit/VB Mexico/NNP ,/, a/DT boatload/NN of/IN samurai/NNS warriors/NNS blown/VBN ashore/RB 375/CD years/NNS ago/RB ./.
"/" From/IN the/DT beginning/NN ,/, it/PRP took/VBD a/DT man/NN with/IN extraordinary/JJ qualities/NNS to/TO succeed/VB in/IN Mexico/NNP ,/, "/" says/VBZ Kimihide/NNP Takimura/NNP ,/, president/NN of/IN Mitsui/NNS group/NN s/POS Kensetsu/NNP Engineering/NNP Inc./NNP unit/NN ./.
Battle-tested/NNP*/JJ industrial/JJ managers/NNS here/RB always/RB buck/VB*/VBP up/IN*/RP nervous/JJ newcomers/NNS with/IN the/DT tale/NN of/IN the/DT first/JJ of/IN their/PP$ countrymen/NNS to/TO visit/VB Mexico/NNP ,/, a/DT boatload/NN of/IN samurai/NNS*/FW warriors/NNS blown/VBN ashore/RB 375/CD years/NNS ago/RB ./.
"/" From/IN the/DT beginning/NN ,/, it/PRP took/VBD a/DT man/NN with/IN extraordinary/JJ qualities/NNS to/TO succeed/VB in/IN Mexico/NNP ,/, " /"  says/VBZ Kimihide/NNP Takimura/NNP ,/, president/NN of/IN Mitsui/NNS*/NNP group/NN s/POS Kensetsu/NNP Engineering/NNP Inc./NNP unit/NN ./.
318 Mitchell P. Marcus et al.
(Median speeds per 1,000 words were 22 vs. 42 minutes.)
320 Mitchell P. Marcus et al.
Figure 3 (NBAK (ADJP (ADJ "Battle-tested/JJ") (ADJ "industrial/JJ")) (NPL "managers/NNS"))) (?
(PP (PKEP "up/KP") (NP (NBAR (ADJ "nervous/JJ") (NPL "newcomers/NNS"))))) (?
(PP (PREP "with/IN") (NP (DART "the/DT") (NBAK (N "tale/NN")) (PP of/PKEP (NP (DART "the/DT") (NBAK (ADJP (ADJ "first/JJ")))))))) (?
(PP of/PREP (NP (PROS "their/PP$") (NBAK (NPL "countrymen/NNS")))) (?
(NP (IAKT "a/DT") (NBAK (N "boatload/NN")) (PP of/PKEP (NP (NBAK (NPL "warriors/NNS")))) (VP (VPPKT "blown/VBN") (?
(ADV "ashore/KB")) (NP (NBAR (CARD "375/CD") (NPL "years/NNS")))))) (ADV "ago/KB")) (FIN "./.")))
324 Mitchell R Marcus et al.
The Treebank provides two notational devices to ensure this goal: the X constituent label and so-called "pseudo-attachment."
326 Mitchell P. Marcus et al.
of Agriculture bulletins Library of America texts MUC-3 messages IBM Manual sentences WBUR radio transcripts ATIS sentences Brown Corpus, retagged 231,404 231,404 3,065,776 1,061,166 78,555 78,555 105,652 105,652 111,828 111,828 89,121 89,121 11,589 11,589 19,832 19,832 1,172,041 1,172,041 Total: 4,885,798 2,881,188 Some comments on the materials included: ?
1990; Brill 1991) or the skeletally parsed corpus (Weischedel et al.
1991; Pereira and Schabes 1992).
N0014-85-K0018, byDARPA and AFOSR jointly under grant No.
AFOSR-90-0066 and by ARO grant No.
DAAL 03-89-C0031 PRI.
June 1990, 275-282.
Houghton Mifflin.
"User manual for Fidditch."
"Studies in part of speech labelling."
"Syntactic disambiguation."
"Inside-outside r estimation from partially bracketed corpora."
"Part-of-speech tagging guidelines for the Penn Treebank Project."
"Bracketing uidelines for the Penn Treebank Project."
Veilleux, N. M., and Ostendorf, Mari  .
"Probabilistic parse scoring based on prosodic features."
Weischedel, Ralph; Ayuso, Damaris; Bobrow, R.; Boisen, Sean; Ingria, Robert; and Palmucci, Jeff  .
The Automated Acquisit ion of Topic Signatures for Text Summarizat ion Chin -Yew L in  and  Eduard  Hovy In fo rmat ion  S(:i(umes I l l s t i tu te Un ivers i ty  of Southern  Ca l i fo rn ia Mar ina  del Rey, CA  90292, USA { cyl,hovy }C~isi.edu Abst rac t In order to produce, a good summary, one has to identify the most relevant portions of a given text.
Since many texts may describe all the compo- nents of a comI)lex concept without ever exI)lic- itly mentioning the mlderlying complex concel/t--a tol)ic--itself, systems that have to identify topic(s), for summarization or information retrieval, require a method of infcuring comt)hx concelltS flom their component words in the text.
A summary is gen- erated })ased on what has been (:al)tured or filled in the teml)Iate.
The recent success of infornmtion extractk)n re- search has encoreaged the FI{UM1 ) api)roach.
The SUMMONS   takes tem- l)late outputs of information extra(:tion systems de- velofmd for MUC conference and generating smn- maries of multit)le news artMes.
FRUMP and SUM- MONS both rely on t/rior knowledge of their do- mains, th)wever, to acquire such t)rior knowledge is lal)or-intensive and time-consuming.
I~)r exam-- l)le, the Unive.rsity of Massa(:husetts CIRCUS sys- l.enl use(l ill the MUC-3   terrorism do- main required about 1500 i)erson-llours to define ex- traction lmtterns 2  .
  1)resent a system AutoSlog-TS that generates extraction i)atterns and learns lexical con- straints automatically flom t)rec]assified text to al- leviate the knowledge ngineering I)ottleneck men- tioned above.
ABCNEWS.cona  : De lay  in  Hand ing  F l ight  990   [  robe  to  FB I NI SI3 C l la i tn lan  Jarl leS t la l l  says  Egypt ian  clff icials Iv811l to  I,~view res t l l t s of  t i le  invest igat ion  intcl lhe  cras l l  o f  l lggyptA i r  F l ight  990 before  t i le  case i~ lu r l led  over  Ic, t i le Fi31, Nt lv.
IG - U S. i lxvestigl~lo[~ lLppear to  be leat l i l lg i i Iore thg l l  eveF low~trd t i le poss ib i l i ty  that  one  o f  the  cc~-pilot~ o f  EgyptA i r  F l ight  990 may have de  [ ihera le ly  c rashed t i le p lane  las t  I lafl l lth, k i l l i ng  all 217 peop le  on  board .
to  M Iow Egypt ian  exper ts  to rev iew ev idence  ill t i le case.
Summary Generat ion :  SUMMARIST can pro- duce keyword and extract type summaries.
Ve only activate the position mod- ule, tile tfidfmodule, and the.
496 sulnlllary.
l e lev;tnt  set ,  012 is the  [ r ( !qu(nlcy of Lerm t i t)c- curring in the  ] lol lreleval lt ,  set ,  O21 is the  f le(l l lel l( :y of tt;rnl  [ i?
(Manning ;tnd Sch/itze, I999) t)ag, es 172 l.o 175 for d(!t.ails.
Equation 5 indi- cates that mutual inforntation 6 is an e(tuiwdent mea- sur(.
(:lassify doctunents as relevant or nonrclcwmt according t() tile given topic 2. comt)ut.e the -21oflA wdue using Equation 3 for each Lcrm in the document colle(:Lion "{.
-SUMMAC   that is a sttbset of the TREC collectioliS.
497 TREC Top ic  Da~cr lp t ion (nunQ Number :  151 ( t i t le}  Top ic :  Co, p ing  w i th  overc rowded pr i sons (dese} Deser i l l t io l l : The  doeu l laent  will p rov ide  in f ,~rn lat ion ol~ jai l  and  pr ison overc rowd iuK and  how i r lmates  are forced to cope  wi th  th,~se cond i t ions ;  or it wil l revea l  p lan~ to  re l ieve  ti le overc rowded ?o l ld i t lon .
(nar t )  Nar ra t ive : A re levant  docunaent  will descr ibe  scene~ of overcro~vdi l lg that  have beco lne  all too  crlllllllOll ill ja i l s  and  pr i sons  a ro t tnd  the  count ry ,  T i le document  will i dent i fy  how inmates  are forced to  cope w i th  those  over - crowded cond i t ion~,  and/or  what  ti le Cc l r reet iona l  Syste l l l  is do ing ,  or ph lnn ing  to do,  to a l lev ia te  ti le c rowded col ld i t io l l .
(/top) Test  Quest ions QI  Mehat are  name and/or  locat ion  of ti le cor rec t ion  fae i l i l ies where  the  repor ted  ~vercrowd ing  ex is ts?
Q2 x~Vhat negat ive  exper iences  have  there  been  at t i le overc rowded fac i l i t ies  (whether  or not tile)" are thought  to have  been  caused by  the  overc rowd lng)?
,  morator iums on admisMon,  a l te rnat ive  pena l t ies ,  p rograme to reduce c r ime/ rec ld iv i sm?
Q5 What  measures  have  been  taken/p lanned/ recommended (e tc . )
g rant ing  ear ly  re lease ,  t rnns fer ing  to  uncrowded fac i l i t ies?
Sample  Answer  Keys (DOCNO)  AP891027-0063 ( /DOCNO) (F ILE ID)  AP -NR-  10-27-89 0615EDT( /F ILE ID) ( IST_L INE) r  a PM-Cha ined Inmates  10-27 0335( / IST .L INE) (2ND-L INE)PM-Cha ined  lnmates ,0344 ( /2ND_L INE) ( I IEAD)  lnmates  Cha ined  to 1.Vails in 13Mtimore Po l i ce S ta t ions ( / l lEAD) (DATEL INE)BALT IMOIT IE  (AP)  ( /DATEL INE} (tEXT) (Q ,q )pr i soner~ are  kept  cha ined  to the wall~ of local po l ice  lcJekup~ for as long as th ree  days  at a t ln~e I)ecattse of overc rowd ing  ill regu la r  je l l cel ls ,  pol ice sa id .
( /Q3} Overcrowd ing  at  the  (Q1) lqMt l rnore  County  Detent ion  Center ( /Q1) h~ forced pn l lee  tn  .
9,Ve use the stopword list supplied with the SMAIIT re- trieval system.
i  67  ,3(~t~ ~h+.
6.1 Comparing Summary Extraction Effectiveness Using Topic Signatures+ TFII)t",  and Bas(,line Algor i thms In orde)" I() (~vahla(.
Sllltllll~tly StHII~011(CS ex(~ract,(~d 1)y the tol) ic si~Ilil[lll0, module+, basulin(.
module, and tfidf lnothll(~s with lm- ntan annot,  at(~(l lllo(lo,] Sllllllll}llios.
f~rln fVln ~,, # of  .sc,tcncc.~ c:rtratcd th,t  olso atqwar in.
The tfidf module assigns a score t.o a tt++rllI ti at:cord- ing to the product; of its flequc, ncy within a dot:- lllll(Hlt .j ( t f i j )  and its illV(~IS(} doctmmnt  t?equoncy (idfi lo.q ,~).
to t, lw sigmmlre topic.
SU.~[.MAt/IST Inoduced (!xttat:ts of tlm samu l(~xI.q sui)aralely for each ,,lodul0, for a s(~li(,s of ex- tracts ranging from ()cX; to 100% of the.
Althottgh many rel<want docttments are avaita})l+, for each t01>ic, Ollly SOlll0 o[ [h0111 htlv(~ allSWOl kc!y 499 markut)s. The mnnber of documents with answer keys are listed in the row labeled: "# of Relevant Does Used in Training".
References Eneko .~girre, Olatz Ansa, Edumd Hovy, and David Martinez.
Word as- sociation IIOrlllS, mutual information and lexicog- raphy.
In ~2mdy G. Lehnert and Martin H. Ringle, editors, Strategies for natural language processing, pages 149-76.
Lawrence Erlbaum A.s- so(lares.
Computa- tional Linguistics, 19:61--74.
Compu- tational Linguistics, 23:33-64.
Eduard Hovy and Chin-Yew Lin.
Automated text summarization i SUMMAIRIST.
In Inder- jeer Mani and Mark T. Maybury, editors, Ad- vances in Automatic 71xxt Summarization, chap- ter 8, pages 81 94.
Kevin Knight and Steve K. Luk.
500 -~  ..~:,., .
- -=-"  _..  _ .
-~-- - .a  ~  .
"~" ~ 257 44" ?
:ms o.a-~9 I o..~.o o.aa4 o .
.a t , ,  I e.a.~w-I +4.58 +7.48 +15.6a +14.17 +8.66 +3.
, 257_,~i,ic.~ig +45.5~ +64.06 +31.88 ~ +20.40 [ +20.60 [ 4_-~01 +12.4&- I14 .24  - O.
Cohmms indicate at diffe.rent summary lengths related to fldl length docum(mts.
Inderje(?t Mani, David House, Gary KMn, Lyn(~tt(~ ttirschman, Leo ()brst, Thdr6se Firmin, Micha(d Chrzanowski, and Beth Sundheim.
The T IPSTER SUMMAC t~xl smmnmiza- tion evaluation final r(:t)ort.
%~(:hnical I/,ol)orl; MTR98W0000138, The MITRE Corporation.
Christopher Manning and Hinrich Schiitzc.
1999. t}mdatious of Statistical Natural Language Pro~ cessing.
In hMtu.iet~t Mani and Mark T. Maybury, edi t,ors, Admm.ces in Automatic Text Sv,.mmarization, chapter 24, pagc+s 381 :/89.
Ellen Riloff and Jeffrey Lorenzen.
Kluwer Academic Publishc, r.q.
Jinxi Xu and W. Bruc(!
In lrocee.dings of the 17th Annual International A(JM SIGIR Cot@rence.
Starting with 100k words of parallel data, we eventually collect 20M words of in-domain Arabic-English data and 90M words of in-domain Chinese-English data.
Utiyama et al.   use the BM25   similarity measure.
Heidon 1985; Markowitz, Ahlswede, and Evens 1986; Byrd et al. 1987; Nakamura and Nagao 1988; Klavans, Chodorow, and Wacholder 1990; Wilks et al.
2.3.2 Thesauri.
Resnik 1995b).
3.1.1 Microcontext.
(Hayes 1977a, 1997b; Wilks 1973 and 1975b; Hirst 1987).
3.2.2 Granularity.
3.3.1 Evaluation In Vitro.
3.3.2 Evaluation In Vivo.
4.1.
(he=John) (8b) He vas annoyed by John's call.
(he=John) (8b) He vas annoyed by John's call.
We evaluated all 20 schemas.
Effects of Adjective Orientation and Gradability on Sentence Subjectivity Vas i le ios  Hatz ivass i log lou Depar tment  o1 Computer  Sc ience Co lumbia  Un ivers i l y New York,  NY  10027 vh@cs ,  co lumbia ,  edu Janyce  M.  Wiebe Depar tment  o f  Computer  Sc ience New Mex ico  State Un ivers i ty Las  Cruces ,  NM 88003 w iebe@cs ,  nmsu.
Tiffs paper explores lira benelits that some lexical fea- tures of adjectives offer lor the prediction of a contexlual sentence-level feature, suOjectivity.
Current in- formation extraction and rolricval lechnology focuses al- most exclusively on lhe subject matter of the documcnls.
Then, Sec- tion 3 presents a novel method for learning gradablc ad- jectives using a largo corpus and a statistical feature com- bination naodel.
3 Gradability Gradability (or grading) (Sapir, 1944; Lyons, 1977, p. 27 I) is the semantic property that enables a word to par- ticipate in comparative constructs and to accept mod- ifying expressions that act as intensitiers or diminish- ers.
This rel- ativism in the interpetation of gradable words indicates that gradability is likely to be a good predictor ?71 subjec- tivity.
This statistical model is particularly suited for model- ing variables with a "yes"-"no"  .
302   was nlanually annotated with sub- jeciivity chlssifications.
Bruce and Wiebe   performed a statistical anal- ysis of the assigned classitications, linding lhat ac(iec- tivcs are statistically signilicantly and positively corre- lated with subjective sentences in the corpus on the basis (, .
  term dynamic, which "denote qualities that a,e thoughl to be subjecl to con- trol by the possessor" (p. 434).
IZxamples are "kind" and "careful".
In 10-fold cross valida- lion experiments applied to the corpus described above, a probabilislic lassilier oblaincd an average accuracy on subjectivity lagging of 72.17%, nlorc Ihan 20 perccnlage poinls higher than the baseline accuracy obtained by al- ways choosing tile nlore frcquent class.
By wirying 1tlo sot (e.g., all adjeclives, only gradable adjectives, only nega- tively orienied adjectives, etc.)
we call assess the t, seful- heSS of ihe additional knowledge for predicting subjec- livity.
The lifth cohimn gives 111c onditional probability that a sentence is subjective.
givell that (tile of iilorc illstatices of ti/enlbcl+S of +5; ap- pears.
In nlany cases where statistical signilicance Iwe applied achi-square l st Oll the 2 x 2 cross-classificalion able  .
Adjeclive Set S # Subj Sents with (s G ,5) + Dyn Adjs fq S of L5.
# Obj Sents l(Subj Sent I Significance with (s G ,5) + (~ e S) +) Against maiority Against all adjs All Adjectives 403 321 0.56 0.0041 N/A Dynamic Adjectives 92 32 0.74 1.1989 ?
1.0 - r  1..6369 - 10 -4 Pol+, man 138 87 0.61 0.0007 0.1546 Pol- ,  man 79 37 0.67 0.0001 0.0158 Pol+ U Pol- ,  man 197 114 0.63 6.91.91 ?
10 -~ 0.0260 Grad, man 193 115 0.63 1.9633 ?
10 -~ 0.0440 Not Grad, man 172 147 0.54 0.1084 0.6496 to1+, auto 121 79 0.60 0.0026 0.2537 Pol- ,  auto 61 21 0.74 1.1635 ?
10 -~ 0.0017 PoI+ U Io1--, auto 170 95 0.64 8.5888 - 10 -~ 0.0202 Grad, auto 30 14 0.68 0.0166 0.1418 Not Grad, auto 63 51 0.55 0.2079 0.9363 51 19 0.73 0.0001 0.0081 8.0397.10 -~ Dyn Adjs 71 S of L6.
39 8 0.83 l)yn Adjs 71 S of L I0.
50 19 0.72 0.0002 0.0103 Dyn Adjs 71 S ofLl  I 7 2 0.78 0.1582 0.3220 Grad 71 Pol+, man 90 58 0.61 0.0070 0.2891 Grad 71 Pol-,  man 35 I6 0.69 0.0080 0.09711 Grad 71 (Pol+ U Pol-), man 119 71 0.63 0.0005 0.1000 Grad fl Pol+, auto 13 6 0.68 0.1376 0.3833 Grad n Pol-,  auto 2 0 1.00 0.4556 0.5838 Grad 71 (Pol+ U Pol-), auto 15 6 0.71 0.0636 0.2255 l)yn Adjs N S o1 L22.
Some subjective features are included in exist- ing ontologies (for example, Mikrokosmos (Mahesh and 304 Nirenburg, 1995) includes atlitude slots).
References I)ouglas M. Bates and 1)onald G. Watts.
Edwin L. Battistella.
Markedness: 7he Evahiative Siq~etwtructure qfLanguage.
Rebecca Bruce and ,lanyce Wiebe.
Association for Computa- tional Linguistics.
Vasileios Hatzivassiloglou and Kathlcen R. McKeown.
Combining and slandardizing large-scale practical ontologies for machine lransla- lion and other uses.
Jerrold J. Kalz.
Kevin Knight and Steve K. Luk.
Building a large- scale knowledge base liw machine hanslation.
Ill Pro- ceedi,gs o[" the 12th Natio,al Co,ference o, Artifi- cial l,telli,q,e, ce (AAAI-94), w)lume 1, pages 773-778, Sealtlc, Washinglon, July-Augt, st. American Associ- ation for Artificial Intelligence.
Adrienne Lehrer.
K. Mahesh and S. Nirenburg.
A siluated ontol- ogy for practical NLP.
In Pmceedi,gs of the Work- shol~ oil Basic Ontological Issues in Knowledge Shar- ing, 14th lntenmtio,al.loi, t Co,ference oil Artificial Intelligence (LICAI-95), MontrEal, Canada, Augusl.
Milchell E /Vlarcus, Beatrice Santorini, and Mary Ann Marcinkiewicz.
Building a large aunotaled cor- pus of Fmglish: the Penn Treebank.
I~tandolph Quirk, Sidney Grecnbaum, Geoffrey l,eech, alld Jall Svartvik.
A Complvhe,sive Grammar elthe English l.cmguage.
Sanlner and Diane E. l)uffy.
l~hilosol;hy qfScie,ce, 2:93-116.
J. Wiebe, R. Bruce, and T. OHara.
Develop- ment and use of a gold standard ata set for subjec- tivity classilieations.
44NMINVitta (Ben gang de jing ji qian jing yu zhang gu6, te bie shi guang dong sheng de jing ji qian jing xi xi xiang guan.)
(WO win quin zhi chi ta de yi jian.)
Mt (Zhe xie an pai ke jia qiing wo men ri hOu wei chi jin r6ng wen ding de neng 11.)
These arrangements will enhance our ability to maintain monetary stability in the years to come. tWt, ftRAMT.A1t: ZOM, ftrig*IliTtAtIttM3R/OIAMPfiEfissi R. wa zai ke yl ken ding de shuO, wO men jiang hul ti gong wei di dao ge xiang zhii yao mu biao suO xil de jing fei.)
A coarse evaluation of (Xiang gang de an ding fan rong shi WO men sheng hu6 fang shi de zhi Hong Kong's stabilize boom is us life styles's pillar.
44NMINVitta (Ben gang de jing ji qian jing yu zhang gu6, te bie shi guang dong sheng de jing ji qian jing xi xi xiang guan.)
(WO win quin zhi chi ta de yi jian.)
(Zhe xie an pai ke jia qiing wo men ri hOu wei chi jin r6ng wen ding de neng 11.)
These arrangements will enhance our ability to maintain monetary stability in the years to come. tWt, ftRAMT.A1t: ZOM, ftrig*IliTtAtIttM3R/OIAMPfiEfissi R. gu'o, wa xian zai ke yl ken ding de shuO, wO men jiang hul ti gong wei di dao ge xiang zhii yao mu biao suO xil de jing fei.)
Levinger et al.   developed a context-free method in order to acquire the morpho-lexical probabilities, from an untagged corpus.
Bar-Haim et al.   developed a word segmenter and PoS tagger for Hebrew.
4.1 Normal-Form Constraints.
For exam ple, NP/NP could combine with NP/NP accordingto CCG?s combinatory rules  .
SUPERTAGGING/PARSING TIME SENTS WORDS CONSTRAINTS SEC /SEC /SEC ? = 0.01?
0.1 3 523 0.7 16 CCGbank constraints 1 181 2.0 46 Eisner constraints 995 2.4 55 ? = 0.1?
Thenew strategy increases the F-score over labelled de pendencies by approximately 0.5%, leading to the figures reported in Clark and Curran  .
Sarkar etal.
Kaplan et al   report high parsing speedsfor a deep parsing system which uses an LFG gram mar: 1.9 sentences per second for 560 sentencesfrom section 23 of the Penn Treebank.
Overview of BioNLP Shared Task 2011
The task setup and data since have served as the basis for numerous studies (Miwa et al., 2010b; Poon and Vanderwende, 2010; Vlachos, 2010; Miwa et al., 2010a; Bj¨orne et al., 2010).
The REL task (Pyysalo et al., 2011b) involves the recognition of two binary part-of relations between entities: PROTEIN-COMPONENT and SUBUNITCOMPLEX.
BioNLP-ST 2011 received 46 submissions from 24 teams (Table 3).
In Eq.
In Eq.
Large scale parsing-based statistical machine translation  , Quirk et al.  , Galley et al.
0713448 and 0840112.
More precisely, we need to process left-dependents bottom-up and right-dependents top-down.
SemEval-2007 Task 15: TempEval Temporal Relation Identification
Thiscomplication was not necessary for the Tem pEval data.
The EVENT and TIMEX3 annotations were takenverbatim from TimeBank version 1.2.2 The annota 2TimeBank 1.2 is available for free through the Linguistic Data Consortium, see http://www.timeml.org for more 76tion procedure for TLINK tags involved dual annotation by seven annotators using a web-based anno tation interface.
77
A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars E. Black, S. Abney, D. Flickenger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. I(lavans, M. Liberman, M. Jl4arcus, S. Roukos, B. Santorini, T. Strzalkowski IBM Research Division, Thomas J. Watson Research Center Yorktown Heights, NY 10598 The problem of quantitatively comparing tile perfor- mance of different broad-coverage rammars of En- glish has to date resisted solution.
"go there", "has been laughing" - ?
"laughing", "does sing it correct ly" - ?
"sing it correctly", but not: "is a cup", "is blue", "has a dollar", "does the laundry" (b) "Not" E.g.
"precisely asleep, John sort of dozed" (c ) Pre- inf init ival "to" E.g.
"she opted retire", "how to construe it" - ?
ILorisl mother" (i.e.
-> This is it A l l - -or  almost al l - -of  them -> All or almost all of  them But leave as is: 13,~56 18.2gl 13/17/g01 111:301 Ip.m.I I1)1 Ieh.D.I IU.N.
2007; Giampiccolo et al. 2008).
This method yields a corpus containing approximately 140, 000 quasi-parallel sentence pairs {(E1, E2)}, where E1 = e11e21 ... em1 , E2 = e12e22 ... en2.
In recent years, a number of such fora have been made available to the automatic paraphrasing community (Inui and Hermjakob 2003; Tanaka et al. 2004; Dras and Yamamoto 2005; Sekine et al.
Domain-Specific Paraphrasing.
Four CLTE corpora have been created for the following language combinations: Spanish/English (SP-EN), Italian/English (IT-EN), French/English (FR-EN), German/English (DE-EN).
FBK [cross lingual, compositional & multiclass] (Mehdad et al., 2012a) uses cross-lingual matching features extracted from lexical phrase tables, semantic phrase tables, and dependency relations (Mehdad et al., 2011; Mehdad et al., 2012b; Mehdad et al., 2012c).
We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al., 2003; Koehn, 2004a), against our system.
S. D. G.
Mixture-Model Adaptation for SMT
Fass   describes Met*, a system for interpreting nonliteral language that builds on Wilks   and Wilks  .
A Multi-Pass Sieve for Coreference Resolution
FA8750-09-C-0181.
Cicchetti, Domenic V. and Alvan R. Feinstein.
1990.
1960.
Tagging for many phenomena, such as dialogue acts (Carletta et al. 1997; Di Eugenio et al.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
2.1 Prepositions.
2.2 Determiners.
169
Izumi et al   train a maximum entropy classifier to recognise various er rors using contextual features.
Finally, Gamon etal.
5.1 Prepositions.
172 %of training data Prec.
6.1 Working with L2 text.
6.2 Prepositions.
6.3 Determiners.
175
= c cw c cw c cwcw ji ji ji mimi mimi w,wsim 22
4.1.
4.3.
6.1.
1Available at www.cs.ualberta.ca/~lindek/minipar.htm.
6.2.
6.3.
DATA SET TOTAL WORDS m Average # of Features TOTAL CLASSES S13403 13403 250 740.8 202 S3566 3566 3500 2218.3 150 DATA SET TOTAL WORDS M Avg.
Features per Word 13403 250 740.8 3566 3500 2218.3 Table 2.
ALGORITHM S13403 S3566 CBC 60.95 65.82 K-means (K=250) 56.70 62.48 Buckshot 56.26 63.15 Bisecting K-means 43.44 61.10 Chameleon n/a 60.82 Average-link 56.26 62.62 Complete-link 49.80 60.29 Single-link 20.00 31.74 ( ) ( ) c cwnc cprecision ?= CBC discovered 943 clusters.
Walker et al. [forthcoming] and Boguraev and Briscoe [1988]).
Hobbs et al. 1988; Charniak and Goldman 1988).
Katz and Fodor 1963; Karttunen 1971, 1974; Seuren 1985).
Dowty 1991).
Levin 1989; Dowty 1991).
Jackendoff 1983).
Wilks 1975a; Katz 1972; Lakoff 1971; Schank 1975).
Quillian 1968; Collins and Quillian 1969; Fodor 1975; Carnap 1956; Brachman 1979).
Katz and Fodor 1963; Katz 1972; Wilks 1975; Schank 1975).
Grimshaw 1990 and Pustejovsky 1991).
Pustejovsky 1991; Moens and Steedman 1988).
Dowty 1989 and Chierchia 1989).
Hinrichs 1985; Moens and Steedman 1987; and Krifka 1987).
Dowty 1979).
Grimshaw 1979; Elliott 1974).
Ingria and Pustejovsky 1990).
Additional evidence for this distinction is given in Pustejovsky and Anick   and Briscoe et al.  .
2a.
Pustejovsky and Boguraev [1991] for discussion).
Lakoff [1987] and Pustejovsky and Anick [19881): a. John crawled through the window. b.
Copestake and Briscoe [1991] for details).
  and Evans and Gazdar (1989, 1990).
Touretzky 1986).
Pustejovsky 1991).
Barselou 1983).
This issue is explicitly addressed in Briscoe et al.   as well as Pustejovsky and Briscoe  .
LBRANCH and RBRANCH choose the left- and right-branching structures, respectively.
This overproposal drops span-2 precision.
Its most frequent members are a mix of obvious distituents (IN DT, DT JJ, IN DT, NN VBZ) and seemingly good sequences like NNP NNP.
0121285.
The analyser--and therefore the generator includes exception lists derived from WordNet (version 1.5: Miller et al., 1993).
Karttunen et al.  ).
We have described a generator-for -English flectional morphology.
1991; Gale & Church 1993; Church 1993; Dagan & Church 1994; Simard et al. 1992; Chen 1993; Melamed 1995; Wu & Xia 1994; Wu 1994; Smadja et al.
Hierarchical Phrase-Based Translation  
5.3.1 Rescoring.
5.3.2 Intersection.
5.3.3 Pruning.
We compared Hiero against two baselines: the state-of-the-art phrase-based system ATS (Och et al. 2004; Thayer et al.
I would like to thank Liang Huang, Philipp Koehn, Adam Lopez, Nitin Madnani, Daniel Marcu, Christof Monz, Dragos Munteanu, Philip Resnik, Michael Subotin, Wei Wang, and the anonymous reviewers.
S. D. G.
The conditional probability of this type of error is E2: |sum1 |<9 |sum2 |but at a lower order |sum1 |==n |sum2|.
 ) of the well-known Cocke-Younger-Kasami  .
This should be tagged as/RB X/{RB,JJ} as/IN in the Penn Treebank.
This differs from document-to-document 204 or query-to-document comparison.
It serves as the first component of a domain-independent multidocument summarization system [McKeown et al. 1999] which generates a summary through text reformulation [Barzilay et al.
The Lancaster treebank uses 195 part-ofspeech tags and 19 non-terminal labels.
The Penn Treebank uses 46 part-of-speech tags and 27 non-terminal labels.2 The WSJ portion of the Penn Treebank is divided into 25 sections, numbered 00 - 24.
Identifying Semantic Roles Using Combinatory Categorial Grammar
only Total list size 8, 211 1, 336 Total adjectives 1, 904 1, 336Tags assigned Positiv, Nega tiv or no tag Positiveor Nega tive Adj.
The availability 8GI-H4 contains 1268 and HM list has 1336 positive andnegative adjectives.
As an illustrative example of our method, consider the following German sentence, together with a “translation” into English that follows the original word order: Original sentence: Ich werde Ihnen die entsprechenden Anmerkungen aushaendigen, damit Sie das eventuell bei der Abstimmung uebernehmen koennen.
This sentence contains two clauses: Clause 1: Ich/I werde/will Ihnen/to you die/the entsprechenden/corresponding Anmerkungen/comments aushaendigen/pass on Clause 2: damit/so that Sie/you das/them eventuell/perhaps bei/in der/the Abstimmung/vote uebernehmen/adopt koennen/can These two clauses illustrate a number of syntactic phenomena in German which lead to quite different word order from English: Position of finite verbs.
Another example concerns verb-particle constructions, for example in Wir machen die Tuer auf machen and auf form a verb-particle construction.
Philipp Koehn was supported by a grant from NTT, Agmt. dtd.
6/21/1998.
The mutual information is log2 7N/(84 x 481) = 9.48.
The first 100 verbs are: refrain/vb, gleaned/vbn, stems/vbz, stemmed/vbd, stemming/vbg, ranging/vbg, stemmed/vbn, ranged/ vbn, derived/vbn, ranged/vbd, extort/vb, graduated/ vbd, barred/vbn, benefiting/vbg, benefitted/vbn, benefited/vbn, excused/vbd, arising/vbg, range/vb, exempts/ vbz, suffers/vbz, exempting/vbg, benefited/vbd, prevented/vbd (7.0), seeping/vbg, barred/vbd, prevents/ vbz, suffering/vbg, excluded/vbn, marks/vbz, profiting/ vbg, recovering/vbg, discharged/vbn, rebounding/vbg, vary/vb, exempted/vbn, separate/vb, banished/vbn, withdrawing/vbg, ferry/vb, prevented/vbn, profit/vb, bar/vb, excused/vbn, bars/vbz, benefit/vb, emerges/ vbz, emerge/vb, varies/vbz, differ/vb, removed/vbn, exempt/vb, expelled/vbn, withdraw/vb, stem/vb, separated/vbn, judging/vbg, adapted/vbn, escaping/vbg, inherited/vbn, differed/vbd, emerged/vbd, withheld/vbd, leaked/vbn, strip/vb, resulting/vbg, discourage/vb, prevent/vb, withdrew/vbd, prohibits/vbz, borrowing/vbg, preventing/vbg, prohibit/vb, resulted/vbd (6.0), preclude/vb, divert/vb, distinguish/vb, pulled/vbn, fell/ vbn, varied/vbn, emerging/vbg, suffer/vb, prohibiting/ vbg, extract/vb, subtract/vb, recover/vb, paralyzed/ vbn, stole/vbd, departing/vbg, escaped/vbn, prohibited/ vbn, forbid/vb, evacuated/vbn, reap/vb, barring/vbg, removing/vbg, stolen/vbn, receives/vbz.
Alshawi et al.   use hierarchical finite-state transducers.
Zhang and Gildea   found ITG to outperform the tree-to-string model for word-level alignment, as measured against human gold-standard alignments.
This work was partially supported by NSF ITR IIS-09325646 and NSF ITR IIS-0428020.
Semi-supervised models such as Ando and Zhang  , Suzuki and Isozaki  , and Suzuki et al.   achieve state-of-the-art accuracy.
The model is discriminative and nonprobabilistic.
The linear CRF chunker of Sha and Pereira   is a standard near-state-of-the-art baseline chunker.
For example, 1980 becomes *DDDD* and 212-325-4751 becomes *DDD**DDD*-*DDDD*.
RCV1 is a superset of the CoNLL03 corpus.
We induced embeddings with 25, 50, 100, or 200 dimensions over 5-gram windows.
We induced embeddings with 100 dimensions over 5-gram windows, and embeddings with 50 dimensions over 5-gram windows.
We compare to the state-of-the-art methods of Ando and Zhang  , Suzuki and Isozaki  , and—for NER—Lin and Wu  .
Given the improvements to the C&W embeddings since Turian et al.  , C&W embeddings outperform the HLBL embeddings.
Suzuki and Isozaki   present a semisupervised extension of CRFs.
Thank you to Andriy Mnih for inducing his embeddings on RCV1 for us.
FA8750-09-C-0181.
2.1 Data.
Search Web Ser vices (http://developer.yahoo.com/search/web/).
2.3 Baselines.
68 Macro-averaged Scores F-measures rank team-id ? =,5 ? =,2 Pur Inv Pur 1 CU COMSEM ,78 ,83 ,72 ,88.
2 IRST-BP ,75 ,77 ,75 ,80.
3 PSNUS ,75 ,78 ,73 ,82.
5 SHEF ,66 ,73 ,60 ,82.
6 FICO ,64 ,76 ,53 ,90.
7 UNN ,62 ,67 ,60 ,73.
8 ONE-IN-ONE ,61 ,52 1,00 ,47.
9 AUG ,60 ,73 ,50 ,88.
10 SWAT-IV ,58 ,64 ,55 ,71.
11 UA-ZSA ,58 ,60 ,58 ,64.
12 TITPI ,57 ,71 ,45 ,89.
13 JHU1-13 ,53 ,65 ,45 ,82.
14 DFKI2 ,50 ,63 ,39 ,83.
15 WIT ,49 ,66 ,36 ,93.
16 UC3M 13 ,48 ,66 ,35 ,95.
17 UBC-AS ,40 ,55 ,30 ,91.
18 ALL-IN-ONE ,40 ,58 ,29 1,00.
The header dataset contains 935 headers.
Semantic-Head-Driven Generation
J. Saffran, E. Newport, and R. Aslin.
1996.
M. Sun, D. Shen, and B. Tsou.
1998.
Y. Teh, M. Jordan, M. Beal, and D. Blei.
2005.
Y. Teh.
2006.
A. Venkataraman.
2001.
Kozima  , for examthen and hold.
The ILEX project is supported by EPSRC grant GR/K53321.
Cardelli and Wegner 1985).
Fillmore 1968; Lakoff 1968, 1970).
Evans and Gazdar 1990; Copestake and Briscoe 1992; Russell et al. 1992).
Techniques for identifying explicit information in machine-readable dictionaries have been developed by many researchers (Boguraev et al. 1989; Slator 1988; Slator and Wilks 1987; Guthrie et al.
Alshawi  , Boguraev et al.  , Vossen, Meijs, and den Broeder  , and the work described in Wilks et al.
Lakoff 1987 and Martin 1990).
Hindle 1990).
Church and Hanks 1990; Klavans, Chodorow, and Wacholder 1990; Wilks et al. 1993; Smadja 1991a, 1991b; Calzolari and Bindi 1990).
The renormalization needed in Eq.
12.
Komagata  .
Non-local information, such as arity  .
There has been extensive work on data-driven dependency parsing for both projective parsing (Eisner, 1996; Paskin, 2001; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004; McDonald et al., 2005a) and non-projective parsing systems (Nivre and Nilsson, 2005; Hall and N´ov´ak, 2005; McDonald et al., 2005b).
Let |xα |= nα and p(T |nα) = βα.
Let xαi be the ith word of xα.
tem: Experiments in Automatic Document Pro- M. Sanderson.
1994.
A.F.
Smeaton and A. Quigley.
1996.
A. Smeaton, F. Kelledy, and R. O'Donnell.
1995.
M. Voorhees.
1994.
First- and Second-Order Expectation Semirings with Applications to Minimum-Risk Training on Translation Forests
By that semiring’s definitions of ® and � ( PdED QeEd ke, PdED PeEd(Qe0Ed,e0�e ke0)xe).
The second component (giving ˆx) can be rearranged into Pe Pd: eEd(Q7e''Ed,e0�e ke0)xe = Pe kexe, where ke def Pd: eEd (l le0Ed,e0�e ke0) is found from Q, α.
We plan to incorporate more informative features described by Chiang et al.  .19
We applied the approach proposed in (Zhao et al., 2008b).
Baseline-2: Baseline-2 extends Baseline-1 by combining multiple resources.
On-Demand Information Extraction
(Riloff 96), (Agichtein and Gravano 00) and (Yangarber et al. 00).
We would like to thank Prof. Ralph Grishman, Dr. Kiyoshi Sudo, Dr. Chikashi Nobata, Mr. Takaaki Hasegawa, Mr. Koji Murakami and Mr. Yusuke Shinyama for useful comments, discussion.
in the seutence "The 1977 P6s could store two pages of data.
Jelinek   and Cutting et al.
Nakamura el; al.
Using tile predictor, Nakamura et al.
It is simi- lar to tile network of Nakamura et al.
At each unit j ,  the weighted inlmt activations aiwij are summed and a bias pa- rameter Oj is added.
For a de.tailed introduction to MLP networks see e.g.
r 4 Tt IG  I~_AGGER NI i  ,TWO1{I ( The Net-Tagger consists of a Ml, P-network and a lex- icon (see tlg.
suffix ess 10 I gp /  <iS l_5 __1 2 t~a~ 143 sufllx ness suffix less 1 85 2 8 45 0 0 2 48 95 labeled i.
l o ,a~- -  ... ~ 1.32 (9) 143 143 143 143 ].lie corresponding values for the chihl nodes are 0.39 for hess and 0.56 for less.
6We used a gain threshohl of 10.
, 95 .=_ 90 ~ ?
:~ 85 Net-Tagger - " - ~o= Xer0x-Tagger .... o J 80 -~ Trigram Tagger -=- 75 ..,I .
I 10000 100000 1 e+06 size of training corpus estimate 110,592 trigrams, the Net-Tagger only has to train 13,824 network parameters.
8 REFERENCES Church, K. W.  .
Pro- ceedings of the Second Conference on Applied Natvral Language Processing, p. 136-143.
Cutting, D., a. Kupiec, a. Pedersen and P. Sibun  .
Federici, S. and V. Pirrelli  .
Analogical mod- elling of text tagging, unpublished report, Istituto di Linguistica Computazionale, Pisa, Italy.
B and G. M. R.ubin  .
Auto- matic grammatical tagging of English.
aelinek, F.  .
In J.K. Skwirzinski Ed., Impact of Pro- cessing Techniques on Communication, Nijhoff, Dor- drecht.
Lippmann, R.. P.  .
Marnyama, T. Kawabata and K. Shikano  .
l(arlgren Ed., COLING-90, lIelslnki University, p. 213-218.
Rumelhart, D. E. and J. L. McClelland  .
Par- allel Distributed Processing.
for Recall-Oriented Understudy for Gisting Evaluation.
We call the LCS-based F-measure, i.e.
Melamed et al.   used unigram F-measure to estimate machine translation quality and showed that unigram Fmeasure was as good as BLEU.
Therefore S2 is better than S3 according to ROUGE-L.
ROUGE-2 would prefer S4 than S3.
LCS∪ (ri, C) is the LCS score of the union longest common subsequence between reference sentence ri and candidate summary C. For example, if ri = w1 w2 w3 w4 w5, and C contains two sentences: c1 = w1 w2 w6 w7 w8 and c2 = w1 w3 w8 w9 w5, then the longest common subsequence of ri and c1 is “w1 w2” and the longest common subsequence of ri and c2 is “w1 w3 w5”.
The union longest common subsequence of ri, c1, and c2 is “w1 w2 w3 w5” and LCS∪ (ri, C) = 4/5.
We call the WLCS-based Fmeasure, i.e.
Equation 15, ROUGE-W.
We call the skip-bigram-based Fmeasure, i.e.
Equation 18, ROUGE-S.
Using Equation 18 with ß = 1 and S1 as the reference, S2’s ROUGE-S score is 0.5, S3 is 0.167, and S4 is 0.333.
Therefore, S2 is better than S3 and S4, and S4 is better than S3.
Comparing skip-bigram with LCS, skip-bigram counts all in-order matching word pairs while LCS only counts one longest common subsequence.
This might due to the double sample size in DUC 2002 (295 vs. 149 in DUC 2001) for each system.
In Table 3 A1, A2, and A3, we show correlation analysis results on DUC 2001, 2002, and 2003 100 words multi-document summarization data.
ROUGE-1, ROUGE-S4, ROUGE-SU4, ROUGE-S9, and ROUGESU9 with stopword removal had correlation above 0.70.
200 and 400 words summaries.
CRFs are presented in more complete detail by Lafferty et al.  .
Supertag.
Srole.
Ssubcat.
This is the surface-syntactic subcategorization frame.
Drole.
Dsubcat.
This is the deep-syntactic subcategorization frame.
Semsubcat.
We now experiment with our surface syntax features: Pred HW, Arg HW, Ssubcat, and Srole.
Our next experiment involves using deep syntax features: Pred HW, Arg HW, Dsubcat, and Drole.
This experiment considers use of semantic features: Pred HW, Arg HW, Semsubcat, and Drole.
The error rates are 2.8% for SEM-TAG and 7.4% for SYNTTAG.
These features may either be directly derived from a TAG, such as Supertag path, or indirectly via aspects of supertags, such Task: determine Recall Precision F base + arg 0.65 0.75 0.70 base + bnd 0.48 0.55 0.51 base + bnd + arg 0.48 0.55 0.51 as deep syntactic features like Drole.
IIS-98-17434.
Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).
Replacing Eq.
Templates C0–C6 are basic character-level unigram features taken from  .
Templates B0-B9 are basic wordlevel bigram features.
F1 =
The out-of-vocabulary  .
Ng and Low   (N&L04) used CTB 3.0.
Zhang and Clark   (Z&C08) generated CTB 3.0 from CTB 4.0.
Jiang et al. (2008a; 2008b) (Jiang08a, Jiang08b) used CTB 5.0.
Shi and Wang   used CTB that was distributed in the SIGHAN Bakeoff.
Our experiment on the large training corpus is identical to that of Jiang et al. (Jiang et al., 2008a; Jiang et al., 2008b).
Following Zhang and Clark  , we first generated CTB 3.0 from CTB 4.0 using sentence IDs 1–10364.
For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).
The second-order features are built from the following conjunctions of word and POS identity predicates xi-pos, xk-pos, xj-pos xk-pos, xj-pos xk-word, xj-word xk-word, xj-pos xk-pos, xj-word where xi-pos is the part-of-speech of the ith word in the sentence.
3.1.2 Experiment.
A morphosyntactic analysis of the text was performed using the Conexor FDG parser7.
The suffixes -lle, -n, -on, and -sta are linguistically correct.
Efficient Normal-Form Parsing For Combinatory Categorial Grammar
Although similar work has been attempted in the past, with varying degrees of success (Karttunen, 1986; Wittenburg, 1986; Pareschi & Steedman, 1987; Bouma, 1989; Hepple & Morrill, 1989; Ki5nig, 1989; Vijay-Shanker & Weir, 1990; Hepple, 1990; Moortgat, 1990; Hendriks, 1993; Niv, 1994), this appears to be the first full normal-form result for a categorial formalism having more than contextfree power.
3.1 Prompts.
3.3 Interruptions.
3.3.3 Clarifications.
The number of OOVs decreased by 19% for hs+ss and by 75% for hs+ss+cs.
Saleem et al.   and Bertoldi et al.
HR0011-06-2-0001.
Following the successful development of wide-coverage lexicalized grammars (Riezler et al. 2000; Hockenmaier and Steedman 2002; Burke et al.
We describe methods for representing HPSG parse trees and predicate–argument structures using feature forests (Miyao, Ninomiya, and Tsujii 2003; Miyao and Tsujii 2003, 2005).
Maximum entropy models   are now becoming the de facto standard approach for disambiguation models for lexicalized or feature structure grammars (Johnson et al. 1999; Riezler et al.
2000, 2002; Geman and Johnson 2002; Clark and Curran 2003, 2004b; Kaplan et al. 2004; Carroll and Oepen 2005).
Inside/outside α-products roughly correspond to inside/ outside probabilities in PCFGs.
This is tractable when ˜|C |and ˜|D |are of a reasonable size.
Compositional semantics usually satisfies the above conditions, including MRS (Copestake et al. 1995, 2006).
Data size (MB) 5, 0.80 108 5,103 341 5, 0.90 150 6,242 407 5, 0.95 190 7,724 469 5, 0.98 259 9,604 549 10, 0.80 130 6,003 370 10, 0.90 268 8,855 511 10, 0.95 511 15,393 727 10, 0.98 1,395 36,009 1,230 15, 0.80 123 6,298 372 15, 0.90 259 9,543 526 15, 0.95 735 20,508 854 15, 0.98 3,777 86,844 2,031 POS features contributed to the final accuracy, although the differences were slight.
Table 14 shows the accuracies for predicate–argument relations when partsof-speech tags are assigned automatically by a maximum-entropy-based parts-ofspeech tagger  .
CRFs are now widely used for sequence-based tasks, such as parts-of-speech tagging and named entity recognition, and have been shown to achieve the best performance in various tasks (McCallum and Li 2003; McCallum, Rohanimanesh, and Sutton 2003; Pinto et al. 2003; Sha and Pereira 2003; Peng and McCallum 2004; Roark et al.
2004; Settles 2004; Sutton, Rohanimanesh, and McCallum 2004).
A series of studies on parsing with LFG (Johnson et al. 1999; Riezler et al.
Most of the state-of-the-art studies on parsing with lexicalized grammars have adopted feature forest models (Clark and Curran 2003, 2004b; Kaplan et al. 2004; Riezler and Vasserman 2004).
2006; Chun 2007).
967
3.1 WMT06.
3.2 Chinese.
107 106 105 1000100101 Phrasetable Size by Pruning Threshold size3 3 333 3 3 3 3 107106105 BLEU by Phrasetable Size no smoothing 3 3 3333 3 3 3 GT (+1) ++ ++++ + + + KN3 (+2) 222222 2 2 2 ZN (+3) ??????
en 688,031 13.4415892 WMT06: es??
en 730,740 13.501813 WMT06: de??
en none 9,314,165 100% 11,591,013 100% 6,954,243 100% 10 7,999,081 85.9% 10,212,019 88.1% 5,849,593 84.1% ??
Phrasetables produced by the standard Diag-.
Mutalik et al.   developed Negfinder, a rule-based system that recognises negated patterns in medical documents.
1 Callison-Burch et al   and Zhang and Vogel   use suffix arrays as follows.
using the phrase extraction method of Koehn et al  .
Both Callison-Burch et al   and Zhang and Vogel   solve this with sampling.
It works on a pattern w1Xw2X...wI consisting of I contiguous substrings w1, w2, ...wI ,each separated by a gap.
4.2 Analysis.
Foreven moderately frequent subpatterns this term dom inates complexity.
5.1 Precomputation.
Our precomputation includes the most frequent n-gram subpatterns.
If |Q| log |D| < |D| then theperformance is guaranteed to be sublinear.
980 5.4 Efficient Enumeration.
Path construction in this subtree proceeds dif ferently.
0 0 0 1000 0 Number of frequent subpatterns Insert text here 41 sec/sent 41 seconds 405 sec/sent 0 MB.
10 Timingresults are reported for machines with 8GB of mem ory and 4 3GHz Xeon processors running Red Hat linux 2.6.9.
Both Callison-Burch et al   and Zhang and Vogel   use suffix arrays to relax the length constraints on phrase-based models.
HR0011 06-2-001.
984
Many statistical parsing methods developed for English use lexicalized trees as a representation (e.g., (Jelinek et al. 94; Magerman 95; Ratnaparkhi 97; Charniak 97; Collins 96; Collins 97)); several (e.g., (Eisner 96; Collins 96; Collins 97; Charniak 97)) emphasize the use of parameters associated with dependencies between pairs of words.
Soon et. al.
Ng   obtains f-score improvements of 2.8-4.5% by tuning the anaphoricity threshold on held-out data.
HR0011-06C-0022.
We are grateful to Jes´us Gim´enez, Dan Melamed, Maja Popvic, Ding Liu, Liang Zhou, and Abhaya Agarwal for scoring the entries with their automatic evaluation metrics.
We thank Yoav Freund and Yishay Mansour for helpful discussions.
  and Polanyi and Scha(1983b).)
  and Polanyi and Scha(1983b).)
i=1 p(ti|t1...ti?1o).
The right-to-left decomposition is P (t1...tn|o) = n?
2.2 Decoding with the Easiest-First Strategy.
word to tag..
Tag the word..
4.1 Part-of-speech tagging experiments.
471 The/DT/4 company/NN/7 had/VBD/11sought/VBN/14 increases/NNS/13 total ing/VBG/12 $/$/2 80.3/CD/5 million/CD/8 ,/,/1 or/CC/6 22/CD/9 %/NN/10 ././3 Each token represents Word/PoS/DecodingOrder.
A perceptron algorithm gives 97.11%  .
Non-heads.
NULL-generated.
We refer this two-stage approach to as two-stage SS-SCM.
These settings match the evaluation setting in previous work such as (McDonald et al., 2005a; Koo et al., 2008).
 ’s secondorder semi-supervised dependency parsers.
Jacquemin   and Barzilay and McKeown   identify phraselevel paraphrases, while Lin and Pantel   and Shinyama et al.   acquire structural paraphrases encoded as templates.
2.1.
Machine-readable dictionaries Jbr WSD.
2.2.
3.1.
, : ' .i \ [ ~ Word Node Sense Node ~ . Excitatory Link ..........................
3.2.
ve?ts?inou nema?
ani za?jem a taky na to ve?ts?inou nema?
Using this spanning tree representation, we extend the work of McDonald et al   on online large-margin discriminative training methods to non-projective depen dencies.
= arg maxx?
Many lan guages that allow non-projectivity are still primarily projective.
  for online large-margin dependency pars ing.
Figure 4 gives pseudo-code for the MIRA algorithmas presented by McDonald et al  .
3.1 Single-best MIRA.
= arg maxy?
We performed experiments on the Czech Prague De pendency Treebank (PDT) (Hajic?, 1998; Hajic?
et al,2001).
COLL1999: The projective lexicalized phrase-structure.
parser of Collins et al  .
N&N2005: The pseudo-projective parser of Nivre and Nilsson  .
McD2005: The projective parser of McDonald et al.
4.1 Results.
ing.
Using this framework, we pre sented results showing that the non-projective modeloutperforms the projective model on the Prague De pendency Treebank, which contains a small number of non-projective edges.
Keller and Lapata   investigated the validity of web counts for a range of predicate-argument bigrams (verbobject, adjective-noun, and noun-noun bigrams).
0.93 0.83 0.88 0.95 0.87 0.91 0.93 0.88 0.91 0.94 0.99 0.96 0.92 0.98 0.95 0.98 0.83 0.90 0.91 0.52 0.66 0.90 0.63 0.74 0.75 0.79 0.77 0.85 0.74 0.79 0.86 0.79 0.82 0.85 0.77 0.81 0.86 0.89 0.88 0.87 0.96 0.92 0.97 0.81 0.88 0.84 0.42 0.56 0.88 0.58 0.70 0.48 0.46 0.47
Jelinek.
1991. language modeling speech In A. Waibel and K.F.
Morgan Kaufmann, 1991 D. Kernighan, K Church and W. Gale.
Kukich.
1992. for automatically corwords in ACM Computing Surveys,
Finally we carry out the 3rd experiment using dictionary look-up plus bi-gram LM.
Im in ns, lik soccer, clubbin hangin w frenz!
Wat bout u mee?
3-gram is
Comlex  Syntax :  Bu i ld ing  a Computat iona l  Lex icon Ra lph  Gr i shm:m,  Cather ine  Mac leod,  and Adam Mcyers Computer  Science Depar tment ,  New York Un ivers i ty 715 Broadw,~y, 7th F loor ,  New York, NY 10003, U.S.A. {gr i s lnnan ,mac leod ,me.yers  } (@cs.nyu.e(ht Abstract We des((tile tile design of Comlex Syntax, a co,nputa- tional lexicon providing detailed syntactic iuformation ff)r approximately 38,000 English headwords.
1 In addil.ion, we have ahned to be irio,e cOrrlpreheiisive ill capturhig featt, res (hi partic.u- ]ar, stibcategorization [eatures) than co,iI,llercial dic tlonaries.
SOllie sauil)le dicticl l ,ary entries are shown ilt F igure 1.
For exaniple> the verb "ai )andon" eali occur with a IlOllri phrase followed by a prepositional phrase with tim preposition "to" (e.g., "1 abandoned hii,i to the linguists.")
()ur resu l t ing  feature sys- ten, includes 92 subcategorization features Ibr w~rbs, 14 for adjectives, and 9 for llO,,ns.
Fur- thermore, the notation allows us to indicate that verl) Irlay haw~ dill>rent control features for different comlflement structmes~ or ewm for dilrerent preposi- tions within the complement.
"), whereas "blanle for" involw,s ol)-.
Earh corn plement ype is formally defined by n fr;uue (see Fig-.
The fhst, s, is for flail sententiM complements with ;m optional "that" eo,nplementizer.
Alth-ugh methods haw~ been dew%ped .ww tile last few years for autovual,ically ideutifyi,g sore,: subcat- i,gorizati(~ll consl,r:tillts I,llrotlgh corpus ;tllulysis [2,5[, these methods are sl,ill lhuited iu the range cf disthlc l, ions they can identify and their Mfility to deal with ](~w-frequency words.
The entry of lexical information is being performed by flmr gll;tdllllte liuguistics studcllts, relerled I.o as elves ("elf" = euterer ,,f lexical features).
Tile elw:s are provided with a memMmsed interl~ce c-ded in C-lu- mort 1,isp using the Garnet GI/I package, aim runuiug on Sun workst.atimls.
Au initial dicti<mary contahlhut ewtries for all the u(u.us, verbs and adjvci,ives ill tile ()AI,I) was coluldetml iu M.y, 1!
tiffs dicti,mary ;tg;tillSt sevela{ SOIIrC(!S, VVe hltelld to C?
We also hltend to mMw COml)ar- is~ms against sewnal corpus deriw~d lists: at the very least, with w!rb/l~reptMthm and w~rb/partMe pairs wit.h high mutual inf, rmation [3] mid, if possible, wil.h the results of recently-developed procedures for ex tractinF, subcai,egorlzal, iou tYames from corpor;t [2,.ti].
creation, it sliould be most wduable as a basis for com- parisons.
The agree- ment rate for examl)les whicti were not flagged was 96% to 98%.
llie "(~oinl~lements only" would corre- spond rougllly to the type of inforinal, ion provided by OALI)  and l,I.
The "COlllpielnc:nl,s q- l>relmsitions/l)articles" colliirin inehides eli the fl,al.ures> tllal, is it, eonsidelS the correct idenl,ill- cation of the conip]einent l)]ilS the sp,~cilie prepo- sil.ions aiid adverbs it!
(lllile(] by eert~thi comple- illonl.s.
Ttie two COlllliiliS of (igiiies iUlder "Ci)ni- l)lenients-t-I>rel>ositions/lari.icles , show tim re- suits with and without the enumeration of dhoe- tional l)reposltlons.
tirne and eliminate errors of rriissing prepo- sitions.
elf # Coml)len,mts only ( ~ mpl ~menls -F I repositions/I)artMes tvithoul.
This was a miss- ing intransitNe.
spec- itied, results ill a lmlcelfl.ag(; of 79.
We haw~ adOld.ed tw.
I)epartment of Energy, aml ;ill additional newspal~er (the Wall ~treet Jnur- Iiztl).
but "Apple is a wonderflfl fla- vor.").
MDA972-92-J-1016 and N00014-90-J-1851, and The IYustees of the University of Pennsylwmia.
Computalional Linguisties, 19(2):243--262, 1993.
Structural ambi- guity and lexieal relations.
In Proceeding.s" of the 29th Annual MeetiT~g of the Assn.
flrr Computa- lional Ling.uislics, pages 229-25;6, Berkeley, CA, June 1991.
A. S. Ilornby, edito,.
Christol)ller Manning.
Automatie acquisition of a large subeategorization dictionary fiom eo,pora.
fl)r Compulalional Linguistics, pages 22/5 242, Columbus, OI1, June 1993.
Standardization of tim complement- ad.iunct distinction.
[7] George Miller, Clm,dia Leaeoek, l{andee Tengl, and Ross Ihmker.
Longman Dictionary of Con- lemporary English.
Long,nan, 1978.
Natural Language Information Pro- cessing.
[10] Antonio Sanlilippo.
In q. Briscoe, A. Copestake, and V. de Iavia, editors, l)cfaull Inheritance in Unification-Based Approaches to Ihe Lexicom Cambridge University Press, 1!)92.
Computational Lin- guistics, 19(2):219-242, 1993.
Target Evaluation Text (labels not used for training) Primarul comunei <place> Rosia Montana </place> judetul <place> Alba </place> <fname> David </fname> <lname> Botar </lname> a intrat in legenda datorita unor intimplari de-a dreptul penibile, relatate in &quot;Evenimentul zilei&quot;.
Practic, primul gospodar al celei mai bogate comune in aur din <place> Muntii Apuseni </place> este mai tot timpul beat-crita, drept pentru care, la oficierea unei casatorii, a sarutat mina mirelui, a strins mina miresei si a intocmit certificat de deces in locul celui de casatorie.
Recent, <fname> Andrei </fname> <lname> Paunescu </lname> fiul poetului, a intentionat sa achizitioneze gospodaria unei bucurestence care se stabilise de o vreme in <place> Rosia Montana </place> La primarie Ins., turmentatul primar 1-a trimis pe fiul lui <fname> Adrian </fname> <lname> Paunescu </lname> sa-i cumpere ceva de baut, pentru a se putea concentra indeajuns asupra hirtiilor tranzactiei imobiliare.
Figure1.
Munteanu et al.,   used news articles published within the same 5-day window.
This EM method differs from some previous work, which used a seed-word lexicon to extract new word translations or word senses from comparable corpora (Rapp 1995, Fung & McKeown 1997, Grefenstette 1998, Fung and Lo 1998, Kikui 1999, Kaji 2003).
(Fung and McKeown 1997, Kikui 1999, Zhao and Vogel 2002) extracted bilingual word senses, lexicon and parallel sentence pairs from such corpora.
5.4.
6.3.1.
6.4.
Several  ,  , (Paik et al.
...
...
Discriminative Reranking For Natural Language Parsing
In particular, previous work (Ratnaparkhi, Roukos, and Ward 1994; Abney 1997; Della Pietra, Della Pietra, and Lafferty 1997; Johnson et al. 1999; Riezler et al.
First, several of the best-performing parsers on the WSJ treebank (e.g., Ratnaparkhi 1997; Charniak 1997, 2000; Collins 1997, 1999; Henderson 2003) are cases of history-based models.
Feature selection methods have been proposed in the maximum-entropy literature by several authors (Ratnaparkhi, Roukos, and Ward 1994; Berger, Della Pietra, and Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997; Papineni, Roukos, and Ward 1997, 1998; McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004).
 , Riezler et al.  , and Och and Ney  .
4.2.2 Log-Likelihood.
Two-level rules.
Two-level bigrams.
Trigrams.
Grandparent bigrams.
Lexical bigrams.
PPs.
Further lexicalization.
The ExpLoss method was trained with several values for the smoothing parameter e: {0.0001, 0.00025, 0.0005, 0.00075, 0.001, 0.0025, 0.005, 0.0075}.
Results on section 23 of the WSJ Treebank.
Ratnaparkhi, Roukos, and Ward  , Johnson et al.  , and Riezler et al.
Johnson et al.   and Riezler et al.
Another difference is that both McCallum, and Riezler and Vasserman, describe approaches that use a regularizer in addition to feature selection: McCallum uses a two-norm regularizer; Riezler and Vasserman use a one-norm regularizer.
Airola et al.   provide more systematic results on a number of proteinprotein interaction datasets.
Transition-based Dependency Parsing with Rich Non-local Features
Transition-based dependency parsing (Yamada and Matsumoto, 2003; Nivre et al., 2006b; Zhang and Clark, 2008; Huang and Sagae, 2010) utilize a deterministic shift-reduce process for making structural predictions.
Recent research have focused on action sets that build projective dependency trees in an arc-eager (Nivre et al., 2006b; Zhang and Clark, 2008) or arc-standard   process.
Unigram information for S0h, S0l, S0r and N0l The head, left/rightmost modifiers of S0 and the leftmost modifier of N0 have been used by most arc-eager transition-based parsers we are aware of through the combination of their POS-tag with information from S0 and N0.
Unigram label information has been used in MaltParser (Nivre et al., 2006a; Nivre, 2006).
Third-order features of S0 and N0 Higher-order context features have been used by graph-based dependency parsers to improve accuracies  .
The new templates include unigram word, POS-tag and dependency labels of S0h2, S0l2, S0r2 and N0l2, as well as POS-tag combinations with S0 and N0.
Monz and de Rijke [2001] and Hedlund et al. [2001] successfully use lexicon based approaches to compound splitting for information retrieval.
We limit possible parts of compounds to words that occur most of the time as one of following POS: ADJA, ADJD, ADV, NN, NE, PTKNEG, VVFIN, VVIMP, VVINF, VVIZU, VVPP, VAFIN, VAIMP, VAINF, VAPP, VMFIN, VMINF, VMPP.
The baseline 1-gram and the background MEMM capitalizer were trained on various amounts of WSJ   data from 1987 — files WS87_{001-126}.
Almost all of the work in the area of automatically trained taggers has explored Markov-model based part of speech tagging [Jelinek, 1985; Church, 1988; Derose, 1988; DeMarcken, 1990; Cutting et al., 1992; Kupiec, 1992; Charniak et al., 1993; Weischedel et al., 1993; Schutze and Singer, 1994; Lin et al., 1994; Elworthy, 1994; Merialdo, 19951.2 For a Markov-model based tagger, training consists of learning both lexical probabilities (P(worclItag)) and contextual probabilities (P(tagiltagi_i tagi_n)).
[Weischedel et al., 1993; Charniak et al., 1993]).
Below is an example of the initial-state tagging of a sentence from the Penn Treebank [Marcus et al., 1993], where an underscore is to be read as or.8 Rival/JJ_NNP gangs/NNS have/VB_VBP turned/VBD_VBN cities/NNS into/IN combat/NN_VB zones/NNS ./.
This method is employed in [Kupiec, 1992; Cutting et al., 1992].
for cranes, hoists, and lift s. TOOLS hovetlfitheisht,atower crane is oftea med .SB TM* TOOLS ?labocate oaumhip ribalds cranes build ?
NA~rrES, 23-28 AO~r 1992 4 5 4 PRec.
Fo~ illustrative simplicity, we will refer to words in context, In pnlctice, all op~]lil~t$ ale ac~uMly p~rfonned onthe Iemma~ of the words (eal/V = eat,eatg.elling,ate,elae~l), lind inflecdonml dlnincdons tire igltored.
ACIES DE cOL1NG-92, NANTES, 23-28 Ao(rr 1992 4 S g PROC.
Weight ANIMALINSECT Weight water 0.76 lift 2.44 lift 2.44 grain 1.68 used 1.32 heavy 1.28 Treadmills 1.16 attached 0.58 grind 0.29 water 0,11 TOTAL 11,30 TOTAL 0.76 4.
For example, the category AMIJSI~I,,g~-r (# 876) lisa ?
OF COLING-92, NANTES, AUG. 23-28, 1992 TABLE i Sen~ R~etCat~o~ N Co~.
STAR (Hirst, 1987: N/A) Space Object UNIVERSE 1422 96% Celebrity r~rcrm~TArNt.X 222 95% Staa" Shaped Object INSlOlqIA ..... _5_6_ ...... .82.% 1700 96% MOLE (HirsL 1987: N/A *) Quantity OII!MlCALS 95 98% Mammal ANIMALJNSECI" 46 100% Skin Blemish DISEASE 13 100% Digging Machine SUPPORT 4 100~o 160 99% GALLEY (LusL 1986: 50-70% overall) Ancient Slfip SIIIP,BOAT 35 97% Printers Tray PRI~flNG 5 100% Ships Kitchen .
COOKING 2 50% 42 95% CONE (Lesk, 1986; 50-70% overall *) Part of Trec PLANT 71 99% Shape of Ohject ANGULARITY 89 61% Part of Eye VISION 13 69% 173 77% BA&q (HearsL 1991: 100%; Speech Synthesis) Musical Senses MUSIC 158 99% Fish ANIMAL,INSECrf 69 100% 227 99% BOW (Clear, 1989: < 67%; Speech Synthesis) Weapon ARMS 59 92% Front of Ship StllP,BOAT 34 94% Violin Part MUSICAL INSTR 30 100% Ribbon ORNAMENTAalON 4 25% Bend in Object CONV~.XnV 2 50e Lowering Head RESPF.CT .______0_ .
5_-___ 129 91% ~- -~Clear ,  1989: < 65%) Preference PARI]CULA RIIY 228 93% Flavor SENSATION 80 93% 308 93% INTEREST (Black, 1988: 72%; Zemik, 1990: > 70%) Curiosity REASONING 359 88% Advantage IN/UffI1CE 163 34% Financial DEBT 59 90% Share PROPERTY 21 38% 602 72% ISSUE (Zemik, 1990: < 70%) Topic rotrtacs 831 94% Periodical BOOKS.PERIODI 28 89% Stock SECURn1Es 9 1OO% 868 94% Sense Roget Category N Corr.
DUTY (Gale et el, 1992: 96%) Obligation DUTY 347 96% Tax PRICE.Iq:~.
52 96% 399 96% SENTENCE (Gale et al, 1992, 90% *) Florishment t .EGALACI1ON 128 99% Set of Words GRAMMAR 213 98% 341 98% SLUG (Hirsk 1987: N/A *) Animal ANI MAL,INSI!CT 24 100% Type Strip I,RINTtNO 8 100% Mass Unit WEIGItT 3 100% Fake Coin MONEY 2 50% Metallurgy 1MPUIZE.IMPAC-f I 100% Bullet ARMS 1 100% 39 97% Notes: 1) N refers to the total number of each sense obseawed in the test corpus.
AcrEs DE COLlNG-92, NAI~ES, 23-28 AOt3T 1992 4 5 7 PROC.
OF COLING-92, NArCrES, AUG. 23-28, 1992 3.
eomlTletely random u~ of words hould iffer, 7.
~urality (~" the word, afuture we cura~ntly dont utilize.
OF COLING-92, NANTES, AUG. 23-28, 1992 sense numbers.
Others such as Lesk  , Walker  , Veronis and Ide  , and Guthrie et al.
By entirely circumventing the issue of polysemy AClXS DE COLING-92, NANqVS, 23-28 Aovr 1992 4 5 9 PRec.
OF COLING-92, NAI~fES, AUG. 23-28.
References Bar-Hillel  .
"Automatic Translation fLanguages," in Advances in Coenpmera, Donald Booth and R. E. Meagher, eds., Academic, New York.
IBM Journal of Research and Dev?lopmenl, v 32. pp 185-194.
Brown, Peter, Vil,,c~at Delh Pintra, Peter deSouza, nd Rck~rt Mercer  , "clasa-based n-gram Modeht of Natural Language," Proceedings of the IBM Natural Language ITL, Paris, Fnmce, pp 283- 298.
Rogets International Thesaur~  .
"Disambiguation by Short Contexts," Computera and the ltwnanities, v 19. pp.
"An Experiment in Automatic Word Sense ld~RificJtlon."
Courdl, Garriton  .
A Connectionist Appre.ach to Word Sense Disamblguatioa, Pitman, London.
Dagan, 13o, Alon leaS, and Olrike Schwall  , "Two Languages am Infmmative than One," Proceedings ofthe 29th Annual Meeting of the Aesoclation for Computatiosal Linguistics.
Gale, William, Kenneth  , "Ditcriminatlon Decisions for 100,000-Dimensional Sp ces" AT&T Statistical Retear?.h Report No.
Large Ca~.ts," to appear in Computers and llumdnitits, Gnmger, Richard  , "FOUL-UP A program that figures out meanings ofwo~ from ?~ntext," HCAII-77, pp.
Miller, George  , "Woednea: An On-line Leaical Database," InterncUionalJournal ofLexicography, 4(3), 1990.
Salton, G.  , Automatic Text Processing, Addis0n-Wesley Publishing Co. Sinclair, J., Ilanks, P., Fox, G., Moon, R., Stock, P. et el.
Lexical AcqioMtion: E:9~ioitiog On-Line ResoW:ces to B~Id a L~icon, Lawrence Edbamn, Hillsdale, NJ.
v. 9. pp 33-4 I, Veronis, Jean and Nancy lde  , "Word Sense Disamliiguation wilh Very Large Neural Networks Extracted from Machine Readable Dictionaries," in Proceedings COLING-90 , pp 389-394.
AcrEs DE COLING-92, NANTES.
23-28 AO~r 1992 4 6 0 PROC.
OF COL1NG-92, NANrFES, AUG. 23-28, 1992
We thank Eric Breck, Claire Cardie, Rich Caruana, Yejin Choi, Shimon Edelman, Thorsten Joachims, Jon Kleinberg, Oren Kurland, Art Munson, Vincent Ng, Fernando Pereira, Ves Stoyanov, Ramin Zabih, and the anonymous reviewers for helpful comments.
Wi l l i ams Bu i ld ing Col lege Park ,  MD 20742 {bonnie, j ones}~umiacs, umd.
1Both the database and the parser are encoded in Quin- tus Prolog.
Following Saint-Diziers work, we construct N-ary syntactic haracterizations.
"lbny broke the crystal vase.
There are 1082 positive examples and 586 nega- tive examples.
The second, three-way, distinction involves preposi- tions, and breaks the two previous distinctions involv- ing negative vidence into three sub-cases.
3.3 Experiment 2" Class-based Approach In this experiment, we attempt o discover whether each class-based syntactic signature uniquely identifies a sin- 324 Verb-based Exper iment  (No Disami)iguation) :ed ,~sitions ~i~ ed )sitions qYgfy )sitions Overlap Median Mean Perfect Median Mean Perfect Median Mean Perfect With No Negative Negative Evidence Evidence O.lO 0.09 0.17 0.17 6.3% 5.2% 0.t0 0.09 0.17 O.
Note that this algorithm assmnes that there is a "canonicM" set of LDOCE codes tbr each of Levins semantic lasses.
We have automatically classified 10,000 "unknown" verbs, i.e., those not occurring in the Levin classifica- tion, using this technique.
We found that 69 verbs were classifed correctly, SThe Spanish-English dictionary was built at the Univer- sity of Maryland; The Arabic-English dictionary was pro- duced by Alpnet, a company in Utah that develops transla- tion aids.
i.e., 82% accuracy.
References Alshawi, H. 1989.
Analysing the Dictionary l)efini- tions.
In B. Boguraev and T. Briscoe, editor, Compuo rational Lexicography for Natural Language Prvcess- ing.
Longman, London, pages 153 169.
Boguraev, B. and T. Briscoe.
Utilising the LDOCE Grammar Codes.
In B. Boguraev and T. Briscoe, editor, Computational Lexicography for" Nat- ural Language Processing.
Longman, London, pages 85-116.
Brent, M. 1993.
Chmch, K. and P. Hanks.
Com- pntational Linguistics, 1(5:22 29.
Vossen, A. Ageno, I. Castellon, F. l{ibas, (J. t{igau, 1t.
l{odr{guez, and A. Samiotou.
Acquisition of LexicM Transla- tion Relations from MRDS.
Machine Translation, 9. l)orr, B., J. Garlnan, and A. Weinberg.
1995. l,rom Syntactic Encodings to [hematic Roles: Building Lexieal Entries lbr Interlingual MT.
Machine 7rans- lation, 9.
326 LDOCE Code Argmnentg Adjuncts ExmnI)le I I-AI,TER I- I,O 1/.
T1-IN~IO T3 q4 NP ADV/PP NP NP t P~af~ T q , ~ .  ]
tr led to do it 7qh(7 Grh.~dl eating the new food WV4 ing adjectiwd Ive ha.d a, trying day -ed adjectiwd WV5 lie was convicted for attelnpte(1 murder Tabh.
A Multiq,evel Ap proach to lnterlingual MT: I)etining the Interface between l{epresentt~tional l, nguages, lnlcrnational Journal of l,,,pert Systcms.
Construction el, repres6ntation de classes sdmantiques de verbes: une coop&ation entre syntaxe et cognition, manuscript, IRIT- CNRS, Toulouse, lirance.
Guthrie, trod Y. Wilks.
Automat- ically Creating Lexical Entries for UI,FRA, a Multi- lingual MT System.
The Case lbr (?ase.
Argument blruclure.
Studies in Lcxical Rela?ions.
Guthrie, J., L. Guthrie, Y. Wilks, and 11.
In l~roceedings oJlhc 29th An- nual Meeting of lhe Associalion for Compulalional Linguistics, pages 146 152, (Jniversity of California, Berkeley, CA.
Ilearst, M. 1991.
Noun llomograph l)isambiguation Using 1,oeal (Jontext in Large Pext Corl)ora.
Jackendoff, R. 1990. fiemanlic Structures.
Dictionar- ies and (k)rpora: (Jolnbiniug (~ort)us aud Machine,- readable Dictionary l)ata lbr Building 13ilingual I,ex icons.
Machine lYanslatiou, 10.
quisition of l,arge Lexicous for Practical Knowledge- Based MT.
Machine Translation,9.
Neff, M. and M. Mc(;ord.
Acquiring I,exh:at I)ata fronl Machinc-II.eadable )ictionary I~esourccs for Machine Translation.
Pinker, S. 1989. hearnability and Cognilion: The Ac- quisitiou of Argument Structure.
Procter, P. 1978.
Lou, gman Dictionary of Conlcmpoo ra W I5uglish.
Sanfilippo, A. and V. Iozmmsk[.
The Acquisi- tion of [,exieal Knowledge from (~olnbine(l Machine- Readable Dictionary Ih-.som(es.
In Proceedings of th.e Applied Natural Languaqc Processing Confcrencc, pages 80 87, Tren{;o, Italy.
l,awrence Erlbaum Associates, llillsdale, New Jersey, pages 69 83.
M(Domdd, and T. l|ate.
Providing Machine tractable [)ic- ~ionary lbols.
A Tractable Machine Dicl;io- nary as a. I{.esource for Computational Semanl, ics.
In B. Bogura.ev and T. Briscoe, editor, Computaiional Lexicograph, y for Natural Language Processing.
[,oug-- man, l,ondon, pages 85 116.
Word-Sense l)isambigual, io|~:, Us ing Statistical Models of Rogets Categories Trainc.,d on l,arge Corpora.
In Proceedings of the l/ourlce~lh lntcrnatioual UonJi:renc~ on Compulalional Linguis- lie.s, pages 454 460, Nantes, l~rancc.
A non-zero weight is assigned to Ak, only when |C · (Ok − Ek) |= 1/2.
The L2-based regularizer, also seen in SVMs, produces a non-sparse solution where all of Ak have non-zero weights.
The hyperparameters C for L1-CRFs and L2CRFs are selected by cross-validation.
The three F-scores (seg/top/all) for our CRFs and a baseline bi-gram HMMs are listed.
Collins   uses WSJ 0018 for training and WSJ 22-24 for testing, and Toutanova and Manning   use WSJ 00-20 for training and WSJ 23-24 for testing.
Kamal Nigam, John Lafferty, and Andrew McCallum.
1999.
Adwait Ratnaparkhi.
1996.
In Proceedings of the EMNLP Conference, pages 133-142, Philadelphia, PA. Adwait Ratnaparkhi.
1998.
Adwait Ratnaparkhi.
1999.
Machine Learning, 34(1-3):151-175.
Ronald Rosenfeld.
1996.
Mark Steedman.
2000.
Kristina Toutanova and Christopher D. Manning.
2000.
Hans van Halteren, Jakub Zavrel, and Walter Daelemans.
2001.
A third approach, exemplified by Moldovan et al.   and Raina et al.
For example, the graph in figure 1 might generate the quasi-LF rose(e1), nsubj(e1, x1), sales(x1), nn(x1, x2), Mitsubishi(x2), dobj(e1, x3), percent(x3), num(x3, x4), 46(x4).
Antonymy features.
Socher et al. (2011a) and Socher et al.
Word embeddings are distributed representations, low-dimensional and real-valued.
The model is discriminative and non-probabilistic.
The n-gram is paired with a corrupted n-gram x˜ = (w1,..., ˜wn) where ˜wn =6 wn is chosen uniformly from the vocabulary.
The rate at which embeddings were learned ranged from 3.4 x 10−10 to 6.7 x 10−10 to 10−9.
Boostexter   uses word-based decision stumps for topic-based text classification.
123 pages on the SIGHAN website.
2.2!
Encodings Training Size (Words/Types) Test Size (Words/Types) Academia Sinica (Taipei) AS Big Five Plus, Unicode 5.45M / 141K 122K / 19K Beijing University PK CP936, Unicode 1.1M / 55K 104K / 13K City University of Hong Kong CityU Big Five/HKSCS, Unicode 1.46M / 69K 41K / 9K Microsoft Research (Beijing) MSR CP936, Unicode 2.37M / 88K 107K / 13K Table 1.
Technology Wei JIANG ZH "!
5 France Telecom R&D Beijing Heng LI ZH "!
Institute of Technology Huipeng ZHANG ZH "!
of Hong Kong Guohong FU HK "!
8 Computer Science Dept., Xiamen.
University Hua-lin Zeng ZH "!
13 Nanjing University Jiajun CHEN ZH "!
14 Stanford NL Group Huihsin TSENG US " " " ".
15 Nara Institute of Science and Tech-.
nology Masayuki ASAHARA JP " " " " 16 Academia Sinica Yu-Fang TSAI TW ! !.
19 National University of Singapore Hwee Tou NG SG ! !
21 Kookmin University Seung-Shik KANG KO " " ".
Tung Nan Institute of Technology Jia-Lin TSAI TW " 26 ICL, Peking University Huiming DUAN ZH "!.
27 Yahoo!
Inc. Aitao CHEN US "!
Kong Tak Pang LAU HK " " " 31 City University of Hong Kong Ka Po CHOW HK ! !.
33 City University of Hong Kong Chun Yu KIT HK " " ".
Chinese Academy of Sciences ShuangLong LI ZH "!
2.3!
Participating SitesThirty-six sites representing 10 countries ini tially signed up for the bakeoff.
Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 15 b 122610 0.952 ?0.00122 0.951 ?0.00123 0.952 0.043 0.696 0.963 15 a 122610 0.955 ?0.00118 0.939 ?0.00137 0.947 0.043 0.606 0.971 14 122610 0.95 ?0.00124 0.943 ?0.00132 0.947 0.043 0.718 0.960 27 122610 0.955 ?0.00118 0.934 ?0.00142 0.945 0.043 0.468 0.978 12 122610 0.946 ?0.00129 0.942 ?0.00134 0.944 0.043 0.648 0.959 7 122610 0.947 ?0.00128 0.934 ?0.00142 0.94 0.043 0.523 0.966 15 c 122610 0.944 ?0.00131 0.934 ?0.00142 0.939 0.043 0.445 0.967 33 122610 0.944 ?0.00131 0.902 ?0.00170 0.923 0.043 0.234 0.976 5 122610 0.948 ?0.00127 0.900 ?0.00171 0.923 0.043 0.158 0.983 4 122610 0.943 ?0.00132 0.895 ?0.00175 0.918 0.043 0.137 0.979 Table 5.
Academia Sinica ? Closed (italics indicate performance below baseline) Participant Run ID Word Count R Cr P Cp F OOV Roov Riv 19 122610 0.962 ?0.00109 0.95 ?0.00124 0.956 0.043 0.684 0.975 27 122610 0.958 ?0.00115 0.938 ?0.00138 0.948 0.043 0.506 0.978 12 122610 0.949 ?0.00126 0.947 ?0.00128 0.948 0.043 0.686 0.961 7 122610 0.955 ?0.00118 0.938 ?0.00138 0.946 0.043 0.579 0.972 31 122610 0.943 ?0.00132 0.931 ?0.00145 0.937 0.043 0.531 0.962 4 122610 0.952 ?0.00122 0.92 ?0.00155 0.936 0.043 0.354 0.979 5 122610 0.952 ?0.00122 0.919 ?0.00156 0.935 0.043 0.311 0.981 Table 6.
4.1!
Various machine learning approaches have been proposed for chunking (Ramshaw and Marcus, 1995; Tjong Kim Sang, 2000a; Tjong Kim Sang et al., 2000; Tjong Kim Sang, 2000b; Sassano and Utsuro, 2000; van Halteren, 2000).
(Joachims, 1998; Taira and Haruno, 1999; Kudo and Matsumoto, 2000a).
1Originally, Uchimoto uses C/E/U/O/S representation.
Tjong Kim Sang et al. report that they achieve accuracy of 93.86 for baseNP-S data set, and 94.90 for baseNP-L data set.
conveys the ACE-style relation ?EMPLOYMENT.exec?
Since then, many methods, such as feature-based (Kambhatla 2004; Zhou et al2005, 2006), tree ker nel-based (Zelenko et al2003; Culotta and Sorensen 2004; Bunescu and Mooney 2005a; Zhang et al2006) and composite kernel-based  , have been proposed in lit erature.
Zhang et al  also showed that the widely-used Shortest Path-enclosed Tree (SPT) performed best.
It achieved the Fmeasure of 70.9/57.2 on the 5 relation types/24 rela tion subtypes in the ACE RDC 2003 corpus and the F-measure of 72.1/63.6 on the 7 relation types/23 relation subtypes in the ACE RDC 2004 corpus.
3.1 Dynamic Context-Sensitive Tree Span in.
cate gory.
His mother Lebanese landed PRP$ NNP VBD IN NP-E1-PER NP-E2-GPE PP S d) descriptive NP NN at ? VP Jane ABC news , NNP , NNP NNS , NNP . NP NP-E1-PER NP-E2-ORG NP c) semi-structured California . . , , , NP(NN) of Microsoft IN NNP NP-E2-ORG PP(IN)-subroot b) context -sensitive NP(NN) of Microsoft IN NNP NP-E2-ORG S(VBD) PP(IN)-subroot c) context -sensitive PP(IN)-subtoot NP-E2-ORG of Microsoft IN NNP a) context -free ? NP John and Mary got NNP CC NNP VBD married NP-E1-PER NP-E2-PER VP S VP VBN ? John and Mary got NNP CC NNP VBD married NP-E1-PER NP-E2-PER VP NP VP ? NP CEO of Microsoft announced NN IN NNP VBD ? NP-E1-PER NP-E2-ORG VP S b) PP -linked PP ? John ?s wife found a job NNP POS NN VBD DT JJ NN NP NP-E1-PER NP-E2-PER VP S a) embedded good 731 Since ?predicate -linked?
3.2 Context-Sensitive Convolution Tree Kernel.
For compari son, we use the same setting as Zhang et al  by applying a 5-fold cross-validation on a subset of the 2004 data, containing 348 documents and 4400 rela tion instances.
Concerning the ASE algorithm, threshold parameters3 were set as PHRASEMAXF=107, SETMINF=102, SETMAXF=105, SETMINP=0.066, and SETMAXP=0.666.
This work was partially supported by the MOREWEB project, financed by Provincia Autonoma di Trento.
The phrase-based-like submodels have been proved useful in phrase-based approaches to SMT  .
The performance is measured using the Bleu metric   on lowercased, tokenized outputs/references.
Acknowledgements.
Thus, we compare (2*1+ 10*2)/3 = 7.33 with (3.5*2+2*1)/3 = 3.0 and select the first, 7.33.
Max-Margin Parsing
In Eq.
As shown in Taskar et al.  , the dual in Eq.
Length 5 10 15 20 30 40 50 Sec .11 .17 .20 .28 .44 .58 .72 We also tested the system on the syntactically rather varied and complex input of Figure 2 (which is made up of 20 words).
In this sense it is related to the algorithmof Liang et al  .
2.1 Semantics.
2.2 Combinatory Categorial Grammars.
Combinatory categorial grammar  .
2.3 Log-Linear CCGs.
2.4 Zettlemoyer and Collins 2005.
3.2 Additional Rules of Type-Raising.
Fortest, we used the ATIS NOV93 test set which con tains 448 examples.
This approach can significantly improve F-measure on the partial-match cri terion in particular.
6.3 Results.
Precision Recall F1 Single-Pass Parsing 96.76 86.89 91.56 Two-Pass Parsing 95.11 96.71 95.9 He and Young   ? ?
Agrawal et al.  ).
Notable early papers on graph-based semisupervised learning include Blum and Chawla  , Bansal et al.  , Kondor and Lafferty  , and Joachims  .
IIS-0329064.
Forest Reranking: Discriminative Parsing with Non-Local Features
4.1.
We implemented both n-best and forest reranking systems in Python and ran our experiments on a 64bit Dual-Core Intel Xeon with 3.0GHz CPUs.
23.
McClosky et al.   achieved an even higher accuarcy (92.1) by leveraging on much larger unlabelled data.
11.
Ait-Kaci 1984).
Steedman 1982).
McCawley 1971; Partee 1973; Isard 1974).
46.
Pennsylvania; and NSF grant IRI-10413 A02, ARO grant DAA6-29- 84K-006f, and DARPA grant N001485-K0018 to CIS, Univ.
GermaNet - A Lexical-Semantic Net For German
The relation pertains to relates denominal adjectives with their nominal base (finanztell 'financial' with Finanzen 'finances'), deverbal nominalizations with their verbal base (Entdeckung 'discovery' with entdeeken 'discover') and deadjectival nominalizations with their respective adjectival base (Miidigkeit 'tiredness' with raids 'tired').
We describe the ory justifying the algorithms througha modi cation of the proof of conver gence of the perceptron algorithm forclassi cation problems.
1-8.
string date occurrence Local .125 context All .125 word distribution Narrow .125 .083 .083 .083 .125 Wide IDF RF Burstiness 1 exact-match accuracy 0.8 0.6 0.4 0.2 4 3 2 1 combo combo minus levenshtein 0 0 500 1000 1500 2000 2500 3000 3500 4000 4500 test words covered 0 500 1000 1500 2000 combo levenshtein only 2 1 0 500 1000 1500 2000 4 combo combo minus context 3 2 online + paper dictionary scoring online dictionary scoring 1 4 0 500 1000 1500 2000 3 combo combo minus date 2 1 0 500 1000 1500 2000 combo combo minus rfjdf,burstiness 4 3 2 1 4 3 0 500 1000 1500 2000 4 3 bulg+czech bulg+czech w/ retrained levenshtein bulg+czech w/ retrained levenshtein & context 2 1 0 500 1000 1500 2000 RANK CRIB.
SCR.
C'OMBINED STRING DATE-LOCAL WIDE-COS NARROW-C'OS BURSTINESS RF 1 0.18 protest/N (1) abhorrence/N break/V protest/V protest/N protest/N protest/N 2 0.19 opening/N (1) abomination/N resistance/N protest/N system/N reluctance/N port/N 3 0.24 break/N (1) allergy/N stress/V break/V break/V break/N opening/N 4 0.28 mouth/N (1) animosity/N protest/V hate/V protest/V kick/V stress/V 5 0.29 objection/N (1) antagonism/N escape/V opening/N antagonism/N protest/V protest/V 6 (1) antipathy/N protest/N escape/V hate/V escape/V escape/V 7 0.30 opposition/N (1) aperture/N opening/N stress/V dislike/V opposition/N resistance/N 8 0.33 reluctance/N (1) averse/J break/N system/N resentment/N mouth/N break/N 9 0.33 port/N (1) aversion/N kick/V defiance/N unit/N unit/N break/V 10 0.36 hole/N (1) bore/N system/N mouth/N disgust/V formation/N opposition/N 11 0.38 stress/N (1) bore/V opposition/N contradiction/N reluctance/N port/N unit/N 12 0.38 escape/N (1) boring/J kick/N kick/V formation/N stress/V hole/N 13 0.38 formation/N (1) boring/N formation/N resentment/N animosity/N objection/N kick/V 14 0.40 animosity/N (1) break/N punch/N dislike/V dislike/N protestation/N outlet/N 15 0.40 resentment/N (1) break/V unit/N reluctance/N escape/V hate/V column/N (1) resistance/N RANK CRIB.
SCR.
C'OMBINED STRING DATE-LOCAL WIDE-C'OS NARROW-COS BURSTINESS RF 1 (1) freedom/N independence/N independence/N independence/N evidence/V free/V 2 0.09 freedom/N relation/N single/J ease/N necessity/N cold/J 3 0.11 depend/V free/J cold/N irrelevant/J fair/J abandon/V 4 0.13 relation/N (4) irrelevance/N side/N side/N ease/V single/V importance/N 5 0.20 consequence/N (5) illegality/N importance/N independent/J applicability/N application/N ease/V 6 0.21 lift/V (5) illegitimacy/N depend/V consequence/N single/J independence/N licence/N 7 0.21 importance/N independent/J freedom/N disagreement/N currency/N lift/V 8 0.22 obligation/N single/J abandon/V lift/V free/V miss/N 9 0.23 ease/V life/N lack/V cold/N inadequacy/N green/N 10 0.23 independent/J freedom/N depend/V depend/V pride/N involvement/N 11 0.23 single/J irrelevant/N moment/N pride/N cold/J green/J 12 0.24 abandon/V miss/V importance/N side/N irrelevant/J consequence/N 13 0.24 integrity/N imperative/J relation/N realty/N side/V utility/N 14 0.24 necessity/N safety/N lack/N consequence/N disagreement/N lack/V 15 0.24 irrelevant/J obligation/N necessity/N drag/N independent/N independent/N (25)indpndnce/N RANK CRIB.
SCR.
COMBINED STRING DATE-LOCAL WIDE-COS NARROW-C'OS BURSTINESS RF 1 quarter/N currency/N currency/N exchange/V bless/V 2 0.43 chop/V (1) calibre/N good/J applaud/V praise/V making/N chop/V 3 0.45 bless/V (1) chop/N quality/N praise/N superior/J praise/N commend/V 4 0.48 applaud/V (1) chop/V class/N praise/V good/J class/N laud/V 5 0.49 exchange/V (1) class/N exchange/N good/J class/N currency/N making/N 6 (1) class/V compliment/N making/N good/N applaud/V applaud/V 7 0.56 commend/V (1) making/N superior/J bless/V quarter/N quarter/N superior/J 8 0.57 class/V (1) quality/J exchange/V superior/J quality/N superior/J praise/N 9 0.68 quarter/V (1) quality/N superior/N good/N biennial/J good/N superior/N 10 0.71 compliment/V (1) quarter/N praise/V exchange/V exchange/N quality/N compliment/N 11 0.81 scroll/V (1) quarter/V praise/N chop/V bless/V superior/N scroll/N 12 2.30 superior/J (12) applaud/V good/N exchange/N praise/N laud/V exchange/V 13 2.30 class/N (12) biennial/J bless/V quality/N exchange/V praise/V chop/N 14 2.34 quality/N (12) biennial/N currency/N class/N exchange/N good/N 15 2.35 making/N (12) bless/N caliber/N biennial/J bless/V calibre/N 17 32 (12) laud/V RANK CRIB.
SCR.
C'OMBINED STRING DATE-LOCAL WIDE-C'OS NARROW-COS BURSTINESS RF 1 rise/V bear/V widow/N stand/V horse/N 2 0.30 suffer/V (1) endure/V suffer/V stand/V stand/V raise/V expire/V 3 0.31 bear/V (1) expire/V stand/V leave/V leave/V suffer/V proceed/V 4 0.39 leave/V (1) leave/V limit/N suffer/V bear/V bear/V quantity/N 5 0.41 proceed/V (1) proceed/V raise/V endure/V boundary/N leave/V boundary/N 6 0.41 endure/V (1) raise/V bear/V limit/N endure/V rise/V limit/N 7 0.42 raise/V (1) rise/V leave/V raise/V limit/N proceed/V endure/V 8 0.44 rise/V (1) shallow/J horse/N quantity/N suffer/V endure/V widow/N 9 0.45 expire/V boundary/N proceed/V proceed/V limit/N bear/V 10 0.45 limit/N (1) suffer/V expire/V horse/N raise/V expire/V suffer/V 11 0.52 boundary/N (11) mischief/N quantity/N widow/N expire/V quantity/N stand/V 12 0.57 quantity/N (12) boundary/N proceed/V boundary/N rise/V widow/N mischief/N 13 0.61 widow/N (12) horse/N endure/V shallow/J horse/N horse/N raise/V 14 0.62 horse/N (12) limit/N widow/N rise/V quantity/N boundary/N shallow/J 15 0.72 shallow/J (12) quantity/N mischief/N expire/V shallow/J rise/V 5: tables show the performance of individual similarity measures as well as their combined choice, after model retraining.
Mann, G. and D. Yarowsky, 2001.
These models were iteratively reestimated using an ExpectationMaximization algorithm  .
the Alvey NL Tools  ; the COMLEX Syntax dictionary, Grishman et al.
Jackendoff, 1977), by Chomsky-adjunction to maximal projections of adjuncts (XP XP Adjunct) as opposed to 'government' of arguments (i.e. arguments are sisters within X1 projections; X1 XO Argl... ArgN).
Grishman et al., 1992); see figure 65.
Ushioda et al.   utilise a PoS tagged corpus and finite-state NP parser to recognize and calculate the relative frequency of six subcategorization classes.
1The dataset and word vectors can be downloaded at http://ai.stanford.edu/?ehhuang/.
2.3 Learning.
We show how our 875model can readily adopt the multi-prototype ap proach.
4.2 WordSim-353.
A standard dataset for evaluating vector-space mod els is the WordSim-353 dataset  , which consists of 353 pairs of nouns.
We downloaded these embeddings from Turian et al  .
100 Our Model-g Wiki.
22.8 C&W RCV1 29.5 HLBL RCV1 33.2 C&W* Wiki.
64.2 Our Model* Wiki.
71.3 Pruned tf-idf Wiki.
73.4 ESA Wiki.
75 Tiered Pruned tf-idf Wiki.
Of the 2,003 word pairs, 1328 are noun-noun pairs, 399 verb-verb, 140 verb-noun, 97adjective-adjective, 30 noun-adjective, and 9 verb adjective.
241 pairs are same-word pairs.
Erk and Pado?
 , Thater et al   and Dinu and Lapata   evaluated wordsimilarity in context with a modified task where systems are to rerank gold-standard paraphrase candi dates given the SemEval 2007 Lexical SubstitutionTask dataset.
FA8750-09-C-0181, and the DARPA DeepLearning program under contract number FA8650 10-C-7020.
and Vincent J. Della Pietra.
1996.
Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions
2, we have the following triplets: ((y1 -+ x3x4), (y2 -+ x2y1), (y1 -+ x1y2)).
2.1.
For the five categories, the numbers of votes are [14, 816;13, 325;10, 073; 30, 844; 5, 801].
KL Predicted&Gold V. Entry (Shortened if it ends with ...) .03 .16 .16 .16 .33 .16 6 I reguarly shoplift.
2.1.
FA8750-09-C-0181.
Escudero et al.   evaluated k-nearest neighbor, Naive Bayes, Winnow-based, and LazyBoosting algorithms on the DSO corpus.
WEKA implements AdaBoost.M1.
The top three systems for SENSEVAL-2 are: JHU (S1)  , SMUls (S2)  , and KUNLP (S3)  .
The top three systems for SENSEVAL-1 are: hopkins (s1)  , ets-pu (s2)  , and tilburg (s3)  .
1993; Berger et al. 1994).
Examples of two- to seven-word bilingual phrases obtained by applying the algorithm phrase-extract to the alignment of Figure 2. ja , yes , ja , ich yes , I ja , ich denke mal yes , I think ja , ich denke mal , yes , I think , ja , ich denke mal , also yes, I think, well ,ich , I , ich denke mal , I think , ich denke mal, , I think , , ich denke mal, also , I think, well , ich denke mal, also wir , I think, well we ich denke mal I think ich denke mal, I think, ich denke mal, also I think, well ich denke mal, also wir I think, well we ich denke mal , also wir wollten I think, well we plan to denke mal, think , denke mal , also think, well denke mal , also wir think, well we denke mal, also wir wollten think, well we plan to , also , well , also wir , well we , also wir wollten , well we plan to also wir well we also wir wollten well we plan to wir wollten we plan to in unserer in our in unserer Abteilung in our department in unserer Abteilung ein neues Netzwerk a new network in our department in unserer Abteilung ein neues Netzwerk set up a new network in our department aufbauen unserer Abteilung our department ein neues a new ein neues Netzwerk a new network ein neues Netzwerk aufbauen set up a new network neues Netzwerk new network It should be emphasized that this constraint to consecutive phrases limits the expressive power.
The algorithms of Kudo and Matsumoto  , Yamada and Matsumoto  , and Nivre (2003, 2006b) all belong to this family.
Dependency Treebank (Hajiˇc et al. 2001; B¨ohmov´a et al.
Altogether it has now been applied to 19 different languages (Nivre et al. 2006, 2007; Hall et al.
I also want to thank Sabine Buchholz, Matthias Buch-Kromann, Walter Daelemans, G¨uls¸en Eryi˘git, Jason Eisner, Jan Hajiˇc, Sandra K¨ubler, Marco Kuhlmann, Yuji Matsumoto, Ryan McDonald, Kemal Oflazer, Kenji Sagae, Noah A. Smith, and Deniz Yuret for useful discussions on topics relevant to this article.
200 10K tags cov. cov.
WSJ is the entire Penn English Treebank WSJ portion.
The combined model beats the CCM on English F1: 77.6 vs. 71.9.
50 nouns and 50 verbs.
The relations considered were WordNet’s hypernyms, hyponyms, synonyms, meronyms and holonyms.
This dataset is part of OntoNotes  .
The block bigram model in Eq.
N66001-99-28916.
The paper has greatly profited from discussion with Kishore Papineni and Fei Xia.
Stallard 1987, p. 181).
Stallard's work has not yet been implemented (ibid., p. 184).
Stallard   also briefly discusses anaphora resolution.
Jakobsen and Halle 1956; Ullmann 1962).
The process of finding metonymies is called metonymic inferencing.
Sense-frame nodes for nouns (node-type 0) resemble Wilks'   pseudo-texts.
Sense-frames for crook1 and crook2 (noun senses) sf(eatl, sf(drinkl, [faros, [[arcs, [[supertype, [ingestl, espendl MI, (isupertype, [ingestl, expendl MI, [node2.
Both metonymic concepts are target-driven.
A sister match is found between [animall, drinkl, drinkl] and [carl, use2, gasoline1] from carl.
Figure 10 shows the match of the nonrelevant cells from animall and carl.
Gentner's   Structure-Mapping Theory has no treatment of metonymy.
Jakobsen and Halle 1956).
The resulting datasets are available at http://research.microsoft.com/enus/people/chrisq/wikidownload.aspx.
Bootstrapping POS-Taggers Using Unlabelled Data
We call this method agreement-based cotraining.
Naive co-training is more efficient than agreementbased co-training.
Finally, Passonneau has been advocating the use of Krippendorff’s α (Krippendorff 1980, 2004a) for coding tasks in CL which do not involve nominal and disjoint categories, including anaphoric annotation, wordsense tagging, and summarization (Passonneau 2004, 2006; Nenkova and Passonneau 2004; Passonneau, Habash, and Rambow 2006).
2.6.2 Cohen’s κw.
As mentioned in Section 2.4, this difference has been the subject of much debate (Fleiss 1975; Krippendorff 1978, 2004b; Byrt, Bishop, and Carlin 1993; Zwick 1988; Hsu and Field 2003; Di Eugenio and Glass 2004; Craggs and McGee Wood 2005).
4.1.1 Generating Data to Measure Reproducibility.
2000), Verbmobil  , and Communicator (e.g., Doran et al.
2000), K = 0.90 for the smaller 20-tag subset of the CSTAR scheme used by Doran et al.  .
1997; Hearst 1997).
4.4.1 Passonneau’s Proposal.
4.4.3 Discourse Deixis.
Krippendorff 2004a, pages 213–214).
Passonneau 2006).
RestrictIon Grammar is a descendent of Sager's string grammar [Sager19811.
Within this class, Xtract retrieves subjectverb, verb-object, noun-adjective, verb-adverb, verbverb and verb-particle predicative relations.
Xstat is the co-occurrence compiler.
Presumably, the re-estimation null-word weight makes the inital null-word weight redundant.
Algorithm 1 gives pseudo-code for MC-SAT.
We generated 100 samples using MC-SAT for each expectation approximation.6 We conducted experiments on MUC-6, ACE-2004, and ACE Phrase-2 (ACE-2).
The MUC-6 dataset consists of 30 documents for testing and 221 for training.
MLN-HAN The predicate-nominal rule was added.
The B3 scores of MLN-HAN on the ACE2004 dataset are 71.6 (precision), 68.4 (recall) and 70.0 (F1) for BNEWS, and 75.7 (precision), 69.2 (recall) and 72.3 (F1) for NWIRE.
This research was funded by DARPA contracts NBCHD030010/02-000225, FA8750-07-D-0185, and HR001107-C-0060, DARPA grant FA8750-05-2-0283, NSF grant IIS-0534881, and ONR grant N-00014-05-1-0313 and N00014-08-1-0670.
A TAG-Based Noisy-Channel Model Of Speech Repairs
Four of them are black-box techniques: Good-Turing and three fixed-discount techniques (fixed-discount interpolated with unigram distribution, Kneser-Ney fixed-discount, and modified Kneser-Ney fixeddiscount).
HR0011-06-C0023.
Consider Example 10 (HG82).
The pitch accents in Pierrehumbert's description of English include two simple tones—H* and L*—and four complex ones—L*+H, L+H*, H*+L, and H+L*.
Deaccented H* or Complex L* Sentential 5 31 0 Discourse 31 0 5 (51.7%) versus 5 of the 37 sentential nows (13.5%).
No sentential now was uttered with a L* accent—although 13 discourse nows were.
Here the underlined bunsetsus are KBs.
Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported li- cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Al- gorithm 1 shows pseudocode for the algorithm.
is a second-order edge- factored representation  .
PREDPARENTWORD and PREDPARENTPOS.
CHILDDEPSET, CHILDWORDSET, CHILD- WORDDEPSET, CHILDPOSSET, CHILD- POSDEPSET.
PREDRELTOPARENT.
ARGWORD and ARGPOS.
LEFTWORD, LEFTPOS, RIGHTWORD, RIGHT- POS.
LEFTSIBLINGWORD, LEFTSIBLINGPOS, RIGHTSIBLINGWORD, RIGHTSIBLING- POS.
RELPATHTOSUPPORT.
VERBCHAINHASSUBJ.
CONTROLLERHASOBJ.
3.3 Global SRL Model Toutanova et al.
Experiments with a higher-order pro- jective dependency parser.
Crammer, Koby, Ofer Dekel, Joseph Keshet, Shai Shalev- Schwartz, and Yoram Singer.
Eisner, Jason M. 1996.
Lin, Chih-Jen, Ruby C. Weng, and S. Sathiya Keerthi.
Trust region Newton method for large-scale logistic regres- sion.
Nivre, Joakim and Jens Nilsson.
Surdeanu, Mihai, Richard Johansson, Adam Meyers, Llu?s M?rquez, and Joakim Nivre.
In Proceedings of CoNLL?2008.
Toutanova, Kristina, Aria Haghighi, and Christopher D. Man- ning.
IRI 96-19124 and IRI 96-18797.
IRI 96-19124 and IRI 96-18797.
They were 0.71 for 1996-2001 and 0.44 for 1989-1996.
One-to-one had about 640,000 alignments and one-to-many had about 660,000 alignments.
NPs that do not contain NPs.
Mitra et al.  ) and question answering (e.g.
Cardie et al.  ) systems.
Argamon et al.  ), and memory-based learning (e.g.
Co-Training.
Corrected Co-Training.
VP modifiers can be ADVPs, temporal and spatial NPs, QP, PPs, CPs, IPs, DVPs, and LCPs.
DNPs DNPs are formed by ?XP+DEG,?
LCP IP NP-A NPB NN ?(accident) VP VV u)(happen) LC 
Therefore we use an unlexicalized PCFG.
Bold-faced numbers in the bilingual parsers indicate significant improvements on the PCFG baseline using the paired-sample t-test at the 0.01 level. tences.
Knowledge-Free Induction Of Inflectional Morphologies
Grabar and Zweigenbaum   use the SNOMED corpus of semantically-arranged medical terms to find semantically-motivated morphological relationships.
(For example, the PPMVs of car/cars and ally/allies had NCS values of 5.6 and 6.5 respectively, whereas car/cares and ally/all had scored only -0.14 and -1.3.)
More generally, suppose word X has circumfix C1=B1/E1 and pseudo-stem -S-, and word Y has circumfix C2 =B2/E2 also with pseudo-stem -S-.
Such word sets form Prs-o (valid) = Prsem +Prorth - (Prsem Prorth ).
The MaltParser works deterministically.
Our graph-based and transition-based parsers share many similarities.
Following Duan et al.  , we 1A recent paper, Koo et al.
Like Duan et al.  , we use gold-standard POS-tags for the input.
Participants who received the Haitian Creole data for WMT11 were given anonymization guidelines mwen se [FIRSTNAME] mwen gen twaset ki mouri mwen mande nou ed pou nou edem map tan repons I am [FIRSTNAME], I have three sisters who have died.
Eske lekol kolej marie anne kraze?mesi Was the College Marie Anne school destroyed?
Nou pa ka anpeche moustik yo m`ode nou paske yo anpil.
We can’t prevent the mosquitoes from biting because there are so many. tanpri k`em ap kase mwen pa ka pran nouvel manmanm.
4636:Opital Medesen san Fwonti`e delmas 19 la f`emen.
Opital sen lwi gonzag nan delma 33 pran an chaj gratwitman tout moun ki malad ou blese Mwen r´es´evoua mesaj nou yo 5 sou 5 men mwen ta vle di yon bagay kil`e e koman nap kapab f`em jwin `ed sa yo pou moune b la kay mwen ki sinistw´e adr`es la s´e 4636: The Doctors without Borders Hospital in Delmas 19 is closed.
The address is Sil vous plait map chehe [LASTNAME][FIRSTNAME].di yo relem nan [PHONENUMBER].mwen se [LASTNAME] [FIRSTNAME] Bonswa mwen rele [FIRSTNAME] [LASTNAME] kay mwen krase mwen pagin anyin poum mange ak fanmi-m tampri di yon mo pou mwen fem jwen yon tante tou ak mange..mrete n I’m looking for [LASTNAME][FIRSTNAME].
I live Mw rele [FIRSTNAME], mw f`e mason epi mw abite lapl`en.
Yo dim minustah ap bay djob mason ki kote pou mw ta pase si mw ta vle jwenn nan djob sa yo.
Souple mande lapolis pou fe on ti pase nan magloire ambroise prolonge zone muler ak cadet jeremie ginyin jen gason ki ap pase nan zone sa yo e ki agresi
We are dying of hunger Mwen se [FIRSTNAME][LASTNAME] mwen nan aken mwen se yon j`en ki ansent mwen te genyen yon paran ki tap ede li mouri p`otoprens, mwen pral akouye nan k`omansman feviye alongside the SMS data.
Sil vou pl´e ´ede mwen avek moun ki viktim yo nan tranbleman de t´e a,ki kit´e potoprins ki vini nan provins- mwen ede ak ti kob mwen te ginyin kouni´e a 4636: Manje vin pi che nan PaP apre tranbleman te-a. mamit diri ap van’n 250gd kounye, sete 200gd avan.
Mayi-a 125gd, avan sete 100gd Silvouple ede mwen av`ek moun ki viktim yo nan tranblemannt`e a, ki kite P`otoprens ki vini nan pwovens, mwen ede ak ti k`ob mwen te genyen kounye a 4636: Manje vin pi ch`e nan PaP apre tranblemannt`e a. Mamit diri ap vann 250gd kounye a, sete 200gd avan.
Mayi-a 125gd, avan sete 100gd.
Most fluent readers of English who }lave never be- fore encountered the term q3amhara ndang" will nev- ertheless from this sentence infer that a "Bambara udang" is a kind of "bow Iute".
For example, t All examples in this paper are real text, taken from Grolters Amerwan Acaderntc Encyclopedia(Groher tg00) AcrF.s DE COLING-92, NANTI~S, 23-28 Aol}r 1992 5 3 9 PROC.
(Markowitz e~ al.
The tradeoff is that the the refor- mation acquired is coarse-grained.
Semant ic  Relatedness In fo rmat ion .
hyf)onym I~author", "Ilerrick), llyponym( "author", "(;oldsmith "), hyponynl( "author", "Shakespeare") (3) NP {, NP} * {,} o, other NP Bru ises ,  wounds ,  broken bones or o ther in ju r ies  .
~... hyponym( "bruise".
"injury"), hyponym ( "wo und", "mj ury" ), hyponym( "broken bone", "injury") (4) NP {, NP}* {,} and other NP ... temples ,  t reasur ies ,a l td  o ther impor tant  c iv ic  buildings.
:~- hyponym("tenlple", "civic building"), hyponym( "treasury ", "civic building") (5) m, {,} .~clsa,,~y {NP 5* {o,.
~ hyponym( "France", "European country"), hyponym( "England", "European country"), hypouym( "Spain", "European country") When a relation hyponym(NPo, NI  I )  is discov- ered, aside from some temmatiz ing and removal of unwanted modifiers, tile uonn phrase is left as all atomic unit, not broken clown and analyzed.
Adjecti- val quantiflers uch as "other" and "some" are usu- ally undesirable and can be eliminated in most cases without making the statement of tile hypouym rela- tion erroneous.
AcrEs DE COLING-92, N^mEs, 23-28 hotrr 1992 5 4 1 l)Roc, ov COLING-92, NAbrrEs, AUG. 23-28, 1992 We have tried applying this technique to meronymy (i.e., the part/whole relation), but without great suc- cess.
2 WordNet (Miller et al.
AcrEs DE COL1NG-92, NANTES, 23-28 AoUr 1992 5 4 2 PRec.
,__/_"-._._, Figure t: A Fragment of the WordNet Noun Hier- archy.
In order to detect the lexico-syntactic patterns, we use a unification-based constituent analyzer  ), which builds on the output of a part-or=speech tag- ger (Cutt ing el al.
Ont of 8.6M words of encyclopedia text, there are AcrEs DE COL1NG-92, NANt .F.S, 23-28 ho,,~r 1992 5 4 3 Paoc.
ov COLING-92, NANTES, AUO.
23-28, 1992 7067 sentences that contain tile lexemes "such as" contiguously.
As to be expected, metonymy occurs, as seen in hyponym("king", "in- stitution").
Similarly, relations were found be- tween "device" and "plot", "metaphor", and "char- acter", underspecifying the fact that literary devices of some sort are under discussion.
For example, the algorithm finds hyponym( "Washington", nationalist")and hy- ponym( "aircraft", "target") which are somewhat con- text and point-of-view dependent.
There are a few relations whose hypernyms are very high-level terms, e.g., "substance" aud "form".
Acknowledgements .
References Ahlswede, T. & M. Evens  .
Alshawi, H.  .
American Jour- nal of Computational Linguistics, 13(3):195 202.
Brent, M. R.  .
Automatic acquisition ofsubcat- egorization frames from untagged, free-text cor- pora.
In Proceedings of the 29th Annual Meet- ing of the Association foe Computational Lin- guistics.
Calzolari, N. & R. Bindi  .
Coates-Stephens, S.  .
Cutting, D., J. Kupiec, J. Pedersen, & P. Sibun  .
Sub- mitted to The 3rd Conference on Applied Natural Language Process*ng.
Grolier  .
Grolier Electronic Publishing, Danbury, Con- neeticut.
Jensen, K. & J.-L. Binot  .
Markowitz, J., T. Ahlswede, & M. Evens  .
Se- mantically significant patterns in dictionary def- initions.
Proceedings of the 24th Annual Meet- ing of the Assoczation for Computational Lin- guistics, pages 112-119.
Miller, G. A., R. Beckwith, C. Fellbaum, D. Gross, & K. J. Miller  .
Introduction to wordnet: An on-line lexieal database.
& G. Hirst  .
& M. Nagao  .
Extraction of se- mantic inlbrmation t?om an ordinary english dic- tionary and its evaluation.
& K. R. McKeown  .
Proceedings ofthe 28th An- nual Meeting of the Association for Computa- tional Linguistics, pages 252-259.
Velardi, P. & M. T. Pazienza  .
Proceed- ings of the 27th Annual Meeting of the Associ- ation for Computational Linguistics, pages 185- 192.
A., D. C. Fass, C. ruing Guo, J. E. McDon- ald, T. Plate, & B. M. Slator  .
Hindle, D.  .
Proceedings ofthe 28th An- nual Meeting of the Association for Computa- tional Linguistics, pages 268-275.
Jacobs, P. & U. Zernik  .
In Proceed- ings of AAAI88, pages 739-744.
ACrF~ DE COLING-92, NANTES, 23-28 AOt~T 1992 5 4 5 PRoc.
OF COLING-92, NANTnS.
SURFACE GRAMMATICAL ANALYSIS FOR THE EXTRACTION OF TERMINOLOGICAL NOUN PHRASES Didier BOURIGAULT Ecole des Hautes Etudes en Sciences Sociales et Electlicit6 de France Direction des Etudes et Recherches 1, avenue du G6n6ral de Gaulle 92141 Clamart Cedex France Tel : +33 1 47 65 50 64 ABSTRACT LEXTER is a software package for extracting terminology.
AUlXS DE COLING-92, NANTES, 23-28 AO~r 1992 9 7 7 PROC.
This referential function is, for E. Benveniste, the "synaptic" mark of a syntagm [Benveniste 1966].
ACRES DE COL1NG-92, NAN~S, 23-28 Aotrr 1992 9 7 8 PROC.
(exce~ t "de" et "a") + det.
..... > frontier maximal-length noun phrases TRAITEMENT DE TEXTE DISQUE DUR DE LA STATION DE TRAVAIL parsing parsing rules nouffladj prep det noun2 prep noun3 nounl adj noun2 fire D noun3 [ .
NANTES, 23-28 AOt~r 1992 9 7 9 PROC.
ACRES DE COLING-92, NANTES, 23-28 AOOT 1992 9 8 0 PROC.
NANTES, AUG. 23-28.
This principle, called "of relative strictness", is justified in that it will be easier for the te~ninologist toeliminate certain likely units than to find real terminological units that escaped etection by LEXTER 6) Re ferences [Benveniste 1966] Benveniste Emile   "Formes nouvelles de la composition nominale", in Probldmes de linguistique gdn~rale, Tome 2, PP 163-176, Gallimard, Paris [Bourigault 1992a] Bouriganlt  Didier   "LEXTER, vers un outil liguistique daide b. lacquisition des connaissances", Actes des 3dines Journ~es dAcquisition des Cot,naissances, Avri11992, Dourdan [Bourigault 1992b] Bonrigault  Didier   "LEXTER, un logiciel dextraction de terminologie", Actes du symposium TAMA 92, Juin 1992, Avignon [Debili t982] Debili Fathi  , "Analyse syntaxico-stmantique fondte sur une acquisition automatique de relations lexicales stmantiques", Th~se d6tat, Orsay [Le Gueru 1984] Le Guern Michel  , "Les descripteurs dun systtme documentaire.
Essai de definition", Actes du colloque "Traitement automatique des langues naturelles et syst~mes documentaires ", Clermont-Ferrand [Milner 1989] Milner Jean-Claude  , "Introduction ~t une science du langage", Scull, Paris [Monteil 1990] Monteil Marie Gaelle, P~not Nadine  , "Indexation Automatique, fonctionnement - Principes gtntraux", Note interne HN46464, EDF, Direction des Etudes et Recherches, Service IPN, Clanlart AC~E.S DE COLING-92, N^tcrs, 23-28 ,~o~ 1992 9 8 l Pgoc.
ov COLING-92, Nh~ES.
AUG. 23-28, 1992
A Conditional Random Field Word Segmenter for Sighan Bakeoff 2005
3.1 Features.
Table 1 The number of features in each corpus # of data features # of lambda weights AS 2,558,840 8,076,916 HK 2,308,067 7,481,164 PK 1,659,654 5,377,146 MSR 3,634,585 12,468,890 3.2 Experiments.
3.2.1 Results on Sighan bakeoff 2003 Experiments done while developing this system showed that its performance was signifi cantly better than that of Peng et al  .
As seen in Table 2, our system?s F-score was 0.863 on CTB (Chinese Treebank from Univer 169 sity of Pennsylvania) versus 0.849 F on Peng et al.
Table 2 Comparisons of Peng et al   and our F score on the closed track in Sighan bakeoff 2003 Sighan Bakeoff 2003 Our F-score F-score Peng et al   CTB 0.863 0.849 AS 0.970 0.956 HK 0.947 0.928 PK 0.953 0.941 3.2.2 Results on Sighan bakeoff 2005 Our final system achieved a F-score of 0.947 (AS), 0.943 (HK), 0.950 (PK) and 0.964 (MSR).
F-score AS HK PK MSR n-gram 0.943 0.946 0.950 0.961 n-gram (PU fixed) 0.953 +Unk&redupl 0.947 0.943 0.950 0.964 +Unk&redupl (PU fixed) 0.952 Table 3 lists our results on the four corpora.
0.718?
0.960 HK 0.941 0.946 0.943?
0.698?
0.961 HK (PU-fix) 0.952 0.952 0.952 0.791 0.965 PK 0.946 0.954 0.950?
0.787?
0.956 MSR 0.962 0.966 0.964?
0.717?
0.968 3.3 Error analysis.
170
Chinese Part-Of-Speech Tagging: One-At-A-Time Or All-At-Once? Word-Based Or Character-Based?
Our word segmenter achieved higher F-measure than the best reported F-measure in the SIGHAN bakeoff on the ASc, HKc, and PKc corpus.
Word-based or character-based?
One-at-a-time or all-at-once?
2.1.
Metropolis-Hasting steps.
BAYESSEG-CUE-PROP adds the linguisticallymotivated proposal distribution.
Utiyama and Isahara, 2001; Malioutov and Barzilay, 2006).
42.
43.
44.
Charniak 1986).
We include both pM1(¯e |f) and pM1( f|¯e).
An SVM-based part-of-speech (POS).
tagger   is 20 tokens/sec on an Alpha 21164A 500 MHz processor.
Another problem with SVMs is its incomprehensibil ity.
See Vapnik  .
1.2 SVM-based NE recognition.
Our sys tem uses the Viterbi search   instead of sequential determination.For training, we use ?CRL data?, which was prepared for IREX (Information Retrieval and Extrac tion Exercise1, Sekine and Eriguchi  ).
It has about 19,000 NEs in 1,174 articles.
Both datasets are based on Mainichi Newspaper?s 1994 and 1995 CD-ROMs.
We use IREX?s formal test data calledGENERAL that has 1,510 named entities in 71 ar ticles from Mainichi Newspaper of 1999.
and ?preci sion?
ChaSen uses about 90 POS tags such as common-noun and location-name.
Other words in the nameare PERSON-MIDDLE.
bdc klghme // Current word is ?Bush?
bdc nghji // Current word is not ?Charlie?
bdc nqre^skghme // Previous word is ?Herbert?
1.3 Comparison of NE recognizers.
76 78 80 82 84 86 88 90 Number of NEs in training data ( ??
Fa mous SVM-Light 3.50   took 1.2 days to classify 569,994 vectors derived from 2 MB documents.
Inother domains such as character recognition, dimen 3http://cl.aist-nara.ac.jp/?taku-ku/software/TinySVM sion ` is usually fixed.
(=15) non-zero elements.
XQK is 102 times faster than SVM-Light 3.50 which took 1.2 days.
XQK-FS is 28.5 (=21754.23/ 763.10) times faster than TinySVM.
For instance, when we removed 5,066 features that ap peared four times or less in the training data, themodified classifier for ORGANIZATION-END misclassified 103 training examples, whereas the origi nal classifier misclassified only 19 examples.
TinySVM?s clas sifier prepares a list fi2si Z??
Yamada   also reports that F*??
Although his sys tem attained F = 83.7% for 5-fold cross-validation of the CRL data  , our system attained 86.8%.
Osuna and Girosi   propose two meth ods.
We also thank Shigeru Katagiri and Ken-ichiro Ishii for their support.
Kudo and Matsumoto   used the sigmoid function to obtain pseudo probabilities in SVMs.
Dtd.
6/21/1998.
Dtd.
6/21/1998.
SemEval-2010 Task 13: TempEval-2
AFTER(e1,e2)
As 3Seehttp://www.timeml.org. such, BAT was well-suited for TempEval-2 annotation.
Data preparation followed the annotation guidelines created to deal with the specificities of event and timex expressions in Spanish (Saur´ı et al., 2009a; Sauriet al., 2009b).
Irina Prodanof.
The syntax is that of Edinburgh Prologs, e.g., DEC-20 Prolog.
***************************************************************************
Suppose t=<qvr>.
Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 61 Jerry R. Hobbs and Stuart M. Shieber An Algorithm for Generating Quantifier Seopings
We backtransliterated these 222 phrases.
A first-name/last-name model would rank richard bryan more highly than richard brian.
  and Zhou et al.  .
This yields low-recall but high-precision features.
However, until very recently, only handwritten grammars, which lack the wide coverage and robustness of Treebank parsers, were available for these formalisms (Butt et al. 1999; XTAG-group 1999; Copestake and Flickinger 2000; OpenCCG1 [White and Baldridge 2003; White 2006]).
Because treebank annotation for individual formalisms is prohibitively expensive, there have been a number of efforts to extract TAGs, LFGs, and, more recently, HPSGs, from the Penn Treebank (Xia 1999; Chen and Vijay-Shanker 2000; Xia, Palmer, and Joshi 2000; Xia 2001; Cahill et al. 2002; Miyao, Ninomiya, and Tsujii 2004; O’Donovan et al.
2005; Shen and Joshi 2005; Chen, Bangalore, and Vijay-Shanker 2006).
Extensions of CCG to other languages and word-orders are discussed by Hoffman  , Kang  , Bozsahin  , Komagata  , Steedman  , Trechsel  , Baldridge  , and C¸ akıcı  .
Parentheticals.
Multi-Word Expressions.
Sections 02–21 contains 39,604 sentences (929,552 words/tokens), whereas section 00 consists of 1,913 sentences (45,422 words/tokens).
CCGbank contains 48,934 (99.44%) of the 49,208 sentences in the entire Penn Treebank.
CCGbank has already enabled the creation of several robust and accurate wide-coverage CCG parsers, including Hockenmaier and Steedman  , Clark, Hockenmaier, and Steedman  , Hockenmaier (2003b), and Clark and Curran (2004, 2007).
It was indexed 54,550 times by AltaVista in 1998.
Averaging the remaining predictions gives an estimate of three billion words of German that could be accessed through AltaVista on the day in February 2000 that we conducted our test. oder 0.00561180 13,566,463 2,417,488,684 sind 0.00477555 11,944,284 2,501,132,644 auch 0.00581108 15,504,327 2,668,062,907 wird 0.00400690 11,286,438 2,816,750,605 nicht 0.00646585 18,294,174 2,829,353,294 eine 0.00691066 19,739,540 2,856,389,983 sich 0.00604594 17,547,518 2,902,363,900 ist 0.00886430 26,429,327 2,981,546,991 auf 0.00744444 24,852,802 3,338,438,082 und 0.02892370 101,250,806 3,500,617,348 Average 3,068,760,356 This technique has been tested on controlled data   in which corpora of different languages were mixed in various proportions and found to give reliable results.
Consider the compositional French noun phrase groupe de travail.
Not all items are errors (e.g., “...pienso de que manera...” ... think how...).
Habert and colleagues (Folch et al. 2000; Beaudouin et al.
An alternative method is presented by Wessel Kraaij, Jian-Yun Nie, and Michel Simard.
The potential function is set so that it assigns a non-zero potential only when e, .1 abel = el .1 abel V e2.1abel V ...V en .1 abel .
The first dataset is Yapexl which consists of 200 Medline abstracts.
IMINANT ANAI ,YS IS J USSI  [ (AIt I ,C,  ILEN juss i~sics.se Swedish Insl;il,ute of (2)ml),tter Science Box 1263, S 164 28 K[SrA, Stockholm, Sw(.den I)OUOI,ASS (]UTIIN(-} cut t ing@apple ,  com hl)l)le Compel ,  or Cupe.rl.lno, CA 95014, USA Abstract A siml)le method for (:~d, egorizing texts into pre-deturmincd text gem:e c;ttcgorics using tit(: st;tti.,t, icM sl.+utd+ud tcch nique of discriminatH, amdysis is demonstrated wil.h appli- cation to the Brown(:orpus.
different types of l;exL [exl.s "al)oui," l.he sa.me th ing m~ty be in differing geurcs, of difl(~rem.
el.ers, a.ll relcwull, for l,he gcuera.l inlortlu~tiol~ rel, ri(wal problem of real.thing rea(lcr needs m.I texts.
diserinl- inatc on(: topic from auother.
Na.l,ura.lly, there is (;o-va.riancc.. Iexl.s al)oul.
Douglas I~il)et: has sl, udied l;exl, variat.ion along scv eral l )aranmtcrs, and found that  t,cxt.s can I)(,, cousidcrcd to wvry along live ditnensious.
In his st, udy, he clush.rs [~ai.ures according t.o eowuiauce, t.o find tmderlyiug di mens ions  (198!)).
We wish to liud a method  for idenl.ifv- in ;  easily eomput.al)h; I)[tl:al,|et.cHs t.hat ra.l>idly classify previously IlllS(?
(~ll texts in gell(:r~ql classes and along a smal l  set smalh~r 1,tmn I~,il>ers [ivl.
of dimm,siot,s, s,,ch that l.hcy can bc cxplai,,(~d in i,,t,tit.iwdy siml)le terms to l.hc ,,so," of a.n informal.ion rel.riewd ~Hq)liea-- tion.
Skills and lIohhies 1..
21 Non-.tiction -- l lT(h)v. doc.
Fiction K. (,eneral "ietion I,.
More mid more of I/ihcrs |egtlaileS will be awfilahle with tim advent of more prolieieut aua.lysis programs,  for iusl,a.nce if eom- plel.e surface syntaet.ic l>a.rsing were performed hefore catl!gorizat.iotl  .
atmlysis tak,s a set of l)rCcat.egorized iml iv iduals and (I;~ta ou t,hcir vm.m l iOl, Oil iI lltllIlb(21" o1 plLr~lliiCl.elS~ lLlld WOlks olll.
a s(!t discriminant Juuctions which dist;ingnishes hetw(.etl t.he groups.
These l uuetious can l.llen l)e used I.o predicl, the ca+l.egory mlmd)ershil)s of new iudiv iduals  based on tJmir )ara.met(!r scores (Tal.sluoka, 1971 ; M ustouen,  1965).
Evaluat ion "or data.
we used the Browu corpus of English text sn,i, )hs of uuifolnt length, ca.l,cgorized ht se,cral cal.cgorh~s I07/ Variable Range Adverb count 19 - 157 Character  count 7601 12143 ],ong word count (> 6 chars) 168 - 838 Preposit ion count 151 433 Seeond person pronoun count 0 - 89 "Therefore" count 0 -  11 Words per sentence average 8.2 - 5a.2 Chars / sentence average 34.6 266.3 First person pronoun count 0 - 156 "Me" count 0 3(1 Present part iciple count 6 - 1(11 Sentence count 40 236 Type / token rat io 14.3 - 53.0 "I" count 0 120 Character  per word average 3.8 - 5.8 "It" count 1 - 53 Noun count 243 -- 75:l Present verb count 0 - 79 "That"  count :1 72 "Which" count 0 -- 40 Fable 2: Parameters  for l ) i sc r iminant  Ana lys i s Category  I tems Er rors [.
ln fo rmat iw  .
Imag inat ive  126 6 (5 %) qbtM 500 22 (4 %) Tab le  3: Categor i za t ion  in Two Categor ies as seen in tab le  1.
We used the SPSS sys tem for sta- t i s t i ca l  data  ana lys i s ,  wh ich  has  as one of i ts  fcatm.es a complete  d i sc r iminant  ana lys i s   .
2 categor ies In the ease of two categor ies ,  on ly  one funct ion  is nec- essary  foe determin ing  the category  of an i tenl .
4 categor ies Us ing the three funct ions  ext rac ted ,  366 cases were cor- rect ly  c lassi f ied,  and  134 eases were misc lass i f ied,  out  of t i le 500 cases, as can be seen in tab le  4 and  f igure 2.
"M isce l laneous" ,  the most  p rob lemat ic  category ,  is a loose group ing  of d i f ferent  in fo rmat ive  texts .
The  s ing le most  p rob lemat ic  subsubset  of  texts  is a subset  of eigh teen non- f ic t ion  texts  labe led  "learned/humalfities".
S ix teen of them were eniselassit ied,  th i r teen  as "mis - eell&eleotls".
l 134 (27 ?/~T Tab le  4: Categor i za t ion  in Four  Categor ies + .
+ -2 .0  0 .0  2 .0 F igure  2: l ) i s t r ibut ion ,  4 Categor ies 1072 15 (or 10) cat(;gorh.~s Using th0 [Oill:l;eell funetions extracted, 258 cases w(we correctly classified and 242 cases inischlssilied out of the 500 cases, as shown in table 5.
guish I)eLween the di[ferenL types of fiction is exl)en- sive.
[[ the tiction subcategories were collapsed there only wouht be ten categories, and the error rate R)r the c.atogorizal,ion would iniprove as showil ill th0 "revis0d totM" record of the tal)le.
The "learned~humanities" nubcal;egory is, as I)erore, prol)-- lematic: only two of the.
others were irlost often misclassilied as "l / ,cl igion" or "Belles l.ettre.s".
the techlii(lUe in retrieval tooln.
(-Jorl, ain l)aranieterst)robal)ly varG lnor~ ill certahl text types than other% aild they may have a s[~c?lJcd dislribulion as well.
This is i iot dillicull, to deterli i ine, although l.h(!
standard methods do llOt nupl)orl, illltO lnatic detcr ininat ion of staudard devial,iou or skl:wness as discrinl ination criteria.
lT)gethcr with iJle hwesti-.
gation of sew;ra] hil, herto Ultl.ried l)aranlcters, this is a 11(7.
Acknowledgements Thanl,:s to Hans Karlgrcu, Gumml  K,~iJlgren, (_h~c, ff Nun- berg, Jau l>ederscn, and the (,<>ling re.ferees, who all have colH:ril>uted with suggestions and method()logical discussious.
7074 l~eferences Doug las  B i tmr  1989.
"A typology of English texts", I, iu- guistics, 27:3--43.
Jeanne  S. Cha l l  1948.
Ke lnmth  C lmrch  1988.
"A Stochastic Parts of 5;fmc<:h aJtd Noun Pitrasa Pa+rser for Unrestricted Text", lbocs.
2rid ANLP,  Austbt.
Douglas,+ Cut th tg ,  Ju l ian  Kupi(w., Jan  l)(.
"A Ihact.ical lbn:t-of--Stmech 13.gger", lbocs.
2rd A NLP, Trcnto.
Doug lass  Cu?,t.lng, D. Karger ,  Jan  Pedersml ,  m~d John  Tuk(,.y 1992.
Working Papers of the lnll"illcr Project, available I,y gopher from dsv .su .se : /pub/ In tF i  ]  te r .
George  R. K la re  1963.
W.  N. ~5ancis "rod F. Ku i :era  1982. l"rcq++cm:g An,/!/sis of /J*tglish Usage , [loughton MilllilL.
"M ultiple t)iscriminsu+l Analy sis in Linguistic Problems", 5t:ttislical Methods i~t /,in- :lui.slics, /t:37-:1,t.
M. M.  Tatsuoka  7197l.
A t ro  Vout i la inen  and  pas l  5[?1I)all~-thlelt I993.
"Ambi- guity resoh,l.ion in a, reduct.ionistic parser", Procs.
6lh ]~uropcan A CL, t ltrcchl.. SPSS  1990.
Consider a sentence 5 = w1w2...wn.
Rescoring We rescore 1000-best translations   by replacing the 3-gram LM score with the 5-gram LM score computed offline.
After 5-gram rescoring, it achieved 1.21 point improvement in BLEU and 1.19 improvement in TER.
Zo is then Ps αT(s).
As a simple example, the head parameter class smoothes PH0(H  |P, wh, th) with PH1(H  |P, th) and PH2(H  |P).
6.9.2 Unknown-Word Mapping.
SBR-89-20239 and DARPA grant no.
N66001-00-1-8915.
The test sub-corpus consists of the 100 MUC-6 documents.
As long as T. m¯ =� 0, the process expands some node pair (d1, d2) E T. ¯m.
The outer loop iterates bottom-up over nodes c1 of T1; an inner loop iterates bottom-up over c2 of T2.
Bootstrapping Statistical Parsers From Small Datasets
Some pre- vious approaches to the pronominalization deci.
Following Grosz, Joshi and Weinstein  , references to other entities present in cache mem- ory may also be pronominalized, provided the cen- tre is pronominalized.
DS ~--- inde= ..~ = status =.
Artificial Intelligence, 26, 1-33.
Clocksin, William F. and Melllsh, Christopher S.   Programming in Prolog.
Berlin: Springer- Verlag.
151, 74 NP N2 Nl l NPx NPI ---4.
In Proceed- ings of the ~lst Annual Meeting o/the Associa- tion for Computational Linguistics, Massachusetts Institute of Technology, Cambridge, Mass., 15-17 June, 1983, pp44-49.
Computational Linguistics, 12, 175-204.
Hobbs, Jerry R.   Resolving Pronoun Refer- ences.
Lingua, 44, 311-338.
Kamp, Hans   Two Theories about Adjec- tives.
Cambridge: Cambridge Uni- versity Press.
McDonald, David D.   Natural Language Gen- eration as a Process of Decision-Making under Con- straints.
Linguistic In- quiry, 20, 134--139.
Shieber, Stuart M.   An Introduction to Unification- based Approaches to Grantmar.
London: Garland Pub- lishing.
Barzilay and McKeown   incorporated part-of-speech information and other morphosyntactic clues into their co-training algorithm.
Ibrahim et al.   generated structural paraphrases capable of capturing longdistance dependencies.
• The paraphrase criterion could be changed from being e2 =� e1 to specifying that e2 is not sub- or super-string of e1.
0713448.
544
This can be computed in time O(|V|(|£ |+ |V |log |V|)), which we can rewrite as O((|R |+ |S|)(|R||S |+ (|R |+ |S|) log(|R |+ |S|))).
We use the set of sentence-level features described by Riedel et al.  , which were originally developed by Mintz et al.
Yao ing noisy data.
FA8750-09-C-0181.
'Gemini is implemented primarily in Quintus Prolog version 3.1.1.
Watashi ga sensei ni hon wo I NOM teacher DAT book ACC katte morat-ta. buy get-past 'The teacher bought me a book.'
Nihongo no benkyou wo hajimeru.
Schubert 1986; McRoy and Hirst 1990).
Frazier and Rayner 1990).
Fox et al. 1988).
Church and Hanks 1990; Smadja and McKeown 1990).
Dyer and Zernik 1986).
Indeed, running our MCCA model with only orthographic features on EN-ESW, labeled ORTHO in table 1, yielded 80.1 p0.33, a 31% error-reduction over EDITDIST in p0.33.
In these cases, MCCA yielded much lower precisions of 26.8 and 31.0 p0.33, respectively.
It contains segments S3 and S4 within it, and consists of utterances UI ... U6.
Thus, c2(D2) is .5.
Similarly .1V(ci) for user 11 is -1.51.
Cli2: Ok.
Ok?
ers plans.
In Proc.
[Sid79] Candace L. Sidner.
Finite-state-grammar-based approaches to parsing are exemplified by the parsing systems in Joshi,  , Abney  , Appelt et al.  , Roche  , Grishman  , Hobbs et al.
 , Joshi and Hopely  , and Karttunen et al.  .
The trigram model was trained on (part-of-speech, supertag) pairs collected from the LTAG derivations of 5,000 WSJ sentences and tested on 100 WSJ sentences.
A more detailed discussion about these properties is presented in Joshi (1985, 1987), Kroch and Joshi  , Schabes, Abeille, and Joshi  , and Joshi and Schabes  .
It was partially supported by NSF grant NSF-STC SBR 8920230, ARPA grant N00014-94 and ARO grant DAAH04-94-G0426.
Entity-Based Cross-Document Core f erencing Using the Vector Space Model
The initial step is to take a histogram of a corpus with accents and diacritics retained, and compute a table of accent pattern distributions as follows: De-accented Form Accent Pattern % Number cesse cesse 53% 669 cesse 47% 593 cout mut 100% 330 couta cofita 100% 41 coute colite 53% 107 mite 47% 96 cote cote 69% 2645 cote 28% 1040 cote 3% 99 cote <1% 15 cotiere cOtiere 100% 296 For words with multiple accent patterns, steps 2-5 are applied.
As such WordNet provides relations beyond is–a, including has–part, is–made–of, and is–an–attribute–of.
WordNet::Similarity was preceeded by the distance.pl program, which was released in June 2002.
Thereafter Siddharth Patwardhan ported this measure to WordNet::Similarity.
Toward Memory--based Translation Satoshi SATO and Ma.koto NAGAO Dept.
of Electrical Engineering, Kyoto  University Yoshida-honmachi,  Sa.kyo, K.yoto, 606, Ja.pan sa.to@kuee.kyoto-u.ac.jp Abst ract An essential problem of example-based transla- tion is how to utilize more than one translation example for translating one source sentence.
The idea first appeared in [Nagao 84], and some research has followed it [Sumita 88][Sato 89][Sadler 89a.
2. tlow to select tile best tra.nslation out of inany candidates?
MBT2 is the second prototype system in our Memory-based Translation Project.. MBT2 ca.n do bi-directional m~nslation between an English word-dependency tree and a Japanese word- dependency tree.
It is implemented in Sicstus Prolog.
Kate ha nouto wo ka~.
(4) Kate ha kokusMseiji nitsuite kM~reta hon WO ka~ll.
A lack of this abil- ity restricts the power of example-based trans- lation.
%% Kare ha nouto wo kau.
3.2 T rans la t ion  Un i t A word-dependency (sub)tree which has a cor- respondence link is transhttable; .g.
Sadler calls them translation w,,its[Sadler 89a,].
te %% kakareta  hon wo yomu.
Kate ha kokusaisei j i  nitsuite ~,~, kakareta hon wo kau.
For example, n7 corresponds with rn6 or m7.
Hito ha yasal wo taberu.
San ha kinzoku wo oka.qu.
MBT2 chooses htberu for he cat.s t~ota, toes and okasu for sulfuric acid cals i ron.
It produces high quality trans- lations.
References [Nagao 84] Makoto Nagao, A Framework of a Mechanical Translation between Japanese and English by Analogy Principle, in ARTI- FICIAL AND tIUMAN INTELMGENCE (A. Elithorn and R. Banerji, editors), El- sevier Science Publishers, B.V, 198.t.
[Sadler 89a] Victor Sadler, The Bilingual Knowledge Bank(BKB), BSO/Research, 1989.
[Sato 89] Satoshi Sa.to and Makoto Nagao, Memory-based Translation, IPSJ-WG, NL- 70-9, 1989.
In~oducfion This paper tommlizes the model for natural Imlgnage introduced m [Sclm 199o].
(Markov- cludns, see e.g.
Non-lexical l,fl~els represent syi~tactic and/or semantic mid/or i)ragnlalie infonnatiou, depending on file kind of corpns being used.
We will write (toU)ov ;Ls touov, and ill general (..((tloQ)o(~)o..)otn as tl~t2o(~o...otn.
Thell 7) occurs ill" (tll,...,tlnl) or (t21,...,ten 2) or .... or (Ikl,,.,tknk) occur, aud (thl,...,tlmt) (~culs iff thl and th2 and .... ACrl!s ol.
AcrEs Dr: COLING-92.
1992 grammaticality and the structure of new utterances univocally.
[Salomaa 1969]: Salomaa, A., Probabilistic and weighted grmnmars, in: lnfomJation and control 15, p. 529-544, [Scha 1990]: Scha, R., Language Theory and Language Technology; Competence and Perfomumce (in Dutch), in: Q.A.M.
de Kort & G.L.J.
), Computertoepassingen in de Ncerlandistiek, Almere: Landelijke Vereniging van Neerlandici.
(LVVN- jaarboek) [Scholtes 1992]: Scholtes, J. C. and Bloembergen, S., The Design of a Neural Data-Oriented Parsing 0DOP) System, Proceedings of  the Intonational Joint Conference on Neural Networks 1992, Baltimore.
ACRES DE COLING-92, NANTES, 23-28 AOt~l" 1992 8 5 9 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
Second, the parsers in (Collins 96) and (NIagerman 95; Jelinek et al. 94) produce trees without information about whmovement or subcategorisation.
(Magerman 95; Jelinek et al. 94) describe a history-based approach which uses decision trees to estimate P(TIS).
LexPageRank: Prestige In Multi-Document Text Summarization
Task 2 involves summarization of 50 TDT English clusters.
2.1 Pattern-based approaches.
Berland and Charniak   used similar pattern-based tech niques and other heuristics to extract meronymy (part-whole) relations.
Girju et al   improved upon Berland and Charniak's work using a machine learning filter.
2.2 Co-occurrence-based approaches.
Sample of 10 is-a relationships discovered by our co-occurrence and pattern-based systems.
4.1 Algorithm.
The optimal pattern is retrieved by {Phil Donahue,Pat Sajak,Arsenio Hall} N:gen:N talk show 93 11.77 television show 24 11.30 TV show 25 10.45 show 255 9.98 audience 23 7.80 joke 5 7.37 V:subj:N joke 39 7.11 tape 10 7.09 poke 15 6.87 host 40 6.47 co-host 4 6.14 banter 3 6.00 interview 20 5.89 N:appo:N host 127 12.46 comedian 12 11.02 King 13 9.49 star 6 7.47 Figure 1.
Following are two of them: 1) X_JJ#NN|JJ#NN#NN|NN _CC Y_JJ#JJ#NN|JJ |NNS|NN|JJ#NNS|NN#NN|JJ#NN|JJ#NN#NN e.g. ?caldera or lava lake?
2) X_NNP#NNP|NNP#NNP#NNP#NNP#NNP#CC#NNP |NNP|VBN|NN#NN|VBG#NN|NN ,_, _DT Y_NN#IN#NN|JJ#JJ#NN|JJ|NN|NN#IN#NNP |NNP#NNP|NN#NN|JJ#NN|JJ#NN#NN e.g. ?leukemia, the cancer of ...
5.2 Precision.
5.3 Recall.
PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 38.7% 41.0% 41.0% 4.3% 8.0% 7.3% 15MB 39.1% 43.0% 41.5% 14.6% 32.0% 24.3% 150MB 40.6% 46.0% 45.5% 51.1% 73.0% 67.0% 1.5GB 40.4% 39.0% 39.0% 56.7% 88.0% 77.7% 6GB 46.3% 52.0% 49.7% 64.9% 90.0% 78.8% 15GB 55.9% 54.0% 52.0% Too large to process Table 6.
PATTERN SYSTEM CO-OCCURRENCE SYSTEM Prec Top-3 MRR Prec Top-3 MRR 1.5MB 56.6% 60.0% 60.0% 12.4% 20.0% 15.2% 15MB 57.3% 63.0% 61.0% 23.2% 50.0% 37.3% 150MB 50.7% 56.0% 55.0% 60.6% 78.0% 73.2% 1.5GB 52.6% 51.0% 51.0% 69.7% 93.0% 85.8% 6GB 61.8% 69.0% 67.5% 78.7% 92.0% 86.2% 15GB 67.8% 67.0% 65.0% Too large to process 775 However, Figure 2 shows that the pattern-based approach extracts many more relationships.
5.3.2 Definition questions Following Fleischman et al  , we select the 50 definition questions from the TREC2003   question set.
However, by being consistent across all Total Number of Is-A Relationships vs. Dataset 0 200000 400000 600000 800000 1000000 1200000 1400000 1.5MB 15MB 150MB 1.5GB 6GB 15GB Datasets To ta l Is A Re la tio n s hi ps s Pattern-based System Co-occurrence-based System Figure 2.
Average precision of the pattern-based sys tem vs. WordNet and human hyponyms.
WNet Human 1.5MB 38.7% 45.8% 83.0% 41.0% 84.4% 83.0% 15MB 39.1% 52.4% 81.0% 41.5% 95.0% 91.0% 150MB 40.6% 49.4% 84.0% 45.5% 88.9% 94.0% 1.5GB 40.4% 43.4% 79.0% 39.0% 93.3% 89.0% 6GB 46.3% 46.5% 76.0% 49.7% 75.0% 76.0% 15GB 55.9% 45.6% 79.0% 52.0% 78.0% 79.0% Table 8.
Average precision of the co-occurrence based system vs. WordNet and human hyponyms.
PRECISION MRR Co-occ WNet Human Co-occ WNet Human 1.5MB 4.3% 42.7% 52.7% 7.3% 87.7% 95.0% 15MB 14.6% 38.1% 48.7% 24.3% 86.6% 95.0% 150MB 51.1% 57.5% 65.8% 67.0% 85.1% 98.0% 1.5GB 56.7% 62.8% 70.3% 77.7% 93.0% 98.0% 6GB 64.9% 68.9% 75.2% 78.8% 94.3% 98.0% Relative Recall (Pattern-based vs. Co-occurrence-based) 0.00 1.00 2.00 3.00 4.00 5.00 6.00 7.00 1.5MB 15MB 150MB 1.5GB 6GB 15GB (projected) Datesets Re la tiv e Re ca ll Figure 3.
Toward this end, we pooled a number of resources: COMLEX Syntax (Macleod et al., 1998a), NOMLEX (Macleod et al., 1998b) and the verb classes from  .
*This research was supported by an NDSEG Fellowship and by DARPA grant N00014-90-J-1863.
Homophones: aid/aide, cellar/seller, censor/sensor, cue/queue, pedal/petal .... ?
OCR Ambiguities: terse/tense, gum/gym, deaf/dear, cookie/rookie, beverage/leverage .... ?
APPL ICAT IONS 7.1.
Bahl, L., P. Brown, P. de Souza, R. Mercer, "A Tree-Based Sta- tistical Language Model for Natural Language Speech Recog- nition," in IEEE Transactions on Acoustics, Speech, and Signal Processing, 37, 1989.
Gale, W., K. Church, and D. Yarowsky, "One Sense Per Dis- course," Proceedings of the 4th DARPA Speech and Natural Language Workshop, 1992.
Leacock, Claudia, Geoffrey Towell and Ellen Voorhees "Corpus-Based Statistical Sense Resolution," inProceedings, ARPA Human Language Technology Workshop, 1993.
Rivest, R. L., "Learning Decision Lists," in Machine Learning, 2, 1987, pp 229-246.
Sproat, R., J. Hirschberg and D. Yarowsky "A Corpus-based Synthesizer," in Proceedings, International Conference on Spoken Language Processing, Banff, Alberta.
— Nous passons maintenant A l'or— dre du jour de cette semaine.
— (EN> Monsieur le President, je pro— teste energiquement contre le fait que l'ordre du jour de cette session ne prevoit pas de &bat d'actualite et d' urgence.
Je sais que cette decision a ete prise par le Bureau elargi parce qu'il s'agit d'une session extraordinaire.
Neanmoins, comment pourrions—nous, en tant que Parlement, etre pris au serieux si nous ne nous occupons que de nos petits problemes internes sans nous soucier de cc qui se passe dans le monde?
Je vous serais recon— naissant de bien vouloir demander au Bureau ear— gi de voir comment nous pourrions avoir des seances supplementaires pour aborder les questions urgentes.
Cela dit, et puisqu'il n'y a pas de problemes urgents, je voudrais demander A la Commission de faire des declarations sur deux points.
Premiere— ment: quelles actions la Communaute envisage—t— ele pour venir en aide au peuple du Nicaragua, textes d'accords: CE. proces—verbai.
[italics added] qui vient de subir une immense catastrophe natu— relle laissant sans abri le tiers de la population?
Deuxiemement: le comrnissaire Sutherland pour— rait—il faire une declaration au sujet de la situation creee au Royaume—Uni par la decision du gouver— nement britannique d'accorder a la societe Aero— space une subvention s'elevant A un milliard de livres sterling en lui vendant les Royal Ordinance Factories A un prix cadeau et en lui permettant de brader des elements d'actif afin de reunir des liquidites de cet ordre?
— Je pense que vous venez de parler de quatre urgences en une seule.
Nous ne pouvons le permettre.
Le Bureau elargi a pris une decision.
Cette decision a ete transmise A l' Assem— bide et l'Assemblee l'a enterinee.
La presente pe— node de session est une periode de session spe— ciale.
Nous avons beaucoup de pain sur la planche et je vous propose d'avancer.
ing operations.
IRI 96-19124 and MI 96-18797.
Lemma 4 Let ki X1 Al X2.
4.7.1 Computing 1-expansion probabilities.
Viterbi parse  .
I /Y v• ]/3&quot;,7&quot;] i: kX AY.,u [0,7] j kX -4 A.Yp, [r3C-Y1 for all pairs of states 1Y -4 v. and kX A.Ybt in the chart.
Edge-Based Best-First Chart Parsing
Bobrow   and Chitrao and Grishman   introduced best-first PCFG parsing, the approach taken here.
1994: Kochman and Kupin.
1991: N1agerman and Marcus, 1991).
11.
Procedure MoveWord
For the first experiment we trained predictive class-based 5-gram models using clusterings with 64, 128, 256 and 512 clusters1 on the en target data.
HHMM-Based Chinese Lexical Analyzer ICTCLAS
The unigram predicates (see e.g.
Carreras et al.  ).
For example, Moody becomes Aa, A.B.C. becomes A.A.A. and 1,345.05 becomes 0,0.0.
Multi-Source Transfer of Delexicalized Dependency Parsers
Ganchev et al. also report results for Bulgarian.
Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a).
Draw second-level infinite multinomial over subsymbols πs0szc — DP(α,βs0).
Variational approximations to the HDP are truncated at 10.
As examples, Kneser-Ney Smoothing  ,Katz Backoff   and linear interpola tion   can be expressed inthis scheme  .
5.2 Generation of n-Grams.
maxorder-1 Emit(ids[i-j ..
The required n grams wii?n+1 and wi?1i?n+1 always share the same first word wi?n+1, except for unigrams.
861 Step 0 Step 1 Step 2 context counting unsmoothed probs and interpol.
MapReduce 2 computes theinterpolation.
Katz Backoff requires similar additional steps.
300 billion n-grams.
7.3 Perplexity and n-Gram Coverage.
The Penn Discourse TreeBank 2.0.
4.1.
rd =i 1 4.2.
and ?paramod mahajan.?
Stochastic Attribute-Value Grammars
The Kullback-Leibler divergence D(pllq) is 0.03.
Stanfordâ€™s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task
FA8750-09-C-0181.
3.1.1 LOB.
3.1.2 WSJ.
3.1.3 Eindhoven.
3.2.1 Error-driven Transformation-based Learning.
3.2.2 Memory-Based Learning.
Ratnaparkhi 1996).
TagPrecision is clearly inferior to TotPrecision.
The most frequent ones are Securities (146 NNP vs. 160 NNPS) and Airlines (72 NNP vs. 83 NNPS).
There are only two very unbalanced cases: Times (78 NNP vs. 6 NNPS) and Savings (76 NNP vs. 21 NNPS).
Examples here are about in cases such as about 20 (405 IN vs. 385 RB) or about $20 (243 IN vs. 227 RB), ago in cases such as years ago (152 IN vs. 410 RB) and more in more than (558 JJR vs. 197 RBR).
In the training set, stock-index in premodifying position is tagged JJ 64 times and NN 69 times.
The difference is always significant, except in the cases MXP+HMM+MBT+TBL vs. MXP+HMM+MBT and HMM+MBT+TBL vs. HMM+MBT.
1997.
The dot product of x1 and x2 is given by x1 · x2 = |X1 n X2|.
The PKE with a Cubic Kernel tends to make Q large (e.g., |Q |= 2.32 million for JWS, |Q |= 8.26 million for JDP).
Isozaki et al. propose an XQK  .
XQK can be subsumed into PKE.
µd ¶µ
Vieira & Poesio  , Harabagiu et al.  , and Markert & Nissim   explore the use of WordNet for different coreference resolution subtasks, such as resolving bridging reference, otherand definite NP anaphora, and MUC-style coreference resolution.
Luo et al.  , Kehler et al.
Wikipedia is a multilingual Web-based free-content encyclopedia5.
I SEMROLE the semantic role argumentpredicate pairs of REi.
J SEMROLE the semantic role argumentpredicate pairs of REQ.
For example, pleonastic it has been identified using heuristic approaches  , Lappin and Leass  , Kennedy and Boguraev  ), supervised approaches  , M¨uller  , Versley et al. (2008a)), and distributional methods (e.g., Bergsma et al.
Rather than deriving features from parse trees, Iida et al.   and Yang et al.
Publicly available coreference systems currently include JavaRAP  , GuiTaR  , BART (Versley et al., 2008b), CoRTex  , the Illinois Coreference Package  , CherryPicker  , Reconcile  , and Charniak and Elsner’s   pronoun resolver.
Multi-Prototype Vector-Space Models of Word Meaning
et al, 2007), Chinese  , Czech (Bo?hmova?
Arc-eager projective left-to-right.
Arc-eager projective right-to-left.
Arc-standard projective left-to-right.
Covington non-projective right-to-left.
two non-projective parsers.
E1.
M1.
Any two text spans (beg1, end1) and (beg2, end2), are the same iff beg1 = beg2 and end1 = end2.
They access external resources such as the WordNet (Hovy et al., 2001, Pasca and Harabagiu, 2001, Prager et al., 2001), the web  , structured, and semistructured databases  .
Qt2: How did _p die?
St2: _p died of causeDeath(_p).
et al, 2009).
We combined thisparsing algorithm with the passive-aggressive perceptron algorithm  .
Shi etal.
93bles.
te tp ta r total par.
trai.
{} // thread-save data list for w1 ? 1 to |xi| for w2 ? 1 to |xi| data-list?
remove-first-element(data-list) if d is empty then end-thread ...
ThresholdFor non-projective parsing, we use the NonProjective Approximation Algorithm of McDon ald and Pereira  .
96
These include celebrity-from, animal-of, lakein, borders-on and enemy-of.
Other relations generated include served-with, bait-for, food-type, spot-type, and gill-type.
In dictionary-based methods (e.g.
Although Eq.
To resolve CA, we select 70 high-frequent two-character CAS (e.g.
The annotated test set contains in total 247,039 tokens (including 205,162 lexicon/morph-lexicon words, 4,347 PNs, 5,311 LNs, 3,850 ONs, and 6,630 factoids, etc.)
We picked 933 sentences at random containing 22,833 words (including 329 PNs, 617 LNs, and 435 ONs) for testing.
By combining several parsers with f-scores ranging from 91.0% to 86.7%, we obtain reparsed results with a 92.1% f-score.
N66001-99-2-8916.
Supertagged Phrase-Based Statistical Machine Translation
Two kinds of supertags are employed: those from Lexicalized Tree-Adjoining Grammar and Combinatory Categorial Grammar.
Lexicalized Tree-Adjoining Grammar   and Combinary Categorial Grammar  .
Both the lexicalized syntactified target phrase.
Both supertaggers achieve a supertagging accuracy of 90–92%.
Briscoe and Carroll   gen erate underspecified semantic representations fromtheir robust parser.
In E—*F: 84.2/92.0/13.0 F—*E: 86.9/91.1/11.5 Intersection: 97.0/86.9/7.6 Joint training nous nous nous ne ne ne avons avons avons pas pas pas cru cru cru bon bon bon de de de assister assister assister a` a` a` la la la r´eunion r´eunion r´eunion et et et en en en avons avons avons inform´e inform´e inform´e le le le cojo cojo cojo en en en cons´equence cons´equence cons´equence .
Reiter and Dale 2000).
Kleene 1971,pages 6–8).
The trigram model is smoothed using deleted interpolation with the bigram and unigram models,  , as in (1): w# kAn AyrfAyn Al*y Hl fy Al# mrkz Al# Awl fy jA}z +p Al# nmsA Al# EAm Al# mADy Ely syAr +p fyrAry $Er b# AlAm fy bTn +h ADTr +t +h Aly Al# AnsHAb mn Al# tjArb w# hw s# y# Ewd Aly lndn l# AjrA' Al# fHwS +At Al# Drwry +p Hsb mA A$Ar fryq 2 A manually segmented Arabic corpus containing about 140K word tokens has been provided by LDC (http://www.ldc.upenn.edu).
لا, تا) and multi-component (e.g.
S7, S8, & S9 are the segmentations given the prefix wA# and suffixes 0, +A, +hA.
Develop Segmenteri trained on Corpus0 through Corpusi with Vocabi.
N66001-99-2-8916.
SENSEVAL-2 English all-words task results.
Press: Editorial 2 63 51 C. Press: Reviews 3 64 54 D. Religion 4 62 52 E. Skills and Hobbies 6 63 53 F. Popular/.,ore 4 66 54 G. Belles Let~es 3 64 52 H. Miscellaneous (reports) 1 62 50 J.
Learned (science) 33 66 55 K. General Fiction 29 69 59 L. Detective Fiction 2 68 58 M. Science Fiction 2 68 57 N. Western Fiction 1 68 59 P. Romance and Love Story 2 67 55 R. Humor 5 69 58 3.3 Ef fects  o f  Guess ing As the most-frequent heuristic is defined above, when a polysemous open-class word is encountered in the test material that has not occurred anywhere in the training material, a random guess at its sere  is used.
REFERENCES I. Gale, W., Church, K. W., and Yarowsky, D.   Estimating upper and lower beunds on the performance of word-sense disambiguation programs.
Miller, G. A., Ed.
Interna- tional Journal of Lexicology, 3, No.
Boston, MA: Houghton Mifflin.
Teachers Col- lege Record, 39, 65-77.
Thomdike, E. L., and Barnhart, C. L., Eds.
  Thorndike- Barnhart Junior Dictionary.
Miller, G. A., Leacock, C., Tengi, R., and Bunker, R.   A semantic oncordance.
Proceedings ofa Human Language Technology Workshop, p. 303-308.
Leacock, C., Towel], G., and Voorhees, E.   Corpus- based statistical sense resolution.
Proceedings ofa Human Language Technology Workshop, p. 260-265.
): 2LP and 3LP are 2- or 3-layer perceptrons using our surface cues.
This style resembles CKY and Earley parsers.
C=C/C++, Py=Python, Ja=Java.
9,10
Yue Zhang helped with Chinese datasets, and Wenbin Jiang with feature sets.
Toutanova etal.
MacKay   and Beal   describe Variational Bayesian   describe VBfor PCFGs (which only involves a minor modifica tion to the M-step of the Inside-Outside algorithm).
0.5.
  and Teh et al  .
303
tomatically ~xtracted from a large corpus.
' l~-ansformat ion-Based Er ror -Dr iven Learn ing Tra, nS\]bl'm~d;ion-lmsed errol:-dHven learlting is ~ sin@e learning a.lgorithm tlmt has t)eeu applied to a. number of natural la.ngm,ge prol)ie.ms, includ- Jllg l)a.t't O\[' speech tagging and syuta.cl, ic l)m:sing (1h:i92, \]h:i93a, Bri!)gb, Bri9d).
Figure :1 illus- trates the learning l)l:OCC'SS, l:irsL, tlll;21nlola, ted text; is l)assed through the initial-st;ate mmota- tot.
Ouce text has beeu passed through the iuitia.l-state almOl, at.or, it.
So far, ouly ~ greedy search al)proach as been used: at eaeh itera.tion o\[' learning, t.he tra nsfo> nl~tion is found whose application results in the greatest iml)rovenmnt; ha.t transfk)rmation is then added to the ordered trmlsforlmLtiou list and the corpus is upd~d.ed by a.pplying the.
r lh:ansformation-B ased Prepos i t iona l Phrase At tachment We will now show how transformation-based e.rrol> driwm IGmfing can be used to resolve prep(~si- tiered phrase at, tachment ambiguity.
1,'or all sentences that conlbrm to this pattern in the Penn Treeb~mk W{dl St, l:eet 3ourlml corpns (MSM93), such a 4-tuplc was formed, attd each :l-tuple was paired with the at~aehnteut de- cision used in the Treebauk parse) '\['here were 12,766 4q;ul)les in all, which were randomly split into 12,206 trnining s**mples and 500 test samples.
\[n the initial sl,~te mmotator, all prepositional phrases I \])at.terns were extra.clxxl usJ.ng tgrep, a. tree-based grep program written by Rich Pito.
'\]'\]te 4-tuples were cxtract;ed autom~tk:ally, a.ud mista.kes were not.
m~vn tta.lly pruned out.
Accuracy 81.00 rl 80.00 !!
Applying l.hese transt'ormai.ions to the test set l'eslllted in a.n accuracy of' 81.8%.
\[n figure 4 we show tile lirst 20 tra.nsform{~l, ions lem'ned using ilOllll classes.
(; 'Phe first; grans- Ibrmation st~l.cs thai.
if" N2 is a. nomt I, hal; describes time (i.e. ix a. member of WordNet class that in- cludes tim nouns "y(;ar," "month," "week," and others), thell the preltositiomd phrase should be al;tache(\[ t,() the w;rb, since, tim(; is \]nlMl more l ikely Io modify a yet'It (e.g. le,vc lh(: re(cling iu an hour) thaJl a, lloun.
This exlw, r iment also demonstrates how rely \[~?~l;ul:e-based lexicon or word classiflcat, ion scheme cau triviaJly be incorlJorated into the learner, by exLencling l;ransfot'nlal,iolls to allow thent to make l'efel'eAlc(?
\],valuation against Other Algorithms In (lIl~91, HR93), tra.inittg is done on a superset el' sentence types ttsed ill train- ing the transforlJ~atiolFbased learner.
The transformation-based learner is I, rained on sen- tences containing v, n\[ and p, whereas the algo- r i thm describe.d by l l indle and I~,ooth ca.n zdso use sentences (;ontailfing only v and p, (n' only nl and i1.
\[11 their lmper, they tra.in on ow~r 200,000 sen- Lettces with prel)ositions f'rotn the Associated Press (APt newswire, trod I;hey quote a.n accuracy of 78- 80% on AP test &~ta..
P is i~ and N\] is 15 N1 V \[written co.mmlu~ication\] 16 N1 V l ) is wilhoul 17 N1 V P is during 18 N 1 V 19 NI V. 20 N1.
The t.ech- nique described in (Res93b, 1{1t93), which com- bined Hindle and Rooth's lexical association tech- nique with a WordNet-based conceptual associa- tion measure, resulted in an accuracy of 76.0%, also lower than the results obtained using trans- formations.
Since llindle and Rooth's approach does not make reference to n2, we re-ran the transformation-learner disalk)wing all transforma- tions that make reference ~o n2.
1202 or both Mnds of i ld'ormation as eotll;extual fea- tlll?eS riley {lescril)e a search process use(\[ to {letePn6\]m what, sul)set of the available ill\['or,~Ht- l ion will Im used in the model.
They also report that a (leeision tree mode/ eon- st\];u(:t~d using the same features m,d I,i;aining data ac\[lieve{I I)erformanee of 77.71~, (}n t\[:e same I.est set, A llUll ll)el' o\[' other reseaPehers have exl)lored eorlms-I)ased approaches I;o l)repositional phrase attaehmet, t disaml)iguation tM~t n\]~d{c use of word classes, l"or example, Weisehed{q cl al.
(WAIH91) and Basili el al.
(BI}V91) bol,\]l deseril)e the use of lnanual ly coustrueted, donmhv Sl){~eitic word classes together with cori}us-tmsed si,t~tisties in o f d{2r to resolve i)rel)ositional 1)hrase a.t, taehlllellt &Ill-.
COl\[lD~/l:iSOll, Conc lus ions The.
tPansl 'ormation-hased approach to resolving preposit ional phl:ase disanlbiguat ion has a mlmt)er of advaiH;ages over (}l,\]ler ;i.l)l)roatehes.
\[11 a (\]irect eoml);u:ison with lexical association, higher ble(;ll- vaey is achieved using words alolm (wen though at tachment inf\}rnlation is captured i*l a relatively small numl)er of simple, rea(lable rules, as opl)osed to a. large lllllll\])eF Of lexical co-oeetlrreltee l)l'o\])a -- I)ilities.
And in (:outrast to ap- pro~ches using class--based prol)abil istic models (BPV91, Res93e, WAI~ F91) or classes derived vi;~ statist ical clusl.ering methods (1~.R94), t:his {ech- l l ique pro(hlees a, I:HIO set that (:al}l;ltr{es eolteepl:~lal geueralizal;ions couciseIy a.ml ill \]mman-rea{Ial}\]e for I n. F/\]rthel:lllOl:e, iuso\['ar as (:oHq)a, risolls e&ll I)o ina(h- all lOl lg separa, Le exl'}el:llllel/l;s l lsi lt~ Wai l Street Jour\]ml training aml test data (( l lRgl) , reiml)l('meute(l as reI)oPted above; (l{es93e, 1t1193); (IH1.94)), the rule-based approach de..
scribed here achieves better perl'orlttaucc, using ml algol:ithm tlmt is eoncel}tually quite Mml)le am/ iu l)l'~l.(;tiea\] teFlttS extretuely easy to i lnplenlel~t, s A more genera\] point ix tha.t the transl'orm~d,ion-based ;~l)l}roateh is eas- ily a(lapl,ed t;o s i tuat ions in which some learning 1"rein a (:orpus is desiral)le, 1}ui, hand-construetc{I l}l:ior knowledge is also available.
And knowu exceptious {:au 1)e handh'(l t ransparent ly simply hy adding add\]: \[onal rules to tim set thai; is learned, IlSillg tile sall le representat io\] l . A disadwmtage of the al)l)roach is that it re- quires supervised t ra in ing that is, a representa- tive set of "true" c~ses t'FOlll which Co learn.
Ilow- ever, this l)eeomes less of a probh'.m as atmotated eorl}ora beeolne increasingly available, and sug- gests the comhinat ion o1:' supexvised and uusuper vised methods as a.u ilfl;eresth G ave\]me \['or \['urther rese;ire\] \[.
Nobata et al.   and Collier et al.
F-score.
  TEXTRUNNER is a fullyimplemented, highly scalable example of OIE.
PTREE.
EXACTLY1.
ATMOST1.
NAND.
NOT2.
NO2CYCLE.
SIB.
CHILDSEQ.
NOCROSS.
For PTREE  .
To explore the phenomenon of control in rela- tion to ATTENTIONAL STATE [GS86, GJW86, Sid79] 4.
-- COMMANDS: Utterances intended to in- stigate action.
The class REPETI- TION/SUMMARY corresponds to the controller pro- ducing a redundant  utterance.
It prop- erly contains cross-speaker interruptions that in- volve topic shift, similar to the true-interruptions of Grosz and Sidner[GS86], as well as clarification subdialogues[Sid83, LA90].
The financial ADs had 45 event anaphors in 474 utterances.
We also found that con- trol was distributed and exchanged ifferently in the ADs and TODs.
Hobbs has ap- plied COHERENCE RELATIONS to face-to-face con- versation in which mixed-initiative is displayed by participants[HA85, Hob79].
A cen- tering approach to pronouns.
[CLNO90] Phillip R. Cohen, Hector J. Levesque, Jose H. T. Nunes, and Sharon L. Ovi- att.
Unpub- lished Manuscript.
The pragmatics of re- ferring and the modality of communica- tion.
ComputationalLinguistics, 10:97- 146, 1984.
Computa- tional Linguistics, 13:11-24, 1987.
[CP82] Phillip R. Cohen, C. Raymond Per- rault, and James F. Allen 1982.
Inc, Hillsdale, N.J., 1982.
[CP86] Philip R. Cohen and C. Raymond Perrault.
In Bonnie [CWG86] [FL89] [GJW86] [Gro77] [GS86] [GS90] [HA85] [HL87] [Hob79] [Jos82] Lynn Webber Barbara J. Grosz, Karen Sparck Jones, editor, Readings in Nat- ural Language Processing, pages 423- 440.
Morgan Kauffman, Los Altos, Ca., 1986.
Referring as a collaborative pro- cess.
Cognition, 22:1-39, 1986.
David M. Frohlich and Paul Luff.
Con- versational resources for situated action.
Annual Meeting of the Com- puter Human Interaction of the ACM, 1989.
Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
Technical Report 151, SRI Inter- national, 333 Ravenswood Ave, Menlo Park, Ca.
Barbara J. Grosz and Candace L. Sid- net.
Barbara J. Grosz and Candace L. Sid- her.
Julia Hirschberg and Diane Litman.
Coherence and corefer- ence.
Cognitive Science, 3:67-90, 1979.
Aravind K. Joshi.
Rec- ognizing and relating discourse inten- tions and task-oriented plans.
Inten- tions in Communication, MIT Press, Cambridge, MA., 1990.
Hector J. Levesque, Phillip R. Cohen, and Jose H. T. Nunes.
On acting to- gether.
In AAAIgO, 1990.
Kathleen R. McKeown.
On converational in- teraction with computers.
Elsevier Science, 1976.
Sharon L. Oviatt and Philip R. Cohen.
Janet Pierrehum- bert and Julia Hirschberg.
Intentions in Commu- nication, MIT Press, Cambridge, MA., 1990.
National Conference on Artifi- cial Intelligence, 1982.
Technical Report 403, SRI International - Artificial Intel- ligence Center, 1986.
Emanuel A. Sehegloff.
In D. Tannen, ed- itor, Analyzing Discourse: Text and Talk, pages 71-93.
Georgetown Univer- sity Press, 1982.
Candace L. Sidner.
Toward a computa- tional theory of definite anaphora com- prehension i english.
Candace Sidner.
Technical Report MS-CIS-86-74, Line Lab 42, Depart- ment of Computer and Information Sci- ence, University of Pennsylvania, 1986.
Steve Whittaker and Phil Stenton.
27.78 47.23 36.78 Min. error 22.52 54.72 36.78 Ann. min. risk 31.16 54.66 36.71 2: dependency accuracy on parsing 200sentence test corpora, after training 10 experts on 1000 senand fitting their weights 200 more.
References L. R. Bahl, P. F. Brown, P. V. de Souza, and R. L. Mercer.
1988.
E. Charniak and M. Johnson.
2005.
Coarse-to-fine n-best and maxent discriminative reranking.
S. F. Chen and R. Rosenfeld.
1999.
K. Crammer, R. McDonald, and F. Pereira.
2004.
In Structured Outputs M. Dreyer, D. A. Smith, and N. A. Smith.
2006.
In G. Elidan and N. Friedman.
2005.
6:81–127.
V. Goel and W. J. Byrne.
2000.
Minimum Bayes-Risk auspeech recognition.
Speech and Lan- 14(2):115–135.
J. T. Goodman.
1996.
1999.
K.-U.
Hoffgen, H.-U.
D. S. Johnson and F. P. Preparata.
1978.
S. Katagiri, B.-H. Juang, and C.-H. Lee.
1998.
86(11):2345–2373, November.
P. Koehn, F. J. Och, and D. Marcu.
2003.
Statistical phrasetranslation.
S. Kumar and W. Byrne.
2004.
Minimum bayes-risk decodfor statistical machine translation.
In J. Lafferty, A. McCallum, and F. C. N. Pereira.
2001.
In F. J. Och.
2003.
K. Papineni, S. Roukos, T. Ward, and W.-J.
Zhu.
2002.
K. A. Papineni.
1999.
Discriminative training via linear In A. Rao and K. Rose.
2001.
K. Rose.
1998.
86(11):2210–2239.
N. A. Smith and J. Eisner.
2004.
Synchronous Tree-Adjoining Grammars
Form the resultant pair </3t(oq, nl), ;32(~2, n2)).
4.2 Quant i f ie rs.
Furthermore, it is rea- sonable to require that the semantic omponent of a syn- chronous TAG t~ lexicalized (in the sense of Schabes et al.
Stan- dard parsing algorithms for both TAGs and CFGs rely on this optimization.
Arg0 or ArgM in PropBank or Agent and Goal in FrameNet.
Fbuckle.
We considered all PropBank arguments6 from Arg0 to Arg9, ArgA and ArgM for a total of 122,774 and 7,359 arguments in training and testing respectively.
ETB and CTB.
Thus Ln+1 = Rm+1 = STOP.
3.2.2 Probabilities over Subcategorization Frames.
Then we set Analogous definitions for f2 and u2 lead to A2 = f2 f2+5u2 .
Results on Section 23 of the WSJ Treebank.
LR/LP = labeled recall/precision.
Of particular relevance is other work on parsing the Penn WSJ Treebank (Jelinek et al. 1994; Magerman 1995; Eisner 1996a, 1996b; Collins 1996; Charniak 1997; Goodman 1997; Ratnaparkhi 1997; Chelba and Jelinek 1998; Roark 2001).
Joshi and Srinivas   describe an alternative “supertagging” model for tree-adjoining grammars.
Charniak   gives measurements of perplexity for a lexicalized PCFG.
Jelinek et al.  , and Magerman  .
STATISTICALLY-BASED
We created such dataset by using YourQA  , our basic Webbased QA system1.
F1-measure.
YourQA.
Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).
The current state-of-the-art is confusion-networkbased MT system combination as described by Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b).
Bangalore et al.   used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al.
Karakos, et al.   proposed an ITGbased method for hypothesis alignment, Rosti et al.
We compare to the TER-based method used by Rosti et al.  .
 ; Sys5 is a hierarchical system proposed by Chiang  ; Sys-6 is a lexicalized re-ordering system proposed by Xiong et al.  ; Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn  ; and Sys-8 is a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b).
Sys-13 is a phrasal system proposed by Koehn et al.  , Sys-14 is a hierarchical system proposed by Chiang  , and Sys-15 is a syntax-based system proposed by Galley et al.
The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.
299.
Widdows  , Mitchell & Lapata  , Giesbrecht  , Baroni & Lenci  , who propose various DSM approaches to represent argument structure, subject-verb and verb-object co-selection.
PLSR shows a mixed behaviour.
2.1 Tree-to-string alignments.
rhs(ri) is represented as a se quence of target-language words and variables.
2Specifically, an xRs rule ri is extracted fromG by taking a subtree ? ?
-9 2 1-9 2 1-9 1 2-9 7-8 1-5,9
4 1-9
-9 9 1-8 1-2 3-9 NP 7-8 1-5,9 NP 5 1-4, 7 -9 PP 4-5 1-4,7 -9 VP 4-5 1-3,7 -9 NP 4-8 1-3,9 VP 3-8 1-2,9 S 1-9 ? 7!
"# $ %& '( ) *+ , . Thes e peop le inclu de astro naut s com ing from Fran ce ..
963 2.3 Algorithm.
of nb.
For example, from the perspective of a decoder, theword by is immediately transformed into a prepo sition (IN), but it is in general useful to know which particular function word is present in thesentence to motivate good re-orderings in the up 966 lhs1: NP-C(x0:NPB PP(IN(of) x1:NP-C)) (NP-of-NP) lhs2: PP(IN(of) NP-C(x0:NPB PP(IN(of) NP-C(x1:NPB x2:VP)))) (of-NP-of-NP-VP) lhs3: VP(VBD(said) SBAR-C(IN(that) x0:S-C)) (said-that-S) lhs4: SBAR(WHADVP(WRB(when)) S-C(x0:NP-C VP(VBP(are) x1:VP-C))) (when-NP-are-VP) rhs1i p(rhs1i|lhs1) rhs2i p(rhs2i|lhs2) rhs3i p(rhs3i|lhs3) rhs4i p(rhs4i|lhs4) x1 x0 .54 x2 ? x1 ? x0 .6754 ? , x0 .6062 ( x1 x0 ? .6618 x0 x1 .2351 ( x2 ? x1 ? x0 .035 ? x0 .1073 S x1 x0 ? .0724 x1 ? x0 .0334 x2 ? x1 ? x0 , .0263 h: , x0 .0591 ( x1 x0 ? , .0579 x1 x0 ? .026 x2 ? x1 ? x0 .0116 ? ?
HR0011 06-C-0022.
Order 2 c p Order 1 c p Order 0 c p Prediction Prediction Prediction be -, o 1 1/2 b -, e 2 3/4 -4 b 2 3/26 -, esc 1 1/2 -4 esc 1 1/4 -4 e 2 3/26 eo r 1 1/2 e , o 1 1/2 --, n 1 1/26 -, esc 1 1/2 -, esc 1 1/2 -4 o 4 7/26 no t 1 1/2 n -4 o 1 1/2 -, r 1 1/26 -4 esc 1 1/2 , esc 1 1/2 -4 t 3 5/26 ob -, e 2 3/4 o -, b 2 3/8 -4 esc 6 3/13 -, esc 1 1/4 -, r 1 1/8 Order —1 or -- n 1 1/2 -4 t 1 1/8 -4 esc 1 1/2 --). esc 3 3/8 Prediction c p ot ---. t 1 1/2 r —+ n 1 1/2 -4 A 1 1/IA1 -4 esc 1 1/2 -4 esc 1 1/2 rn —p o 1 1/2 t -4 o 2 1/2 -, esc 1 1/2 , t 1 1/6 to -4 b 2 3/4 -, esc 2 1/3 -4 esc 1 1/4 tt -4 o 1 1/2 -, esc 1 1/2 Once any necessary escape event has been transmitted and received, both encoder and decoder agree that the upcoming character will be coded by the order 4 model.
The probawhere f(ai,j,ai−1,k) is the number of times feature ai,j is preceded by feature ai−1,k in the corpus.
1999; Tang et al. 2002; Steedman et al.
Let NE1 = w11w12...w1n...w1N, (n = 1,..., N) and NE2 = w21w22...w2m...w2M, (m = 1,..., M) denote two word sequences to be matched.
The batch size K = 50 in GENIA and 10 in MUC-6.
(277 words) 900 sent.
(26K words) 8004 sent.
(223K words) Newswire PER MUC-6 5 sent.
(131 words) 602 sent.
(14K words) 7809 sent.
(130 words) 7809 sent.
(113 words) 7809 sent.
Random, Strategy1 and Strategy2.
Ji and Grishman   also supple- ments.
Selectional preferences  .
The final F1 with these Attack subtypes is .40.
FA8750-09-C-0181.
Randomised Language Modelling for Statistical Machine Translation
Here we constrast the Boolean BFLM with the log-frequency BF-LM with different quantisation bases (2 = fine-grained and 5 = coarsegrained).
Text 1 Text 2 maxSim IDF jurors jurors 1.00 5.80 courtroom jurors 0.30 5.23 questionnaire questionnaire 1.00 3.57 groups questionnaire 0.29 0.85 were were 1.00 0.09 taken asked 1.00 0.28 asked asked 1.00 0.45 fill complete 0.86 1.29 out – 0 0.06 40 – 0 1.39 Next, we use equation 7 and determine the semantic similarity of the two text segments with respect to text 1 as 0.6702, and with respect to text 2 as 0.7202.
Subcorpus Extraction.
Several different workers give labels yi1, yi2, ... yiW.
Add it to .A4 2With a certain f requency cut-off, usual ly 3 to 5 3 Also with a certain f requency cut-off 0.85 0.8 0.75 0.7 0.65 0.6 0.55 0.5 PERFORMANCE: Wall St. Journal io io .
20 1 O0 120 140 160 180 200 Figure 1" Performance of Maximum Entropy Model on Wall St. Journal Data 4.
Features redun- dmlt or correlated to those features already in .A.4 will produce 252 1 0.9 0.~ 0.7 0.6 0.5 ENTROPY: Wall St. Journal Training 0.4 20 A dO dO .
Jaynes, E. T., "Information Theory and Statistical Mechanics."
43, pp 1470-1480, 1972.
Delia Pietra,S., Della Pietra, V., Mercer, R. L., Roukos, S., "Adaptive Language Modeling Using Minimum Discriminant Estimation," Proceedings oflCASSP-92, pp.
Black, E., Garside, R., and Leech, G., 1993.
Black, E., Jelinek, F., Lafferty, J., Magerman, D. M., Mercer, R., and Roukos, S., 1993.
Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J., 1984.
Brown, P. F., Della Pietra, V. J., deSouza, P. V., Lai, J. C., and Mercer, R. L. Class-based n-gram Models of Natural Language.
Hindle, D. and Rooth, M. 1990.
Structural Ambiguity and Lex- ical Relations.
Hidden Valley, Pennsylva- nia.
Magerman, D., 1994.
chl, dozhang@microsoft.com mhli@insun.hit.edu.cn muli, mingzhou@microsoft.com guanyi@insun.hit.edu.cn Abstract Inspired by previous preprocessing approaches to SMT, this paper proposes a novel, probabilistic approach to reordering which combines the merits of syntax and phrase-based SMT.
However, long-distance reordering is problematic in phrase-based SMT.
We will present an extension of our own research on TDT [Radev et al., 1999] to cover summarization of multidocument clusters.
Table 2 shows a sample centroid, produced by CIDR [Radev et al., 1999] from cluster A.
— 0.732) or 0.963.
We would like to thank Inderjeet Mani, Wlodek Zadrozny, Rie Kubota Ando, Joyce Chai, and Nanda Kambhatla for their valuable feedback.
80s  , while Bio-NER accuracy ranges between the low 70s and 80s, depending on the data-set used for training/evaluation  .
Wordnet   is a broad-coverage machine-readable dictionary which includes 11,306 verbs mapped to 13,508 word senses, called synsets, and 114,648 common and proper nouns mapped to 79,689 synsets.
Section 5.3.
The SEMv dataset only includes supersense labels for verbs.
The supersense tagger was trained on the Semcor datasets SEM and SEMv.
A STATISTICAL APPROACH TO LANGUAGE TRANSLAT ION P. BROWN,  J. COCKE,  S. DEL I ,A  PIETRA,  V. DELLA P IETRA, F. JEL INEK,  R, MF, RCF, R, and P. ROOSSIN IBM Research Divis ion T.J. Watson  Research Center Depar tment  of Computer  Science P.O.
Whether "affccting" is to be translated as "apropos"  or "cuncernant," or, as  our dictionary has it, "touchant" or "cmouvant," or in a variety of other ways, depends on the rest of the sentence.
In particular, in the example of Figme l, one would expect hat "reflects" woakl generate both "which" and "on" by secondary production, and "rise" would similarly generate "on."
We have just fitfished arguin b, itt Section 5 that the parti l ioning of sottrcc +ext ili1O locutions is SOIIIUWIIHt conlplex, and that it must be approached statistically.
The estimate of P(el ./; ~11"1 ) would be derived from courtts o1 locttlion alignments in sentmlce translate pai,s, the al ignments being dstimated based on non-contextual  glossary probabilitit+s of the form (5.2).
REFERENCES 111 L.R.
Bahl, F. Jclinek, and R.l,.
Fcrguson, Ed., ltldden Marker Models for Speech.
8-15 14] J. Metl.
Sinclair: "Lcxicogral~hic F.vidence" in, I)ielionarie,~, Lexicography and Langaage l,earniog (l!1+F Doeoments: 1211), editol R. llson, NewYork: Pergamon Press, pp.
Sampson, The Comlmlational Analysis of l(l,glish: a Corpus-Based AI)l)roach, I.ongman 1987 1161 G.R.
lhoceeding+, of tile I lth lnlernalional Corfferenee oil (k+mputaliotml l,inguintics (COl ,IN(] 86) Bonn 151-155, 1986.
171 W. Weaver: Translalion (194.9).
: Maelnine Iranslalimn of hmguages.
Calnbrid,ee, MA.
18] I[lansards: Official l)roeeedings of the liouse of Cemlnons of Canada, 19"I4+.78, CanadialJ Government Printie~ Bureau, Ihtll, Quebec ( ~ ~111~/(Ja.
IIrciman, J.ll.
Gallager: Informalion Theory aad reliahle (ommuniealion, John Wiley and Sons, Ii1c,, New York, 1968.
Dcmpstcr, N.M.l.aird, al/d It.B.
ll.ubin: Maximum likelihood from ineolnpletc data via tile I"M algorithm, Journal of Ihe Royal S|atist ical Society,  39(B) :  1-38, 1977.
1121 A.J, Viterbi: Error bounds Ior conw)httional codes and an asylntotically optimum decoding algorithm, 11,1.;1,~ Transactions on Information Theory, 1T-13:2611-267, 19fi7.
Bauln: All inequality and associated inaxilnization tcc]miquc in statistical estimatkm of probabilistic functions o1 a Maikov process, lneqoalities, 3:1-8, 1972.
Mr. Speaker, I rise on a question of privilege Monsieur l Orateur, je souleve la qoestion de privilege affecting the rights and prerogatives of pmliamentary committees a propos des droits et des prerogatives des eomites parlenmnlaires and o11o which reflects oii tile wold of two ininisters et i)otlr nlettre en d<mte les i)ro])os tie detlX illhlistles of the Crown.
F IGURE I AI,IGNMENT OF A FRENCII AND ENGHSH SI;,NTENCE PAIR 75 eau water lait milk banque bank banques banks hier yesterday janvier January jours days votre your cufants children trop too toujours always trois three monde world pourquoi why aujordbui today sans without lui him mais but suis am seulemeot only peut cannot ceintures seat ceinturcs belts bravo !
FIGURE 2 A LIST OF HIGH MUTUAL INFORMATION FRENCH-ENGLISH WORD PAIRS WHICH QUI I. qui 0.380 who 0.188 2. que 0.177 which 0.161 3. dont 0.082 that 0.084 4, de 0.060 0.038 5. d 0.035 to 0.032 6. laquclle 0.
(131 of 0.027 7. ou 0.027 the 0.026 8. ct 0.022 what 0.018 THEREFORE DONC 1. donc 0.514 therefore 0.322 2. consequent 0.075 so 0.147 3. pat" 0.074 is 0.034 4. ce 0.066 then 0.024 5. pourquoi 0.064 thus 0.022 6. alors 0.025 the 0.018 7. il 0.025 that 0.013 8. aussi 0.015 us 0.012 STILL ENCORE 1. encore 0.435 still 0,181 2. toujours 0.230 again 0.174 3. reste 0.027 yet 0.148 4.
*** 0.020 even 0.055 5. quand 0.018 more 0.046 6. meme 0.017 another 0,030 7. de 0.015 further 0.021 8. de 0.014 once 0.013 FIGURE 3 (PART I) EXAMPLES OF PARTIAL GLOSSARY LISTS OF MOST LIKELY WORD TRANSLATES AND THEIR PROBABILITIES Note: *** denotes miscellaneous words not belonging to the lexicon.
PEOPLE GENS 1. les 0.267 people 0.781 2. gens 0.244 they 0.013 3. personnes 0.100 those 0.009 4. population 0.055 individuals 0.008 5. peuple 0.035 persons 0.005 6. canadiens 0.031 peoples 0.004 7. habitants 0.024 men 0.004 8. ceux 0.023 person 0.003 OBTAIN OBTENIR l. obtenir 0.457 get 0.301 2. pour 0.050 obtain 0.108 3. les 0.033 have 0.036 4. de 0.031 getting 0.032 5. trouver 0.026 seeking 0.023 6. se 0.025 available 0.021 7. obtenu 0.020 obtaining 0.021 8. procurer 0.020 information 0.016 QUICKLY RAPIDEMENT 1. rapidement 0.508 quickly 0.389 2. vite 0.130 rapidly 0.147 3. tot 0.042 fast 0.052 4. rapide 0.021 quick 0.042 5. brievement 0.019 soon 0.036 6. aussitot 0.013 faster 0.035 7. plus 0.012 speedy 0.026 8. bientot 0.012 briefly 0.025 FIGURE 3 (PART II) EXAMPLES OF PARTIAL GLOSSARY LISTS OF MOST LIKELY WORD TRANSLATES AND THEIR PROBABILITIES EXAMPLES OF RECONSTRUCTION TttAT PRESERVE MEANING: would I report directly to you?
The main differencebetween this approach and several of our earlier ap proaches as described in Carpuat and Wu (2005b) and subsequently Carpuat et al   lies in the fact that we focus on repurposing the WSD systemfor multi-word phrase-based SMT.
62
BLEU NIST METEOR METEOR (no syn) TER WER PER CDER SMT 20.41 7.155 60.21 56.15 76.76 88.26 61.71 70.32 SMT+WSD 20.92 7.468 60.30 56.79 71.34 83.87 57.29 67.38 5.1 Data set.
5.2 Baseline SMT system.
Since our focus is not on a specific SMT architec ture, we use the off-the-shelf phrase-based decoderPharaoh   trained on the IWSLT train ing set.
⎛⎞⎛ ⎞⎛ vous achet ⎞⎛ chat ⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟ ⎜⎟⎜ ⎟⎜ PRO PRO VB ART NN ⎟⎜ ⎟⎜ ⎟ ⎜⎟⎜ ⎟⎜ je vous acheter ⎟⎜ chat ⎟⎜ ⎟⎜ ⎟⎜ ⎝⎠⎝ ⎠⎝ st present masc / ⎠⎝ ⎛ ⎞⎛ buy ⎞⎛ ⎞⎛ ⎞ you a cat ⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟ ⎜⎟⎜ VB ⎟⎜ ⎟ PRO ART NN ⎜ ⎟⎜ tobuy ⎟⎜ ⎟⎜ ⎟ you a cat ⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟⎜ ⎟ ⎝⎠⎝ Figure 2.
Correlations are 0.48 and 0.54 respectively.
In general, lines drawn between corresponding lexemes in a French sentence and its Les neo-democrates ont aussi pane de General Motors dans ce contexte .
Message Unders tand ing  Conference  - 6: A Br ie f  H is tory Ralph Grishman Dept.
Beth Sundheim Naval Command, Control and Ocean Surveillance Center Research, Development, Test and Evaluation Division (NRaD) Code 44208 53140 Gatchell Road San Diego, CMifornia 92152-7420 sundhe im@poj  ke .
The government people at- tending wcre George Doddington, Donna Harman, Boyan Onyshkevych, John Prangc, Bill Schultheis, and Beth Sundheim.
The tag ENAMEX ("entity name expression") is used for both people and organiza- tion names; the tag NUNEX ( "numer ic  expression") is used for currency and I)ercentages.
To meet this goal, we decided that the infbrmation extraction task for MUC-6 wouhl have to involve a relatively simple template, more like MUC-2 than MUC-5; this was duhbed "mini- 467 Mr. <ENAMEX TYPE="PERSON">Dooner</ENAMEX> met with <ENAMEX:TYPE="PERSON">Martin Puris</ENAMEX>, president and chief executive officer of <ENAMEX TYPE="ORGANIZATION">Ammirati & Puris</ENAMEX>, about <ENAMEX TYPE="ORGANIZATION">McCann</ENAMEX>~s acquiring the agency with billings of <NUMEX TYPE="MONEY">$400 million</NUMEX>, but nothing has materialized.
), me(liated perhaps by a "re- lational" level template.
These low- level t;emptates were named "telnplate lements".
Pred icate -argument  s t ruc ture :  the sys- tem wouhl have to create a tree interrelating the constituellts of the sentence, using sonm set of gralnma.tical flnmtional relations The committee recognized that, in seh;eting sneh internal measures, it, was inaking sortie presumI) tion regarding the structures and decisions which an analyzer should make in understanding a doc- llmellt.
How- ever, froln the current perslmctive of tnost of the eolnmittec, @ese seenmd fairly ])asic aspects of unde, rstanding, and so an experinmnt in evahlat- ing them (and encouraging improvem(mt in them) 4:68 would I)e worl;hwhil(~.
l ier MU(Js) annol:~mxl a shorl: newst)~p(w mtM(, using (.ach set of specif i(:ations.
Prot) lems arose with ea.
rela.tions, mM d is t ingu ish ing  the, two; a decis ion wa.s lm;er made to l imit  ourselv(;s I;() i(lenLi(;y rela.I;ions.
Wal l  St reet  .
~;}1( ~.cons is tency of a.mloi;m;ion /w.|:weeu silx~s.
in I.he winter  o[ 1994-95.
For na.nied cnl;iifies, this was rel~tl;ively st, rtdght, forwar([.
8 The fo rmal  eva luat ion The MUC6 formal  ewflu;tt ion was /mhl in ,~{(q)l:emt)ex 1995.
of Shefliehl, SouLhe, rn Metlmdisl; Univ., mr(1 Ultisys.
469 Maybe <COREF ID="136" REF="I34">he</CSREF>II even leave something from <COREF ID="138" REF="I39"><COREF ID="137" REF="I36">his</COREF> office</COREF> for <CSREF ID="I40" REF="91">Mr.
<COREF ID="I41" REF="I37">Mr.
James</COREF> says <COREF ID="142" REF="I41">he</COREF> framed <COREF ID="143" REF="I44" STATUS="OPT">it</COREF> and kept <COREF ID="145" REF="I44">it</COREF> by <COREF ID="146" REF="I42">his</COREF> desk as a "personal reminder.
The top-scoring sys- tem had 75% recall, 86% precision.
the following templates were to be generated: <SUCCESSION_EVENT-9402240133-3> := SUCCESSION_ORG : <ORGANIZATION-9402240133-1> POST: "v ice chairman, ch ie f  s t ra tegy off icer,  wor ld-wide" IN_AND_OUT : < IN_AND_OUT-9402240 i33~5> VACANCY_REASON : OTH_UNK < IN_AND_OUT-9402240133-5> := IO_PERSON : <PERSON-9402240133-5> NEW_STATUS : IN ON_THE_ JOB : YES OTHER_ORG : <ORGANIZAT ION-9402240133-8> REL_OTHER ORG : OUTSIDE_ORG <ORGANIZAT ION-9402240133-  i> := ORG_NAME : "McCann" ORG_TYPE : COMPANY <ORGANIZAT ION-9402240133-8> := ORG_NAME: "J. Walter  Thompson" ORG_TYPE : COMPANY <PERSON-9402240133-5> := PER NAME: "Peter Kim" Although we cannot explain al] tile details of the template here, a few highlights shouht be noted.
Guiding Semi-Supervision with Constraint-Driven Learning
Researchers have explored the use of this kind of document segmentation to improve automated summarization (Salton et al. 1994; Barzilay and Elhadad 1997; Kan, Klavans, and McKeown 1998; Mittal et al.
1999; Boguraev and Neff 2000) and automated genre detection  .
1998; Beeferman, Berger, and Lafferty 1997, 1999).
1999; Eichmann et al. 1999; van Mulbregt et al.
1999; Choi 2000).
Pk penalizes FP2 less than FP1 and FP3, and FNP2 less than FNP1 and FNP3.
WD penalized FP1 the most and FP3 the least among the FP segmentations.
1993; Lehnert et al. 1993).
ZEDDoc (Passormeau et al. 1997; Kukich et al.
4.3.2 Contradiction.
4.3.3 Addition.
4.3.4 Refinement.
4.3.5 Agreement.
4.3.6 Superset/Generalization.
4.3.7 Trend.
4.4.1 Input.
Reichman-Adar 1984, Schank et al. 1982, Mann and Thompson 1983), nor on the particulars of individual intentions.
DS2 yields a focus space that is stacked relative to FS1 because DSP, of DS1 dominates DS2's DSP, DSP2.
N00014-85-C-0079.
 , Ponzetto and Strube  ).
Luo et al.   represent one of the earliest attempts to investigate learning-based entity-mention models.
Discourse-new detection.
Extraposition Grammars
...un --> V. can be applied to bracketed string s if s = x0u1x1u2 etc. xn_ unxn and each of the gaps x1, ..., xn_1 is balanced.
4b.
In eqn.
The C2E back-transliteration is more challenging than E2C transliteration.
MBT: A Memory-Based Part Of Speech Tagger-Generator
Church, 1988; DeRose, 1988; Cutting et al. 1992; Merialdo, 1994, etc.).
For example, Aw et al.   propose a phrase-level SMT SMS normalisation method with bootstrapped phrase alignments.
10.
11.
The wordnets for other languages in MCR use the English WordNet synset numbers as ILIs.
CW=Context Windows, BoW=bag of words, Syn=syntactic vectors.
A simple translation strategy also yields good results for distributional methods. automobile, car 3.92 62 journey, voyage 3.84 54 gem, jewel 3.84 61 boy, lad 3.76 57 coast, shore 3.7 53 asylum, madhouse 3.61 45 magician, wizard 3.5 49 midday, noon 3.42 61 furnace, stove 3.11 50 food, fruit 3.08 47 bird, cock 3.05 46 bird, crane 2.97 38 implement, tool 2.95 55 brother, monk 2.82 42 crane, implement 1.68 26 brother, lad 1.66 39 car, journey 1.16 37 monk, oracle 1.1 32 food, rooster 0.89 3 coast, hill 0.87 34 forest, graveyard 0.84 27 monk, slave 0.55 17 lad, wizard 0.42 13 coast, forest 0.42 18 cord, smile 0.13 5 glass, magician 0.11 10 rooster, voyage 0.08 1 noon, string 0.08 5
WSJ examples.
Research by McCarthy et al.   and Koeling et al.
Employing count-merging with a-estPred produces the curve a-c-estPred.
915
CPOSTAG: Coarse-grained part-of-speech tag,.
POSTAG: Fine-grained part-of-speech tag,.
10.
This includes the work of Roark and Bacchiani  , Flo rian et al  , Chelba and Acero  , Daume?
Additional care was taken to remove sen tences that contained non-WSJ part-of-speech tagsor non-terminals (e.g., HYPH part-of-speech tag in dicating a hyphen).
Isol.
Sla.
Hel.
F.-U.
Tur.
Annotation d d c+f c+f d c+f d c+f c+f d c+f d Training data Development data Tokens (k) 112 51 431 337 432 447 65 132 71 65 5 Sentences (k) 2.9 3.2 15.0 57.0 25.4 18.6 2.7 6.0 3.1 5.6 0.2 Tokens/sentence 38.3 15.8 28.8 5.9 17.0 24.0 24.2 21.8 22.9 11.6 25.1 LEMMA Yes Yes Yes No Yes No Yes Yes Yes Yes No No.
CPOSTAG 15 25 17 13 12 31 18 16 14 14 25 No.
POSTAG 21 64 54 294 59 45 38 43 28 31 37 No.
FEATS 21 359 33 0 71 0 31 50 21 78 0 No.
DEPREL 29 35 42 69 46 20 46 49 22 25 18 No.
DEPREL H=0 18 17 1 1 8 1 22 1 1 1 1 % HEAD=0 8.7 9.7 3.5 16.9 11.6 4.2 8.3 4.6 5.4 12.8 4.0 % HEAD left 79.2 44.5 60.0 24.7 46.9 49.0 44.8 27.4 65.0 3.8 50.0 % HEAD right 12.1 45.8 36.5 58.4 41.5 46.9 46.9 68.0 29.6 83.4 46.0 HEAD=0/sentence 3.3 1.5 1.0 1.0 2.0 1.0 2.0 1.0 1.2 1.5 1.0 % Non-proj.
arcs 0.4 2.9 0.1 0.0 1.9 0.3 1.1 2.9 0.5 5.5 0.4 % Non-proj.
10.1 26.2 2.9 0.0 23.2 6.7 20.3 26.4 7.4 33.3 8.0 Punc.
920results for the CHILDES data was considered op tional.
3.3 Overview.
are both described in Duan et al  .
923 5.1 Architectures.
For languages with non-projective depen dencies, graphs therefore need to be projectivized for training and deprojectivized for testing (Hall et al., 2007a; Johansson and Nugues, 2007b; Titov and Henderson, 2007).
This technique is used by Sagae and Tsujii   and in the Nilsson system (Hall et al, 2007a).
5.2 Transition-Based Parsers.
This type of model is used by the majority of transition-based parsers (Attardi et al, 2007; Duan et al, 2007; Hallet al, 2007a; Johansson and Nugues, 2007b; Man nem, 2007; Titov and Henderson, 2007; Wu et al, 2007).
924 (Duan et al, 2007; Johansson and Nugues, 2007b; Sagae and Tsujii, 2007; Titov and Henderson, 2007).
5.3 Graph-Based Parsers.
Thistype of scoring function is often referred to as a first order model.8 Several systems participating in this year?s shared task used first-order models (Schiehlen and Spranger, 2007; Nguyen et al, 2007; Shimizu and Nakagawa, 2007; Hall et al, 2007b).
Maximum spanning tree algorithms can be used for finding the highest scor ing non-projective tree in a first-order model (Hall et al, 2007b; Nguyen et al, 2007; Canisius and Tjong Kim Sang, 2007; Shimizu and Nakagawa,2007), while Eisner?s dynamic programming algorithm solves the problem for a first-order factoriza tion in the projective case  .
5.4.2 Ensemble-Based Approaches Dredze et al   trained a diverse set of parsers in order to improve cross-domain performance byincorporating their predictions as features for an other classifier.
Anto`nia Mart??
Anton??n, Llu??s Ma`rquez, Manuel Bertran, Mariona Taule?, DifdaMonterde, Eli Comelles, and CLiC-UB (Cata lan); Shih-Min Li, Keh-Jiann Chen, Yu-Ming Hsieh, and Academia Sinica (Chinese); Jan Hajic?, Zdenek Zabokrtsky, Charles University, and the LDC (Czech); Brian MacWhinney, Eric Davis, the CHILDES project, the Penn BioIE project, and the LDC (English); Prokopis Prokopidis and ILSP(Greek); Csirik Ja?nos and Zolta?n Alexin (Hun garian); Giuseppe Attardi, Simonetta Montemagni, Maria Simi, Isidoro Barraco, Patrizia Topi, Kiril Ribarov, Alessandro Lenci, Nicoletta Calzolari, ILC, and ELRA (Italian); Gu?ls?en Eryig?it, Kemal Oflazer, and Ruket C?ak?c?
Finally, we want to thank the following people,who in different ways assisted us in the organi zation of the CoNLL 2007 shared task: Giuseppe Attardi, Eckhard Bick, Matthias Buch-Kromann,Xavier Carreras, Tomaz Erjavec, Svetoslav Mari nov, Wolfgang Menzel, Xue Nianwen, Gertjan van Noord, Petya Osenova, Florian Schiel, Kiril Simov, Zdenka Uresova, and Heike Zinsmeister.
The availability of semantically annotated corpora such as the Proposition Banks   and FrameNet   have enabled the development of a rapidly growing list of statistical semantic analyzers (Giidea and Jurafsky, 2002; Giidea and Palmer, 2002; Chen and Rambow, 2003; Pradhan et al., 2003; Pradhan et al., 2004; Sun and Jurafsky, 2004; Palmer et al., submitted).
LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example).
The values {100, 200, 300, 400, 500} represent the dimensionality of the trained space.
C99 and C99b are the algorithms described in (Choi, 2000a).
The ASO baseline is an implementation of Ando and Zhang (2005b).
NBCHD030010.
868
Factored models extend this ap proach.
house|NN|plural ? houses ? house|NN|singular ? house ? home|NN|plural ? homes ? ...
{ houses|house|NN|plural, homes|home|NN|plural, buildings|building|NN|plural, shells|shell|NN|plural, house|house|NN|singular, ...
} 870
5.1 Training.
Morphologi cal features were exploited with a 7-gram languagemodel.
6.4 Integrated Recasing.
874 6.5 Additional Experiments.
849 ..
Monotone with previous p(oi = M|ei, f ai ,ai?1,ai) 1 ,4 and is 0.223 0.672 0.942 2 , and also 0.201 0.560 0.948 Swap with previous p(oi = S|ei, f ai ,ai?1,ai) 3 ?){ of china 0.303 0.617 0.651 4 ??
/0 12 34 56 the russi an side hope s to hold cons ultati ons with iran on this issue in the near future ..................
For A-E: LDC2007E103, LDC2005E83, LDC2006E24, LDC2006E34, LDC2006E85, LDC2006E92, LDC2007E06, LDC2007E101, LDC2007E46, LDC2007E86, and LDC2008E40.7We combine lexicalized reordering models by simply treat ing them as distinct features, which incidentally increases the number of model parameters that must be tuned with MERT.
Improvements on MT06 and MT05 are very sig nificant (p ? .01).
The best non-hierarchical models achieve only 33.79, 32.32, and 26.32, respectively.All these differences (i.e., .57, .53, and .71) are sta tistically significant at the .05 level.Our results for Arabic-English are shown in Ta bles 5 and 6.
All thesedifferences (i.e., .63 and .55) are statistically signifi cant at the .05 level.
855
WordNet includes few proper noun MWUs.
Can semantic-only rescoring help?
Rescoring caused five-fold degradation!
The datasets are freely available2 for further benchmark experiments at http://www.inf.u-szeged.hu/ rgai/conll2010st.
22, 16 and 13 teams submitted output for Task1B, Task1W and Task2, respectively.
Regarding cross submissions, Zhao et al.   and Ji et al.
It is interesting to see that Morante et al.   who obtained the best results on Task2 achieved a medium-ranked F-measure on the cue-level (e.g.
SpanishEnglish or French-English.
Verbmobil Task.
Single-Word Based Systems (SWB).
Variants of PCFGs form the basis of several broadcoverage and high-precision parsers  .
NC2.
We show how adjunction al- lows us to lexicalize a CFG freely.
*This work is partially supported by ARO grant DAA29-84-9- 007, DARPA grant N0014-85-K0018, NSF grants MCS-82-191169 and DGR-84-10413.
Zellldja grant.
57,~ show how adjunction enables one to freely lexicalize a CFG.
aNote that  a CFG in Greibach normal  form can be lexicallzed trivially.
TAGs were first introduced by Joshi, Levy and Takabashi   and Joshi  .
TALs properly contain context-free languages.
579 complements.
They can take nomi- nal or sentential arguments.
Lex is the lexicon , i.e.
The sequent T1," ? "
,anl3rl e Lex(al) s. t. ~- r l ,  " , rn  ----+ S} Also, one can state a necessary condition on the correct- ness of a sentence similar to the category count theorem of van Benthem (1985 and 1986).
5 Extending the Earley-type parser for TAGs An Earley-type parser for TAGs has been proposed by Schabes and Joshi (1988a).
The Subst i tu t ion  Pred ic tor  performs the same op- erations as Earleys original predictor.
But the use of adjunction permits lexicalization with linguistically mo- tivated structures.
van Benthem, Johns, 1985.
Lambek Calculus.
Manuscript, Filosofisch Instituut, Rijks Universiteit, Groningen.
van Benthem, Johan, 1986.
D. Reidel Publishing Company.
Gross, Manriee, 1984.
Joshi, Aravind K., 1985.
How Much Context-Sensitivlty is Nec- essary for Characterizing Structural Descriptions--Tree Ad- joining Grammars.
In Dowry, D.; Karttunen, L.; and Zwicky, A.
Joshi, A. K.; Levy, L. S.; and Ta~ahashi, M, 1975.
Tree Ad- junct Grammars.
Kroch, A. and Joshi, A. K., 1985.
Lambek, Joachim, 1958.
The Mathematics of Sentence Struc- ture.
Lambek, Joachim, 1961.
Schabes, Yves and Joshi, Aravind K., 1988 (a).
Shieber, Stuart M., 1984.
Shieber, Stuart M., 1985.
Using Restriction to Extend Pars- ing Algorithms for Complex-feature-based Formalisms.
Shieber, Stuart M., 1986.
Vijay-Shanker, K., 1987.
Vijay-Shanker, K. and Joshi, A.K., 1988.
3.0.1 The KnowItAll System.
The inter-annotator agreement was 86%.
Nota tion: po=potential opinion, M=modifier, NP=noun phrase,S=subject, P=predicate, O=object.
d) WordNet-supplied synonymy, antonymy, IS-A andmorphological relationships between words.
3.4 Experiments.
We thank Minquing Hu andBing Liu for providing their data sets and for their com ments.
Co-Training for Cross-Lingual Sentiment Classification
Bel et al.   present practical and cost-effective solutions.
For instance, adjective phrases (ADJP)—which are generally good candidates for deletions—appear in 90 different NProoted SCFG productions in Ziff-Davis,2 61 of which appear only once, e.g., NP , (DT ADJP JJ NN NN, DT JJ NN NN).
Input Prices range from $5,000for a microvax 2000 to $179,000for NoisyC the vax 8000 or higher series.
and ?rea sonable?
Weuse the second set (359 documents/7,611 sen tences/13,183 subjective expressions) in 10-fold cross-validation experiments, described below.
349
6.2 Performance of a Prior-Polarity Classifier.
The classifiers are evalu ated in 10-fold cross-validation experiments.
Yu and Hatzivassiloglou  , Kim and Hovy  , Hu and Liu  , and Grefenstette et al.
Kim and Hovy, Hu and Liu, andGrefenstette et al multiply or count the prior po larities of clue instances in the sentence.
The resulting numbers are 100, 50,20, 100, 100.
Interevaluator Kappa between scores 1,2 and 3,4 was 0.56, 0.67 and 0.72 for Dmoz, BNC and Russian respectively.
Bies   p.35).
Zhou, Tey and Su   implemented a chunk tagger based on HMMs.
Multitext Grammars And Synchronous Parsers
Alal.
R2D2A can be compared to Wu  's procedure for parsing non-lexicalized ITGs, which runs in —1 22 j1 j1 j2 X7.
E.g.
: i2 6[6] i2 i2 X2 [h2] ' 21_2 [(12] 122 „ L R2D2A most of its time compospairs of non-seed items into larger A bottom-up one-dimensional parser composes onedimensional items until it infers an item that covers the input text.
E.g.
Thanks to Jason Eisner, Sanjeev Khudanpur, Owen Rambow, Giorgio Satta, and members of NYU's Proteus Project for helpful discussions.
Agarwal and Rambow are funded by NSF grant IIS-0713548.
Please contact Deepak Mittal (deepak.mittal@ngicorportion.com) about obtaining the data.
Evaluation of multi-document summarization is difficult.
IRI-96-1879.
Brown et al. 1993).
Simard, Foster, and Perrault 1993).
Statistical Phrase-Based Translation
Foreign-English or English-foreign?
3.9.2 Details for IBM-4 Model.
4.2.2 Preprocessing Steps.
4.2.6 English-to-German Translation Experiments.
Input Chacun en lui - mˆeme est tr`es complexe et le lien entre les deux le est encore davantage de sorte que pour beaucoup la situation pr´esente est confuse.
S 01 04 M 02 10 This string describes the German-to-English word reordering.
S 02 10 M 01 04 This string describes the English-to-German word reordering.
Bedford, MA 01730 mbv, john, aberdeen, lynette@mitre .org; dennis.x.connolly@ameritech.com This note describes a scoring scheme for the coreference task in MUC6 .
Key Links : <A-B B-C B-D> ?
45 others, including the "non-problematic" case of <A-B B-C C-D> .
For recall, Sundheim et al .
Key: <B-C C-D D-E E-G G-H H-J> ?
Key: <A-B B-C D-E E-F F-G > ?
French nous avons pris 1 initiative d 4valuer et de modifier des lois et des politiques en vigueur afin qu elles correspondent ~ une interprdation ggn4reuse de la charm.
The program wouM produce the following correspondences: Output: we/nous took/O the/O initiative/initiative in/O assessing/6valuer and/et ammending/modifier current/O legislation/O and/et policies/politiques to/~ ensure/O that/qu they/elles reflect/O a/une broad/O interpretafion/interpr6tation of/de theBa charter/charte ./.
The entry for "the" found in prawn et al.)
wilson ) et le gouvemeur de la banque du canada ont frt?quemmct reduced by over 800 per cent in one week through bank action.
100 en une semaine i!
cause d une banque .
SENT voili un chemisic~ bank/ banc ("ulace" sense) .
SENT such was the case in the gwrges bank issue which was settlcd be~u entre les dtats-unis et le canada B p r o p  du banc de george .
SENT en fait , lors des nCgc 3.
~2 picks up this difference; Table 3 has a ~2 of 0.098, signitieantly ess than Table 2% ~2 of 0.62: t = ~2(hch) - ~2(hc?)
French: nous avons Inis 1 initiative d ffvaluer et de modifier des lois et des politiques en vigueur afin qu elles correspondent ~tune interpr&ation gdn&euse de la charte.
I English j French slope score 1 we 1 nous 1 --0.5 2 took NULL -5.5 3 the NULL -10.5 4 initiative 5 initiative 4 -14.2 5 in NULL -19.2 6 assessing 7 6valuer 2 -21.5 7 and 8 et I -22.0 8 amending 10 modifier 2 -24.2 9 current NULL -29.2 10 legislation NULL -34.2 11 and 13 et 3 -37.3 12 policies 15 politiques 2 -39.6 13 to 22 /t 7 -44.5 14 ensure NULL -49.5 15 that 19 qu -3 -54.1 16 they 20 riles I -54.6 17 reflect NULL -59.6 18 a 23 une 3 --62.7 19 broad NULL -67.7 20 interpretation 24 interprttation 1 -.-68.2 21 of 26 de 2 -70.4 22 the 27 la 1 -70.9 23 charter 28 charte 1 -71.4 24 29 1 -71.9 The matching procedure uses a dynamic programming optimization to find the sequence of j values with the best score.
References Brown, P., J. Cocke, S. Della Pietra, V. Della Pietra, F. Jelinek, J. Lafferty, R. Mercer, and P. Roossin   "A  Statistical Approach to Machine Translation," ComputationaILinguistics, v 16, pp 79-85.
Kay, M. and M. RSscheisen   "Text-Translation AlignmentS unpublished ms., Xerox Palo Alto Research Ceuter.
Klavans, J., an6 E. Tzoukermarm   "The BICORD System," COLING-90, pp 174-179.
Warwick, S. and G. Russell   "Bilingual Coneordaneing and Bilingual Lexicography," Euralex 1990.
All algorithms except voted perceptron maximize the penalized loglikelihood:  = arg maxa La.
Conjugate-gradient  .
GIS, CG, and L-BFGS were used to train CRFs and MEMMs.
For example, the tagging The accident was a tragedy/cALAmnv would yield L'accident etait une catastrophe/CALAMITY.
WordWord CCG SOURCE TARGETFigure 1.
n=1 ?nhn(sc, tw) However, in many cases multiple dependenciesare desirable.
2see http://www.statmt.org/moses/ 3see http://svn.ask.it.usyd.edu.au/trac/candc/wiki This consists of 855,677 sentences with a maximum of 50 words per sentence.
4.2 Sequence Models Over Supertags.
Model BLEU sw, tw 23.97 sw, twp 24.11 sw, twc 24.42 sw, twpc 24.43 Table 1.
This means that at most 6 words in 4see http://www.statmt.org/wpt05/ 5see http://www.statmt.org/wpt06/ 12 the source sentence can be skipped.
Model Translated Reordered sw, tw 81 36 sw, twc 87 52 Table 2.
Model None 1gram 3gram 5gram 7gram sw, twc 24.18 23.96 24.19 24.42 24.32 sw, twpc 24.34 23.86 24.09 24.43 24.14 Table 3.
4.5 Language Model vs. Supertags.
Model None 1gram 3gram 5gram 7gram sw, tw - 21.22 23.97 24.05 24.13 sw, twp 21.87 21.83 24.11 24.25 24.06 sw, twc 21.75 21.70 24.42 24.67 24.60 sw, twpc 21.99 22.07 24.43 24.48 24.42 Table 4.
4.6 Lexicalised Reordering vs. Supertags.
Reord.
sw, tw 23.97 24.72 sw, twc 24.42 24.78Table 5.
4.7 CCG Supertags on Source.
Model BLEU sw, tw 23.30 swc, tw 19.73 single 23.29 LOP 23.46 Table 6.
CCG supertags?
15
Statistical alignment models are often the basis of single-word-based statistical machine translation systems (Berger et al. 1994; Wu 1996; Wang and Waibel 1998; Nießen et al.
1998; Garc´ıa-Varea, Casacuberta, and Ney 1998; Och, Ueffing, and Ney 2001; Germann et al. 2001).
On Hansards, we use 15H10334363.
Toutanova et al.  ).
I.e.
This yields a ils sont par certaines limites qui ont été fixées garantir que la liberté de une ne pas sur de une . restreints pour personne empiète celle autre f 1, if eat = ‘of’ n ft = ‘de’ l 0, otherwise In order to train the model, we maximize (2).
This aggregation process produced 22,146 scenarios, each containing |s |= 36 multi-field records.
87; Jelinek 85; Kupiec 89; Meteer et al. 911.
The parameters of the model can be estimated from tagged ([Church 88; DeRose 88; Deroualt and Merialdo 86; Garside et al. 87; Meteer et al.
91]) or untag,ged ([Cutting et al. 92; Jelinek 85; Kupiec 89]) text.
In [Meteer et at.
[Garside et al. 87] reports an accuracy of 96-97%.
Unlike LI~ parsing, 4For formalisms with complex structured nonterminals, the start "symbol" need only be unifiable with the left-haud-side nonterminal.
Kays "powerful parser" and the GSP both em- ployed an agenda mechanism to control additions to the chart.
canonical intentionally logical equivalent forms LFs NL expression grammar defines LF la  / LF 1 ~- - - -  LF lb LF l c LF 2a / LF2  ~- -  LF2b LF 2c ?
LF  3a  / LF 3 ~ LF 3b LF 3e , I I .
l?eferences [Appelt, 1987] Douglas E. Appelt.
[Frazier and Fodor, 1978] Lyn Frazier and Janet Dean Fodor.
Cognition, 6:291-325, 1978.
[Hasida nd Isizaki, 1987] KSiti Hasida and Syun Isizaki.
Depen- dency propagation: a unified theory of sentence comprehension and generatimu In Proceedings ofAAAI-87~ pages 664-670, Seat- tle, Washington, 13-17 July 1987.
[Jacobs, 1985] Paul S. Jaeobs.
Computational Linguistics, 11(4):219-242, October-December 1985.
[Kaplan, 1973] Ronald M. Kapian.
In Theoretical Issues in Natural Language Pracessing--Supplement to the Proceedings, pages 12-15, Cam- bridge, Massachusetts, 10-13 June 1975~ [Pereira and Warren, 1983] Fernando C. N. Pereira and David tL D. Warren.
[Pereira and Shieber, 1987] FernandoC.
N. Pereira and Stuart M. Shieber.
Proloy and Natural-Language Analysis.
[Shieber, 1983] Stuart M. Shieber.
[Shieber, 1985] Stuart M. Shieber.
[Shieber, 1986] Stuart M. Shieber.
[Steinackerand Buchberger, 1983] Ingeborg Steinacker and Ernst Buchberger.
[Wahlster tal., 1983] Wolfgang Wahlster, Heinz Marburger, An- thony Jameson, and Stephan Busemann.
Some of these methods make use of prior knowledge in the form of an existing thesaurus (Resnik 1993a, 1993b; Framis 1994; Almuallim et al. 1994; Tanaka 1996; Utsuro and Matsumoto 1997), while others do not rely on any prior knowledge  .
We are grateful to K. Nakamura and T. Fujita of NEC C&C Res.
We thank K. Yaminishi and J. Takeuchi of C&C Res.
3.1.6 The QUERY-W Move.
4.5.1 Measures.
4.5.2 Diagnostics.
60 100 160 200 260 300 nix*. el cleeee•
11.
11.
In a 10 million—word corpus, with about 60,000 different words, there are about 3.6 x 109 possible bigrams, 2.16 x 1014 trigrams, and 3 x 1033 7-grams.
10.
NYT contains 12 million words.
The Chinese Treebank consists of 4185 sentences of Xinhua newswire text.
Hypot.
Sentence-by-sentence.
Token-level offsets.
2.2 Reordering WFST for MJ-1.
2.3 Reordering WFST for MJ-2.
MJ-1 model parameters are estimated over all bitext on A-E and over the non-UN bitext on C-E.
Minipar   is a rulebased dependency parser.
Integrating Graph-Based and Transition-Based Dependency Parsers
3.2.2 Significance.
Boundary Threshhold Narrative 2 4 7 15 Average > 3 .50 .60 .73 .50 .58 and can be applied to multivalued variables that are quantitative or qualitative.
3.2.5 Discussion.
4.1.3 Evaluation.
4.2.1 Pauses.
Nakatani 1996; Swerts 1995).
4.2.5 Discussion.
The authors wish to thank J. Catlett, W. Chafe, K. Church, W. Cohen, J. DuBois, B. Gale, V. Hatzivassiloglou, M. Hearst, J. Hirschberg, D. Lewis, K. McKeown, and E. Siegel for helpful comments, references, and resources.
Passonneau's work was not conducted under Bellcore auspices.
DSMs have found wide applications in computational lexicography, especially for automatic thesaurus construction (Grefenstette 1994; Lin 1998a; Curran and Moens 2002; Kilgarriff et al. 2004; Rapp 2004).
In structured DSMs, co-occurrence statistics are collected instead in the form of corpus-derived triples: typically, word pairs and the parser-extracted syntactic relation or lexico-syntactic pattern that links them, under the assumption that the surface connection between two words should cue their semantic relation (Grefenstette 1994; Lin 1998a; Curran and Moens 2002; Almuhareb and Poesio 2004; Turney 2006b; Pad´o and Lapata 2007; Erk and Pad´o 2008; Rothenh¨ausler and Sch¨utze 2009).
LexDM.
LexDM is a 30,693 x 3,352,148 x 30,693 tensor with density 0.00001%.
TypeDM.
The distinct TypeDM links are 25,336.
TypeDM is a 30,693 x 25,336 x 30,693 tensor with density 0.0005%.
The Battig test set introduced by Baroni et al.   is based on the expanded Battig and Montague norms of Van Overschelde, Rawson, and Dunlosky  .
See Baroni et al.   for the full list.
6.1.4 Selectional Preferences.
The McRae data set   consists of 100 noun–verb pairs rated by 36 subjects.
Our first test pertains to the seven relations between nominals in Task 4 of SEMEVAL 2007  : Cause–Effect, Instrument–Agency, Product– Producer, Origin–Entity, Theme–Tool, Part–Whole, Content–Container.
6.2.3 Qualia Extraction.
The Agentive and Telic patterns also harvest noun–verb pairs.
2005; Vinson and Vigliocco 2008).
It consists of 232 causative/inchoative verbs and 170 non-alternating transitive verbs from Levin  .
Alshawi et al.   and Hwa et al.
HR001106-2-0001.
SemEval-2007 Task 07: Coarse-Grained English All-Words Task
This paper presents the coarse-grained En glish all-words task at SemEval-2007.
State-of-the-art systems attained a disam biguation accuracy around 65% in the Senseval-3 all-words task  , whereWordNet   was adopted as a ref erence sense inventory.
2.2 Creation of a Coarse-Grained Sense.
of 6.18.
2.4 Inter-Annotator Agreement.
Comparedto previous results on fine-grained evaluation exer cises  , the systems?
On the other hand, the difference in performancebetween the MFS baseline and state-of-the-art sys tems (around 5%) on coarse-grained disambiguationis comparable to that of the Senseval-3 all-words ex ercise.
However, given the novelty of the task webelieve that systems can achieve even better perfor 32 System A P R F1 NUS-PT 100.0 82.50 82.50 82.50 NUS-ML 100.0 81.58 81.58 81.58 LCC-WSD 100.0 81.45 81.45 81.45 GPLSI 100.0 79.55 79.55 79.55 BLMFS 100.0 78.89 78.89 78.89 UPV-WSD 100.0 78.63 78.63 78.63 TKB-UO 100.0 70.21 70.21 70.21 PU-BCD 90.1 69.72 62.80 66.08 RACAI-SYNWSD 100.0 65.71 65.71 65.71 SUSSX-FR 72.8 71.73 52.23 60.44 USYD 95.3 58.79 56.02 57.37 UOFL 92.7 52.59 48.74 50.60 SUSSX-C-WD 72.8 54.54 39.71 45.96 SUSSX-CR 72.8 54.30 39.53 45.75 UOR-SSI?
ferent performance depending on the part-of-speechtag.
System F1 NUS-PT 82.50 NUS-ML 81.58 LCC-WSD 81.45 GPLSI 79.55 BLMFS 78.89 UPV-WSD 78.63 SUSSX-FR 77.04 TKB-UO 70.21 PU-BCD 69.72 RACAI-SYNWSD 65.71 SUSSX-C-WD 64.52 SUSSX-CR 64.35 USYD 58.79 UOFL 54.61 UOR-SSI?
System N V A R NUS-PT 82.31 78.51 85.64 89.42 NUS-ML 81.41 78.17 82.60 90.38 LCC-WSD 80.69 78.17 85.36 87.98 GPLSI 80.05 74.45 82.32 86.54 BLMFS 77.44 75.30 84.25 87.50 UPV-WSD 79.33 72.76 84.53 81.25 TKB-UO 70.76 62.61 78.73 74.04 PU-BCD 71.41 59.69 66.57 55.67 RACAI-SYNWSD 64.02 62.10 71.55 75.00 SUSSX-FR 68.09 51.02 57.38 49.38 USYD 56.06 60.43 58.00 54.31 UOFL 57.65 48.82 25.87 60.80 SUSSX-C-WD 52.18 35.64 42.95 46.30 SUSSX-CR 51.87 35.44 42.95 46.30 UOR-SSI?
33 d001 d002 d003 d004 d005 System P R P R P R P R P R NUS-PT 88.32 88.32 88.13 88.13 83.40 83.40 76.07 76.07 81.45 81.45 NUS-ML 86.14 86.14 88.39 88.39 81.40 81.40 76.66 76.66 79.13 79.13 LCC-WSD 87.50 87.50 87.60 87.60 81.40 81.40 75.48 75.48 80.00 80.00 GPLSI 83.42 83.42 86.54 86.54 80.40 80.40 73.71 73.71 77.97 77.97 BLMFS 85.60 85.60 84.70 84.70 77.80 77.80 75.19 75.19 74.20 74.20 UPV-WSD 84.24 84.24 80.74 80.74 76.00 76.00 77.11 77.11 77.10 77.10 TKB-UO 78.80 78.80 72.56 72.56 69.40 69.40 70.75 70.75 58.55 58.55 PU-BCD 77.16 67.94 75.52 67.55 64.96 58.20 68.86 61.74 64.42 60.87 RACAI-SYNWSD 71.47 71.47 72.82 72.82 66.80 66.80 60.86 60.86 59.71 59.71 SUSSX-FR 79.10 57.61 73.72 53.30 74.86 52.40 67.97 48.89 65.20 51.59 USYD 62.53 61.69 59.78 57.26 60.97 57.80 60.57 56.28 47.15 45.51 UOFL 61.41 59.24 55.93 52.24 48.00 45.60 53.42 47.27 44.38 41.16 SUSSX-C-WD 66.42 48.37 61.31 44.33 55.14 38.60 50.72 36.48 42.13 33.33 SUSSX-CR 66.05 48.10 60.58 43.80 59.14 41.40 48.67 35.01 40.29 31.88 UOR-SSI?
In the hope of over coming the current performance upper bounds, we 34 System SC DSO SE OMWE XWN WN WND OTHER UC TR MFS CS GPLSI ? ?
UOR-SSI?
SSI LKB ? ?
Previous attempts to handle multiple information sources in the LDA framework (e.g., Griffiths et al. 2005; Barnard et al.
Typical systems are Univ. of Sheffield's LaSIE-II [Humphreys+98], ISOQuest's NetOwl [Aone+98] [Krupha+98] and Univ. of Edinburgh's LTG [Mikheev+98] [Mikheev+99] for English NER.
The representative machine-learning approaches used in NER are HMM (BBN's IdentiFinder in [Miller+98] [Bikel+99] and KRDL's system [Yu+98] for Chinese NER.
's system in [Sekine98] and SRA's system in [Bennett+97]).
's MENE.
During parsing, Aj must be rewritten by a λ-function fj of arity kj.
Steps 4–6.
Soon et al.   and Yang et al.
Preprocessing.
B3 Complications.
(Similarly, recall(ce) = 1/|KC  |if ce is twinless.)
Luo et al.  , McCallum and Wellner  ).
Bengtson and Roth   and Luo  .
Xiaoqiang Luo.
2007.
1.1 Motivation.
1.2 Approach.
Thus, categories form a directed acyclic graph, allowingmultiple categorization schemes to co-exist simul taneously.
2.4 Hyperlinks.
4.1 Context-Article Similarity.
s jk = wf(x jk) for some user provided fea ture mapping f and abbreviate wf(x,y) = ? jk y jk wf(x jk).
2.1 Large-margin estimation.
We follow the large-margin formulation of Taskar et al (2005a).
2.2 The extragradient method.
(Korpelevich, 1976; He and Liao, 2002; Taskar et al, 2005b).
We model all of these in some way, 76 on e of th e ma jo r ob je ct iv es of th es e co ns ul ta ti on s is to ma ke su re th at th e re co ve ry be ne fi ts al l . le un de les grands objectifs de les consultations est de faire en sorte que la relance profite e?galement a` tous . on e of th e ma jo r ob je ct iv es of th es e co ns ul ta ti on s is to ma ke su re th at th e re co ve ry be ne fi ts al l . le un de les grands objectifs de les consultations est de faire en sorte que la relance profite e?galement a` tous .
(a) Dice only (b) Dice and Distance on e of th e ma jo r ob je ct iv es of th es e co ns ul ta ti on s is to ma ke su re th at th e re co ve ry be ne fi ts al l . le un de les grands objectifs de les consultations est de faire en sorte que la relance profite e?galement a` tous . on e of th e ma jo r ob je ct iv es of th es e co ns ul ta ti on s is to ma ke su re th at th e re co ve ry be ne fi ts al l . le un de les grands objectifs de les consultations est de faire en sorte que la relance profite e?galement a` tous .
in 19 78 Am er ic an s di vo rc ed 1, 12 2, 00 0 ti me s . en 1978 , on a enregistre?
1,122,000 divorces sur le continent . in 19 78 Am er ic an s di vo rc ed 1, 12 2, 00 0 ti me s . en 1978 , on a enregistre?
1,122,000 divorces sur le continent .
These or thographic and other features improved AER to14.4.
78 tures are used.
79
(For the unergative/unaccusative distinction, see Perlmutter [1978]; Burzio [1986]; Levin and Rappaport Hovav [19951).
This lexical causativization of unergatives (in contrast to analytic causativization) is a distributionally rarer phenomenon—found in fewer languages—than lexical causatives of unaccusatives.
The lowfrequency group had 24 verbs (14 unergatives, 5 unaccusatives, and 5 object-drop), the intermediate-frequency group had 25 verbs (5 unergatives, 9 unaccusatives, and 11 object-drops), and the high-frequency group had 10 verbs (1 unergative, 5 unaccusatives, and 4 object-drops).
Schulte im Walde   applies two clustering methods to two types of frequency data for 153 verbs from 30 Levin   classes.
[French]: <s snum=18> fixe moi ton salaire , et je te le donnerai .
Trial sets consisted of 37 English-French, and 17 Romanian-English aligned sentences.
We aug ment Collins?
The semantichead of N3 is clearly N1.
for bowner in the pre vious example.
5.1 Collins Head-Driven Model 2.
Subcat framesrepresent knowledge about subcategorization preferences.
Le petit crayon est cass´e.
(French) the-M little-M pencil-M is broken-M. ‘The little pencil is broken.’ b.
(14) a. Er weinte.
(16) PRON-TYPE: pers poss null .
PSEM: locational directional .
PTYPE: sem nosem .
QUANT-FORM .
E-mail: lyn@linc.cis.upenn.edu.
E-maih iida@csli.stanford.edu.
E-mail: cote@linc.cis.upenn.edu.
Note that the interpretation of zeros is indicated in parentheses: Example 1 a. Taroo ga b. C. kooen o sanpositeimasita.
Ziroo ga 0 hunsui no mae de mitukemasita.
0 0 kinoo no siai no kekka o kikimasita.
Example 2 a. Taroo ga b. C. kooen o sanpositeimasita.
0 Ziroo o hunsui no mae de mitukemasita.
0 0 kinoo no siai no kekka o kikimasita.
The two major previous accounts are those of Kuno (Kuno 1972, 1976b, 1987, 1989) and Kameyama (Kameyama 1985, 1986, 1988).
Taroo wa Hanako no kaban o mitukemasita.
Taroo TOP/SUBJ Hanako GEN bag OBJ found Taroo found Hanako" s bag.
0 0 tanzyoobi no purezento irernasita.
198 Marilyn Walker et al.
200 Marilyn Walker et al.
Example 3 a. Taroo wa b. Hanako o eiga ni sasoimasita.
Taroo TOP/SUBJ Hanako OBJ movie to invited Taroo invited Hanako to the movie.
Cb: TAROO Cf: [TAROO, HANAKO] 0 itiniti-zyuu nani mo te ni tukimasendesita.
Example 4 a. Taroo ga kooen de hon o yondeimasita.
0 koora o kai ni baiten ni hairimasita.
Cb: TAROO Cfl: [TAROO, COLA] CONTINUE SUBJ OBJ c. Ziroo wa 0 sokode guuzen dekuwasimasita.
Cb: TAROO Cf: [ZIROO, TAROO] RETAIN TOP OBJ d. 0 0 eiga ni sasoimasita.
202 Marilyn Walker et al.
The SMOOTH-SHIFT interpretation corresponds to the reading Ziroo invited Taroo to a movie whereas the ROUGH-SHIFT interpretation corresponds tothe Taroo invited Ziroo reading.
203 Computational Linguistics Volume 20, Number 2 Example 5 a. Taroo wa b. saisin no konpyuutaa o kaimasita.
C. Cb: TAROO Cf: [TAROO, JOHN, COMPUTER] CONTINUE 0 0 atarasiku sonawatta kinoo o setumeisimasita.
We will 204 Marilyn Walker et al.
Consider: Example 6 Taroo ga 0 aimasita.
Taroo SUBJ OBJ2 met Taroo met (0).
Example 7 Taroo ga Hanako ni aimasita.
Taroo SUBJ Hanako OBJ2 met Taroo met Hanako.
For example: Example 8 Hutari wa paatii ni kimasita.
206 Marilyn Walker et al.
Example 9 a. Dono hito b-1.
Taroo ga Ziroo o bengosimasita.
Taroo SUBJ Ziroo OBJ defended Taroo defended Ziroo.
*Taroo wa Ziroo o bengosimasita.
Taroo TOP/SUBJ Ziroo OBJ defended Taroo defended Ziroo.
Ziroo o bengosimasita ka.
Example 10 a. Taroo ga b. Ziroo o bengosimasita.
Taroo SUBJ Ziroo OBJ defended Taroo defended Ziroo.
Taroo wa Ziroo o bengosimasita.
Taroo TOP/SUBJ Ziroo OBJ defended Taroo defended Ziroo.
Example 11 Taroo wa Hanako ga bengosita.
Example 12 Tokyoo e wa Hanako ga itta?
Example 14 *Dono hito wa Ziroo o bengosimasita ka.
Example 15 a. Taroo hugged Saburoo.
b. Taroo hugged his son.
c. Saburoos father hugged him.
For example, consider the following utterance: (i) Taroo wa Hanako ni migigawa no hon o totte-kureta.
Taroo TOP/SUBJ Hanako OBJ2 right GEN book  OBJ take-gave Taroo did Hanako aflavor in taking a book on his~her right.
208 Marilyn Walker et al.
Example 16 Taroo ga Ziroo ni hon o kureta.
Taroo SUBJ Ziroo OBJ2 book OBJ gave Taroo gave Ziroo a book.
EMPATHY=OBJ2=ZIROO Example 17 Taroo ga Ziroo ni hon o yatta.
Taroo SUBJ Ziroo OBJ2 book OBJ gave Taroo gave Ziroo a book.
Example 18 Hanako wa Taroo no tokoro ni kita.
Hanako  TOP/SUBJ Taroo of place to came Hanako came to Taroos place.
For example: Example 19 Hanako ga Taroo ni hon o yonde-kureta.
Hanako SUBJ Taroo OBJ2 book OBJ read-gave Hanako did Taroo a favor in reading a book.
16 Certain intransitive rbs cannot be made into empathy-loaded v rbs ince the empathy-loaded versions make no sense, .g.
209 Computational Linguistics Volume 20, Number 2 Example 20 Hanako ga Taroo o tazunete-yatta.
Hanako SUBI Taroo OBJ visit-gave (lit.
)Hanako received afavor in visiting Taroo.
Example 21 Taroo ga Ziroo ni okane o kasite-kureta.
Taroo SUBJ Ziroo OBJ2 money OBJ lend-gave Taroo did Ziroo a favor in lending him some money.
Example 22 *Taroo ga dareka ni okane o kasite-kureta.
Example 23 *Taroo ga misiranu hito ni okane o kasite-kureta.
Then preferences for CONTINUE over RETAIN when EMPATHY is involved can be demonstrated, as in example 24 below: 17 Example 24 a. Hanako wa kuruma ga kowarete komatteimasita.
Cb: HANAKO Cf: [HANAKO, CAR] b. Taroo ga 0 sinsetu-ni te o kasite-kuremasita.
Taroo SUBJ OBJ2/EMP kindly hand OBJ lend-gave.
210 Marilyn Walker et al.
Japanese Discourse C. Tugi no hi 0 0 eiga ni sasoimasita.
A simple sentence to show this point is given in example 25 below: Example 25 Taroo wa Ziroo ni hon o yonde-kuremasita.
Taroo  TOP/SUBJ Ziroo OBJ2 book OBJ read-gave Taroo gave Ziroo a //avor off reading a book.
Example 26 a. Taroo wa syukudai o zenbu yari-oemasita.
Taroo TOP/SUB homework OBJ all do-finished Taroo finished his homework.
0 Ziroo ni hon o yonde-kuremasita.
SUBJ Ziroo OBJ2 book OBJ read-gave (Taroo) gave Ziroo a //avor o//reading a book.
The only difference in these examples is that Mitiko is wa-marked in 27a but is ga-marked in 28a: Example 27 a. Mitiko wa kanai o gityoo ni osite-kuremasita.
Mit iko  TOP/SUBJ w i fe  OBJ/EMP chairman OBJ2 recommend-gave Mitiko did my wife a favor in recommending her as chairperson.
0 asu no kaihyoo-kekka o tanosimi-ni siteim asu.
Example 28 a. Mitiko ga kanai o gityoo ni osite-kuremasita.
Mitiko SUBJ wife OBJ/EMP chairman OBJ2 recommend-gave Mitiko did my wife a //avor in recommending her as chairperson.
0 asu no kaihyoo-kekka o tanosimi-ni siteimasu.
212 Marilyn Walker et al.
213 Computational Linguistics Volume 20, Number 2 Example 29 a. Taroo ga b. deeta o konpyuutaa ni utikondeimasita.
21 Example 30 a. Taroo ga b. Ziroo o minna no mae de tatakimasita.
Cb: TAROO Cf: [TAROO, ZIROO] 3 Cb: ZIROO Cf: [ZIROO, TAROO] 8 In example 30, Taroo is introduced by ga.
214 Marilyn Walker et al.
Example 31 a. Taroo wa Ziroo o minna no mae de tatakimasita.
Initial experiments were performed on the IWSLT 2004 Chinese-English and Japanese-English tasks  .
The word error rate is reduced e. g. from 54.6 to 47.8%.
HR0011-06-C0023.
El: how it pardon what when where which• who why E2: my our E3: today tomorrow E4: ask call make E5: carrying changing giving looking moving putting sending showing waking E6: full half quarter Si: c'omo cu'al cu'ando cu'anta d'onde dice dicho hace qu'e qui'en tiene desk of a hotel.
(11) and Eq.
For EuTRANs-I we used 60 classes and for EuTRANs-II we used 500 classes.
5.3.1 Plurals.
To solve this problem, Coecke et al. −−→ milk.
5.6 x 5.9 then adding these 46.2 + 33.04 and obtaining the total weight 79.24.
We wish to thank P. Blunsom, S. Clark, B. Coecke, S. Pulman, and the anonymous EMNLP reviewers for discussions and comments.
Support from EPSRC grant EP/F042728/1 is gratefully acknowledged by M. Sadrzadeh.
Pre-processing including sentence boundary detection and tokenization with the Stanford 1http://simple.wikipedia.org 2http://en.wikipedia.org 3As of Aug 17th, 2009 4As of Aug 22nd, 2009 5http://download.wikimedia.org Parser package  , and lemmatization with the TreeTagger  .
We henceforth chose sentence-level TF*IDF to align our dataset.
Tok.
Word Constituent iLength isSplit Prob.
SBAR 1 true 0.0016 ?which?
SBAR 1 false 0.9984 ?which?
SBAR 2 true 0.0835 ?which?
Alg.
Const.
and the word ?calen dar?
Dep.
Const.
isCopied Pos.
canbe any substitution in the SubFT.
The proba bility of the phrase substitution is calculated as P (sub|node) = SubFT (Substitution|Origin).Fig.
Alg.
sp res1 contains pt1 and s1.
sp res2 contains pt2 and s2.
CFT is initial ized as 0.25.
After each itera tion, the updateProbability function recalculatesthese probabilities based on the cnt for each fea ture.
Obviously, the purpose of Mosesis cross-lingual translation rather than monolin 1358 gual simplification.
and ?cre ating?
isdropped.
TSM gets the best PPL score.
1360
Efficient Third-Order Dependency Parsers
Suzuki et al.   and phrase-structure annotations in the case of Carreras et al.
Y. Chouelca.
1988.
Ido Dagan and Alon Itai.
1994.
1993.
Marti A. Hearst.
1998.
The dataset contains 783 entities (96loc, 223-org, 276-per, 188-misc).
These issues led us to report token-level entity-identification F1 score for this dataset.
Extracts 124,403 titles and 130,588 redirects.
Extracts 211,872 titles and 194,049 redirects.
Extracts 28,739 titles and 31,389 redirects.
Extracts 39,800 titles and 34037 redirects.
Extracts 50,454 titles and 49,252 redirects.
Extracts 109,645 titles and 67,473 redirects.
Extracts 20,176 titles and 15,182 redirects.
2001.
J. Artif.
Intell.
For example, in wsj 1303.mrg Japan’s Daiwa Securities Co. named Masahiro Dozen president., the noun phrase Masahiro Dozen is labeled as an NP-SBJ.
Derouault and Merialdo use a bootstrap method for training [Derouault and Merialdo, 1986].
Statistical methods have also been used (e.g., [DeRose, 1988], [Garside et al., 1987]).
Derouault and Merialdo use a bootstrap method for training [Derouault and Merialdo, 1986].
Probabalistic predictions of a word's category can be made by analyzing suffixes in untagged text [Kupiec, 1992, Meteer et al., 1991].
 , Yang et al.  , Luo et al.
For instance, Iida et al.   and Zelenko et al.
McCallum and Wellner   and Zelenko et al.   have employed graph-based partitioning algorithms such as correlation clustering  .
Finally, Strube et al.   and Iida et al.
PCFG parsing algorithms with worst-case cubic-time bounds are well-known.
Chitrao and Grishman  , Caraballo and Charniak  , Charniak et al.  , and Collins   describe best-first parsing, which is intended for a tabular item-based framework.
I-tries are as in Charniak et al.  , where NP— DT JJ NN becomes NP — XDT JJ NN and XDT JJ — DT JJ, and correspond to dropping the portion of an Earley dotted rule after the dot.7 O-tries, as in Leermakers  , turn NP— DT JJ NN into NP — XNP→ · NN NN and XNP→ · NN — DT JJ, and correspond to dropping the portion which precedes the dot.
579
  is a rare study in textbased inference of sentence-level emotional affin ity.
4.2 Implementation.
Experi ments used 10-fold cross-validation, with 90% train and 10% test data.2 4.3 Data.
They were imple mented as boolean values, with continuous valuesrepresented by ranges.
Sentence length in words (0-1, 2-3, 4-8, 9-15,.
13.
14.
of addressing TEP for TTS.
[A/AT former/AP top/NN aide/NN] to/IN [At-torney/NP/NP General/NP/NP Edwin/NP/NP Meese/NP/NP] interceded/VBD to/TO extend/VB [an/AT aircraftNN company/NN 's/$ govern-ment/NN contract/NN] ,/, then/RB went/VBD into/IN [business/NM] with/IN [a/AT lobby-ist/NN1 [who/WPS] worked/VBD for/IN [the/AT defense/NN contractor/NN] ,/, according/IN to/IN [a/AT published/VBN report/NN] ./.
[James/NP/NP E/NP./NP Jenkins/NP/NP] ,/, [a/AT one-time/JJ senior/JJ deputy/NN] to/IN [Meese/NP/NP] joined/VBD [the/AT board/NN] of/IN [directors/NNS] of/IN [Transworld/NP/NP Group/NP/NP Ltd/NP./NP] on/IN [April/NP/NP 28/CD] ,/, [1984/CD] ,/, [the/AT Chicago/NP/NP Tribune/NP/NP] reporteci/VBD in/IN [its/PP$ Tuesday/NR editions/NNS] ./.
[The/AT principal/JJ figure/NN] in/IN [Trans-world/NP/NP] was/BEDZ [Richard/NP/NP Mill-man/NP/NP] ,/, [a/AT lobbyist/NN] for/IN [Fair-child/NP/NP Industries/NP/NP Inc/NP./NP] ,/, Virginia/NP/NP de fense/NN con- 142 tractor/NN] I, [the/AT Tribune/NP/NP] said/VBD .1.
[A/AT federal/JJ grand/JJ jury/NN] is/BEZ in- [the/AT Fairchild/NP/NP transaction/NN] and/CC [other/AP actions/NNS] of/IN [Meese/NP/NP] and/CC [former/AP White/NP/NP House/NP/NP aide/NN Nofziger/NP/NP] in/IN [connection/NN] with/IN [Wedtech/NP/NP New/NP/NP York/NP/NP defense/NN company/NN] [that/WPS] received/VBD [$250/CD million/CD] in/IN [govemment/NN contracts/NNS] issued/VBN without/EN [competitive/JJ bidding/NN] during/IN [the/AT Reagan/NP/NP administration/NN] ./.
[Jenkins/NP/NP] left/VBD [the/AT White/NP/NP House/NP/NP] in/IN [1984/CD] 1, and/CC joined/VBD [Wedtech/NP/NP] as/CS [its/PP$ director/NN] of/IN [marketing/NN *]*[ two/CD years/NNS] later/RBR .1.
[Deborah/NP/NP Tucker/NP/NP] ,/, [a/AT spokeswoman/NN] for/IN [Fairchild/NP/NP] ,/, said/VBD [Friday/NR] that/CS [the/AT cornpany/NN] had/HVD been/BEN contacted/VBN by/IN [the/AT office/NN] of/IN [independent/JJ counsel/NN James/NP/NP McKay/NP/NP] and/CC [subpoenas/NNS] had/HVD been/BEN served/VBN on/IN [Fairchild/NP/NP] ./.
[Tucker/NP/NP] said/VBD [the/AT investigation/NN] involving/IN [Fairchild/NP/NP] had/HVD been/BEN going/VBG on/IN [a/AT number/NN] of/IN [weeks/NNS] and/CC predates/VBZ [last/AP week/NN 's/$ exof/1N [McKay/NP/NP 's/$ investigation/NN] to/TO include/VB [Meese/NP/NP] ./.
[The/AT company/NN] is/BEZ cooperating/VBG in/1N [the/AT investigation/NN] ,/, [Tucker/NP/NP] said/VBD ./.
[A/AT source/NN *] close/NN***] to/IN [McKay/NP/NP] said/VBD [last/AP week/NN&quot; that/CS [Meese/NP/NP] isn't/BEZ* under/IN [cruninalaJ investigation/NN] in/IN [the/AT Fairchild/NP/NP matter/NN] ,/, but/RB is/BEZ [a/AT witness/NN] ./.
[The/NP Tribune/NP/NP] said/VBD [Mill- ,/, acting/VBG as/CS [a/AT lobbyist/NN] for/1N [the/AT Chantilly/NP/NP] ,/, [Va/NP.-based/NP company/NN] ,/, went/VBD to/TO see/VB [Jenkins/NP/NP] in/IN [1982/CD] and/CC urged/VBD [him/PPO] and/CC [Meese/NP/NPI to/TO encourage/VB [the/AT Air/NP/NP Force/NP/NP] to/E0 extend/VB [the/AT production/NN] of/1/•1 [Fairchild/NP/NP 's/$ A-10/NP bomber/NN] for/IN [a/AT year/NN] ./.
[Millman/NP/NP] said/VBD there/RB was/BEDZ [a/AT lucrative/JJ market/NN] in/IN [Third/NP/NP World/NP/NP countries/NNS] ,/, but/CC that/CS [Fairchild/NP/NP 's/$ chances/NNS] would/MD be/BE limited/VBN if/CS [the/AT Air/NP/NP Force/NP/NP] was/BEDZ not/* producing/VBG [the/AT plane/NN] ./.
[The/AT Air/NP/NP Force/NP/NP] had/HVD decided/VBN to/TO discontinue/VB [production/NN] of/IN [the/AT A-10/NP] ,/, [a/AT 1960s-era/CD ground-support/NN attack/NN bomber/NN] at/IN [the/AT time/NN *]*[ Fairchild/NP/NP] was/BEDZ hoping/VBG to/TO sell/VB [A-10s/NP] abroad/RB j, [the/AT Tribune/NP/NP] said/VBD ./.
[The/AT newspaper/NN] said/VBD [one/CD source/NN] reported/VBD that/CS after/CS [Millman/NP/NP] made/VBD [his/PPS pitch/NN] J, [Meese/NP/NP] ordered/VBD [Jenlcins/NP/NP] to/TO prepare/VB [a/AT memo/NN] on/IN [behalf/NN] of/IN [Fairchild/NP/NP] ./.
[Memos/NP***] signed/VBD by/IN [Meese/NP/NP] ,/, stressing/VBG [the/AT importance/NN] of/IN [Fairchild/NP/NP 's/$ arranging/VBG sales/NNS] in/IN [Third/NP/NP World/NP/NP countries/NNS] j, were/BED sent/VBN to/IN [the/AT State/NP/NP Department/NP/NP] and/CC [the/AT Air/NP/NP Force/NP/NP] ./.
[Millman/NP/NP] did/DOD not/* return/VB [telephone/NN calls/NNS] to/EN [his/PP$ office/NN1 and/CC [referral/NN numbers/NNS] [Monday/NR] ,I, [the/AT Tribune/NP/NP] said/VBD ./.
This permits non-synchronous and many-to-many alignments.
Hwa et al.   tested the DCA under idealized conditions by obtaining hand-corrected dependency parse trees of a few hundred sentences of Spanish-English and Chinese-English bitext.
Weeber et al.   and Figure 8).
We randomly selected 965 items (15%) from the AdjN hapaxes, and 983 items ( 0.35%) from the low-frequency PNV triples.
The work of B. Krenn has been sponsored by the Fonds zur Förderung der wissenschaftlichen Forschung (FWF), Grant No.
P12920.
Experiments With A Multilanguage Non-Projective Dependency Parser
“o suspeito, de 38 anos, que traba7ha”), that produce diversions in the flow.
This work was supported by DARPA contract N6600100-1-9814 and MURI grant N00014-00-1-0617.
 , Yu and Hatzivassiloglou  , Wiebeand Riloff  ).
sen timent.
356 Lafferty et al  .
3.1 Features.
6.1 Baselines.
Bethard et al evaluate their system on manuallyannotated FrameNet   and Prop Bank   sentences and achieve 48% recall with 57% precision.
Our IE pattern learner can be viewed as a crossbetween AutoSlog (Riloff, 1996a) and AutoSlog TS (Riloff, 1996b).
361
SD-100 is for single document summaries of 100 words and MD-50, 100, 200, and 400 are for multi-document summaries of 50, 100, 200, and 400 words.
Recall and precision curves of N-gram co-occurrence statistics versus human assessment for DUC 2001 multi-document task.
Participants have re Research supported by NSF grants IIS-9801638 and ITR IIS 0085836 and an ONR MURI Award.
4 describes our experimen tal study.
3.1 A Hierarchical ClassifierQuestion classification is a multi-class classification.
Pos tags are extracted using a SNoW-based pos tagger  .
4.1 Data.
4.2 Evaluation.
We use Nivre and Nilsson?s PATH scheme2.
2.1 Dependency Parsing with a Data-Driven.
Otherwise, we get a list of parser actions act0...actn (with associated probabilities Pact0...Pactn) corresponding to state Tcurrent.
Sa gae and Lavie (2006a) and Zeman and ?abokrtsk?
Discriminative log-linear models are now becoming a de facto standard for probabilistic disambiguation models for deep parsing (Johnson et al., 1999; Riezler et al., 2002; Geman and Johnson, 2002; Miyao and Tsujii, 2002; Clark and Curran, 2004b; Kaplan et al., 2004).
Corpus-Based Identification Of Non-Anaphoric Noun Phrases
This produced 849 definite NPs.
We present algorithms that are more efficient relative to the lattice algorithms presented in Macherey et al. (2008; Tromble et al.
A related MBR-inspired approach for hypergraphs was developed by Zhang and Gildea  .
Chiang  , Zollmann and Venugopal  , Mi et al.  ) is a directed hypergraph or a packed forest  .
The arity of a hypergraph is the maximum arity of its hyperedges.
On some systems such as the Arabic-English SAMT, the gains from Hypergraph MBR over 1000-best MBR are significant.
We select the MBR scaling factor   based on the development set; it is set to 0.1, 0.01, 0.5, 0.2, 0.5 and 1.0 for the aren-phrase, aren-hier, aren-samt, zhen-phrase zhen-hier and zhen-samt systems respectively.
On lattices, it achieves similar run-times as the implementation System BLEU (%) MAP MBR default mert-b mert+b aren.pb 54.2 54.8 54.8 54.9 aren.hier 52.8 53.3 53.5 53.7 aren.samt 53.4 54.0 54.4 54.0 zhen.pb 40.1 40.7 40.7 40.9 zhen.hier 41.0 41.0 41.0 41.0 zhen.samt 41.3 41.8 41.6 41.7 described in Macherey et al.  .
The new Lattice MBR decoder achieves a 20X speedup relative to either FSAMBR implementation described in Tromble et al.   or MBR on 1000-best lists.
Score wj corresponds to side1 and uj corresponds to side2.
Opinion-target pairing.
[Kaplan and Bresnan, 831, p. 281).
This advantage grows as the number of subsymbols increases (88.4% vs. 87.3% for 16 subsymbols).
Matsuzaki et al.   discuss two approximations.
Noun-Phrase Co-occurrence Statistics for Semi-Automatic Semantic Lexicon Construction
Pairwise inter-annotator agreement was 27.75%.
SWAG1, SWAG2, USYD, UNT) to obtain counts fordisambiguation, with some using algorithms to derive domain (IRST1) or co-occurrence (TOR) infor mation from the BNC.
5.1 Post Hoc Analysis.
We tried all combinations of 01 = {2,10} and 02 = {.60,.65,.70,.75,.80,.85,.90,.95,1.0}.
Mikheev et al.   and Finkel et al.
BabbleQuest International8 der by various means.
University Polit`ecnica de Catalunya/University de Barcelona   lations.
I. Dan Melamed.
1998.
Arul Menezes and Stephen D. Richardson.
2001.
Anoop Sarkar.
2001.
1994.
Our work is inspired by dual decomposition methods for inference in Markov random fields (MRFs) (Wainwright et al., 2005a; Komodakis et al., 2007; Globerson and Jaakkola, 2007).
10.
10.
1),11 and the 2nd order discriminative dependency parser of Koo et al.  .
11.
Selectional preference  .
Zanzotto et al.   recently explored a different interplay between SPs and inferences.
A Stochastic Japanese Morphological Analyzer Using a Forward-DP Backward-A* N-Best  Search Algor i thm Masa.aki NAGATA NTT  Network Information Systems l~,~bor~ttorics 1-2356 Take, Yokosuka-Shi, Kanagaw~t, 238-03 Japan (tel) 4-81-468-59-2796 (fax) +81-468-59-3428 (e-mail) nagata@nttnly.ntt .
Using character trigrams ms tim word model, it gener- ates the N-best word hypotheses that match the left- most substrings starting at a given position in the input senten  ce.
2 Tagging Model 2.1 Tr i -POS Mode l  and  Re la t ive  F re - quency  Tra in ing We used the tri-POS (or triclass, tri-tag, tri-Ggram etc.)
Con- sider a word segmentation f the input sentence W = wl w2.
ist and path-~ap.
make-parseO ; new-parse.mtart  :~ i ; new-parse.end : -  i + length(word.form); hey-pares,poe :- word.pea; new-parae.nth-order-mtate :~ rest(pos-ngram) ; naw-paree.preb-ee- far  :-  parae.prob-so- far * transprob(pos-ngram) * word.prob; new-parse.previous := paras; reg ie ter -parse - to -parae- l t s t  (new-parse) ; reg is ter -paree- to -path -ma p (new-parse) ; endif elld end end f inn l -e tQp( ) ;  i/ Randlan t r tmai t ion  to tho e~d symbol.
-31.90894138309038 -38 .
S9433~3fi658235fi ~b/tRllDll~iil-ill!lll,Til~l t-J-/lJ/ltlDil, l .
two candidates, since tliere ;ire 12 distinct brackets in tile systems otll.litlt and 9 Inatehing brackets, tile re- call and precision with respect o hal)el consistency are 9/9 aud 9/12, respeetiwqy.
The trigram model achiew;d 97.5% recall and 97.8% precision flu" the top candidate, while tile bigram model achiew.d 96.2% recall and 96.6% precision.
100 95 90 $5 80q 75 90 65 60 Hogpho loq lca l  Ana ly l t s  Accuracy  fo r  N - I les t  Sentences r iw  t r tq ram (c losed  ce :~t)  -a-.-- raw b i t / tam , a ~ t , ?
~ a~othed  t r t~ram wi th  Iopen  text )  -o , .
Imoothed  t r lq ram wi  word  a lo t le l  l opes  te~t )  -~ .... raw m wi th  word  moOel  l apen  text}  ~.
- iraw t r  r l ra  w i thout  word  nloc~el lopes  text )  -.12-::-.
: "A Procedure for Quantit.a- tively Comparing the Syntactic Coverage of En- glish Grammars", I)AIHA Speech an(I Nalma] Language Workshop, pp.306-311, Morgan Kauf- [15] mann, 1991.
[2] Charniak, E., Ilendrickson, C., Jacol)son, N., and Perkowitz, M.: "Equations for Part-of~Speech Tagging", AAAI-93, I)1).784-789, 1993.
[4] Cutting, D., Kupiec, J., Pederseu, J., and Sibnn, P.: "A Practical Part-of-Speech Tagger", ANLP- [17] 92, pp.133-140, 1992.
[5] Ehara, T., Ogura, K. and Morimoto, T.: "hrl~ Dialogue Database," 1CSLP-90, pp.1093-1096, 1990.
[6] IIe, Y.: "Extended Viterbi Algorithm for Second Order Ilidden Markov Process", ICIR-88, pp.718- 720, 1988.
Ilisamitsu, T. and Nitta, Y.: "Morphological Analysis by Minimum Connetivc-Cost Method", [echnical Report S/GNLC 90-8, IEICE, pp.17-24, 1990 (in Japanese).
Matsunobu, E., lIitaka, T., and Yoshida, S.: "Syn- t.actic Analysis by Stochastic P, UNSETSU Gram- mar", Technical Rel)ort SIGNL 56-3, IPSJ, 1986 (in Japanese).
: "Tagging Text with a Probabilistic Moder, ICASSP-9I, pp.809-812, 1991.
Meteer, M. W., Schwartz, R. and Weischedel, R.: "IOST: Using l)robal)ilities in Language Process- ing, lJCAI-9 t, pp.960-965, 1991.
Murakaini, J. and Sagayama, S.: "llidden Markov Model applied to Morphological Analysis", 45th National Meeting of the IPSJ, Vol.3, pp.161-162, 1992 (in Japanese).
and llital?a, T.: "Japanese Word For- marion Model and Its Evahmtion", Trans IPSJ, Vol.34, No.9, pp.1944-1955, 1993 (in Japanese).
Sakai, S.: "Morphological Category l~;igram: A Single Language Model for botl, Spoken l,anguage and Text", ISS1)-93, I)1).87-90, 1993.
Soong, F. K. aml lluang E.: "A Tree-Trellis Based Fast Search for Finding the N Best Sen- tence llypotheses in Continuous Speech Recogni- tion", ICASS P-9 I, pp.705-708, 1991.
Yoshinmra, K, llitaka, T., and Yoshida, S.: "Mor- phological Analysis of Non-marked-off Japanese Sentences hy the Least llUNSETSUs Number Method", trans.
Yoshimura, K., Takeuchi, M., Tsuda, K. and Shudo, K.: "Morphological Analysis of Japanese Sent.ences Containing Unknown Words", Trans.
IPSJ, Vol.30, No.3, pp.294-301, 1989 (in Japanese).
Mot ivat ions and Methods  tbr Text Simpli f icat ion R. Chandrasekar*  Chr ist ine Doran B. Srinivas Institute for Research in l)el)artm<;nt of Deparl;mcnt of Cognitive, Science & (]cntcr for [,inguistics (]Oml)uter $?
the Advanced Study of hldia InlbrHlatioll Scienc(; University ot7 Pcnnsylwmia, lqfiladclphia, PA 19104 {ra?ckeyc, doran, sr in?
upenn, edu Abst ract Lottg alld eolni)licated seltteltces prov(: to b(: a. stumbling block for current systems rely- ing on N[, input.
These systenls stand to gaill frolil ntethods that syntacti<:aHy sim- plily su<:h sentences.
(  ]ompare this with the mult i -sentence ver- sion which has been manual ly  simplif ied: (2) The embatlled Major governmcnl survived a crucial vote ou coal pits closure.
Simplit ication is theretbre inappropr iate  for texts (such as legal docunlents) where it is importa.nt not to lose any nuance.
I|owew;r, one c.~tl] COil- ceive of several areas of natura l  language process- ing where such simplit ication would be of great use.
Re- solving ambiguit ies in a t tachment  of con- st i tuents is non-tr ivial .
Fhus s impler sentences lead to faster parsing and less parse aml)igu- ity.
(3) Talwinder Singh, who masterminded the Kanishka crash in 198~, was killed in a fierce lwo-honr e~.connter... (4) Talwindcr Singh was killed in a .fierce two-hoar cncounler ... Talwinder Siugh masterminded the Kanishka crash in 198~.
Chunk boundaries are regarded as poten- tial articulation-points.
dency attachment techniques as an alternative to the FSG I)ased simpliiication.
4.1 Br ie f  Ovt;rvlt;w of LTAGs The primitive elements el LTA(~ formalism are (.l- ( : lnentary  trees.
4.2 SuI)(*xl;agging Tlte elemmttary trees of LTAG localize dependen- (-ies, including hmg distance dependencies, by re- quiring that all and only the dependent elements be present within the same tree.
Acknowledgements This work is partially supported by NSF grant NSF- STC SBR 8920230, ARPA grant N00014-94 and All.
R. Chandrasekar and S. Ramani.
Auto- matic Simplifica.tion of Natural Language Text.
M~muscript, National Centre for So[tware Technol: ogy, Bombay.
R. Chandrasekar.
Ph.D. thesis, Pata Institute of I"undamcnta] Research/University of Bombay, Bombay.
Ralph Grishman.
Technical Report 519, SRI.
Aravind K. Joshi and B. Srinivas.
Yves Schabes, Anne Abeilld, and Aravind K. Joshi.
Wojcik, Philip tIarrison, rod John Bremer.
3.2.2 Results.
SegAgent.
• wcd6p4er  —a measure based on cder with word-based substitution costs.
2.1 The Log-Likelihood-Based Model.
2.2 The Conditional-Link-Probability-Based.
84 els are treated differently.
An interesting question is why CLP 2outper formed CLP 1 . CLP.
It amounts to reparameterizing θk as θk = θ+k −θ−k , where θ+k and θ−k are positive.
The coordinate descent approach of Dudik et al.   and Friedman et al.
Bobrow   and Chitrao and Grishman   introduced statistical agendabased parsing techniques.
(Klatt 1980; pp.
See Furui (1989; Appendix D.3, pp.
As a result, the empirical approach has been adopted by almost all contemporary part-of-speech programs: Bahl and Mercer  , Leech, Garside, and Atwell  , Jelinek  , Deroualt and Merialdo  , Garside, Leech, and Sampson  , Church  , DeRose  , Hindle  , Kupiec (1989, 1992), Ayuso et al.  , deMarcken  , Karlsson  , Boggess, Agarwal, and Davis  , Merialdo  , and Voutilainen, Heikkila, and Anttila  .
The unigram model is also more than twice as good as Lempel-Ziv (2.1 vs. 4.43 bits/ char.
Koehn  , Tillmann  , and Vogel et al.   describe various heuristics for extracting phrase alignments from the Viterbi word-level alignments that are estimated using Brown et al.
Barzilay and McKeown   extract both singleand multiple-word paraphrases from a monolingual parallel corpus.
3.1 Al ignment w i th M ix ture D is t r i |mt ion.
Thus l.he resulting train- ing procedure is straightforward.
Size AvalancJte \] A\[ \ [ ra i l s Verlmlobil Frolt ch (~('~ l lal l Spanish I,;nglish ( le 11 an English 62849 ,\]4805 --1:77@- 15888 150279 25,\] 27 1993 2265 2008 t 63(} dO 17 2`\]/13 For several years 1)et;weeu 83 and !)2, the Avalanche Bulletins are awdlabte for I>oth Get- ntan and I!'ren(;\]l. The following is a tyl)ical sen-- t<;nce t>air fS;onl the <;or:IreS: Bei zu('.rst recht holnm, Sl)~i.tev tM'eren 'l'em- l)eraJ, uren sind vou Samsta.g his 1)ienstag tno f gett auf <l<'~t; All>ennor(ls<'.ite un</ am All>en-.
ha.uptkanml oberhalb 2000 m 60 his 80 cm Neuschnee gel'aJlen.
l)ar des temp&'atures d' abord dlevdes, puis plus basses, 60 h 8(1 cm de neige sent tombs de samedi h. mardi matin sur le versant herd el; la eft're des Alpes au-dessus de 2000 l\[1.
were ttsed to train 1)oth al ignnmnt models, the mixture-I>ased al ignment model in Eq.(1) and the llMM-base<l a.lignntent mod('l in Eq.(d).
,, l{,efinement traiuiug: The translation pcoba- 1)ilities Dotn the initialization training wet'(; use+d to initialize both the IBM2 model and the I I M M-based nligntnent mo<t<'+l IBM2 Model: 5 iteratious using Lit(" max- i lnum a.I)proximatiolt (Eq+(3)) I IMM Model: 5 iterations usiug l le max-.
In adclitiou t;o the total i>erl>lexity, whi<'.h is the' globa.l opt imizat ion criterion, the tables al- so show the perplexities of the translation prob- abilities and of the al ignment probabil it ies.
that the mixture align- ment gives slightly better perplexity values for the translation l)roba.1)ilities, whereas the I IMM mod- el produces a smaller perplexity for the al ignment l>rohal)ilities.
Iteration Tra,nslatiotl.
Alignrnent Total 0 1 2 9 10 99.36 3.72 2.67 t.87 1.86 20.07 20.07 20.07 20.07 20.07 1994.00 7/1.57 53.62 37.55 37.36 Max.
3.88 20.07 77.!)5 'l'able 3: '1 rans\] ~+tion, aligmn en t and totaJ perplex- ity as a function of the itcra.tion for the IBM2 (A) and the I IMM model (13) Iter.
Tratmlat;i(m A 0 l 2 3 ,\] 5 1~ 0 1 3 4 5 A ligniN.elJ t 3.88- 20.07 3.17 10.82 3.25 10.15 3.22 10.10 3.20 \] 0.06 3.18 10.05 3.88 20.07 3.37 7.99 3.46 6.17 ;{./17 5.90 "Ld6 5.85 3.`\]5 5.8,\] ' l 'otal 77.95 34.27 33.03 32.48 32.18 32.00 77.95 26.98 2t.36 20.48 20.2/1 20.18 Anoth<2r inl;crc:sting question is whether the IIMM alignntent model helps in finding good and sharply fo('usscd word+to-word (-orres\]Jondences.
The, re is virLually no ,:lilfc~rc~nce between the translation l.al>les for the two nn)dels (1BM2 and I IMM).
But+ itt general, the tl M M model seems to giw'.
IBM1 Alpes (684) 0.171 des   0.035 le   0.039 sud (416) 0.427 sur (769) 0.040 versant (431) 0.284 IBM2 Alpes (684) 0.276 sud (41.6) 0.371 versant (431) 0.356 HMM Alpes (684) 0.284 des   0.028 sud (416) 0.354 versant (431) 0.333 This is a result of the smoother position align- ments produced by the HMM model.
Total IBM1 10 2.610 6.233 16.267 IBM2 5 2.443 4.003 9.781 HMM 5 2.461 3.934 9.686 IBM1 10 4.373 10.674 46.672 IBM2 5 4.696 6.538 30.706 ItMM 5 4.859 5.452 26.495 The Verbmobil Corpus consists of spontaneous- ly spoken dialogs in the domain of appointment scheduling.
Most machine translation systems adopt the approach of Koehn et al.   for ‘training’ a phrase-based translation model.2 This method starts with a word-alignment, usually the latent state of an unsupervised word-based aligner such ⇒ hJohn-ga X4 X5, John X5 X4i ⇒ hJohn-ga ringo-o X5, John X5 an applei ⇒ hJohn-ga ringo-o tabeta, John ate an applei as GIZA++.
Our Bayesian model of SCFG derivations resembles that of Blunsom et al.  .
This results in the conditional probability: where nN,−i ri,zi is the count of rewriting zi with nonterminal rule ri, nN,−i ·,zi the total count over all nonterminal rules and |N |is the number of unique non-terminal rules.
5.2.1 Blocks.
= 55.8) as opposed to 380 msec (s.d.
We found glottalization in 24 of the 25 vowel-final fragments in our data.
Finally, SRL requires hand-constructed semantic resources like Propbank and Framenet   as input.
Nigam et al.   addressed a text classification task.
HR001106-C-0022.
The hypothesis translation contains a total of 18 unigrams, 17 bigrams, 16 trigrams, and 15 4-grams.
Menchetti et al.   use RNNs to re-rank different parses.
This paper uses several ideas of (Socher et al., 2011b).
2, we would get the triples ((p1 -+ bc), (p2 -+ ap1)).
PCFG.
The subgradient of Eq.
See Kummerfeld et al.   for more comparisons.
See Kummerfeld et al.   for details and comparisons to other parsers.
Similarly NPs dominate DTs.
3.7.
Text-Translation Alignment
Trifft em Proton auf einen Atomkern in dieser Gashfille, werden drei Arten von Pionen erzeugt.
Die neutralen Pionen zerfallen in jeweils zwei Gammaquanten, die sich beinahe in dieselbe Richtung wie das urspriingliche Proton bewegen.
Nach der Modellvorstellung gibt es gerade zwei Positionen im Umlauf des Pulsars urn semen Begleitstern, bei denen die Strahlung in Richtung zum Beobachter auf der Erde ausgesandt wird.
Pass Correctness Coverage Constraint in SAT of SAT by AST 1 100% 12% 4% 2 100% 47% 17% 3 100% 89% 38% 4 99.7% 96% 41% Das untere Ende des Spektrums der kosmischen Strahlen ist verhaltnismai3ig unscharf definiert.
Jedes Photon (Quant der elektromagnetischen Strahlung) Teilchen mit einer Energie von mehr als Elektronenvolt, das aus dem Weltraum eintrifft, bezeichnet man als kosmischen Strahl. frequently occurred in our data that sentences that separated by colons or semicolons in the original appeared as completely distinct sentences in the German translation.
Dies ist eine vorsichtige Absch5tzung.
Sie ist nur aus den Gammastrahlen-Daten abgeleitet, die auf der Erde gemessen werden; daI3 Cygnus X-3 wahrscheirtlich kosmische Strahlung in alle Richtungen aussendet, ist dabei noch nicht beriicksichtigt.
Alignable Sentence Table (AST).
They seem to come from everywhere, raining down on the earth from all directions at a uniform rate. is rendered in German by the single sentence (5): Dennoch blieben die Quellen der kosmischen Strahlung, die aus alien Richtungen gleichmaSig auf die Erde zu treffen scheint, bis vor kurzem reine Spekulation, wahrend einige der aufregendsten Fortschritte in der Astronomic aus dem detaillierten Studium von Röntgen- und Radiowellen herriihrten.
Trifft em Proton auf einen Atomkern in dieser Gashfille, werden drei Arten von Pionen erzeugt.
Die neutralen Pionen zerfallen in jeweils zwei Gammaquanten, die sich beinahe in dieselbe Richtung wie das urspriingliche Proton bewegen.
Nach der Modellvorstellung gibt es gerade zwei Positionen im Umlauf des Pulsars urn semen Begleitstern, bei denen die Strahlung in Richtung zum Beobachter auf der Erde ausgesandt wird.
Das untere Ende des Spektrums der kosmischen Strahlen ist verhaltnismai3ig unscharf definiert.
Jedes Photon (Quant der elektromagnetischen Strahlung) oder Teilchen mit einer Energie von mehr als 108 Elektronenvolt, das aus dem Weltraum eintrifft, bezeichnet man als kosmischen Strahl.
Aus dieser Absorptionslinie kann man eine untere Grenze der Entfernung von Cygnus X bestimmen.
Die Quelle mu13 jenseits der am weitesten entfernten Wasserstoff-Wolke sein, also weiter als ungefahr 37000 Lichtjahre entfernt, am Rande der Milchstrai3e.
Dies ist eine vorsichtige Absch5tzung.
Sie ist nur aus den Gammastrahlen-Daten abgeleitet, die auf der Erde gemessen werden; daI3 Cygnus X-3 wahrscheirtlich kosmische Strahlung in alle Richtungen aussendet, ist dabei noch nicht beriicksichtigt.
Second-order decisions.
Semiring Parsing
The input string will be denoted w1 w2.. wn.
Earley's algorithm is often described as a bottom-up parser with top-down filtering.
There are three derivation semirings: the derivation forest semiring, the Viterbi-derivation semiring, and the Viterbi-n-best semiring.
We say that al ' b' • ak c1 ci is an instantiation of deduction rule A1 ' • ' —1 .
2.4.4 Iso-valued Derivations.
The Viterbi-derivation semiring computes this value.
There are also books by Salomaa and Soittola   and Kuich and Salomaa  .
A production (lhs, rhs, w) is written lhs →w rhs.
: - r NP(x0:CD, x1:NN) → q.NP.CD x0, q.NP.NN x1 - r NP(x0:CD, x1:NN) → q.NP.NN x1, q.NP.CD x0 The rhs sends the child subtrees back to state q for recursive processing.
peg,. pyscropyrssexa pa...Inn/bee(Esrey:,we6onee nocnemere)seressartba 43csrassartsmeuroto-ssoprbonourseLproronparserrna flaw) sror spe6yer — ,r1 Transducerloacleo a erkirlE.FOL.
, GPE RecallIncreaseon Atonaltmarked iron 06371426571426571la10 type Organization 1.0 increaseon hurnan-markedto 1 0 09444444444444444 Mug 07, limEll.ncreaseon tom0345to 07, 14153ING ANNOTATIONSIt To automatetetteABC Ir.NNOTATKMISinTo embroil,bath PARTIALLYCORRECT Pl4071&quot;ATIC*15nhe automateIDA, PratotationType Annotation type Person Precision increase on human-marked from 08947368421052632 lc 09444444444444444 03444444444444444 al., 2000).
Both the splitter and tagger are domainand application-independent.
Most work concentrates on finding relations between biological entities, like genes and proteins (Krauthammer et al., 2002; Mitsumori et al., 2006; Krallinger et al., 2008a; Krallinger et al., 2008b).
Light et al.   analyse the use of speculative language in MEDLINE abstacts.
Szarvas   follows Medlock and Briscoe   in classifying sentences as being speculative or nonspeculative.
Brown et al. 1993).
In the Japanese text, we introduce &quot;word&quot; boundaries that are convenient Length < 5 < 10 < 15 < 20 All jww 75.8/78.0 45.2/50.4 40.0/45.4 37.2/42.8 37.2/42.8 e2j 89.2/89.7 74.0/76.6 68.6/72.2 66.4/70.1 66.4/70.1 for the training process.
A log-linear model associates each feature f3 with a real-valued parameter 03.
Another feature indicates nonright-branching nonterminal nodes.
Experiments with a Higher-Order Projective Dependency Parser
2.2 Features.
et al, 2004; Aduriz et al, 2003; Mart??
et al, 2007; Chen et al, 2003; Bo?hmova?
et al., 2003; Marcus et al, 1993; Johansson and Nugues, 2007; Prokopidis et al, 2005; Csendes et al, 2005; Montemagni et al., 2003; Oflazer et al, 2003).2We obtained projective trees for training sentences by run ning the projective parser with an oracle model (that assigns a score of +1 to correct dependencies and -1 otherwise).
3.1 Impact of Higher-Order Factorization.
mem.
960
Appelt et al.  , Lin  .
Wacholder et al. 1997, Palmer and Day 1997, Neumann et al.
Using WordNet.
Utilizing EVCA.
Specifically, Ei = N1(Rij) and Ej =N2(Rij).
The exception edu is edu 1.
Categorial Unification Grammars
Such grammars currently run on two PATR implementations: Stuart Shieber's Zetalisp version on the Symbolics 3600 and Lauri Karttunen's Interlisp-D w:rsion on the XEROX 1109.
Grammars 1.2.
Unif ication Grammars and Categorial.
1.2.
As in tradit ional categorial grammars, two such rules sufice.
The lexicon lists uninstantiated ntries.
(26b) Start in 1700.
194
We fit a monotonically decreasing power-law function to the data points (Duda et al. 2001, p. 492).
Note that PB1 and SC1 use co–occurrence features, while PB3 and SC3 rely on bigram features.
In short, Table 3 compares PB1 against PB2 and SC1 against SC2.
Meteer discusses the same problem in McKeown's original TEXT system (Meteer 1990, p.35).
Extracting Parallel Sub-Sentential Fragments From Non-Parallel Corpora
HR001106-C-0022.
Rychlý and Kilgarriff  , Elsayed et al.   and Agirre et al.
2005; Paşca et al. 2006).
Finally, semi-supervised methods have shown great promise for identifying and labeling entities (Riloff and Shepherd 1997; Riloff and Jones 1999; Banko et al. 2007; Downey et al.
2007; Paşca et al. 2006; Paşca 2007a; Paşca 2007b; Paşca and Durme 2008).
Etzioni et al.   and Pantel et al.
The resulting trial dataset consists of 20,220 trials3.
Best-first clustering.
by Bangalore et al.   and Marciniak and Strube  .
SUMTIME is a knowledge-based NLG system.
We also computed NIST-5 and ROUGE-4.
Kudoh and Matsumoto  , Zhang and Johnson  ).
We exploreq=50K, 100K,s=50,100,500,1K, and commonly-used feature splits: ‘current vs. context’ and ‘current+left-context vs. current+right-context’.
Self-training Single-view bootstrapping is sometimes called self-training.
We uni- and bi-grams of words and POS in a 5-token window. word-POS bi-grams in a 3-token window.
N66001-99-2-8916.
Specif ications are constra ints  upon one or more const i tuents  of the rule.
f se t 2- -Q  .
More constra ints  can be added by annotat ing  the rule with specifications.
A template is an abbreviat ion fo ra  l istofspeci f icat ions.
This overwr i t ing operat ion differs flom standard unif ication in that  it never fails; if two specif ications give confl ict ing values to some path, the later specif ication overrules the earl ier one.
barl evel -- one cat--V invertible--false lex~ sense ~- - .
i n - cat l/ c(~t le_~ [ / - t,_.x~ ....... ~ntics--relatior,-fl- ,,d,dion SOMEBODY- -arR!
2.6 F i l lers  and  Gaps Constructh)ns such as the fb[lowing contain const i tuents  that,  semant ical ly  and syntactical ly,  fill a vacant  s lot - -a  gap--somewhere in the adjacent structure.
77 The default  mechan ism uses four special features: gapln, gapOut, relIn and relOut.
These features need to be ment ioned explicit ly only in rules that  introduce fillers, such as the relat ive-clause rule, and in the lexical entr ies of relat ive and interrogat ive pronouns.
F i rst  of all, the const i tuents  are feature sets; second, the const i tuents  in a part ia l ly   [nstant iated rule are general ly  not equal to the corresponding const i tuents in an un ins tant ia ted  rule.
l.) PATR so lves  this problem by carry ing the or iginal rule along with its part ia l ly  instant iated form on active edges.
Kay, M., "Parsing in Functional Unification Grammar," Natural Language Parsing, D. Dowty, L. Karttunen, and A. Zwieky, eds., Cambridge University Press, Cambridge, England, 1985.
Kiparsky, C. "LFG Manual," manuscript, Xerox Palo Alto Research Center, Palo Alto, California  .
Pereira, F. C. N., "A Structure-Sharing Representation for Unification-Based Grammar Formalisms," Proceedings of the 23rd Annual Meeting of the ACL, Association for Computational Linguistics, 1985.
Pereira, F. C. N. and D. H. D. Warren, "Definite-Clause Grammars for Language Analysis--a Survey of the Formalism and a Comparison with Augmented Transition Networks," Artificial Intelligence, 13:231-278, 1980.
Shieber, S. M., H. Uszkoreit, F. C. N. Pereira, J. J. Robinson, and M. Tyson, "The Formalism and Implementation of PATR lI," Research on Interactive Acquisition and Use of Knowledge, B. Grosz and M. Stickel, eds., Sill Final Report 1894, SRI International, Menlo Park, California, 1983.
Shieber, S. M., L. Karttunen, and F. C. N. Pereira, Notes from the Unification Underground: A Compilation of Papers on Unification-Based Grammar Formalisms.
Shieber, S. M., An Introductton to Untficatton-Based Approaches to Grammar, CSLI Lecture Notes Series,  .
Steedman, M., "Combinators, Categorial Grammars, and Parasitic Gaps," paper presented at the Tucson Conference on Categorial Grammar  .
Uszkoreit, H., "On Categorial Unification Grammars," in this volume.
Unsupervised part-of-speech tagging, as defined above, has been attempted using a variety of learning algorithms (Brill 1995, Church, 1988, Cutting et. al. 1992, Elworthy, 1994 Kupiec 1992, Merialdo 1991).
One issue we noticed which impacted tagging accuracy was that of a frequently occurring word (a) The/VB Lyneses/NNP ,/, of/IN Powder/NNP Springs/NNP ,/, Ga./NNP ,/, have/VBP filed/VBN suit/NN in/IN Georgia/NNP state/NN court/NN against/IN Stuart/NNP James/NNP ,/, *-1/-NONE- alleging/VBG fraud/NN ./.
(b) Last/JJ week/NN CBS/NNP Inc./NNP cancelled/VBD ``/`` The/NNP People/NNP Next/NNP Door/NNP ./.
''/'' (c) a/SYM -/: Discounted/VBN rate/NN ./.
5.3 Results.
OUR PREVIOUS WORK ON WORD-SENSE D ISAMBIGUATION 2.1.
entropy 1 67 7569 0 2 16 2552 0.58 3 7 1313 0.56 4 5 1252 1.2 5 1 1014 0.43 6 1 594 1.3 5.
Dagan, Ido, Alon Itai, and Ulrike Schwall  , "Two Languages are more Informative than One," Proceedings of the 29th Annual Meeting of the Asso- ciation for Computational Linguistics, pp 130-137.
Groliers Inc.   New Groliers Electronic En- cyclopedia.
Sutton, G.   Automatic Text Processing, Addison-Wesley Publishing Co. 11.
Yarowsky, David   "Word-Sense Disamhigua- tion Using Statistical Models of Rogets Categories Trained on Large Corpora", submitted to COLING- 92.
Collins et al.   and Miller et al.
First employed in SMT by Watanabe et al.  , and refined by Chiang et al.
To these examples, we added 58,000 NO-RELATION-SAME-TEXT and 58,000 NO-RELATION-DIFFERENT-TEXTS relations.
Roark and Charniak de scribe a ?generic algorithm?
5.1 Methodology.
5.2 Results.
5.3 Analysis.
Ford, Bresnan, and Kaplan 1982; Marcus 1980).
Of the 84 send/V into bigrams, 10 were assigned by steps 2 and 3 ('sure attachements').
Chinese Segmentation with a Word-Based Perceptron Algorithm
Furtherfor decoding. more, our approach provides an example of the poSeveral discriminatively trained models have re- tential of search-based discriminative training methcently been applied to the CWS problem.
Exam- ods for NLP tasks.
ples include Xue  , Peng et al.   and Shi 2 The Perceptron Training Algorithm and Wang  ; these use maximum entropy  .
We follow the format from Peng et al.  .
We proposed a word-based CWS model using the discriminative perceptron learning algorithm.
LR/LP labeled recall/precision.
For comparison SPATTER (Magerman 95; Jelinek et al. 94) was also tested on section 23.
Regarding LKBs, the best results are obtained using WordNet 1.7 and eXtended WordNet.
  uses WordNet 1.7 enriched with eXtended WordNet relations, just as we do.
We used the Spanish WordNet as LKB, enriched with eXtended WordNet relations.
It contains 105, 501 nodes and 623,316 relations.
Type 3 errors were spelling variants (e.g., Kyrgystan vs. Kyrgyzhstan) and name variants (e.g., Beyonce vs. Beyonce Knowles).
Michi -gan).
Overview of Genia Event Task in BioNLP Shared Task 2011
Since then, several improvements have been reported (Miwa et al., 2010b; Poon and Vanderwende, 2010; Vlachos, 2010; Miwa et al., 2010a; Bj¨orne et al., 2010).
UTurku09 was the winning system of Task 1 in 2009  , and Miwa10 was the best system reported after BioNLP-ST 2009 (Miwa et al., 2010b).
Note that although for any i =6 j, we have (ei, ci) =6 (ej, cj), it is possible that ei = ej or ci = cj for some i =6 j. wi is the transliteration score of (ei, ci).
An edge between (ei, ci, wi) and (ej, cj, wj) is constructed iff (ei, ci) and (ej, cj) co-occur in a certain document pair (Et, Ct), i.e. there exists a document pair (Et, Ct), such that ei, ej ∈ Et and ci, cj ∈ Ct.
Memory-Based Dependency Parsing
(In   ? ADV NN 60-talet the-60?s   ? PR VB ma?lade painted PN han he   ? SUB JJ dja?rva bold   ? ATT NN tavlor pictures   ? OBJ HP som which   ? ATT VB retade annoyed ?   SUB PM Nikita Nikita   ? OBJ PM Chrusjtjov.
for the correspond ing undirected relations, i.e. wi ? wj iff wi ? wj or wj ? wi.
Single head (wi?wj ? wk?wj) ? wi = wk Acyclic ?(wi?wj ? wj??wi) Connected wi??wj Projective (wi?wk ? wiwjwk) ?
2.4 Memory-Based Learning.
3.2 Data.
3.3 Evaluation.
This is dif ferent from the original IB1 algorithm, as described in Aha et al.
The memory-based classifiers used in the experi ments were constructed using the Tilburg Memory-BasedLearner  .
Dagan and Engleson, 1995, Weng, et al, 1998).
Marialdo's HMM part-of-speech tagger training  , Charniak's parser retraining experiment  , Yarowsky's seeds for word sense disambiguation   and Nigam et al's   topic classifier learned in part from unlabelled documents.
CDA-94-01024.
We use the WN Similarity jcnscore   since this gave rea sonable results for McCarthy et al and it is efficientat run time given precompilation of frequency information.
We se lected all the polysemous nouns in WN 1.6 that have at least one synset labelled SPORT and one synset labelled FINANCE.
3.3 Characterisation of the Annotated Data.
words FS cds, F sal, S sal and eq sal separately.
Other lexicalized formalisms include  .
-4 VD.
by Brown et al.   and Wang et al.
E.g.
Daille et al., 1994; Smadja et al., 1996) define &quot;collocations&quot; in terms of monolingual frequency and part-of-speech patterns.
2 wrongful conviction erreur judiciaire 2 weak sister parent pauvre 2 of both the users and providers of transportation des utilisateurs et des transporteurs 2 understand the motivation saisir le motif 2 swimming pool piscine 2 ship unprocessed uranium expedier de l'uranium non raffine 2 by reason of insanity pour cause d'alienation mentale 2 l'agence de Presse libre du Québec l'agence de Presse libre du Québec 2 do cold weather research etudier l'effet du froid 2 the bread basket of the nation le grenier du Canada 2 turn back the boatload of European Jews renvoyer tout ces juifs europeens 2 Generic Pharmaceutical Industry Association Generic Pharmaceutical Industry Association
EmoLexBi refers to all the bigrams.
Discriminative Reranking For Machine Translation
100 and 101.
0121285.
Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al.
1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al.
1993; Schutze and Singer 1994).
Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al.
1993; Weischedel et al. 1993; Schutze and Singer 1994).
The third fixes might/MD not reply/NN—VB.
Some studies aim to find an instantiation of parameters that is most consistent with observable data (Strube and Hahn 1999; Karamanis et al. 2004; Poesio et al.
In previous implementations of entity-based models, classes of coreferent nouns have been extracted manually (Miltsakaki and Kukich 2000; Karamanis et al. 2004; Poesio et al.
It is trained on the MUC (6–7) data sets and yields state-of-the-art performance (70.4 F-measure on MUC-6 and 63.4 on MUC-7).
Similar observations have been made in other work which is closer in spirit to Centering’s claims (Hasler 2004; Karamanis et al. 2004; Poesio et al.
We trained the English-to-Spanish system, and tuned the system on two datasets, the WSMT 2006 Europal test set (TUNE1) and the WSMT news commentary devtest set 2007 (TUNE2).
1831.
Other theory-dependent devices that have been modeled with PATR-II include head-feature percolation (Gazdar and Pullum, 821, and LFG-like semantic forms [Kaplan and Bresnan, 83).
acyclic, projective and connected.
Previous work on memory-based learning for deterministic parsing includes Veenstra and Daelemans   and Nivre et al  .
Thesesettings are the result of extensive experiments partially reported in Nivre et al  .
For more infor mation about the different parameters and settings, see Daelemans et al  .
This is dif ferent from the original IB1 algorithm, as described in Aha et al.
The corre sponding F-measures for our best parser (Model 2, BG) are 99.0% and 94.7%.
Carroll et al., 1998; Lin, 1998).
Kiefer et al., 1999).
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
and Marcu, 2002).
Specifi cally, we generalise the model of Cohn and Lapata   to our abstractive task.
3 Available from http://homepages.inf.ed.ac.uk/ tcohn/paraphrase.
138 1a.
1b.
2a.
2b.
3a.
4a.
4b.
5a.
Cohn and Lapata apply this model to ex tractive compression with state-of-the-art results.
Cohn and Lapata   extract a STSG froma parsed, word-aligned corpus of source and target sentences.
VP VBZ does RB not ne pas VP n ' ne ne peut ...
For the pivot grammarwe use the French-English Europarl v2 which con tains approximately 688K sentences.
Model Parameters Our model was trainedon 480 sentences, 36 sentences were used for de velopment and 59 for testing.
These 142 Models Grammaticality Importance CompR Extract 3.10 ? 2.43 ? 82.5 Abstract 3.38 ? 2.85 ? ?
We also included goldstandard compressions.
Post-hoc Tukey tests revealed that our abstractive model received significantlyhigher ratings than the baseline in terms of impor tance (?
This is not surpris ing: human-authored compressions are more fluentand tend to omit genuinely superfluous informa tion.
In thefirst sentence the system rendered Kurtz the sub ject of hitch-hiked.
More specifically, we use LIBSVM   with a quadratic kernel K(xZ, xj) = (-yxT xj +r)2 and the built-in one-versus-all strategy for multi-class classification.
Te fct tht ter e xponentially Nn-local informaton, such as arity   Howinga strucured clasification problem. obaing high parsng accuracie (Klei evr, in the data-driven parsing setting er, in the data-driven parsing setting rentations over the input (McDonald et There has been much recent work on dependency pay advd by h go pog feu p ur o rr ndndi f h so h ip (cald a, 00) pial nre f n parsing using graph-based, transition-based, and pjeti parsig lgithm f bth lig ad Th goal of hi wok i furthe r urrent hybrid methods; see Nivre and McDonald   inference within the datadrven setting We sart by dtdi of th pttil t f for an overview.
Typcal graph-bsed methods invetigating and xtendng he edge-factored model rojtie prsin lgoiths for bth leaig nd consider liear classifiers of the fom inference of McDonald et al. (2005b) In partic ithin the datadri en ettin where f(x, y) is a vector of features and w s the tion over all possble depndency graphs for a givn correspondingyweight vector.
One wants hw. to g bh pttion io a dge pect haveasmallcexpected loss; the typictlnloss functionnis thereHamming loss,cle(y'; y)n°_  |{hi, jid∈ we sho y0: hi, ji ∈/ y}|.
12, with O(|A |· |V |) variables and constraints.
Buchholz and Marsi, 2006).
300.
Animacy.
1111111111111110111111 Le vmdredi 25 cacao 1996.
40 membres nit de la Seeman:anon oat assisth au stninaiste sr les psalm. exemplars en maniac de reglen.tation qui visait I aida la rnininbto 6.. familiarises avec P.ereglemsitation can.
NINA. de rechange asa progr.unes de rtglanentasion.
L'animanur.
61,.. de wasoonnation. owes la Mance en mkt.
It, aphasia dtIndusthe Caned. pe rune de 'Introduction de nif animus de diversification 496 .6*.. A. an.ation da services comma les coda Yokota= l' snort, lons.tion de l'indastrie. a add que pseud. mochainement un document stu I. divenifirstse des modes de postai. da service qui .intrait de divers suj.. comas les anfmnisnes de premvion de rethange des semi. les phi. aggroprifs que A. problemes ...leafs par Nunn Cada volontalms Us code volontaire un ensemble d'engageme. scernaliffs • ne faisant pas eaplidtanent pink d'un Mgirrio lOgialatif ou rEglementaire - cone0 pom lateen.. faxonnex conneller ou israluer is canpartement de ceux qui la ont pan II.
Istiliminent pax a pnnsuivi 6.9.. GINS analyse thincipal.
.6*.. au Racentariat du Conseil du Treece.
Adroit du gaivemement de Makatea.. n, alma simplanent aux mMiciparas une solution de red.., I). reglemenmtioe p..). gomernernmat Au moment a) Is thglementation f objes true examen adru du public. ks gouvornemerns I lishelle town. van des approchen volonmirsat en ..5,190,14 A. la rigkoausion et mans comae submits i celle-d. les codes volontaires prima40 tin cumin menthe &manages. notanstent sible.2 At this point, if there were too many unmatched tokens, the candidate pair is taken to be prima facie unacceptable and immediately filtered out.
E.g. see the 13-language set of the freely available CMU stochastic language iden
in WORDNET.
4.1 Topics.
Burchardt et al. ), Verbnet (Bobrow et al.) and Propbank (e.g.
Adams et al.).
Delmonte, Bar-Haim et al., Iftene and Balahur-Dobrescu).
Nonconcatenative Finite-State Morphology
By replacing these three letters with other appropriately chosen Perfective Imperfective Participle Active Passive Active I katab kutib aktub II kattab kuttib ukattib III kaatab kuutib ukaatib IV ?aktab ?uktib u?aktib V takattab tukuttib atakattab VI takaatab tukuutib atakaatab VII nkatab nkutib ankatib VIII ktatab ktutib aktatib IX ktabab aktabib X staktab stuktib astaktib XI ktaabab aktaabib XII ktawtab aktawtib XIII ktawwab aktawwib XIV ktanbab aktanbib XV ktanbay aktanbiy Passive maktuub mukattab mukaatab mu?aktab mutakattab mutakaatab munkatab muktatab muktabib mustaktab muktaabib muktawtib muktawwib muktanbib muktanbiy Table I I take it as my task to describe how the members of a paradigm like the one in Table I might be generated and recognized effectively and efficiently, and in such a way as to capture profit from the linguistic generalizations inherent in it.
Towards History-based Grammars: Using Richer Models for Probabil ist ic Parsing* Ezra Black Fred Jelinek John Lafferty David M. Magerman Robert Mercer Salim Roukos IBM T.  J .
Hence, t~ corresponds to the senten- tial form aSB or equivalently to the string rlr2.
iNote the abuse of notat ion since we denote by p(r~) the con- ditional probabil ity of rewriting the non-terminal Ni.
The Treebank uses 17 non-terminal labels and 240 tags.
[N It_PPH1 N] [V indicates_VVZ [Fn [Fn&whether_CSW IN a_AT1 call_NN1 N] [V completed_VVD successfully_RR V]Fn~] or_CC [Fn+ iLCSW IN some_DD error_NN1 N]@ IV was_VBDZ detected_VVN V] @[Fr that_CST [V caused_VVD IN the_AT call_NN1 N] [Ti to_TO fail_VVI Wi]V]Fr]Fn+] Fn]V]._.
The parse base is 1.35 parses/word.
137 2. p( Sem ISyn, Rp, Ip?, Hip, It2p, Synp, Serf+) 3. p( R ISyn, Sere, Rp, Ip?, Hip, H2p, Synp, Sern~ ) 4. p( ul [R, Syn, Sere, Rp, Ipo, Hip, H2p ) 5. p(H2 ]Hi, R, Syn, Sem, Rp, Ip~, Synp) While a different order for these predictions is possible, we only experimented with this one.
Resu l ts We compared the performance of HBG to the "broad- coverage" probabilistic ontext-free grammar, P-CFG.
To check the value of the above detailed history, we tried the simpler model: 1. p(Ht IH~p, H=p, Rp, Ipc) 2. p(H2 IHx, Hxp, H2p, Rp, Ip~) 3. p(Sy  IH1, Rp, I 0) 4. p(sem ISy., H1, Rp, Ipc) 5. p(R ISyn, Sam, H1, H2) This model corresponds to a P-CFG with NTs that are the crude syntax and semantic ategories annotated with the lexical heads.
Baker, J. K., 1975.
Brent, M. R. 1991.
Automatic Acquisition of Subcate- gorization Frames from Untagged Free-text Corpora.
Brill, E., Magerman, D., Marcus, M., and Santorini, B.
Brown, P. F., Della Pietra, V. J., deSouza, P. V., Lai, J. C., and Mercer, R. L. Class-based n-gram Models of Natural Language.
Church, K. 1988.
Gale, W. A. and Church, K. 1990.
Hindle, D. and Rooth, M. 1990.
Jelinek, F. 1985.
Magerman, D. M. and Marcus, M. P. 1991.
In Proceedings of the Febru- ary 1991 DARPA Speech and Natural Language Work- shop.
Derouault, A., and Merialdo, B., 1985.
ICASSP 85 Proceedings.
Sharman, R. A., Jelinek, F., and Mercer, R. 1990.
In Proceed- ings of the June 1990 DARPA Speech and Natural Lan- guage Vv*orkshop.
It tokenizes abbreviations (e.g., "Dr .
Mr. Dooner Is on the prowl for more creative talent and Is Interested In acquiring a hot agency rb rb  nnp NNP vbz In dt  nn  in JJR  jj  nn  cc vbz  jj  In  vim  dt jj  n n rb rb  nnp NNP vbz In dt  nn  in RBR  jj  nn  cc vbz  jj  In  vim  dt jj  n n Table 1 : Tagging a text with the lexicon (line 2) and contextual rules (line 3) .
Note the defaul t lexicon assignment of nnp to "Dooner" and the rule-based correction of "more" .
Tagger throughput is around 3000 words/sec.
Organizationally-headed noun phrases are labeled as org, regardless of whether they are simple proper names or more complex constituents such as th e 145 * * * TOTAL SLOT SCORES * * * +	 +	 + SLOT  POS ACTT COR PAR INCI SPU MIS NONI REC PRE UND OVG ERR SU B +	 +	 + <enamex>938 9911 881 0 01 110 57 01 94 89 6 11 16 0 type 938 9911 775 0 1061 110 57 01 83 78 6 11 26 1 2 text 938 9911 840 0 411 110 57 01 90 85 6 11 20 5 subto 1876 19821 1615 0 1471 220 114 01 86 81 6 11 23 8 +	 +	 + ALL OB 2286 24061 1993 0 1631 250 130 01 87 83 6 10 21  8 MATCHD 2156 21561 1993 0 1631 0 0 01 92 92 0 0 8  8 +	 +	 + P&R  2P&R  P&2R F-MEASURES  84 .95  83 .67  86 .2 8 * * * TASK SUBCATEGORIZATION SCORES * * * +	 +	 + SLOT  POS ACTT COR PAR INC SPU MIS NONI REC PRE UND OVG ERR SUB +	 +	 + Enamex : organi 454 4931 392 0 281 73 34 0I 86 80 7 15 26 7 person 373 3641 292 0 601 12 21 0I 78 80 6 3 24 17 locati 111 1341 91 0 181 25 2 0I 82 68 2 19 33 1 6 Figure4: Performance of rules learned for theENAMEXportion of theNEtask(unofficialscore) org-corpnp apposition above.
Base-level phrases, i .e.
.agency" geo-region(geo-07)  "Hollywood " has-location((org-06, geo-07) hasloc-08)  locational pre-modifier Pressing on, the phraser parses the overall org-orgnp apposition as an overarching org .
title(ttl-11)  "chairman" title(ttl-12)  "CEO" group((ttl-11, ttl-12) grp-13)  "chairman and CEO" retired-ttl(grp-13)  "retired " To shift the scope of "retired" from the overall coordination to individual titles, the following rule applies .
person(pers-20)  "Mr. James" title(ttl-21)  ; "chairman " organization(org-22)  "McCann " job-out((pers-20, ttl-21, org-22) j-o-23) person(pers-24)  "Mr. Dooner" successor((pers-24) succ-25 ) One approach to contextualizing the succession clause in this text would require first resolving th e pronominal subject "He" to "Mr. James" and then exploiting any job change facts that held about thi s antecedent.
A organization 86 92 84 92 -2 ?
name 76 78 77 80 +1 +2 alias 60 79 56 78 -4* - 1 descriptor 27 62 16 49 -11 * -13* type 83 90 81 89 -2 - 1 locale 46 87 43 87 -3 ?
country 47 88 45 93 -2 +5 person 94 92 95 87 +1 -5 * name 93 91 93 84 ?
These are all due in this case to missing locational an d 15 2 Nature of the problem Problem cases Resulting errors Naive string matching "McCann " vs. "McCann-Erickson " 9 inc type "John Dooner" vs. "John J .
Dooner Jr." 1 inc text, 1 spu type/text Missing phraser patterns t "Fallon McElligott" ?
naive ` s prorpssing 1 spu type/text Poor phraser patterns t "Coca-Cola Classic" ?
zealous org rule 1 spu type/text Missing date patterns t " the 21st century" 1 mis type/text Ambiguous name "New York Times" ?
embarrassing bugs "James" in <HL> ?
punctoker lost "J ."
alias "McCann" all treated as person "John Dooner" treated as two persons 2 spu pets, 1 mis pers.
NP patternst " the agency with billings of $400 million " 2 mis org .
locale/country Org.
org type Acronym resolution snafu "CAA" vs. "Creative Artists Agency" 1 inc org .
namett , 1 mis org .
namett "Fallon McElligott" (inc .
Errare humanum est.
iationfor Computational Linguistics (ACL-89) .
"FASTUS: A finite-state processor for infor - mation extraction from real-world text".
In Proceedings of the 13th Intl.
Chambery,1993 .
& Vilain, M. "The relation-based knowledge representation of King Kong" .
"Ontological promiscuity" .
Chicago, Ill., 1985.
In Proceedings of the 24th Intl.
Argamon et at.
In recent work Daelemans et at.
For more references and information about these algorithms we refer to (Daelemans et al., 1998; Daelemans et al., 1999b).
NP-SBJ for subject, NP-PRD for predicative object, NP for (in)direct object3, PP-LOC for locative PP adjunct, PP-LOC-CLR for subcategorised locative PP, etcetera.
Features 6-8, 9-11 and 17-19 describe the context words/chunks, Features 12-16 the focus chunk.
PPs yield another 1.1%.
3.7% for locatives and temporals.
American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 173 of tions are possible in rules EC.1 - EC.3 and EI.1 EI.3.
The implementation in Brachman et al [1980] does just that.
If (vi, vj, wij)EE implies (vj, vi, wij)EE, then the graph is undirected.
This was conducted for two unweighted SW-graphs with 1,000 (1K) and 10,000 (10K) nodes, M=5 and a weighted 7-lingual co-occurrence graph (cf. section 4.1) with 22,805 nodes and 232,875 edges.
Biemann et al. 2004).
First, let us define svo (shorter version of) to be: r1 svo r2 iff the righthand side of r1 is a subsequence of the righthand side of r2.
P(NP → DT JJ NN  |NP → DT JJ NN) = 1.
P(NP → DT JJNN  |NP → DT NN) = 3/7.
Finally, P(NP → DT NN  |NP → DT NN) = 4/7.
PRINCIPAR - An Efficient Broad-Coverage Principle-Based Parser
We present an efI\]cient, broad-coverage, principle-based parser for English.
Prin- ciples are constraints over X-bar structures.
The links in the net- work re.present relationships bel;ween the cat- egories.
': '....".v.v.v.v.v.v.v; . ..............
is a donxhia.nce l ink frolil node (v i.o /7 i f /7 cfl, ll })e imme.dia.tely doininal~ed by O& l.'~Ol ' CXi/dl lp lc, SillCC a.IX Nl)a.r l i i&y i lt l- media?cly dominate a. PP adjimct,, t;here is a dominance link from Nbar to pp.
'l.'he nodes ill the nel, wor\]( are compul, ing agents t;lxi~t com- nulnica.t.e wil;h e;~ch oi l ier 1)y sending messa,ges in tile rcv(HJso direcl, ion of the links ilx the.
net- work.
I'\]acll node ha.s a. local n lemory tlxa.t, sDol'es a. set of it;ellx.~.
The source i~lessa,ges represent inlinedi~te constituctlLs o\[ the reel; node.
li',a.ch node in l, he grannil lu: net- work has a. conll) letion I)redicate tllal, deter- tllillCS whether a.n ilieln a.t l;lie node.
is "coin- plete," ilx w i lM i ca.se the it;elXl is sent a.s a, ines- sltge 1;o el;tier l l()dOS i l l 1~110 \]X}VOI'SC direct ion of the links.
~Vilen a, node receives mi itcnl> il; adiLel31pts {o (:onll)ine the itenl w i th il;ems \['rein other nodes 1,o forln Hew il;enis.
t i ieir a.tl, r ibute vMues At mid A~ a.re t lHifli~ble..
3.1.
Bound ing rpheory.
An attribute named ~hbarr?0r is used to imple- ment this l)rinciple.
3.2.
Theory reqlfires tha.t every lexicM NP be assigned an al)stl'act case.
Therei'ore, a case-filter vi- olation is detected if +govern -cm - ca co- occur in an item.
'\]'he -cm attril)ute is cleared.
Lex icon.
4.2.
Reference Entr ies.
For example, when the lc'xieal retriever fails to find an entry for "studies," it searches the lexicon for "studie," "studi" and "study."
IIowever, the snb- catgorization frames of "begin" are not listed again under "began."
/II~ /I L bigwe!ght L ', John John V /~; NP'~/N p /~N~, about Kim read a/ ~b~r read /NP.
Example 5.2.
I rnp lementat ion and Exper imenta l Ftesult;s PRINCII~AR lms been implemented in C-I--I ~.
- - . , I words \[ tmte* p~trses :10 - 11 0.76 i3 0.60 t4 13 0.55 4 \]3 0.51 6 19 O.80 2 26 4.13 32 of the grammar (measure by the number of the total length of the phrase structure rules).
Acknowledgements The author wishes to thanl?
Sure-fire rules rely on known corporate designators (Ltd., Inc., etc.
Jelisic?
Jelisic?
threatning?
Jelisic?
Other poten tially useful classes might be created by associatingwith each noun or verb a set of hypernyms corre sponding to their synsets in WordNet.
To each lex 1URL:http://www.csie.ntu.edu.tw/?cjlin/libsvm/ 2URL: http://opennlp.sourceforge.net 728 ical item corresponds a set of syntactic categories specifying its valency and the directionality of itsarguments.
and ?sta tions?
3URL:http://www.ircs.upenn.edu/?juliahr/Parser/ f a wf wa NP/NP 1 ?several?
and ?sta tions?)
5.2 Extracting dependencies using a CFG.
There have been several approaches to automatically discovering lexico-semantic information from text (Hearst 1992; Riloff and Shepherd 1997; Riloff and Jones 1999; Berland and Charniak 1999; Pantel and Lin 2002; Fleischman et al. 2003; Girju et al.
The result was 159,000 hyponym relationships.
We compared our system with the concepts in WordNet and Fleischman et al. 's instance/concept relations (Fleischman et al.
Arguably the most widely used is the mutual information (Hindle, 1990; Church and Hanks, 1990; Dagan et al., 1995; Luk, 1995; D. Lin, 1998a).
IRI9712068.
The CoNLL dataset contains some nonprojective constructions.
Sagae and Lavie (2006b) extend this model to alternate between left-to-right and right-to-left passes.
Indeed, a simple combination scheme of graph-based, left-to-right and non-directional parsers yields state-of-the-art results on English dependency parsing on the CoNLL 2007 dataset.
Recently, Bergsma et. al.
Additionally, unlike LDA-SP Bergsma et al.’s system doesn’t produce human-interpretable topics.
In all experiments we use hyperparameters α = 771 = 772 = 0.1.
LDA-SP, which uses LinkLDA, substantially outperforms both IndependentLDA and JointLDA.
This application of selectional preferences was introduced by Pantel et. al.
Following Pantel et al.   we randomly sampled 100 inference rules.
Each system’s translation was displayed an average of 5 reference 0.94 google.fr-en 0.85 google.de-en 0.80 rbmt5.de-en 0.77 geneva.de-en 0.63 jhu-tromble.de-en 0.50 times per article.
Charniak et al.   introduces best-first parsing, in which a figure-ofmerit prioritizes agenda processing.
Charniak et al.   pre-parse with a sequence of grammars which are coarser than (parentannotated) treebank grammars.
The method for sampling derivations of a PCFG is given in Finkel et al.   and Johnson et al.
2 using the parser of Petrov et al.  .
In contrast, automatically learned grammars like the one of Matsuzaki et al.   and Petrov et al.
Each majornode connects to several-subnodes .
A-subnode is then connected to -subnodes .
The arc weights between-subnodes and major-nodes are always 1.0. .
Two-Level Many-Paths Generation
SemEval-2007 Task-17: English Lexical Sample SRL and All Words
2.1 English fine-grained All-Words.
2.2 OntoNotes English Lexical Sample WSD.
01, 22, 23 and 24.
2 Hwee Tou Ng <nght@comp.nus.edu.sg> NUS-PT SVM 58.7?4.5.
3 Rada Mihalcea <rada@cs.unt.edu> UNT-Yahoo Memory-based 58.3?4.5.
4 Cai Junfu <caijunfu@gmail.com> NUS-ML naive Bayes 57.6?4.5.
5 Oier Lopez de Lacalle <jibloleo@si.ehu.es> UBC-ALM kNN 54.4?4.5.
6 David Martinez <davidm@csse.unimelb.edu.au> UBC-UMB-2 kNN 54.0?4.5.
7 Jonathan Chang <jcone@princeton.edu> PU-BCD Exponential Model 53.9?4.5.
8 Radu ION <radu@racai.ro> RACAI Unsupervised 52.7?4.5.
9 Most Frequent WordNet Sense Baseline N/A 51.4?4.5.
10 Davide Buscaldi <dbuscaldi@dsic.upv.es> UPV-WSD Unsupervised 46.9?4.5.
11 Sudip Kumar Naskar <sudip.naskar@gmail.com> JU-SKNSB Unsupervised 40.2?4.5.
12 David Martinez <davidm@csse.unimelb.edu.au> UBC-UMB-1 Unsupervised 39.9?4.5.
14 Rafael Berlanga <berlanga@uji.es> tkb-uo Unsupervised 32.5?4.5.
15 Jordan Boyd-Graber <jbg@princeton.edu> PUTOP Unsupervised 13.2?4.5.
Rank Participant System Classifier F 1 Cai Junfu <caijunfu@gmail.com> NUS-ML SVM 88.7?1.2.
2 Oier Lopez de Lacalle <jibloleo@si.ehu.es> UBC-ALM SVD+kNN 86.9?1.2.
5 Lucia Specia <lspecia@gmail.com> USP-IBM-1 ILP 85.1?1.2.
5 Deniz Yuret <dyuret@ku.edu.tr> KU Semi-supervised 85.1?1.2.
6 Saarikoski <harri.saarikoski@helsinki.fi> OE naive Bayes, SVM 83.8?1.2.
8 Ana Zelaia <ana.zelaia@ehu.es> UBC-ZAS SVD+kNN 79.9?1.2.
9 Carlo Strapparava <strappa@itc.it> ITC-irst SVM 79.6?1.2.
10 Most frequent sense in training Baseline N/A 78.0?1.2.
11 Toby Hawker <toby@it.usyd.edu.au> USYD SVM 74.3?1.2.
12 Siddharth Patwardhan <sidd@cs.utah.edu> UMND1 Unsupervised 53.8?1.2.
13 Saif Mohammad <smm@cs.toronto.edu> Tor Unsupervised 52.1?1.2.
- Toby Hawker <toby@it.usyd.edu.au> USYD?
SVM 89.1?1.2 - Carlo Strapparava <strappa@itc.it> ITC?
In con trast, the use of a shared set of role labels, such System Type Precision Recall F UBC-UPC Open 84.51 82.24 83.36?0.5 UBC-UPC Closed 85.04 82.07 83.52?0.5 RTV Closed 81.82 70.37 75.66?0.6 Without ?say?
3.1 Data.
3.2 Results.
91 System Type Precision Recall F UBC-UPC Open 85.31 82.08 83.66?0.5 UBC-UPC Closed 85.31 82.08 83.66?0.5 RTV Closed 81.58 70.16 75.44?0.6 Without ?say?
3.3 Discussion.
Martin et al.  .
These elements are defined as propositions in a property-inheritance network of the usual kind written in NIKL aSchmolze dc Lipkis 831, [Kaczmarek et al. 861), a descendant of KL.. ONE Prachman 78D.
McCallum and Wellner   report 73.4 F1 on the formal MUC-6 test set, which is reasonably close to our best MUC-6 number of 70.3 F1.
Denis and Baldridge   report 67.1 F1 and 69.2 F1 on the English NWIRE and BNEWS respectively using true mention boundaries.
Eq.
Inside-Outside Reestimation From Partially Bracketed Corpora
K. Lan i and S. J.
1990.
Speech and Lan- K. Lan i and S. J.
1991.
1990.
Yves Schabes.
1992.
Stochastic lexicalized treegrammars.
In 92.
Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 34?35, Vancouver, October 2005.
?, Yejin Choi?, Claire Cardie?, Ellen Riloff?, Siddharth Patwardhan?
is di- rectly described.
A high-precision, rule-based clas- sifier is used to identify these expressions.
3The MPQA Opinion Corpus can be freely obtained at http://nrrc.mitre.org/NRRC/publications.htm.
References Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan.
In HLT/EMNLP 2005.
Three generative, lexicalised models for sta- tistical parsing.
J. Lafferty, A. McCallum, and F. Pereira.
E. Riloff and W. Phillips.
E. Riloff and J. Wiebe.
E. Riloff, J. Wiebe, and W. Phillips.
Artificial Intelligence, 85:101?134.
R. E. Schapire and Y.
Machine Learning, 39(2/3):135?168.
J. Wiebe and E. Riloff.
In CICLing- 2005.
T. Wilson, J. Wiebe, and P. Hoffmann.
In HLT/EMNLP 2005.
F. Xia and M. Palmer.
GTM10, 20, and 30 are GTM with exponents of 1.0, 2.0, and 3.0 respectively.
Method Pearson 95%L 95%U Pearson 95%L 95%U BLEU1 0.86 0.83 0.89 0.81 0.75 0.86 BLEU4 0.77 0.72 0.81 0.86 0.81 0.90 BLEU12 0.66 0.60 0.72 0.87 0.76 0.93 NIST 0.89 0.86 0.92 0.81 0.75 0.87 WER 0.47 0.41 0.53 0.69 0.62 0.75 PER 0.67 0.62 0.72 0.79 0.74 0.85 GTM10 0.82 0.79 0.85 0.73 0.66 0.79 GTM20 0.77 0.73 0.81 0.86 0.81 0.90 GTM30 0.74 0.70 0.78 0.87 0.81 0.91 Adequacy Fluency Table 1.
3.1 ROUGE-L: Longest Common Sub-.
We call the LCS based F-measure, i.e. Equation 3, ROUGE-L.
Therefore S2 is better than S3 according to ROUGE-L.
3.2 ROUGE-W: Weighted Longest Common.
for each non-consecutive n-gram sequences.
3.3 ROUGE-S: Skip-Bigram Co-Occurrence.
We call the skip-bigram based F-measure, i.e. Equation 9, ROUGE-S.
Therefore, S2 is better than S3 and S4, and S4 is better than S3.
Comparing skip-bigram with LCS, skip-bigram counts all in-order matching word pairs while LCS only counts one longest common subsequence.
ROUGE-L.
ROUGE-W with weight ranging from 1.1.
to 2.0 with increment of 0.1
To assess the reliability of the results, 95% confidence intervals (95%-CI-L for lower bound and CI-U for upper bound) of average rank of the oracles are Method ORANGE Avg Rank 95%-CI-L 95%-CI-U BLEUS1 35.39% 363 337 387 BLEUS2 25.51% 261 239 283 BLEUS3 23.74% 243 221 267 BLEUS4 23.13% 237 215 258 BLEUS5 23.13% 237 215 260 BLEUS6 22.91% 235 211 257 BLEUS7 22.98% 236 213 258 BLEUS8 23.20% 238 214 261 BLEUS9 23.56% 241 218 265 Table 2.
Method Pearson 95%L 95%U Pearson 95%L 95%U BLEUS1 0.87 0.84 0.90 0.83 0.77 0.88 BLEUS2 0.84 0.81 0.87 0.85 0.80 0.90 BLEUS3 0.80 0.76 0.84 0.87 0.82 0.91 BLEUS4 0.76 0.72 0.80 0.88 0.83 0.92 BLEUS5 0.73 0.69 0.78 0.88 0.83 0.91 BLEUS6 0.70 0.65 0.75 0.87 0.82 0.91 BLEUS7 0.65 0.60 0.70 0.85 0.80 0.89 BLEUS8 0.58 0.52 0.64 0.82 0.76 0.86 BLEUS9 0.50 0.44 0.57 0.76 0.70 0.82 Adequacy Fluency Table 3.
Method ORANGE Avg Rank 95%-CI-L 95%-CI-U ROUGE-L 20.56% 211 190 234 ROUGE-W-1.1 20.45% 210 189 232 ROUGE-W-1.2 20.47% 210 186 230 ROUGE-W-1.3 20.69% 212 188 234 ROUGE-W-1.4 20.91% 214 191 238 ROUGE-W-1.5 21.17% 217 196 241 ROUGE-W-1.6 21.47% 220 199 242 ROUGE-W-1.7 21.72% 223 200 245 ROUGE-W-1.8 21.88% 224 204 246 ROUGE-W-1.9 22.04% 226 203 249 ROUGE-W-2.0 22.25% 228 206 250 Table 4.
ORANGE scores for ROUGE-L and ROUGE-W-1.1 to 2.0.
Method ORANGE Avg Rank 95%-CI-L 95%-CI-U ROUGE-S0 25.15% 258 234 280 ROUGE-S1 22.44% 230 209 253 ROUGE-S2 20.38% 209 186 231 ROUGE-S3 19.81% 203 183 226 ROUGE-S4 19.66% 202 177 224 ROUGE-S5 19.95% 204 184 226 ROUGE-S6 20.32% 208 187 230 ROUGE-S7 20.77% 213 191 236 ROUGE-S8 21.42% 220 198 242 ROUGE-S9 21.92% 225 204 247 ROUGE-S* 27.43% 281 259 304 Table 5.
estimated using bootstrap resampling (Davison and Hinkley).
By examining the rank position of the Method ORANGE Avg Rank 95%-CI-L 95%-CI-U BLEUS6 22.91% 235 211 257 NIST 29.70% 304 280 328 PER 36.84% 378 350 403 WER 23.90% 245 222 268 ROUGE-L 20.56% 211 190 234 ROUGE-W-1.1 20.45% 210 189 232 ROUGE-S4 19.66% 202 177 224 Table 6.
Method ORANGE Avg Rank 95%-CI-L 95%-CI-U BLEUS4 18.27% 2993 2607 3474 PER 28.95% 4744 4245 5292 WER 19.36% 3172 2748 3639 ROUGE-L 16.22% 2657 2259 3072 ROUGE-W-1.2 15.87% 2600 2216 2989 ROUGE-S4 14.92% 2444 2028 2860 Table 7.
Reranking And Self-Training For Parser Adaptation
Finally, the 1-best parses after reranking are combined with the WSJ training set to retrain the firststage parser.1 McClosky et al.   find that the self-trained models help considerably when parsing WSJ.
Bacchiani et al.   applies self-training to parser adaptation to utilize unlabeled in-domain data.
The reranking parser used the WSJ-trained reranker model.
The WSJ+NANC parser with the WSJ reranker comes close to the BROWN-trained reranking parser.
This research was partly funded by ARO grant W911NF-08-10242, DARPA contracts FA8750-05-2-0283, FA8750-07-D0185, HR0011-06-C-0025, HR0011-07-C-0060 and NBCHD030010, NSF grants IIS-0534881 and IIS-0803481, and ONR grant N00014-08-1-0670.
SARG0, SARG1 and SARGM.
Katz, S. M.  .
ASSP-35 No.
Kuhn, R., and De Mori, R.  .
Our initial test had 3 inflectional endings (-ed, -s, -ing), and 32 derivational endings (including -ion, -al, -ive, -1y).
Alanine), and Altered-State (e.g.
A- T point mutation at base pair 47, A48- G or t(11;14)(q13;32)).
Then, the maximum likelihood estimate of fiii is 11-7-71.:+ , where n++ = Eii nii = 504.
Chinese word segmentation is a difficult, im portant and widely-studied sequence modelingproblem.
State-of-the-art perfor mance is obtained.
For example,the N-gram generative language modeling based ap proach of Teahan et al  does not use domainknowledge.
2.1 Regularization in CRFs.
First-order+transitions: Here we add parame-.
respec tively).
This is mostnotorious in CTB dataset.
12.
About 3,600 toplevel markables are extracted from the 30 MUC-6 test documents by our system.
5.1.1 Prenominal Modifier String Match.
Experimental comparisons of different methods on various benchmark problems have generally found relatively small differences in predictive accuracy (Mooney, Shavlik, Towell, & Gove, 1989; Fisher 86 McKusick, 1989; Weiss 86 Kapouleas, 1989; Atlas, Cole, Conner, El-Sharkawi, Marks, Muthusamy, & Bernard, 1990; Dietterich, Hild, & Bakiri, 1990; Kulikowski & Weiss, 1991; Shavlik, Mooney, 86 Towell, 1991; Holte, 1993).
Most rule-based methods, e.g.
They are called PFoiL-DNF, PFOIL-CNF, and PFoiL-DLisT.
99
IIS-0535297.
2-subsequential transducer 73, obtained by composition of 71 and 12.
2.4.3 Syntax.
Finite-state machines are also currently used to represent local syntactic constraints (Silberztein 1993; Roche 1993; Karlsson et al. 1995; Mohri 1994d).
String-toweight transducers clearly realize functions mapping E* to 12.±.
Assume that luvl > 21(2112 — 1 with Ivl > 0.
31 (Figure 15) represents a subsequential string-to-weight transducer.
Minimal transducer 61 obtained from 71 by automata minimization.
W2 admits 38 states and 51 transitions.
Subsequential power series S nonbisubsequential.
Not all subsequential transducers are bisubsequential.
Therefore: Vj E [O. k], C11 = C21 and S2 =- S1.
The application of determinization to 02 results in 03 (Figure 24).
Better K-Best Parsing
lexicalized PCFG model, and on Chiang?s CFG-based decoder for hierarchicalphrase-based translation.
objectivefunctions jointly.
Gildea and Juraf sky   described an O(k2)-overhead extension for the CKY algorithm and reimplemented Collins?
Third, we have implementedour algorithms on top of state-of-the-art, large-scale sta tistical parser/decoders and report extensive experimentalresults while Jime?nez and Marzal?s was tested on rela tively small grammars.
For hypergraphs, Gallo et al   study the shortest hyperpath problemand Nielsen et al   extend it to k shortest hyper path.
In practice, |E| usually dom inates, as in CKY parsing of CFG.
5.1 Experiment 1: Bikel Parser.
59 1.5 2.5 3.5 4.5 5.5 6.5 7.5 1 10 100 1000 10000 Av er ag e Pa rs in g Ti m e (se co nd s) k Algorithm 0 Algorithm 1 Algorithm 3 (a) Average parsing speed (Algs.
0 vs. 1 vs. 3, log-log) 1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2 4 8 16 32 64 Av er ag e He ap S ize k JM Algorithm with 10-5 beam Algorithm 3 with 10-5 beam JM Algorithm with 10-4 beam Algorithm 3 with 10-4 beam (b) Average heap size (Alg.
Average time (both exclud ing initial 1-best phase) vs. k (log-log).
Our second experiment was on a CKY-based decoderfor a machine translation system  , imple mented in Python 2.4 accelerated with Psyco 1.3  .
lexicalized PCFGmodel   and Chiang?s syn chronous CFG based decoder   for machine translation.
Our thanksalso go to Dan Gildea, Jonathan Graehl, Julia Hock enmaier, Aravind Joshi, Kevin Knight, Daniel Marcu,Mitch Marcus, Ryan McDonald, Fernando Pereira, Gior gio Satta, Libin Shen, and Hao Zhang.
SIMR has produced bitext maps for over 200 megabytes of French-English bitexts.
SIMR has produced bitext maps for over 200 megabytes of French-English bitexts.
Bitext maps are injective (1-to-1) partial functions in bitext spaces.
The Spanish/English and Korean/English bitexts were hand-aligned when SIMR was being ported to these language pairs.6 The Spanish/English bitexts were drawn from the Sun Solaris AnswerBooks and hand-aligned by Philip Resnik.
The Korean/ English bitexts were provided by MIT's Lincoln Laboratories and hand-aligned by Young-Suk Lee.
Table 3 shows that SIMR's performance on Spanish/English and Korean/English bitexts is no worse than its performance on French/English bitexts.
Whenever the length-based algorithm prefers a more fine-grained alignment, its judgement overrules SIMR's.
Here, C(vq, vr) might return α1 if vq = vr, and α2 if vq and vr are in the same category, where α1 > α2 > 0.
Typed Unification Grammars Martin C. Emele, Dhni Zajac Project Polygloss* University of Stuttgart IMS~CL/Ifl~AIS, Keplerstrage 17, D - 7000 Stuttgart 1, Federal Republic of Germany {emele,zajac} @is.informatik.uni-st ut gart.dbp.de Abstract We introduce TFS, a computer formal- ism in the class of logic ibrmaiisms which integrates a powerful type system.
Authors describe these extensions as "inheritance grammars", "in- heritance networks", :Ii;ature sorts", "typed t~ature structures",...[1, 3, 5, 13, 17, 15, 9, 11, 7, 8].
Take for exam- ple the rule "noun_phrase(Num, np(Det, Noun)) determiner(Num, Det), noun(Num, Noun)".
The set of well-formed partial syntactic struc- tures, i.e.
TV ---- LIKE V LOVE.
DETERMINER --= LEXICAL_RULE[c-sTm DET].
NAME = LEXICAL-RULE[C-STm PN].
The subtypes PHttASAL.SIGN and LEXICAL-SIGN inherit all the attributes and type re- strictions of SIGN.
(5) phrasal-sign----(HEAD_FP A SUBCAT-FP A ... A (CH_CO_FP V HC*.CO-FP ...)) A LCOMP- DTI~S: LIST_OF_SIGNSJ (6) lexical_sign ----VERB V PNOUN V NOUN V DET V .
The "Complement Head Constituent Order Fea- ture Principle" (9) simply states that a "saturated phrasal sign" (i.e.
(13) HC*-CO-FP -~ [F: igeaa-pnonl " APPEND |B: Icomp-phonl [w. ~ ORDER-COMPL I ~:oM:S: ~ hon,] Lw : [comp-pnonl j 296 (10) SGNI},,o,:{"M,~F "likes" "all" "men")].
We would like to thank Dr. Akira Kure- matsu, president of ATIL Interpreting Telephony Research Laboratories for making our stay possi- ble, and Mr. Teruaki Aizawa, head of the Natural Language Understanding Department for his con- stant support.
We owe many clarifications to Son- dra Ahlen with whom we had many lively discus- sions.
1983 [2] Itassan Ait-Kaci: "An Algebraic Semantics Ap- proach to the effective I{esolution of Type Equa- tions."
45, p. 293-351.
1986 [3] tlassan Ait-Kaci, Patrick Lincoln: LIFE: a nat- ural language for natural anguage, MCC Tech- nical Report ACA-ST-074~88.
Arnold, S. Krauwer, M. Rosner, L. des Tornbes, G.B.
[5] lfdl~ne Bestougeff, G~rard Ligozat: "Parame- terized abstract objects for linguistic informa- tion processing", 2nd European A CL Confer- ence, Geneva.
[7] Martin Emele, R~mi Zajae: "RETIF: A Rewrit- ing System for Typed Feature Structures", (Ky- oto) 1989, [ATR Technical Report TR-I-0071] [8] Martin Emele, ~mi  Zajac: "Multiple Inheri- tance in RETIF", (Kyoto) 1989, [ATR Techni- cal Report TR-I-0114] 297 [9] [lO] [11] [12] [13] Roger Evans , Gerald Gazdar: "Inference in DATR", in: 4th European ACL Conference, Manchester.
Jens E. Fenstad, Per-Kristian Halvorsen, Tore Langholm, Johan van Benthem: Situation, lan- guage, and logic, 1987,(Dordrecht: Reidel) Marc Moens, Jo Calder, Ewan Klein, Mike Reape, ttenk Zeevat: "Expressing generaliza- tions in unification-based formalisms", in: 4th European A CL Conference, 1989, (Manchester) Fernando C.N.
Pereira, David H.D.
War- ren: "Definite Clause Grammars for Language Analysis-A Survey of the Formalism and a Com- parison with Augmented Transition Networks", in: Artificial Intelligence 13: 231-278.
CSLI, Lectures Notes Number 13, Chicago University Press, 1987 [15] Carl Pollard: "Sorts in unification-based gram- mar and what they mean", To appear in M. Pinkal and B. Gregor (eds.
[17] Gert Smolka: A feature logic with subsorts, LILOG report 33, IBM Deutschland, Stuttgart, 1987.
[18] R4mi Zajac: "A Transfer Model Using a Typed Feature Structure Rewriting System with In- heritance.
2b.
An n-gram is a sequence of n adjacent words appearing in r1 ... ri−10ri+1 ... rm.
Once the classifier3 for wj is trained, we apply it to the context r1 ... ri−1❑ri+1 ... rm.
Although crossvalidation is needed to avoid overlearning, ML-DOP outperforms DOP1 on the OVIS corpus  .
U-DOP extends DOP1 to unsupervised parsing  .
Instead, UDOP's all-subtrees approach captures both contiguous and non-contiguous lexical dependencies.
These subtrees show that U-DOP takes into account both contiguous and non-contiguous substrings.
ML-DOP reestimates DOP's subtree probabilities in an iterative way until the changes become negligible.
Prescher et al. 2004).
The resulting subtrees are then given to MLDOP's reestimation procedure.
Manning and Schütze 1999: 401).
But the most surprising result is that UML-DOP's fscore is higher than the supervised binarized treebank PCFG (ML-PCFG) for both WSJ10 and WSJ40.
To be sure, the unbinarized version of the treebank PCFG obtains 89.0% average f-score on WSJ10 and 72.3% average f-score on WSJ40.
UML-DOP's performance still remains behind that of supervised (binarized) DOP parsers, such as DOP1, which achieved 81.9% average fscore on the 10 WSJ40 splits, and ML-DOP, which performed slightly better with 82.1% average fscore.
And if DOP1 and ML-DOP are not binarized, their average f-scores are respectively 90.1% and 90.5% on WSJ40.
McClosky et al. 2006).
A Tree Sequence Alignment-based Tree-to-Tree Translation Model
Huang et al.   study a TSG-based tree-to-string alignment model.
Liu et al.   propose a tree-to-string model.
Zhang et al. (2007b) present a STSG-based tree-to-tree translation model.
Xiong et al.   propose a MaxEnt-based reordering model for BTG   while Setiawan et al.
The evaluation metric is case-sensitive BLEU-4  .
4.1.3 Segmentation.
19.
50.
65.
Restrictive Postmodification.
Nonrestrictive postmodification.
Restrictive Prernodification.
4.2.3 Appositions.
4.4.1 Bridging Descriptions and WordNet.
This so-called named entity recognition task has received considerable attention recently (Mani and MacMillan 1996; McDonald 1996; Paik et al. 1996; Bikel et al.
Mr. Morishita.
5.2.3 Premodifiers.
5.2.5 Errors in Anaphora Resolution.
30.
The petite, 29-year-old Ms. Johnson .
Restrictive premodification.
Restrictive postmodification.
The petite, 29-year-old Ms. Johnson .
The system incorrectly resolved 77 definite descriptions: 19 anaphoric definites and 58 discoursenew.
Vieira and Poesio Processing Definite Descriptions Sidner's Theory of Definite Anaphora Cornprehension.
Carter's Shallow Processing Anaphor Resolver.
The test dataset produces 740 cloze tests (69 narratives with 740 events).
Previous approaches, e.g.,   and (Koo et al.
K-Means is an embarrassingly parallelizable algorithm.
To create 3000 clusters among 20 million phrases using 3-word windows, each KMeans iteration takes about 20 minutes on 1000 CPUs.
2004, Koo, et. al.
4:11 Yuusyoku ni syootaisi-ta no-desu.
23.
The case of Cb-shift is a subcase of Cb-establishment.15 Ambiguous multi-pronouns.
The unmarked Ident is the SUBJECT, but some verbs have nonSUBJECT Ident For instance, among giving/receiving verbs, ageru 'give' and morau 'receive' have SUBJECT 'dent while kureru 'give' has OBJECT2 Ident,I8 and for going/coming verbs, &a 'go' has SUBJECT Ident while kuru 'come' has nonSUBJECT Ident.
I have also greatly profited from discussions with Aravind Joshi and comments on an earlier version by N. Abe, M. Papalaskari, R. Rubinoff, J. Smudski, and
This paper has benefited from the comments of Graeme Hirst, Jan Pedersen, Penni Sibun, and Jeff Siskind.
The best F-measure was 82 in the PER-GPE domain, 77 in the COM-COM domain.
We got 34 ing the threshold of cosine similari ty in complete linkage clustering for the PERSON-GPE domain ty in complete linkage clustering for the COMPANY-COMPANY domain PER-GPE clusters and 15 COM-COM clusters.
We got 80 F-measure in the PER-GPE domain and 75 Fmeasure in the COM-COM domain.
 , Liu et al  ).
The relation classifier is modeled using Markov order-0 CRFs(Lafferty 2Wiebe et al   reports human annotation agreement for opinion expression as 82.0 by F1 measure.
For details, see Choi et al  .
semantic class: xi?s semantic class.9 WordNet: the WordNet hypernym of xi.10
6Using GATE: http://gate.ac.uk/ 7Provided by Rebecca Hwa, based on the Collins parser: ftp://ftp.cis.upenn.edu/pub/mcollins/PARSER.tar.gz 8https://rrc.mitre.org/pubs/mpqaFinalReport.pdf 9Using SUNDANCE: (http://www.cs.utah.edu/r?iloff/ publications.html#sundance) 10http://wordnet.princeton.edu/tity overlaps with a correct opinion or source en tity per the gold standard.
E1 and E2 can be contiguous.
Values of d decrease as 4/4, 4/5, 4/6, 4/7....
NEAREST-1 performs the best in overlap-match F-measure, reaching 59.9.
[E1:srl-arg] [E2:srl-arg], where Ei:srl-arg indi cates the SRL argument type of entity Ei.
Excluding them from thegold standard, the performance of our final sys tem ILP+SRL-f -10 is 72.6% in recall, 72.4% in precision, and 72.5 in F-measure.
TEAM —* our and UNUM —* 4.
I. D. Melamed.
2004.
This work was partially supported by NSF ITR IIS-09325646 and NSF ITR IIS-0428020.
Word Sense Disambiguation using Conceptual Density Eneko Agirre* Lengoaia eta Sistema Informatikoak saila.
Euskal Herriko Universitatea.
649, 200800 Donostia.
jibagbee@si.heu.es German Rigau** Departament de Llenguatges i Sistemes Informhtics.
Universitat Polit~cnica de Catalunya.
Pau Gargallo 5, 08028 Barcelona.
g.rigau@lsi.upc.es Abst ract .
92], [Wilks et al.
93] with LDOCE, [Yarowsky 92] with Rogets International Thesaurus, and [Sussna 93], [Voorhees 9311, [Richardson etal.
94], [Resnik 95] with WordNet.
**German Rigau was supported by a grant from the Ministerio de Educaci6n y Ciencia.
1Semcor comprises approximately 250,000 words.
W W0~d to be disarlJ0iguated: W Context words: wl w2 w3 w4 ...
4 The  Exper iments 4.1 The texts We selected four texts from SemCor at random: br- a01 (where a stands for gender "Press: Reportage"), br-b20 (b for "Press: Editorial"), br-j09 (j means "Learned: Science") and br-r05 (r for "Humour").
text words nouns nouns monosemous in WN br-a01 2079 564 464 149 (32%) br-ab20 2153 453 377 128 (34%) br-.i09 2495 620 586 205 (34%) br-r05 2407 457 431 120 (27%) total 9134 2094 1858 602 (32%) Table 1 : data for each text An average of 11% of all nouns in these four texts were not found in WordNet.
meronymy does  not  improve per fo rmance  as expected.
g lobal  nhyp  is as good as local  nhyp.
The average number of hypouyms or nhyp (c.f.
3_9 80- 70 6O - 50- 40- Coverage:  ~ semantic density .
93] and [Yarowsky 9211.
Sussna disambiguates everal documents from a public corpus using WordNet.
Conceptual Density "/Initial mutual constraint size is 10 and window sizeis 41.
We woukl also like to thank Xabier Arregi, Jose mari Arriola, Xabier Artola, Arantza Dfaz de llarraza, Kepa Sarasola nd Aitor Soroa fiom the Computer Science Faculty of EHU and Franeesc Ribas, ltoracio Rodrfguez and Alicia Ageno from the Computer Science Department of UPC.
22 References Agirre E., Arregi X., Diaz de Ilarraza A. and Sarasola K. 1994.
Agirre E., Rigau G. 1995.
Tzigov Chark, Bulgaria.
Agirre, E. and Rigau G. 1996.
Cowie J., Guthrie J., Guthrie L. 1992.
Francis S. and Kucera H. 1967.
Gale W., Church K. and Yarowsky D. 1993.
Guthrie L., Guthrie J. and Cowie J.
Hearst M. 1991.
Miller G. 1990.
Miller G. Leacock C., Randee T. and Bunker R. 1993.
Miller G., Chodorow M., Landes S., Leacock C. and Thomas R. 1994.
Rada R., Mill H., Bicknell E. and Blettner M. 1989.
Resnik P. 1995.
Richardson R., Smeaton A.F.
Rigau G. and Agirre E. 1996.
Sussna M. 1993.
Voorhees E. 1993.
Using WordNet o Disambiguate Word Senses for Text Retrival, in proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Developement in Information Retrieval, pages 171-180, PA. Wilks Y., Fass D., Guo C., McDonal J., Plate T. and Slator B.
Yarowsky, D. 1992.
Multi-source methods combine lexical cohesion with other indicators of topic shift such as cue phrases, prosodic features, reference, syntax and lexical attraction (Beeferman et al., 1997a) using decision trees   and probabilistic models (Beeferman et al., 1997b; Hajime et al., 1998; Reynar, 1998).
The method is based on Reynar's maximisation algorithm  .
Five versions of Reynar's optimisation algorithm   were evaluated.
R98 and R98(7-„rn) are exact implementations of his maximisation and minimisation algorithm.
Automatic Processing of Large Corpora fbr the Resolution of Anaphor  References Ido Dagan * Alon Itai Computer Science Department Technion, tIaifa, Israel dagan~techunix .b i tnet ,  i ta i~ cs.technion, ac.il Abstract Manual acquisition of semantic onstraints in broad domains is very expensive.
We gathered the statistics for three candidates which occur in the sentence: "col- lection", "money" and "government".
In the ex- periment reported here we have used constraints for the %ubject-verb", "verb-object" and "adjective- noun" relations.
As wa.s noted in [Grishman et al.
1986], the cooccurrence patterns reflect regu- larized or canonical structure.
"Io provide enough candidales, we examined occurrences of "it" ~ffter the 15th word of the senLence.
This happened in 33 cases, getting "accuracy" of 33/38 (87%).
6 Acknowledgements We would like to thank Mori Rimon, Shalom Lap- pin, Wlodek Zadrozny, Slavs Katz, John Justeson, Lisa Braden-Harder and Peter Brown for their fruit- ful advice and technical support.
7 References [Brown et al.
1988] Brown, P., Cocke, J., Della Pietra, S., Della Pietra, V., Jelinek, F., Mercer, R.L.
[Carbonell and Brown 1988] Carbonell, J. G. and Brown, R. D. Anaphora resolution: A multi strategy approach, COLING I988.
[Grishman et al.
1986] R. Grishman, L. Hirschman and Ngo Thanh Nhan, Discovery procedures for sublanguage selectional patterns initial experi- ments, Computational Linguislics, vol.
12,205- 214, 1986.
[Hobbs 1978] ttobbs, J. R. Resolving pronoun ref- erences, Lingua, vol.
44,311-338, 1978.
1989] S. Lappin, I. Golan, M. Ri- mon, Computing grammatical fimctions from a configurational parse tree, Technical Report 88.268, IBM Israel Center of Science and Tech- nology, 1989.
Schone & Jurafsky   applied LSA to MWE identification, althought they did not focus on distinguishing compositional from non-compositional MWEs.
0.769663 0.732372 0.731411 0.717294 0.704939 strecken ‘to lengthen’ 0.743309 fahren ‘to drive’ 0.741059 laufen ‘to run’ 0.726631 fahrt ‘drives’ 0.712352 schließen ‘to close’ 0.704364 We recognize that the composed vector is clearly nowhere near a perfect model of compositional meaning in the general case.
. fj ... fJ, which is to be translated into a target language sentence eI1 = e1 ... ei ... eI.
1995.
C. K. Fan and W. H. Tsai.
1988.
Kok-Wee Gan, Martha Palmer, and Kim-Teng Lua.
1996.
J. Lafferty, A. McCallum, and F. Pereira.
2001.
In of G. Ngai and R. Florian.
2001.
In of NAACLpages 40–47.
Adwait Ratnaparkhi.
1996.
L. Shen and A. K. Joshi.
2003.
In R. Sproat, Chilin Shih, William Gale, and Nancy Chang.
1996.
A stochastic finite-state word-segmentation for chinese.
H. van Halteren, J. Zavrel, and W. Daelmans.
1998.
Improving data driven wordclass tagging by system com- In of COLING-ACL Andi Wu.
2003.
Customizable segmentation of morderived words in chinese. and Chinese Language Nianwen Xue.
2003.
Y-axis stands for the -score.
1096 There are 19 instances of fisheries and 21 instances of p~ches.
The probability of seeing the two words in the same piece is simply: a prob(Vf, Vp) - a+b+c+d The marginal probabilities are: a+b prob(Vf ) - a+b+c+d a+c prob(Vp) = a+b+c+d For fisheries --~ p~ches, prob(Vf, Vp) =prob(Vf) =prob(Vp) =0.2.
3.2 1981 1981 3.0 Richmond Richmond.
3.0 p~ches Fisheries 2.8 Deans Deans.
2.8 Prud Prud.
2.8 Prud homme.
2.7 acheteur Limited 2.7 Communications Communications.
2.6 Mazankowski Mazankowski.
2.5 croisi~re nuclear 2.5 Sant6 Welfare.
2.5 39 39 2.5 Johnston Johnston.
2.5 essais nuclear 2.5 Universit6 University.
2.5 bois lumber 2.5 Angus Angus.
2.4 agriculteurs farmers 2.4 inflation inflation 2.4 James James.
2.4 Vanier Vanier.
2.4 Sant6 Health.
2.3 royale languages 2.3 grief grievance 7.
S. D. G.
Supported by SERC grant GR/F/36750.
E-mail ad- dress is E.Reiter@ed.
tAiso of the Centre for Cognitive Science at the Univer- sity of Edinburgh.
E-mail address i  R. DaleQed.
Ehud Re i te r*and  Rober t  Da le f Depar tment  of Art i f ic ia l  Inte l l igence Un ivers i ty  of Ed inburgh Ed inburgh  EH1 1tlN Scot land ?
OF COLING-92, NANTES, AUG. 23-28, 1992 to the notion of a discour~ focus space [GS86].
This research (e.g., [FO75,Whi76,Son85, A(XES DE COLING-92, NANrES, 23-28 AOlrl 1992 2 3 3 ISOC.
In par- ticular, 1.
ACTF~ DE COLING-92, NANqT~, 23-28 Aotrr 1992 2 3 4 PROC.
FOr exam- ple, basic-level-value(Garfield, type) might be cat.
OF COLING-92, NArCrEs.
AcrEs DE COLING-92, NAbrlns.
23-28 ^ o~r 1992 2 3 7 PRoc, OF COLING-92, NANTES, AtJcl.
Re ferences lapp85] Douglas E Appelt.
Unpub- lished technical report, Information Sciences Insti- tute/University ofSouthern California, 1990.
[BS85] Ronald Brachman and James Schmolze.
Cognitive Science 9:171-216, 1985.
[Cru77] D. Cruse.
Journal of Linguistics , 13:153-164~ 1977.
[Don66] Kelth Donnellan.
Reference and definite descrip- tion.
Philosophical Review, 75:281-304, 1986.
[17075] William Ford and David Olsea The elaboration of the noun phrase in childrens de~riptton of ob- jects.
Journal of Ezpemmentol Child Psychology, 19:371-382, 1975.
[GJW83] Barbara Gresz, Aravind Jeshi, and Scott Wein- stein.
In Proceedings ofthe ?1st An- nual Meeting of the A ssoeiation for Computafional Linguistics, pages 44-50.
[Gri75] H. Paul Grice.
[GS86] Barbara Grenz and Candaen Siduer.
Compu- tatioual Linguistic, 12:175-208, 1986.
[Kns89] Robert Kasper.
Pro- ceedings of the 1989 DARPA Speech and Natural Language Workshop~ pages 153-158.
[Kro86] Amichai Kronfeid.
[Lev89] Willera Levelt.
Speaking: bq~om Intention to Ar- ticulation.
MIT Pre~s, 1989.
[Pec89] Thomas Pechmann.
Incremental speech produc- tion and referential overspeeificatlon.
Linguistics, 27:89-110, 1989.
[Rdg0a] Ehud Reiter.
[Relg0b] Ehud Reiter.
[Rei91] Ehud Reiter.
[RML92] Ehod Relter, Chris Mellish, and John Levine.
Automatic generation ofon-line documentation In tbe IDAS project.
IRes78] Eleanor Rcech.
In E. Resc~ and B. Lloydj editors, Cognition and Cat- egorization, pages 27-48.
Lawrence Erlbaum, Hills- dale, NJ, 1978.
[Sid81] Canda~e Sidner.
[Son85] Susan Sonnenschein.
Journal of Paycholingnistic Research, 14:489-508, 1985.
[Wh176] Graver Whitehurst.
Child Development, 47:473-482, 1876.
ACIds DE COLING-92, NANI~S, 23-28 AOUT 1992 2 3 8 PROC.
OF COL1NG-92, NANIES, AUG. 23-28, 1992
Our input tokens to CGP are morphologically ana- lyzed word-forms.
context-dependent morphological disambigua- tion, , determination of intrasentential clause boun- daries, , disalnbiguation of surface syntactic functions.
We have a five-stage parsing-process.
"@DN>" = determiner as modif ier of the next noun to the right, "@+FMAINV" = finite main verb, "@-FMAINV" = non-finite main verb as member of a verb chain, "@<NQM-FMAINV" = non-finite main verb as post- modifier of a nominal: a a" DET CENTR ART INDEF @DN>" move move" N NOM SG" move "V SUBJUNCTIVE @+FMAINV" move "V IMP @+FMAINV" move" V INF @-FMAINV @<NOM-FMAINV" described by recursive links back to the main lexicon.
Consider the cohort of the Swedish word-form fru- kosten ("_ " = compound boundary, frukost break- fast, fru mrs, kostnutrition, ko cow, sten stone): frukosten frukost" N UTR DEF SG NOM" fru_kost" N UTR DEF SG NOM " fru ko sten" N UTR INDEF SG NOM " By local disambiguation we refer to constraints or strategies that make it possible to discard some readings just by local inspection of the current co- hort, without invoking any contextual information.
This strategy properly discards the readings "fru_kost" and "fru ko sten".
Finnish, German, and Swedish is N(r) (a) (b) 0 13957 13957 1 440035 487994 2 253779 236298 3 55857 44782 4 38062 29053 5 24135 18911 6 3830 312 7 9551 8913 8 541 23 9 232 47 10 72 2 11 46 5 12 124 13 15 14 28 15+ 33 Out of roughly 1,5 million readings assigned by morphology (1.8 readings/word-form), local disam- 169 biguation discards more than 100,000.
The elements are (strings of) features and/or base-forms occurring in readings: (DET "DET") (N "N") (TO "to") (PREMOD "A" "DET") (NOMHEAD "N NOM" "PRON NOM") (VFIN "V PRES" "V PAST" "V IMP" "V SUBJUNC- TIVE") Each constraint is a quadruple consisting of do- main, operator, target, and context condition(s).
Con- ceptually they just express constraints.
as the inherent fea- ture "<**CLB>" in the input stream.
Their seman- tics is identical to that of the disambiguation con- straints: (@w =sO "@+FMAINV" (*-1 VFIN)) (@w =sO "@+FMAINV" (1 VFIN)) (@w =s!
Dis- ambiguation, i.e.
Kimmo Koskenniemi, COLING-90 Proceedings, Vol.
Presently some 400 context-dependent disam- biguation constraints have been formulated for Eng- lish by Atro Voutilainen, Juha Heikkil~, and Arto Anttila.
References Church, K. 1988.
Karlsson, Fred 1989.
"Parsing and Constraint Grammar".
Koskenniemi, Kimmo 1983.
Two-Level Morpho- logy.
The popular microblogging service Twitter (twitter.com) is one particularly fruitful source of user-created content, and a flurry of recent research has aimed to understand and exploit these data (Ritter et al., 2010; Sharifi et al., 2010; Barbosa and Feng, 2010; Asur and Huberman, 2010; O’Connor et al., 2010a; Thelwall et al., 2011).
In particular we self-train the standard Charniak/Johnson Penn-Treebank (C/J) parser using unannotated biomedical data.
However more recent results have shown that it can indeed improve parser performance (Bacchiani et al., 2006; McClosky et al., 2006a; McClosky et al., 2006b).
We self-trained the standard C/J parser on 270,000 sentences of Medline abstracts.
English is today the de facto lingua franca for commerce around the globe.
1 Liu et al 2000 take a similar approach, retrieving.
449
450 4.1 Suggestion Provider Modules for.
The string above is first tokenized and then part-of-speech tagged: 0/I/PRP 1/am/VBP 2/teacher/NN 3/from/IN 4/Korea/NNP 5/./.
451 and 12 billion 5-grams.
The overall accuracy of this module is state-of-the-art compared with results reported in the literature (Knight and Chander 1994, Minnen et al 2000, Lee 2004, Turner and Charniak 2007).
96.83% 86.87%
The LinGO Redwoods Treebank Motivation and Preliminary Applications Stephan Oepen, Kristina Toutanova, Stuart Shieber, Christopher Manning, Dan Flickinger, and Thorsten Brants {oe |kristina |manning |dan}@csli.stanford.edu, shieber@deas.harvard.edu, brants@parc.xerox.com Abstract The LinGO Redwoods initiative is a seed activity in the de- sign and development of a new type of treebank.
Well-understood statistical part-of-speech tag- ging technology is sufficient for this approach.
Trigram probabilities are smoothed by linear in- terpolation with lower-order models.
The extended PCFG (henceforth PCFG-GP) has parameters P(Ak Ai ?
10 1027 5.33% 51.61% ?
References Abney, S. P.  .
Computational Linguistics, 23, 597 ?
Bouma, G., Noord, G. van, & Malouf, R.  .
In W. Daelemans, K. Sima-an, J. Veenstra, & J. Zavrel (Eds.
The TreeBanker.
Charniak, E.  .
Flickinger, D.  .
Harris, T. E.  .
Johnson, M., Geman, S., Canon, S., Chi, Z., & Riezler, S.  .
Manning, C. D., & Schu?tze, H.  .
Mullen, T., Malouf, R., & Noord, G. van.
Toutanova, K., & Manning, C. D.  .
Foundations of speech- to-speech translation.
H(C|K)H(C) else (1) where H(C|K) = ? |K| ? k=1 |C| ? c=1 ack N log ack ?|C| c=1 ack H(C) = ? |C| ? c=1 ?|K| k=1 ack n log ?|K| k=1 ack n Completeness: Completeness is symmetrical to homogeneity.
The F-Measure ofboth of these clustering solutions in 0.6.
413 Adjusted Rand Index  , ?statistic  , Jaccard  , Fowlkes-Mallows   and Mirkin  .
classes3.
There are |Ku| = |K| ? |Knoise| ?useful?
clusters and |Cu| = |C| ? |Cnoise| ?useful?
415 of non-matching useful class/cluster pairs.
P1 For |Ku| < |C| and ?|Ku| ?
With V-measure, we present a different argu ment.
418
1988; Chodorow, Byrd, and Heidron 1985).
We have used McCord's implementation of Slot Grammars (McCord 1990, 1991).
For example, if /51 -= 0.51 and /52 = 0.49, the expected success rate in choosing T1 is approximately 0.5.
For these values Ba -= 1.137.
7.2.1 Bootstrapping.
1990, p. 79).
Let C0k = {eik, fjk}∪FTk.
Adam Lopez, Michael Nossal, Rebecca Hwa, and Philip Resnik.
2002.
Last but not least, we thank the organizers of the previous four shared tasks: Sabine Buchholz, Xavier Carreras, Ryan McDonald, Amit Dubey, Johan Hall, Yuval Krymolowski, Sandra K¨ubler, Erwin Marsi, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
A Simple Similarity-based Model for Selectional Preferences
Brockmann and Lapata   perform a comparison of WordNet-based models.
Rooth et al.   generalize over seen headwords using EM-based clustering rather than WordNet.
In this section we describe experiments comparing the similarity-based model for selectional preferences to Resnik's WordNet-based model and to an EM-based clustering model3.
Like Rooth et al.   we evaluate selectional preference induction approaches in a pseudodisambiguation task.
Next come EM-based clustering models, using 30 (40) clusters and 20 re-estimation steps6, and the last row lists the results for Resnik's WordNet-based method.
Acknowledgements Many thanks to Jason Baldridge, Razvan Bunescu, Stefan Evert, Ray Mooney, Ulrike and Sebastian Pad6, and Sabine Schulte im Walde for helpful discussions.
...
...
Bilingually-Constrained (Monolingual) Shift-Reduce Parsing
2006AA010108.
is an-.
2.4 HDP-PCFG.
690 HDP-PCFG ? ?
2.5 HDP-PCFG for grammar refinement.
timates.
2.7 Structured mean-field approximation.
2.8 Coordinate-wise ascent.
isdegenerate.
We set al hyperparame ters to 1.
3.2 Parsing the Penn Treebank.
We ranexperiments on the Wall Street Journal (WSJ) por tion of the Penn Treebank.
When using a truncation level of K = 16, the standard PCFG with smoothing obtains an F1 score of 88.36 using 706157 effective rules whilethe HDP-PCFG-GR obtains an F1 score of 87.08 us ing 428375 effective rules.
Finkel et al  independently developed another nonpara metric model of grammars.
Kurihara and Sato   and Kurihara and Sato   applied variational inference to PCFGs.
696
Three New Probabi l is t ic  Mode ls for Dependency  Parsing: An  Exploration* J ason  M.  E i sner CIS  Depar tment ,  Un ivers i ty  of  Pe lmsy lva i f ia .
200 S. 33rd  St. ,  Ph i lade lph ia ,  PA  19104-6"{89, USA j eisner@linc, cis.
(a) Tile man in the coiner  taught his dachsht , ld  IO play gol f  I;OS DT NN IN DT NN VBD PP.P$ NN TO VH NN /?
In principle, one couht model the distribution of dependency l)arses l()ur novel parsing algorithm a/so rescues depen dency from certain criticisins: "l)ependency granl- mars .
(LMferty et ;LI., 1992, p. 3) 340 in any uuml)er of sensible or perverse ways.
This is tire philosophy behind stochastic CF(I  (aelinek et a1.1992), "history-based" phrase-structure parsing  , +m(I others.
IIowever, i)rol)ability models derived from parsers sotnetimes focus on i,lci(lental prope.rties of the data.
We believe it is ffttil,[u[ to de.sign prol>al)ility models indel)en(letrtly of tit( pa.rser.
In practice, solrre generalization or "coarsen- lug" of the conditionM probabil it ies in (1) heaps to avoid tile e.ll~ets of undertrMning.
I)ecisions al)out how much coars- enittg t,o lie are+ o1 great pra(-t, ieal interest, b ut t hey (lel)etM on the training corpus an(l tnay l)e olnit- ted from a eonc<.t)tuM discussion of the model.
For ex- +Unl)h. , lh.e price of lh.c sleek fell (l"igure 3a) will tyl>ically 1)e nlisanalyzed under this model.
342 (a) (b) dachshund ovcr  there  can  rea l ly  phty dachshund ow: r  there  can  rea l ly  p lay I,igure 4: Spans ])~uticipa, ting, in the (:orru(:l. i)a, rsc of 7h, at dachs/*und o+wr there c(+u vcalhl ph+g golf~.
3 Bot tom-  [ ) i )  Dependency  Pars ing lu this sec.tAon we sket(:h our dependel .
The a lgor i@m ++(l(Is one link at a l, ime, nmking il; easy to mul t ip ly  oul, the hie(lois l)rolm hility la(:t, ors.
4 []10 liic.t]tod llsed is s imilar t;o t ie  C K Y met.hod of cont.exl,-fr(e l)~rsing, which combines aJIMys(:s of shorl, er substr ings into analys<:s of progressively longer ones.
Mult iple a.na.lyses It;we l, hc s~tnm s ignature  if t;hey are indistinguishal>le i , their M)il ity to (;Otlll)ill(?
()he mighl; guess that each substaing ;mMysis shottld bc t+ lcxicM tree ;+ tagged he;ul- word plus aJl Icxical sulfl;rees dependcnt, upon i/,.
(See l"igure 111.)
11,Mmled depend .
probabil ist ic behavior depends on iL~ he.adword (;he lcxicMisL hypoiJmsis titan dilterent;ly hc~:uhxl a.na.lyses need dilterenI; sigmrtures.
:s are Mlowed in the Sl)a.u, and each Jut,rehal word  of l, he Sl>ml must ha, vc ~ Ira.rein iu the q);m+ Two sl>a, ns at<> illustraJ,ed in I"igure d, lhese di- a,gra.nts a, rc I,yl)ica,l: a, Sl)a,n el" a (Icpendct.
illl,(A hal part; of a, span is gra, nmmtica l ly  iuert: excel)l, Ior tit(, cmlwords dachsh, u~td mid play, l;hc struc lure o1 ea,ch span is irrelewml, I,o t,]1(; Sl>Cms al)i l ity t,o cotnbinc iu ful,ure, so sl)a, ns with different inter- 1ml strucl, tue ca,n colnlmte to bc t;hc I)est,-scoring span wil, h a, lm,rticula,r signal;urc.
This prcvenLs us from assend>ling c in umlt iple ways.
11 A I ~1 c I c T -  x I~,~o1~  1.o I Non-punt  88.9 89.8 89.6 89.1 89.8 77.J Nouns 90.1 89.8 90.2 90.4 90.0 S(;.2 I,ex verbs 74.6 75.9 7.
"/.3 75.8 73.3 67.5 Fable t: Results of preliminary experiments: Per- centage of tokens correctly tagged by each model.
Thc iinusually low I)aseliue t)crJorillance I:esults [lOlll kL conil)iuation of ;t sHiaJl l>ilot Lr;~ill- ing set and ;t Inil(lly (~xten(|e(I t~g set.
The siinplcst and [astest uiodel, the l(~cur-- siw ~, generation uiodel (7, did easily i.he bcsl.
This suggcsts that sut)eategjo rization 1)rcferc[lccs the only I~Lctor (onsidered by model (J I)lay a substantial role in I;he sti:uc- lure of Trcebank scntcn(-cs.
(lndccd, tii(; erl;ors ill model I~, wliich pe:l:forHled worst across the bO~Lr(l, were very frequently arity erl:ors, where ttie desire of a chihl to ~Ltta(:h LO a 1)articular parent over-.
6 Conc lus ions I~arc-bories dependency grammar which requires 1lO Ihik labels> no ~ral f l i i ia i  ,  and ItO fll~S tO lirlderstand iS a clean tcstbcd for studying the lexical a[liniLies of words.
7We l lsed distinctive t~tgs for a,uxi[ia,ry verbs  ;-I, ll(I for words being used as noun modifiers (e.g., partici- ples), bec<xuse they ha.ve very ditferent subca.tcgoriz~> lion fra.mes.
As a lirst step in the study of lexicM a@n- ity, we asked whether there was a "natural" way to stochasticize such ~ siint)le formMism a.s de- pendency, hi f~ct, wc have now exhibited three promising types of lnodel for this simple problem.
Further, we have develol)cd a novel parsing algo- r ithm to compare thesc hyt)otheses, with results tim, so far favor the spe;tker-oriented model C, eveu in written, edited Wall Slrcet dournal I~cxt.
ino(h;Is iiave uoL been investigated l)efore.
Towards history- ba,sed gramnl~u:s: using richer mod(,.ls [br probabilis- tic i,~trsing.
A stochastic parts pro- gi:ntll a, nd noun l)hra,se parser for unrestri(:tcd text.
In /roe, of the 2rid (;onf.
on Applied Natural Lan- guage lJroccssing, 136 148, Austin, TX.
An empirical (:omp~Hison f prob- ~dfility nlodcls for dependeucy gl:a, lnnlaJ:.
Teehnic;d ILeport IRCS 96 11, University of PennsylvaJtilt.
M~rkov sour(:e modeliug of text gener~Ltiou.
Skwirzinski, editor, hnpact of IS"o- tossing 7~chniques ou (;ommunication, /)ordrc(:ht, l"red Jelinek, ,lohn 1).
~INI,I"IIILI7S.
I{obust l)arDof-speech ta.gging us- ing a. hidden Ma, rkov model.
(~ramm~LticaJ trigr~mm: A prob~bilistic model of link gr~mnnar In 15"oc.
of the AAAI  Conf.
St~ttisti(:~d decision-tree models for p~using, in Proceedings of the 33rd An- nual Meeting of the A CL, l~oston, MA.
1988. l)cpcndcncy Syntax: 7?worg and lracticc.
Stochastic lexi(:alized tree- ~tdjoining gra.mmars, lit lrocccdings of C()lHNG- 92, Na.nl.es, I))auce, .lnly.
I)nniel Sleator and Daxy Tcmperlcy.
Pro:sing I",nglish with ~t I,iuk (h:,~mm~m Te(:hnicifl report CM U.-(S-91-196.
(iS Dept., C~m,egic Melk)n tl uiv.
HR0011-06-C-0023.
+hm their/them).
Next comes the class of particle proclitics (PART+): l+ to/for, b+ by/with, k+ as/such and s+ will/future.
D1, D2, and D3: Decliticizations.
D1 splits off the class of conjunction clitics (w+ and f+).
D2 splits off the class of particles (l+, k+, b+ and s+) beyond D1.
PoS unigrams, bigrams and trigrams are extracted using the RASP tagger, which uses the CLAWS4 tagset.
P´erez-Marin et al.  , Williamson  , Dikli   and Valenti et al.
Aspectual divergences are treated by Dorr (1992a).
1991a, 1991b; Beaven 1992a, 1992b; Dorr 1990a, 1990b; Kameyama et al.
1991; Kinoshita, Phillips, and Tsujii 1992; Lindop and Tsujii 1991; Tsujii and Fujita 1991; Whitelock 1992; related discussion can also be found in work by Melby [1986] and Nirenburg and Nirenburg [1988]).
In par- ticular, Barnett et al.
(See Barnett et al.
1991a, 1991b; Carbonell and Tomita 1987; Meyer, Onyshkevych, and Carlson 1990; Nirenburg, Raskin, and Tucker 1987; Nirenburg and Goodman 1990; Nirenburg and Levin 1989; Wilks 1973; among others, for descriptions of interlingual machine translation approaches that take into account knowledge outside of the domain of lexical semantics.)
1991; and Johnson, King, and des Tombe 1985).
1989, 1990; Kaplan and Bresnan 1982; Kaplan et al.
602 Bonnie J. Dorr Machine Translation Divergences Y-MAX Q-MAXj+I  ... Q -MAXk Y -MAX Q-MAXk+ I ... Q .MAX m W-MAX X-MAX X Z-MAX1 ... Z-MAX a Q-MAX 1 ... Q-MAXi X Q-MAXi+ 1 ... Q-MAXj F igure  5 Formal definition of syntactic phrase.
[Y-MAX Q-MAXj+~ ... Q-MAXk [Y-MAX W-MAX [X-MAX [X Q-MAX1 .. .
Q-MAXi X Q-MAXi+I ... Q-MAX i] Z-MAX1 .. .
Z-MAXn]] Q-MAXk+1 .. .
Now that  we  have  fo rmal ly  de f ined  the  representat ions  and  mapp ings  used  dur - ing  t rans la t ion ,  we  wi l l  tu rn  to a c lass i f i ca t ion  of  d ivergences  that  is based  on  these de f in i t ions .
(The terms language-to-language nd language-to-interlingua are taken from Dorr and Voss 1993a.)
~ Z 13 4.Q ?~X Figure 9b shows the revised mapping.
Dorr (1993b, pp.
E. Brill.
1995.
Dagan et al, 1993; Fung and Church, 1994; Wu, 1994; Melamed, 1999; Och and Ney, 2000) tended to focus on translation model applications for their word-alignments rather than the induction of stand-alone monolingual analyzers via cross-language projection.
See (Satta and Peserico, 2005, Sec.
We denote the class of binarizable SCFGs as bSCFG.
260 Proof.
In this way we can uniquely reconstruct the tree-to-string derivation using the two-step SCFG deri vation.
We are also grateful to Daniel Marcu, Giorgio Satta, and Aravind Joshi for discussions.
This work was partially supported by NSF ITR IIS-09325646 and NSF ITR IIS-0428020.
In particular citystate constructions (e.g.
We first evaluate our model on the ACE2004-CULOTTA-TEST dataset used in the state-of-the-art systems from Culotta et al.   and Bengston and Roth  .
Additional manually constructed resources include PropBank  , FrameNet (Baker et al.
Antonymy.
Enablement.
Happens-before.
V1 stronger-than V2, and V2 strongerthan V3 indicates that V1 stronger-than V3, which may be leveraged to identify additional relations or inconsistent relations (e.g.
V3 stronger-than V1).
For example, suppose that a word can take on one or more PUS-tags from the set of open-class POS-tags: (JJ NN NNS RB VB VBD VBG VBN VBZ).
We compute coarse-grained precision as (c1 + c3)/total.
Gartner et al.   adapted SVMs to the MIL setting using various multi-instance kernels.
More exactly, let s = w1w2 ... wk be a sequence of k words, and s� = w1 g1 w2 g2 .
The aim ent (e.g.
Feature Definition headi substring of headj modi == (headj or modj) Alias acronym(headi) == headj or lastnamei == lastnamej Another class of features captures the semantic relation between two words.
Luo et al.  .
Our test set contains the same 107 documents as Culotta et al.  .
Soon et al.  .
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Two learning ap proaches are proposed.
Such approach is notfeasible for non-comparable corpora where statis tical measurement is required.
3.1 Motivations.
3.2 Unary Template Structure.
3.3 Direct Learning of Unary Rules.
This behav ior generates high-score incorrect rules.
Templatesare matched using a syntactic matcher that han dles simple morpho-syntactic phenomena, as in  .
5.1 Results.
electX?
854 5.2 Analysis.
SOME COMPUTATIONAL PROPERTISS OF  TREE ADJO IN ING GRAMM.~.S* K.  V i jay -Shank~"  and  Arav ind  K .
Jouh i Depar tment  o f  Computer  and  In fo rmat ion  ~e ience Room 288 Moore  Schoo l /D2 Un ivers i ty  o f  Pennsy lvan ia Ph i lade lph ia~ PA  191Ct ABSTRACT Tree Adjoining Grammar (TAG) is u formalism for natural language grammars.
*This work wu ptrt is J~ su.~ported by NSP Gr~u~* MkTS-4~IOII6.~~R, MCS42-07.~94.
We wtat to thank Clr |  Pol!ard.
Kelly Rozeh, David Se~ tad David Weu.
The internal nodes are ~11 non-terminals.
IGr~nm~u Ol tad G2 mm w*aJtly equivuJ*a* if the forint ItaCU*ll* of GI, I~Gi} m tim J~in?
lua?un4pD ot G~ ~G2b G I  tad G:I *.,,* ,troo?ly *quivuJeot they m mmkl7 eq~,ivuJeIt tad for etch w UI E,(GI) ~e L(G2), both G i  tad G2 the strne itI~l~urld delleriptioll to v.  A ~ m r  G is ~ly  uleqoa~ for t IPtriD|l llMl~ql~ ~* if UGI  am L G ~1 IttOO?~ I~deql]otdl for b if L(G) m h tad for elgb w is I~ G *~iglm am ?
*ppmpdm e ,ttuctural description to m. The 8oti~a 0( ItrOu?
*dequtcT ~ undoobtodlY not pmciN becsmn it deport ,4* o l  the notion 0~ zpp~pfiato * tn t t tu~ de~.
~mmple 2.1 illustrates part Ca).
I~ I b S I e ~t $ / u T I $b i U ~t 71 == 30 with ~I 3= =* 31 with ~ adjoined at S am indicated in "f0.
Thus s TAG ma~" ~ _z context-free language, ~ign  structural de~riptious to the strinAs that cannot be usi~ned by ~ context-free ~rammnr.
c* results in the language 1~== { a abnec  a /  n>>_o} =-L  t Na b ec" i~ i~ well-known strictly context-sensitive language.
TAGs have more power than CFGs.
we shalJ see in Netin* 4 of this paper and [Vijay-Shankar nd Joehi,1985J.
TAGs  with Lanai Const ra in ts  on Ad, Jo ln ln | The adjoining operation as defmed in Seetion 2.1 is "context- free.
or as O(C) where C is a subeet of the set of all suxifiacy trees adjoisable at u. I~--~amp~ 2.4: Let G == (I~.)
Readers may refer ~o [Krocb and Joshi, 1985] for detads.
DEF IN IT ION 3.1 Let 3,3" be two tre~.We say "r [--" 3" if in 3 we adjoin an auxiliary tree to obtain 3".
in  the f ront ie r  o f  e lemnntsry t r~ whoso l~bel 18 ~*t  In A  [ i .
l  ]  sa t l s fy ins  ?ppropr la tn  rHCr lc t lon8  put ~heix parents in A{?
Pmmlug wi th  Loead Const~mlnt4 So far,we have a~,samed that the give?
C losure  undem Un ion Let G t and G. z be two TAGs generating L I and l.~ respectively.
FIgure 4.3 4.4.
A derivation from n non-terminal produces a pair (i,a1...ai...a~) (a more convenient representation for this pan is al...~ilLl+l...a~ ).
wrapped around* the sub-tree i.e,the string ugv.
However, we c~" ?cheers the S2rne effect by considering the dermitions of the Sl imier ?
Pollard suggests tha* cases such as I J~ ,~)  be IcR u"dermed.
We shrift -~,ume thai if ~" --,.by then L I~.~)  ~, ?
protednrzi deseriptioe of obtaining an equivalent Head Crammat from ?
Tree*Adjoining Grammar.
s derived t.ree with root lnbel X nny wrl~ 8~ovad the 8t.rin4| derived from the nbt.reo below ?.hie node~ r -> L~t(A 1 .
By cedllng t.he procedure recurstvely for i l l  the J chLldren of T with At.k r~nlrlng frox I throuKh J, ve cns derive from I1 the front.
?er of the subtreo belo~ Y} T -> I   { thin iu t~ handle t*hn cue  where no adJuc~on ~d~ns place ?
Repe&t* for o~?h Amctllta~-y t r~ Conret~ m J~ (root.
roo~lmlo l ) where Ccarez~ ~o HG(n~te.nwso) In dettnsd -.. fo l lmm L!
undo 18 an index.aLl node tJmn cnsn I I !
tJm ~mstr~tnt  n~ ~hn node t8 A& add product, ions $~I->LLu(node syubo l .
A| correspond t.o the J chl ldren ot the node sad l= l  I f  foot, node is  not* ?
Cue 2 The conet.r~tnt* ?t* ~bn node Ls JUt.
II*->LCt (AI  .
Stse an Cue I except, that* we dont, a4d Syx->t.C t (At,...Aj) else i f  *.he node hu  ?
ternl?s3, synbol ?
0A then add onXy the product.ion Syu ->l.t1(node s lnt~I .~) L!
the c gnetl"~nt* i l  gA add the product.ion S~w ->.~ We sh~dl now xive so example of converting ?
$ a= I ~= Ftf~ur.
Some of them are listed below t) Pumping lemmn for TAGs 2) TALs are closed under sub6titution and homomorphisms 3) TALs are not closed under the following operations a) intersection vtth TkL8 h) |.ntnrsoct~.on ntth CFLn c) coapleMnt, atton Some other properties that have been considered in [Vijay- Shank~r ~d Joshi,1985j re u follows t) clomsrn under the fo l loetng properttan a) tnver le hosollorphtei b) ~m ~ptn~ 2) 8eLtltnnLrtty tad PartlrJ~-bouadndaan8.
Aho,A.V., and Ullman,J.D., 1073 "Theory nf Parsing, Translation t an__{d Compiling, Volume 1: Pxrsinp;, Prentice-Hall, Englewood Cliffs, N.J., 1973.
Joshi,A.K., 1983 "How much context-sensitivity s necessary for chare~terising structural descriptions - tree adjoining gramman" in Natural Lanpiua~ie ~ - Th#oretieal v Computational I and ~og iea l  Perspectives (ed.
Joshi,A.K., and LevyJ~.S., 1977 "Constraints on Structural Dc,seriptinns: Local Transformations s, SIAM ]ourual of Computinlt; June 1977.
Joshi,A.K., Levy :..S., and Takahashi, M., 1975 "Tree adjoining gramm=rs, Jo, rual of Comout~r ~"~ems and Sc.
;enees March 1975 5.
of Computrr and ?~.formation Scteuee I University of P~nnsvlvania, April 6.
Poll:zrd, C,  t984 "Generalized Fhruse Structure Grammars, Head Grammars, and Natural l"nggagea, Ph.D dissertation t Stanford Univer~itz, August 1984 7.
!<., 1084 "Form~J P.-operties of Head Gra:,~m~rs, unpublbhed manu~ript, Stanford University, also presented at the M-.th~.mir~ ,ff l,anguage~ workshop zt the University of Michigan, Ann Arbor, Oct. lg~.l.
Vijay-S~,ankar,K., Jnshi.A.K.. 1935 "Formal Properties ot Tree Adjolmug Grammars.
Tmhni~.il Report, D~pt.
hi Cnmp,,ter nail hzformation Srit,~rf.~ Univ@r~ttv of Peoesvlvant~, July 1985.
MacKay   and Beal   describe Variational Bayesian (VB) inference for HMMs.
Coreference Resolution in a Modular Entity-Centered Model
We utilized MUC  , B3All  , B3None  , and Pairwise F1.
N000140911081.
11See nlp.cs.berkeley.edu and aria42.com/software.html for software release.
For the 20 narratives, the probabilities of the observed distributions range from p :7-- .114 x 10-6 top < .6 x 10-9.
It's location is FIC number 25.
Recall is .66 (a=.068; max=1; min=.25), precision is .25 (a=.013; max=.44; min=.09), fallout is .16 (a=.004) and error rate is 0.17 (o-=.005).
Recall is 72% (a.=.027; max=.88; min=.40), precision is 15% (a-=.003; max=.23; min=.04), fallout is 53% (a-=.006) and error is 50% (o-=.005).
Recall is 92% (a=.008; max=1; min=.73), precision is 18% (a=.002; max=.25; min=.09), fallout is 54% (a-=.004), and error is 49% (cr=.004).
The authors wish to thank W. Chafe, K. Church, J. DuBois, B. Gale, V. Hatzivassiloglou, M. Hearst, J. Hirschberg, J. Klavans, D. Lewis, E. Levy, K. McKeown, E. Siegel, and anonymous reviewers for helpful comments, references and resources.
Acknowledgements.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
2.1 Model.
is theFH.
2.4 Evaluation.
3.1 Annotation.
3.2 Reliability.
Each rater judged approximately 18,000 prepo sitions contexts, with 18 sets of 100 contextsjudged by both raters for purposes of comput ing kappa.
4.1 Methodology.
sub-corpus contains the remaining 10%.
sub-corpus.
Forthe hypothetical data in Figure 1, these val ues are 600/750 = 0.80 for Hits, and 150/750 = 0.20 for FPs.
4.2 Application.
A sample word segmented Arabic text is given below, where prefixes are marked with #, and suffixes with +. w# s# y# Hl sA}q Al# tjArb fy jAgwAr Al# brAzyly lwsyAnw bwrty mkAn AyrfAyn fy Al# sbAq gdA Al# AHd Al*y s# y# kwn Awly xTw +At +h fy EAlm sbAq +At AlfwrmwlA
Mwskw 51-7 ( Af b ) - Elm An Al# qSf Al# mdfEy Al*y Ady Aly ASAb +p jndy +yn rwsy +yn Avn +yn b# jrwH Tfyf +p q*A}f Al# jmE +p fy mTAr xAn qlE +p ... Mwskw 51-7 ( Af b ) - Elm An Al# qSf Al# mdfEy Al*y Ady Aly ASAbp jndyyn rwsyyn Avnyn b# jrwH Tfyfp msA' Al# jmEp fy mTAr xAn qlEp ...
N66001-99-2-8916.
We would like to acknowledge Salim Roukos and Kishore Papineni for technical discussions.
Principle-Based Parsing Without Overgeneration
Therefore, i4 acquires -cm.
Wh-movements are dealt with by attributes whpg, whbarrier, wh-atts.
The base-position of a wh-movement is case-marked and assigned a 0-role.
A wh-movement carries a whbarrier attribute.
A PROtheorem violation is detected if +govern and -ppro co-occur in an item.
Zhu and Rosenfeld   use Web-based n-gram counts for language modeling.
MINIPAR employs a distributedchart parsing algorithm.
More precisely, zero frequencies were returned for 23 adjective-noun, 16 verb-noun, and 37 noun-noun bigrams.
3.2.1 Method.
To calculate intersubject agreement we used leaveone-out resampling.
We evaluated our Web counts by applying the pseudodisambiguation procedure that Rooth et al.  , Prescher, Riezler, and Rooth  , and Clark and Weir   employed for evaluating re-created verb-object bigram counts.
...
On Coreferring: Coreference In MUC And Related Annotation Schemes
Popescu-Belis 1998; Hirschman and Chinchor 1997).
Nonreferring NPs can enter anaphoric relations.
Researchers in computational linguistics and in artificial intelligence have called these expressions anaphors (cf., Woods 1978, Sidner 1983, Bobrow 1977, Hirst 1981, Webber 1983).
Comrie 1985).
10.
Since 8b is past perfect, ETb < RTb.
That is, 13(Cb,TF,RTb) = Eb.
We carry out experiments using a phrase-based statistical machine translation system [Koehn et al., 2003; Koehn, 2004].
10, 81, and 88 fidence intervals computed for 100 test sets of 300 sentences.
Exploring Content Models for Multi-Document Summarization
As Leuski et al.   and Branavan et al.
2002; Yarowsky, Ngai, and Wicentowski 2001; Yarowsky and Ngai 2001; Riloff, Schafer, and Yarowsky 2002).
Nie and Cai [2001]).
3.2.2 Results.
The Pangloss system and work by several other researchers attempted to combine lattices from many different MT systems (Frederking et Nirenburg 1994, Frederking et al 1997; Tidhar & Küssner 2000; Lavie, Probst et al. 2004).
The word alignment matcher was developed by Satanjeev Banerjee.
1993; Dagan, Church, and Gale 1993; Fung and Church 1994; Wu and Xia 1994; Fung and McKeown 1994).
We call x/€ an Li-singleton, and cly an L2-singleton.
In fact, it is natural to write the parse trees together: (2) E[E[The/e [Financial/14V Secretary/ni [NN Ni' and /fl fi/RINP INP [be/€ accountable/ftrtivv [vp [sr •/.
The usual Chinese NLP architecture first preprocesses input text through a word segmentation module (Chiang et al. 1992; Lin, Chiang, and Su 1992, 1993; Chang and Chen 1993; Wu and Tseng 1993; Sproat et al.
An example is [have acquired/e oi.nij new/t skills/It lig] in Figure 11.
OntoNotes: The 90% Solution
hovy mitch martha.palmer lance.ramshaw weischedel @isi.edu @cis.upenn.edu @colorado.edu @bbn.com @bbn.com We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement.
Tillmann and Zhang  , Liang et al   and Bangalore et al   introduced sparse binary features for statistical machine translation trained ona large training corpus.
Lianget al   introduced an averaged perceptron al gorithm, but employed only 1-best translation.
2.1 Hierarchical Phrase-based SMT.
Based on hierarchical phrase-based modeling, we adopted the left-to-right target generation method (Watanabe et al, 2006b).
2.3 Left-to-Right Target Generation.
We applied an Earley-style top-down parsing approach(Wu and Wong, 1998; Watanabe et al, 2006b; Zoll mann and Venugopal, 2006).
using lexical transla tion models.
Backtrack-based penalties inspired by the dis tortion penalties in phrase-based modeling (Watanabe et al, 2006b).
3.3 Normalization.
Tillmann and Zhang   avoided the problem by precomputing the oracle translations inadvance.
# features 2003 (dev) 2004 2005 NIST BLEU [%] NIST BLEU [%] NIST BLEU [%] surface form 492K 11.32 54.11 10.57 49.01 10.77 48.05 w/ prefix/suffix 4,204K 12.38 63.87 10.42 48.74 10.58 47.18 w/ word class 2,689K 10.87 49.59 10.63 49.55 10.89 48.79 w/ digits 576K 11.01 50.72 10.66 49.67 10.84 48.39 all token types 13,759K 11.24 52.85 10.66 49.81 10.85 48.41 where ? > 0 is a learning rate for controlling the convergence.
Tillmann and Zhang   and Liang et al   solved the problem by introducing a sentence-wise BLEU.
# features 2003 (dev) 2004 2005 NIST BLEU [%] NIST BLEU [%] NIST BLEU [%] baseline 10.64 46.47 10.83 49.33 10.90 47.03 1-oracle 1-best 8,735K 11.25 52.63 10.82 50.77 10.93 48.11 1-oracle 10-best 10,480K 11.24 53.45 10.55 49.10 10.82 48.49 10-oracle 1-best 8,416K 10.70 47.63 10.83 48.88 10.76 46.00 10-oracle 10-best 13,759K 11.24 52.85 10.66 49.81 10.85 48.41 sentence-BLEU 14,587K 11.10 51.17 10.82 49.97 10.86 47.04 by 10-oracle and 10-best list.
The word class3 with surfaceform avoided the overfitting problem.
Even the 1oracle 1-best configuration achieved significant im provements over the baseline system.
Online discriminative training has already been studied by Tillmann and Zhang   and Lianget al  .
We have integrated RAP into McCord's (1989a, 1989b) Logic-Based Machine Translation System (LMT).
2.1.1 The Syntactic Filter on Pronoun—NP Coreference.
2.1.2 Test for Pleonastic Pronouns.
Antecedent NP--lexical anaphor pairs. computer.18 - itself.22 Anaphor--Antecedent links. itself.
Antecedent NP--lexical anaphor pairs.
John.1 - himself.6, Bill.4 - himself.6 Anaphor--Antecedent links. himself.
Non-coreferential pronoun--NP pairs. it.1 - key.9, it.1 - line.16, it.1 - they.18, they.18 - it.1 Anaphor--Antecedent links. it.
(2.1) to emacs.
The parallelism reward causes num ber.
(2.8) is sentence recency.
Lexicalization has been shown to improve parsing performance for the Penn Treebank (e.g., Carroll and Rooth 1998; Charniak 1997, 2000; Collins 1997).
Each context-free rule RHS —* LHS is annotated with an expansion probability P(RHS|LHS).
The head-lexicalized model of Carroll and Rooth   has been applied to German by Beil et al. (1999, 2002).
Of particular relevance are the paraphrasing work by Buzek et al.   and Denkowski et al.
References E. Brill and R. Moore.
2000.
P.F.
Brown, S.A. Della Pietra, V.J.
Della Pietra, and R. Mercer.
1993.
1949.
H-H. Chen, S-J.
Huang, Y-W. Ding, and S-C. Tsai.
1998.
1993.
M. Covington.
1998.
J. Hajie, J. Hric, and V. Kubori.
2000.
Cesilko : Machine translation between closely related lanof ANLP, 7-12.
Jelinek.
1997.
Z. Kirshner.
1982.
Explizite Beschreibung der Sprache und automa- Textbearbeitung, Knight and J. Graehl.
1998.
Machine transliter- Linguistics, E. Ristad and P. Yianilos.
1998.
PAMI, G. Satta and J. Henderson.
1997.
String transforlearning. of ACL/EACL, 444- 451.
M. Simard, G.F. Foster, and P. Isabelle.
1992.
If N1 —* β1 and N2 —* β2 are tied then the tying relation defines a one-to-one mapping between rules in RN, and RN2, and we say that N1 and N2 are tied nonterminals.
Note that like CFGs, split-head bilexical CFGs can be made probabilistic.
For nonterminals N ∈6 B, R′N = RN.
We call this EVG smoothed-skip-val.
We call this EVG smoothed-skip-head.
If a word ie is the k—th candidate for word ic, then wite wite /ki.
Some of the early statistical terminology translation methods are (Brown et al., 1993; Wu and Xia, 1994; Dagan and Church, 1994; Gale and Church, 1991; Kupiec, 1993; Smadja et al., 1996; Kay and Roscheisen, 1993; Fung and Church, 1994; Fung, 1995b).
2eg.
Yamron et al.   briefly mention a pattern-matching approach, while Arbabi et al.
We back-transliterated these 222 phrases.
A first-name/last-name model would rank richard bryan more highly than richard brian.
So we get long wyden instead of ron wyden.
That is, Fi = 1 iff Xj = xj for all (Xj,xj) E Fi.
3.1 SNoW Learning Architecture.
10.
i=1 |P|?
c=1 piczic, subject to |P|?
Suppose arguments Sj1 , Sj2 , Sj3 are consecutive.
If Sj3 isC-V, then Sj1 and Sj2 have to be V and A1, respec tively.
In Prec.
F?=1 1st-phase, non-overlap 70.54 61.50 65.71 1st-phase, All Const.
70.97 60.74 65.46 2nd-phase, non-overlap 69.69 64.75 67.13 2nd-phase, All Const.
For example, the Spanish sentence Es positivo llegar a un acuerdo sobre los procedimientos, pero debemos encargarnos de que este sistema no sea susceptible de ser usado como arma politica. may translate as It is good reach an agreement on procedures, but we must encargarnos that this system is not susceptible to be usado as political weapon. what is more, the relevant cost dynamic is completely under control im Ÿbrigen ist die diesbezŸgliche kostenentwicklung völlig unter kontrolle wir sind es den steuerzahlern schuldig die kosten unter kontrolle zu haben we owe it to the taxpayers to keep in check the costs The strategy that we employ for dealing with unknown source language words is to substitute paraphrases of those words, and then translate the paraphrases.
Dyer et al., 2010).
The Chinese2004), and to determine the significance of MT re- English systems were optimized 300 times, and the sults (Och, 2003; Koehn, 2004; Zhang et al., 2004; German-English systems were optimized 50 times.
Zhang and Vogel, 2010).
The cdec ing  .
Cer et al.   Results are reported using BLEU  , METEOR5  , and TER  .
The features mdist 3mf3p and mdist 3n (21, 22) are refinements of the mdist feature.
E.g.
Paul et al.   presented a corpus-based anaphora resolution algorithm for spoken dialogue.
Acknowledgements.
Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al.
2006, 2007; Gim6nez and Mˆrquez 2007a, 2008).
Senti ment expressions may describe the mood of thewriter (happy/sad/bored/grateful/...)
Others combine additional feature types for this decision (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Wilson et al, 2005; Bloom et al, 2007; McDonald et al, 2007; Titov and McDonald, 2008a; Melville et al, 2009).
Strapparava and Mihalcea   classify blogposts and news headlines to six sentiment cate gories.While most of the works on sentiment analysis focus on full text, some works address senti ment analysis in the phrasal and sentence level, see (Yu and Hatzivassiloglou, 2003; Wilson et al,2005; McDonald et al, 2007; Titov and McDon ald, 2008a; Titov and McDonald, 2008b; Wilson et al, 2009; Tsur et al, 2010) among others.
242
We used ? = ? = 0.1 in all experiments.This pattern based framework was proven effi cient for sarcasm detection in (Tsur et al, 2010; 2Note that the FH and FC bounds allow overlap between some HFWs and CWs.
243 Davidov et al, 2010).
4.1 Twitter dataset.
4.2 Hashtag-based sentiment labels.
The Twitter dataset contains above 2.5 million dif ferent user-defined hashtags.
4.3 Smiley-based sentiment labels.
5.1 Evaluation using cross-validation.
Multi-class classification.
ha haha...wth am I doing?
ing any sentiment6.
Thus f 0.48 in both the F2-21 subcorpora and the F22 corpus.
Parent appends to each nonroot nonterminal node's label its parent's category.
SBR-9720368 and SBR-9812169.
Minimum Bayes-Risk  .
For N-best MBR, we use N-best lists of size 1000.
The most relevant prior work is (Wiebe et al. 98), who dealt with meeting scheduling dialogs (see also (Alexandersson et al.
3.1 Experimental set-up.
3.2 Results.
4.2 Results.
co-occurrences.
Baldwin et al   explore empiricalmodels of compositionality for noun-noun com pounds and verb-particle constructions.
and ?to2Other tests for compositionality investigated by Mc Carthy et al   do much better.
AcknowledgementsThis work was funded by a UK EPSRC stu dentship to the first author, UK EPSRC project GR/S26408/01 (NatHab) and UK EPSRC project GR/N36494/01 (RASP).
The L1 penalty outperformed L2 and mixtures of L1 and L2.
Pharaoh, a state-of-the-art phrase-based MT sys- 2 Word Sense Disambiguation tem  .
The relatively small im- P_1, P0, and P+1, where P0 is the POS of w, and provement reported by Cabezas and Resnik   P_1 (P+1) is the POS of w_1 (w+1).
The integration is accomplished by introduc- nese lexical-sample task.
Furthermore, note that Hiero+WSD has higher n-gram precisions than Hiero.
An interesting example is the translation of the Chinese sentence “A� i� IRR �� �� Ã~ Rz Í õ �� ”.
D. Chiang.
2005.
In Proc. of ACL05, pages 263– 270.
For example, Johnson et al.   and Riezler et al.
Then hk E .77i+1 if and only if Φ(hk) · α¯ > θk.
Features F0 − F10 fire at non-terminal nodes.
0347631.
CoNLL-2011 Shared Task: Modeling Unrestricted Coreference in OntoNotes
The de facto standard datasets for current coreference studies are the MUC   and the ACE1   corpora.
4.0 data.
HR0011-06-C-0022.
S. D. G. rewrites in Chinese-English translation between string-to-string (s-to-s) and fuzzy tree-to-tree (t-tot) grammars.
E-mail: ja-goldsmith@uchicago.edu.
See Tables 10 and 11.
11.
We can rewrite tim t)robal)ility Pr(fille~) t) 3, in- troducing the hidden alignments ai 1 := al ...aj...a.l (aj C {0 , .
The different alignment models we present pro- vide different decoInt)ositions of Pr(f~,a~le().
An alignnlent 5~ for which holds a~ = argmax Pr(fi , al[eI) at for a specific model is called V i terb i  al ignment of" this model.
We t)roI)ose to measure the quality of an alignment nlodel using the quality of tlle Viterbi alignment compared to a manually-produced align- ment.
Therefore, to produce tlle refer- ence alignment we use a relined annotation scheme which reduces the complications and mnbiguities oc- curring in the immual construction of a word align- ment.
2 Al ignment  w i th  HMM In the Hidden-Markov alignment model we assume a first-order dependence for tim aligmnents aj and that the translation probability depends Olfly on aj and not  Oil (tj_l: - ~- el) =p(ajl.
In our extleriments we set pIl = 0.2.
The hunxan-annotated align- ment does not prefer rely translation direction and lnay therefore contain many-to-one and one-to-many relationships.
Train Sente iH : ( i s Words Vocalmlary Dictionary Entries Words Test Sentences Words German I English 34 446 329 625 / 343 076 5 936 ] 3 505 4 183 4 533 I 5 324 354 3 109 I 3 233 Tal)le 1 shows the characteristics of training and test corlms used in the alignment quality ext)eri- inents.
We conclude that more sophisti- cated alignment lnodels are crtlcial tbr good align- ment quality.
Interestingly, the siinl)ler HMM aligninent model outt)erforms Model 3 which shows the importance of first-order align- ment models.
AER [%] Det)endencies -IIMM I Model 4 no 8.0 6.5 source 7.5 6.0 target 7.1 6.1 source ?
Train S ~e,t Sentences Words Vocabulary Se l l te l lees Words PP (trigram LM) I German English 58332 519523 549921 7 940 4 673 147 1968 2173 (40.3) 28.8 For tile evMuation of the translation quality we used the automatically comlmtable Word Error Rate (WEll.)
Alignlnent Model in Training WER[%] SSER[%] Model 1 49.8 22.2 HMM 47.7 19.3 Model 4 48.6 16.8 The results are shown in Table 5.
References Y. A1-Onaizan, J. Cur]n, M. Jahr, K. Knight, J. Laf- ferty, I. D. Melamed, F. a. Och, D. Purdy, N. A. Smith, and D. Yarowsky.
edu/ws99/proj ects/mt/ f inal_report/mr- f inal-report, ps.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer.
The mathenlatics ofsta- tistical machine trmlslation: Parameter estima- tion.
R. Kneser and H. Ney.
Technical Report 98-07, IRCS.
S. Niegen, F. J.
()ch, G. Leusch, and H. Ney.
F. J. Och, C. Tilhnalm, mid H. Ney.
of the Joint SIGDAT Co~?
S. Vogel, H. Ney, and C. Tilhnann.
Verbmobil: Translation of face- to-face dialogs.
1997.
Giacomo Ferrari.
1998.
Relations may be mononuclear or multinuclear.
Woods et al. 1976; Klatt 1980).
Eilenberg 1974).
The accepting automata for regular n-relations are the n-way finite-state transducers.
A path-string for any finite-state transducer T is a (possibly empty) sequence of symbol-pairs u1: v1 u2: v2 .
Let T1 and T2 be E-free acceptors for R1 and R2 and construct an fsm P that accepts the regular pairsymbol language Paths(Ti) - Paths(T2).
These appear as apartmanlarim 'my apartments' and adreslerim 'my addresses.'
Putting all these bracket-restrictions together, the language nLeftcontext(Ak , <k, >k)m—k has each subrule's left-context duly marked by one of that subrule's left-context brackets.
Corresponding substrings belong to 7r*.
Eq.
Eq.
Thus it follows that maxpfig, ..., fNgq~maxpf1, ..., fNqg < ~fg for some -yR.
Stochastic Lexicalized Tree-Adjoining Grammars
more than one context-free rule cannot be captured un- der the context-freeness a sumption.
Lexicalized tree-adjoining grammars (LTAG) t com- bine hierarchical structures while being hxieany sensi- tive and are therefore more appropriate for statistical analysis of language.
ACTES DE COLING-92.
NANTES, 23-28 AOUT 1992 4 2 6 PROC.
x~\[..m\] x~\[$p~\] x0\[..po\] -~ Xl\[$pd x~\[-.p~\] Xo\[$Po\] --~ Xl\[$pl\] X2\[$p2\] where Xk E Vjv, a E VT and po ~.
Prodsuch 2LIGs have been shown to be weakly eqtfivalent to "Ibee- Adjoining Graramars  .
ACIES DE COLING-92, NANTES, 23-28 AO~rf 1992 4 2 7 P~oc.
23-28 AOt~T 1992 4 2 8 PROC.
4 Ins ide -Ous ide A lgor i thm for.
le L\[..T1\] .-* t\[..yqv\] is used, and (17) to th . . .
age number of times no adjunction occnrred on T/.
AcrEs OE COLING-92, NANTES.
23-28 AOOT 1992 4 2 9 DROC.
OF COLING-92, NANTES, AUG. 23-28, 1992 set of the Air Travel hfformation System  .
16 14 12 i0 SCFG .....
Preliminary experiments with a context-free subset of SLTAG confirms that SLTAG enables faster conver- gence than stochastic ontext-free grammars (SCFG).
In collaboration with Aravind Joshi, Fernando Pereira and Stuart Slfieber, we are currently investigat- ing additional algorithnLs and applications for SLTAG, methods for lexical clustering and autonratic onstruc- tion of a SLTAG from a large training corpus.
Aho, A. V. 1968.
Baker, J.K. 1979.
llooth, Taylor R. and Richard A. Thoml)son.
1973.
Chomsky, N., 1964.
Gazdar, G. 1985.
tlempttill, Charles T., John J. Godfrey, and George IL Doddington.
1990.
The ATIS spoken language sys- tems pilot corpus.
Jelinek, F., J. D. Lafferty, and R. L. Mercer.
1990.
Joshi, Aravind K. and Yves Schabes.
1991.
Tree- adjoiuing grammars and lexiealized grammars.
In Maurice Nivat and Andreas Podelski, editors, Defin- ability and Recognizability ofSets of Trees.
Elsevier.
Joshi, Aravind K., K. Vijay-Simnker, and David Weir.
1991.
Joshi, Aravind K. 1987.
John Beujamins, Amster- dana.
Lari, K. and S. J. Young.
1990.
ACRES DE COL1NG-92, NANTES, 23-28 AO~r 1992 4 3 1 PROr'..
OI: COLING-92, NANTES, AUG. 23-28, 1992 Pereira, Fernando and Yves Schabes.
1992.
Inside- outside reest imation from partial ly bracketed cor- pora.
1942.
1991.
Lexicalized tree-adjoining ram- mar for distr ibutional analysis.
Schabes, Yves, Anne Abeill~, and Aravind K. Joshi.
1988.
In Proceed- ings of the 1~ lh International Conference on Compu- tational Linguistics (COLING'88}, Budapest, Hun- gary, August . Sehabes, Yves.
1990.
1991.
An inside-outside algor i thm for est imat ing the parameters of a hidden stochastic context-free grammar based on Earley's algorithm.
Shannon, C. E. 1948.
A mathemat ica l theory of communicat ion.
Shannon, C. E. 1951.
Vi jay-Shanker, K. and David J. Weir.
1991.
Pars ing constrained grammar formalisms.
Vi jay-Shanker, K. 1987.
Then, we classify {xsi jNs i�1using �θt,l.
The core 12K 10K matrix was reduced using SVD to a 12K×300 matrix.
Does Baum-Welch Re-Estimation Help Taggers?
Dtd.
6/21/1998.
T. Koo was funded by NSF grant IIS-0415030.
HR0011-06-C-0022.
Clustering Polysemic Subcategorization Frame Distributions Semantically
Brew and Schulte im Walde  ).
110 test verbs were chosen from this gold standard, 78 polysemic and 32 monosemous ones.
Thanks to P.-K. Halvorsen, U. Heid, H. Kamp, M. Kay and C. Rohrer for discussion and comments.
Features range from words and morphological information   to the inclusion of part-of-speech tags (Minnen et al., 2000; Han et al., 2004, 2006; Chodorow et al., 2007; Gamon et al., 2008, 2009; Izumi et al., 2003, 2004; Tetrault and Chodorow, 2008) to features based on linguistic analysis and on WordNet (Lee, 2004; DeFelice and Pulman, 2007, 2008).
Finally, Yi et al.   and Hermet et al.
Recent research has treated paraphrase acquisition and generation as a machine learning problem (Barzilay & McKeown, 2001; Lin & Pantel, 2002; Shinyama et al, 2002, Barzilay & Lee, 2003, Pang et al., 2003).
Koehn et al. 2003).
Sumita 2001).
TnT - A Statistical Part-Of-Speech Tagger
Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger.
T2.
T3.
T4.
T5.
A1.
A2.
Steps T2, T4 and A2 are trivial.
GTM30 0.87 0.81 0.91 0.79 0.67 0.90 0.83 0.77 0.87 0.73 0.62 0.83 0.83 0.77 0.88 0.71 0.60 0.83 1.
GTM 10, 20, and 30 are general text matcher exponents of 1.0, 2.0, and 3.0.
It ranges from +1 to -1.
ROUGE-L, ROUGE-W, ROUGE-S*, ROUGE-S4, and ROUGE-S9 were performers to measuring fluency.
However, S2 has a ROUGE-L score of 3/4 = 0.75 and S3 has a ROUGE-L score of 2/4 = 0.5, with ,B = 1.
Therefore S2 is better than S3 according to ROUGE-L.
We call the LCS-based Fmeasure, i.e.
Melamed et al.   used unigram F-measure to estimate machine translation quality and showed that unigram F-measure was as good as BLEU.
BLEU-2 would prefer S4 over S3.
Equation 12, ROUGE-W.
We call the skip-bigram-based Fmeasure, i.e.
Equation 15, ROUGE-S.
Using Equation 15 with ,B = 1 and S1 as the reference, S2’s ROUGE-S score is 0.5, S3 is 0.167, and S4 is 0.333.
Therefore, S2 is better than S3 and S4, and S4 is better than S3.
Comparing skip-bigram with LCS, skip-bigram counts all in-order matching word pairs while LCS only counts one longest common subsequence.
GTM 10, 20, and 30 are general text matcher with exponents of 1.0, 2.0, and 3.0.
It ranges from +1 to -1.
Grosz et al.   and Brennan et al.
= utty and pos.
Kameyama's   intra-sentential centering operates at the clause level.
Table 4 gives a comparison of BBN's HMMbased Identifinder   and NYU's MENE and MENE-Proteus systems on different training and test sets.
1998.
Using String-Kernels For Learning Semantic Parsers
next to, [5..7]) the5 states6 bordering7 (STATE?
TRAVERSE(STATE), [1..9]) (TRAVERSE?traverse, [1..7]) Which1 rivers2 run3 through4 the5 states6 bordering7 (STATE?
as the constant substring for the produc tion ?STATEID ? ?texas?.
4.1 Methodology.
4.2 Results.
For 160 trainingexamples it gave 49.2% precision with 12.67% re call.
4.4 Experiments with Noisy NL Sentences.
Experimental results on the TREC datasets demonstrate im provements over state-of-the-art models.
Sun et al   incorporate semantic analy sis in their TREC05 QA system.
Kaisser   proposes a 13 SemStruc ac1SemStruc ac2 SemStruc aci SemStruc q Sent.
We require that EAPs are frame elementsof SemStrucq.
Rather than disambiguiting polysemous pred icates prior to semantic role assignment, we performthe assignment for each frame evoqued by the pred icate.
Phenomenon Ground State Evidence EAP prions 0000 0.01 0.1 0.05 0.05 0.02 0.06 Cognizer.
Phenomenon Ground State Evidence EAP prions 0.1 0.05 0.05 0.02 SemStruc ac (ac: Stanley B. Prusiner) p: discovery Original SR assignments: Optimized SR assignments: 0.25 Cognizer.
Phenomenon Topic Evidence ac prions 0.15 0.2 0.16 0.25 Cognizer.
The expectedanswer phrase (EAP) who and the answer candi date Stanley B. Prusiner are assigned the COGNIZERrole.
The similarity between two subgraphs SubG1, and SubG2 is then formalized as: (5) Sim(SubG1,SubG2) = ? ndSR1 ? SubG1 ndSR2 ? SubG2 ndSR1 = ndSR2 1 |s(ndw,ndSR1 )?
s(ndw,ndSR2 )|+1where, ndSR1 and ndSR2 are semantic role nodes con nected to a frame element node ndw in SubG1 and 2The software is available from http://www.magiclogic.
We used the FrameNet V1.3 lexical database.It contains 10,195 predicates grouped into 795 se mantic frames and 141,238 annotated sentences.
7The software is available from http://www.coli.
If FrameNet is indeedhelpful for QA, we would expect an ensemble sys Model TREC02 TREC03 TREC04 TREC05 SemParse 13.16 8.92 17.33 13.16 SynMatch 35.53?
33.04?
40.00?
36.84?
SemMatch 53.29??
Model TREC02 TREC03 TREC04 TREC05 SynMatch 32.88?
30.70?
35.95?
34.38?
+SemParse 25.23 23.68 28.57 26.70 +SemMatch 38.96??
and EPSRC (Lap ata; grant EP/C538447/1).
The following is an example: Yuehan da-sui le huapin.
Yuehan sui le huapin.
A translation with a causation verb is also anomalous: * V* ft tifa ff T. Yuehan shi huapin sui le.
300-307.
Accuracies of 90-94% are typical.
Veale   used WordNet to answer 374 multiple-choice SAT analogy questions, achievingan accuracy of 43%, but the best corpus-based ap proach attains an accuracy of 56%  .
1http://www.informatics.susx.ac.uk/research/groups/nlp/ carroll/morph.html.
3http://www.wumpus-search.org/.
Turney et al   used a combination of 13 independent modules.
The 80 TOEFL questions yield 320 (80 ? 4) word pairs, 80 labeled positive and 240 labelednegative.
We apply PairClass to the word pairs us ing ten-fold cross-validation.
909
Turney and Littman   used corpus-based features for classifying noun-modifier pairs.
Tur ney   later addressed the same problem using 8000 automatically generated patterns.One of the tasks in SemEval 2007 was the clas sification of semantic relations between nominals  .
This considerably simpli fies the algorithm.
WordNet includes more thana dozen semantic relations (e.g., synonyms, hy ponyms, hypernyms, meronyms, holonyms, and antonyms).
911
2006AA010108 (H. M.), and by NSF ITR EIA0205456 (L. H.).
Stefan Ortmanns, Hermann Ney, and Xavier Aubert.
1997.
Christoph Tillmann and Hermann Ney.
2000.
Word re-ordering and DP-based search in statistical matranslation.
In '00: The 18th Int.
2.3 Inference See MacKay and Peto   for a derivation.
Zipf, G. K., The meaning-fxequency relationship of words.
Yarowsky, D., Word-sense disambiguation using statisti- cal models of Rogets categories trained on large corpora, COLING-9~, 1992.
Voorhees, E. M., Leacock C., and Towell, G., Learning context o disambiguate word senses.
Sta- tistical Research Report 104, AT&T Bell Laboratories, 1992.
Choueka Y. and Lusignan, S., Disambiguation by short contexts.
Communications of the ACM, 18(11):613-620, 1975.
in Rumelhart, D. E. and McCleUand, I. L.
More  accurate  tes ts  Ibr the  s ta t i s t i ca l  s ign i f i cance  of resu l t d i f ferences  * Alexander  Yeh Mitre Corp. 202 Burli l lgl;on Rd.
Bedford,  MA 01730 USA asy~mit rc .o rg Abstract Statisti(:a,1 signiticance testing of (litlerelmeS in v;~hl(`-s of metri(:s like recall, i)rccision and bat- au(:(~(l F-s(:()rc is a ne(:(`-ssary t)art of eml)irical ual;ural language 1)ro(:essing.
Warren Grcit[, l ,ynette Il irschlnm b Christilm l)orall, John llen(lerson, Kelmeth Church, Ted l)unning, Wessel Kraaij, Milch Marcus and an anony- mous reviewer l)rovided hell)rid suggestions.
Copyright @2000 The MITRE Corl)oration.
This mtderest imate comes flom these lnc|h- ells assuming l;hat; the te(:hlfi(tues being con> lmrcd produce indepen(lc, nt results when in our eXl)eriments , the techniques 1)eing COml)ared tend to 1)reduce l)ositively corr(`-lated results.
For such com- 1)lex lne|;ri(;s~ we llSe a colnplll;e-in|;Clisiv(~ ran- domization test (Cohen, 1995, Sec.
5.3), which also ~tvoids this indet)en(lence assmnption.
3) o -2 o-12 + a~ d = --  2p12a10-2 where cri is the true standard eviation (instead of the estimate si) and pl2 is the correlation coefficient between xl and :c2.
When Xl and x2 are independent, p12 = 0, and then (Td = ~-+ c7~ and analogously, Sd = ~ + s~.
From Box et al.
Next;, the transformatiol>rulc t)ased t.cch- nique was rUll with diflerent sets of start ing con- ditions and/or  different, but overlapl)ing , sub- sets of the training set.
A total of 40 compar- isons were made..
24 of the rj2s wore in the 0.50--0.79 range.
An easy--to-analyze case is when the stan- dard devial,ions for the results being eoml)ared a:tc the same.
If one, assumes the re.sults me indcpel:dent (~/SSllllle r,2 = 0), then sd :-~ .sv/22.
Call this wflue sd-i,7,g.
As flu increases in value, Sd decreases: [().38 d 0.T87(sd_i,,d) 1.27 [p.ao I 1.41 [O.80J 0.447(Sd.__i.,,.d) 2.24 lhe rightmost cohunn above indicates the mag- nitude by which erroneously assuming indepen- >[lifts is actually roughly true in the coml)arisons nmde, and is assumed to be true in many of the standard Wsts for statistical significance.
v~due, of d appear less statist;i- cally signifiealtt.
4.1) or two-saml)le t (Harnett,  1982, See.
and :c2 can t)e 1)ased on (tiffering num- 1)ers of saml)les.
Call these retail)ors n~ and n2 r(;sl)ectivcly.
The weighting is b~sed on nl and r7,2.
From Harnett (1982, Scc.
8.7), the denominator Sd ~- nl  + n2 - 2 711 -b r~,2 ) i7,177,2 When nl = n2 (call this common value n), ~1 and s2 will be given equal weight, and Sd siml)li- fie.s to ~ + ,s~)/n.
Making the substitut ion described above of si v/57 tbr si leads to an Sd of 949 s 2 the fbrm had earlier for the -t-, 2, we us ing independence assumption.
The corm- lation coefficient estilnate tor R is 0.35 mid the data is Method 17, 5 t?recision 1 47 48 4!
Similmly, the (lenomimd;or .sd is now esl;inml;ing l;he si;a.ndmd (leviation of l;hese diflerenee wdues, instead of being a funcl;ion of s:l and su.
This is because both precision and F-score ~tre more coml)licated non- linem flmci;ions of rml(lom varial)lcs than recall.
951 3.3 Using randomizat ion fbr precision and F -score A class of technique that ean handke all ldnds of flmetions of random variables without the above problenls is the computationally-intellsive ran- domization tests (Noreen, 1989, Ch.
These tests have previously used on such flmctions during the "message un- derstanding"  .
5One examI)le is the RANDU routine on the IBM360 (Forsythe t al., 1977, See.
: hand l ing  in ter -smnple dependenc ies An assmnption made by all I;he methods men- tioned in this I)~tl)er is ttmt the nlenlbcrs of the Lest set are all independent of one anothex.
Church and Mercer   give some exaln- ples of dependence bctwe.en test set insl;ances ill na tura l  la.llguage.
Re ferences G. Box, W. Hunter, and J. Hmlter.
1978. ,gta, iisl.ics for" <rpc.rim.ent, er.~.
N. Chinchor, L. Hirschman, and l).
K. Church mid 171.. Mercer.
G. Forsythe, M. M~dcolm, and C. Moler.
Com, putcr methods for ~nathcm, atical compu- l.ati~m,.s.
Addison-XYesley Publishing Co., 3rd edi- tion.
R. Larsen and M. Marx.
An Introduc- tion to Ma, th, cmatical Statistics and Its Appli- cations.
[br testing h, ypoth, cscs: an int, rodttction.
Jolm Wiley and Sons, Inc. 953
French (.7') Voila ce qui interesse le consommateur et voila ce que interesse notre parti.
Les deputes d'en face se moquent du gel que a propose notre parti.
Pour eux, c'est une mesure risible.
The correct alignment maps El and E2 to F1 and F2 to nothing.
���������� ���������� ���������� ���������� ���������� ���������� ���������� ���������� ��������� ��������� ��������� ��������� ��������� ��������� ��������� ��������� ��������� ��������� �������� �������� ������� ������� ������� ������� ������ ������ E......... .....r,:: ����� ����� ����� ����� ���� ���� is assigned to the category for which it receives the highest score.
Another area related to our work is opinion expressions identification (Wilson et al., 2005a; Breck et al., 2007).
SCL-MI achieves 79.7% and the in-domain gold standard is 80.4%.
We also note that while Florian et al.   and Blitzer et al.
NBCHD03001.
The 17-tags English tagset allows for V-V transitions.
We use the following 3 context templates: LL=w_2,w_1, LR=w_1,w+1 and RR=w+1,w+2.
EM-HMM, a second-order EM-HMM initialized with the estimated p(t|w).
BHMM is the completely Bayesian-HMM of GG.
Accurate Unlexicalized Parsing
“ DT “ NPˆS VBZ VPˆVP VPˆS !
The F1 after UNARY-INTERNAL, UNARY-DT, and UNARY-RB was 78.86%.
TAG-PA brought F1 up substantially, to 80.62%.
TMP-NP brought the cumulative F1 to 82.25%.
This brought F1 to 82.28%.
The Treebank uses 17 non-terminal labels and 240 tags.
The parse base is 1.35 parses/word.
Extensibility.
Modularity.
Recent work includes (Copestake, 2000; Baldridge et al., 2002a).
gious of CeBIT's 23 hal Is." tile anaphora resolutkm algorithm would be presented with the h}llowing analysis tream.
lar, the grammatical function information (e.g., @SUl~J, O)q.FMAINV) and the integer values (e.g., "offt 39") asso- cia ted with each token.
"For /o f f139" "for" PREP @ADVL "1995/o f f140 ....
1995" NUM CARD @<P " the/o f f l41" "the" DET CENTRAL ART SG/PL @DN> "company/o f f142" "company" N NOM SG/PL @SUBJ "set/off143" "set" V PAST VF IN @+FMAINV "up/of f144" "up" ADV ADVL @ADVL " i t s /o f f145 .... it" PRON GEN SG3 @GN> "headquar ters /o f f146 .... headquar ters" N NOM SG/PL @OBJ " in /o f f147 .... in" PREP @<NOM @ADVL "Ha l l /o f f148 .... hal l" N NOM SG @NN> " l l /o f f149" "Ii" NUM CARD @<P "$ , /o f f l50 ....
," PUNCT " the/o f f l51" "the" DET CENTRAL ART SG/PL @DN> "newest /o f f152 .... new" A SUP @PCOMPL-O "and/of f153 .... and" CC @CC "most /o f f154" "much" ADV SUP @AD-A> "pres t ig ious /o f f155 .... p res t ig ious" A ABS @<P "of /o f f156 .... of" PREP @<NOM-OF "CeBIT ' s /o f f157" "cebit" N GEN SG @GN> "23/0f f158 ....
23" NUM CARD @QN> "ha l l s /o f f159 .... hal l" N NOM PL @<P "$ . /o f f160 ....
PUNCT 2.1 Data collection.
2.2 Anaphora resolution.
SENT-S: 100 iff in the current sentence CNTX-S: 50 iff in the current context SUBJ-S: 80 iff GFUN = subject EXST-S: 70 iff in an existential construction POSS-S: 65 iff GFUN = possessive ACC-S: 50 iff GFUN = direct object DAT-S: 40 iff GFUN = indirect object OBLQ-S: 30 iff the complement of a preposition HEAD-S: 80 iff EMBED = NIL ARG-S: 50 iff ADJUNCT = NIL Note that the values of salience factors are arbitrary; what is crucial, as pointed out by  , is the relational structure imposed on the factors by these values.
Our values for CNTX-S and POSS-S were de- termined using similar tests.
For 1995 the com- pany set up its headquarters in Hall 11, the newest and most prestigious of CeNT's 23 halls."
'l'he following text segment illust rates the resolution of in tersen ten tia l a napho ra.
"Sun's prototype lntemet access device uses a 1-10-Mhz MicroSPARCprocesso~; and is diskless.
sions.
Long-Distance Dependency Resolution In Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations
We extract LFG subcategorisation frames and paths linking LDD reentrancies fromf-structures generated automatically for the PennII treebank trees and use them in an LDD resolu tion algorithm to parse new text.
Currently we achieve f structure/dependency f-scores of 80.24 and 80.97for parsing section 23 of the WSJ part of the Penn II treebank, evaluating against the PARC 700 and DCU 105 respectively.
Fi nally, we conclude.
Lexical-Functional Grammar   minimally involves two levels of syntactic representation:3 c-structure and f-structure.
The Penn-II treebank employs CFG trees with addi tional ?functional?
Tra ditionally, such resources were handcoded.
We extract 3586 verb lemmas and 10969 unique verbal semanticform types (lemma followed by non-empty argu ment list).
F-structure anno tations allow us to distinguish passive and activeframes.
Without Prep/Part With Prep/Part Lemmas 3586 3586 Sem.
The DCU 105  .
The full 2,416 f-structures automatically gen-.
erated by the f-structure annotation algorithm for the original Penn-II trees, in a CCG-style   evaluation experiment Pipeline Integrated PCFG P-PCFG A-PCFG PA-PCFG 2416 Section 23 trees.
# Parses 2416 2416 2416 2414 Lab.
F-Score 75.83 80.80 79.17 81.32 Unlab.
We achieve between 73.78% and 80.97% preds-only and 83.79% to 87.04% all GFs f-score, depending on gold-standard.
Table 8 shows the evaluation result brokendown by individual GF (preds-only) for the inte grated model PA-PCFG against the DCU 105.
+LDD res.
Our method of resolv ing LDDs at f-structure level results in a preds-only f-score of 80.97%.
  present a Penn-II treebank based HPSG with log-linear probability mod els.
The method achieves a preds-only f-score of 80.97% for f-structures with the PA-PCFG in the integrated architecture against the DCU 105and 78.4% against the 2,416 automatically gener ated f-structures for the original Penn-II treebanktrees.
ITG.
Simard et al.   give examples such as English verb-particle constructions, and the French negation ne... pas.
The Romanian/English and Hindi/English data came from Martin et al.  .
For Chinese/English and Spanish/English, we used the data from Ayan et al.  .
E.g.
See http://nlp.cs.nyu.edu/GenPar/ACL06for more examples.
That is, pj(xj, y; 0j)=Qc pj(xjc, yc; 0j).
Let us introduce A0=(A1, ..., AI, AI+1, .
SSL based on a hybrid generative/discriminative approach proposed in   has been defined as a log-linear model that discriminatively combines several discriminative models, pDi , and generative models, pGj , such that: where Λ={λi}Ii=1, and Γ={{γi}Ii=1, {γj}I+J j=I+1}.
For example, {Xu}s+2 u�s_2 is equal to five feature templates, {Xs_2i Xs_1i Xsi Xs+1i Xs+2}.
ITG has been extensively explored in unsupervised statistical word alignment (Zhang and Gildea, 2005; Cherry and Lin, 2007a; Zhang et al., 2008) and machine translation decoding (Cherry and Lin, 2007b; Petrov et al., 2008).
Initially, as in Taskar et al.   and Moore et al.
This yielded 30.6 AER.
The oracle AER computed in this was is 10.1 for A1-1 and 10.2 for AITG.
Log-linear models have previously been applied to statistical parsing (Johnson et al. 1999; Toutanova et al.
Statistical parsers have been developed for TAG  , LFG (Riezler et al. 2002; Kaplan et al.
2004; Cahill et al. 2004), and HPSG (Toutanova et al.
2002; Toutanova, Markova, and Manning 2004; Miyao and Tsujii 2004; Malouf and van Noord 2004), among others.
Combinatory Categorial Grammar (CCG) (Steedman 1996, 2000) is a type-driven lexicalized theory of grammar based on Categorial Grammar  .
The treebank is CCGbank (Hockenmaier and Steedman 2002a; Hockenmaier 2003a), a CCG version of the Penn Treebank  .
10.2.1 Dependency Model vs. Normal-Form Model.
Sagae and Lavie   is a classifier-based linear time parser.
NVliyao and Tsujii   evaluate their HPSG parser against PropBank  .
The results for CCGbank were obtained using the oracle method described previously. aux 93.33 91.00 92.15 95.03 90.75 92.84 96.47 90.33 93.30 400 conj 72.39 72.27 72.33 79.02 75.97 77.46 83.07 80.27 81.65 595 ta 42.61 51.37 46.58 51.52 11.64 18.99 62.07 12.59 20.93 292 det 87.73 90.48 89.09 95.23 94.97 95.10 97.27 94.09 95.66 1,114 arg mod 79.18 75.47 77.28 81.46 81.76 81.61 86.75 84.19 85.45 8,295 mod 74.43 67.78 70.95 71.30 77.23 74.14 77.83 79.65 78.73 3,908 ncmod 75.72 69.94 72.72 73.36 78.96 76.05 78.88 80.64 79.75 3,550 xmod 53.21 46.63 49.70 42.67 53.93 47.64 56.54 60.67 58.54 178 cmod 45.95 30.36 36.56 51.34 57.14 54.08 64.77 69.09 66.86 168 pmod 30.77 33.33 32.00 0.00 0.00 0.00 0.00 0.00 0.00 12 arg 77.42 76.45 76.94 85.76 80.01 82.78 89.79 82.91 86.21 4,387 subj or dobj 82.36 74.51 78.24 86.08 83.08 84.56 91.01 85.29 88.06 3,127 subj 78.55 66.91 72.27 84.08 75.57 79.60 89.07 78.43 83.41 1,363 ncsubj 79.16 67.06 72.61 83.89 75.78 79.63 88.86 78.51 83.37 1,354 xsubj 33.33 28.57 30.77 0.00 0.00 0.00 50.00 28.57 36.36 7 csubj 12.50 50.00 20.00 0.00 0.00 0.00 0.00 0.00 0.00 2 comp 75.89 79.53 77.67 86.16 81.71 83.88 89.92 84.74 87.25 3,024 obj 79.49 79.42 79.46 86.30 83.08 84.66 90.42 85.52 87.90 2,328 dobj 83.63 79.08 81.29 87.01 88.44 87.71 92.11 90.32 91.21 1,764 obj2 23.08 30.00 26.09 68.42 65.00 66.67 66.67 60.00 63.16 20 iobj 70.77 76.10 73.34 83.22 65.63 73.38 83.59 69.81 76.08 544 clausal 60.98 74.40 67.02 77.67 72.47 74.98 80.35 77.54 78.92 672 xcomp 76.88 77.69 77.28 77.69 74.02 75.81 80.00 78.49 79.24 381 ccomp 46.44 69.42 55.55 77.27 70.10 73.51 80.81 76.31 78.49 291 pcomp 72.73 66.67 69.57 0.00 0.00 0.00 0.00 0.00 0.00 24 macroaverage 62.12 63.77 62.94 65.71 62.29 63.95 71.73 65.85 68.67 microaverage 77.66 74.98 76.29 81.95 80.35 81.14 86.86 82.75 84.76 The CCG parser results are based on automatically assigned POS tags, using the Curran and Clark   tagger.
# GRs is the number of GRs in DepBank.
Formalism-Independent Parser Evaluation with CCG and DepBank
  gold-standard.
A supertagger first assigns 84% F-score on labelled dependencies.
Nonparametric Bayesian methods produce state-of-the-art performance on this task (Goldwater et al., 2006a; Goldwater et al., 2007; Johnson, 2008).
CRPs and PYPs nondeterministically generate infinite sequences of natural numbers z1, z2,.
Goldwater et al. demonstrate that modelling bigram dependencies mitigates this undersegmentation.
0.55 0.72 0.84 0.55 0.72 0.78 0.54 0.66 0.75 0.54 0.70 0.87 0.55 0.42 0.54 0.74 0.83 0.88 0.75 0.43 0.74 0.71 0.41 0.76 0.71 0.73 0.87 0.56 0.74 0.84 0.57 0.75 0.78 0.56 0.69 0.76 0.56 0.74 0.88 0.57 0.51 0.55 0.81 0.86 0.89 0.80 0.56 0.82 0.77 0.49 0.82 0.77 0.75 0.88
A Word-To-Word Model Of Translational Equivalence
(Macklovitch, 1994; Melamed, 1996b)), concordancing for bilingual lexicography  , computerassisted language learning, corpus linguistics (Melby.
The bitext preprocessor for our word-to-word model split hyphenated words, but Macklovitch & Hannan's preprocessor did not.
1999.
K. Koskenniemi, 1983.
C.X.
Res., R. Mooney and M. Califf, 1995.
Res., K. Oflazer and S. Nirenburg, 1999.
D. Rumelhart and J. McClelland, 1986.
P. Theron and I. Cloete, 1997.
A. Voutilainen, 1995.
In F. Karlsson, A. Voutilainen, J. Heikkila, and A.
The Hague: Mouton de Gruyter.
This suffix-focused transformational model is not, as given, sufficient for languages with prefixal, infixal and reduplicative morphologies.
NULL . ed. ing vs. e. ed. ing vs. e. ed. es .ing vs. ted.tion) from raw text.
Thus it was used as the primary ranking criteria (over raw similarity score). shake .00149 5.5 1 shake .854 share .073 shoo .500 shoot .002593 shake .465578 shoot .00126 9.3 2 shave .323 ship .068 shoot .333 shoo .002593 shoot .001296 ship .00104 16.3 3 shape .210 shift .062 shoe .310 shock .000096 shoo .001296 shatter .00061 18.9 4 shore .194 shop .060 shake .290 short .000096 shock .000048 shop .00094 19.8 5 shower .184 shake .058 shop .236 shout .000095 short .000048 shut .00081 20.6 6 shoot .162 shut .052 shout .236 ... ... shove .000048 shun .00039 20.7 7 shock .154 shoot .051 show .236 shake .000003 shore .000048 The extent to which such overlaps should be penalized depends on the probability of seeing variant inflections in the morphology, but for Spanish and English this is relatively low.
Inference In DATR
de Smedt  , Flickinger et al.  , Calder & te Linden  , Daelemans (1987a,1987b), Gazdar   and Calder  .
Touretzky 1986, p34; Evans 1987).
- 70
Gazdar's work was supported by grants from the ESRC and SERC.
hand-retagged using the Penn Treebank tagset.
Co-indexing of null elements is done by suffixing an integer to non-terminal cate- gories (e.g~ NP-10, VP-25).
The *EXP* is auto- matically co-indexed by our annotator workstation software to the postposed clause.
Black, E., Jelinek, F., Lafferty, J., Magerman, D.M., Mercer, R., and Roukos, S. 1992.
Brill, E., Marcus, M., 1992.
Brill, E., 1993.
Francis, W., 1964.
Francis, W. and Ku~era, H., 1982.
Houghton Mifflin, Boston.
Garside, R., Leech, G., and Sampson, G., 1987.
A corpus-based ap- proach.
Hindle, D., and Rooth, M., 1993.
D. Magerman and M. Marcus, 1991.
Marcus, M., Santorini, B., Marcinkiewicz, M.A., 1993.
Quirk, R., Greenbanm, S., Leech, G., and Svaxtvik, J., 1985.
Black, E., Abney, S., Flickenger, F., Grishman, R., Har- rison, P., Hindle, D., Ingria, R., Jelinek, F., Klavans, J., Liberman, M., Marcus, M., Roukos, S., Santorini, B., and Strzalkowski, T., 1991.
We use ITG Viterbi alignments instead.
AER
When αC is 1e − 9, VB gets AER close to .35 at iteration 10.
 , Wilson et al.
2.1 Translation with Non-parallel.
For other methods using non-parallel corpora, see also (Tanaka and Iwasaki, 1996; Kikui, 1999, Koehn and Kevin 2000; Sumita 2000; Nakagawa 2001; Gao et al 2001).
 10000
 10
 10000
3.3 Translation Selection -- EM-TF-IDF.
3.5 Combination.
with Nagata et al?s method.
There were about 1 http://encarta.msn.com/Default.asp 3000 Base NPs extracted.
Best translation result for each method Accuracy (%) Top 1 Top 3 Coverage (%) EM-NBC-Ensemble 61.7 80.3 Prior 57.6 77.6 MT-NBC-Ensemble 59.9 78.1 EM-KL-Ensemble 45.9 72.3 EM-NBC 60.8 78.9 EM-TF-IDF 61.9 80.8 MT-TF-IDF 58.2 77.6 EM-TF 55.8 77.8 89.9 Table 1 shows the results in terms of coverage and top n accuracy.
Nagata et als method
The p-values of the sign tests are 0.00056 and 0.00133 for EM-NBC-Ensemble, 0.00002 and 0.00901 for EM-TF-IDF, respectively.
4.2 Our Method vs. Nagata et als Method.
Translation results Accuracy (%) Top 1 Top 3 Coverage (%) Our Method 61.7 80.3 89.9 Nagata et als 72.0 76.0 10.5 We next used Nagata et als method to perform translation.
4.3 Combination.
4.4 Web Data vs. Non-web Data.
Tweets are limited to 140 charac ters.
3.1 Features.
Meta-features.
38 3.3 Polarity Classifier.
We tried different learning al gorithms available on Weka and SVM obtainedthe best results for Unigrams and TwitterSA.
I/PRP ’m/VBP.
Non-traditional words.
Seung, Opper and Sompolinsky   and Freund et al.   proposed a theoretical queryby-committee approach.
Clark et al.   applies self-training to POS-tagging and reports the same outcomes.
Gildea   and Bacchiani et al.   show that out-of-domain training data can improve parsing accuracy.
Sarkar   and Steedman et al.   investigated using co-training for parsing.
Next, a discriminative reranker reorders the n-best list.
A host of discriminative methods have been introduced (Taskar et al., 2005; Moore, 2005; Ayan 17 and Dorr, 2006).
Liang et al.   shows that thresholding the posterior probabilities of alignments improves AER relative to computing Viterbi alignments.
Our models substantially outperform GIZA++, confirming results in Liang et al.  .
Turkers have message boards at http://www.turkernation.com/,where they discuss Requesters.
3http://wiki.github.com/callison-burch/ mechanical_turk_workshop/geolocation 4http://crowdflower.com/ 3.2 Iterative improvements on MTurk.
In the past two years, several papers have published about applying Mechanical Turk to a diverse set ofnatural language processing tasks, including: cre ating question-answer sentence pairs  , evaluating machine translation qual ity and crowdsouring translations  , paraphrasing noun-noun compouds for Se mEval  , human evaluation oftopic models  , and speech tran scription (McGraw et al, 2010; Marge et al, 2010a; Novotney and Callison-Burch, 2010a).
Deng et al  used MTurk to construct ImageNet, an anno tated image database containing 3.2 million that arehierarchically categorized using the WordNet ontol ogy  .
Wang and Callison-Burch   created data for 7http://sites.google.com/site/ amtworkshop2010/ 5recognizing textual entailment (RTE).
Novotney and Callison-Burch (2010b) used MTurk to elicit new speech samples.
Mellebeek et al   used severalmethods to obtain polarity scores for Spanish sen tences expressing opinions about automative topics.
Yano et al   evaluated the political bias of blogposts.
For further work on MTurk and information retrieval, readers are encouraged to see the SIGIR 2010 Workshop on Crowdsourcing for Search Evaluation.8 8http://www.ischool.utexas.edu/?cse2010/ call.htm 6 6.5 Information Extraction.
Yetisgen-Yildiz et al   explored medical named entity recognition.
Both Ambati and Vogel   and Bloodgood and Callison-Burch   explore thepotential of MTurk in the creation of MT paral lel corpora for evaluation and training.
Denkowski et al   generated and evaluated 728 paraphrases for Arabic English translation.
Buzek et al.
Turkers identified 1780 error regions in 1006 English/Chinese sentences.
Other examples include the CoNLL named entity corpus   with 348 citationson Google Scholar), the IMDB movie reviews senti ment data   with 894 citations) and the Amazon sentiment multi-domain data (Blitzer et al.
New workevaluated active learning methods with real users us ing MTurk (Baker et al, 2009; Ambati et al, 2010; Hsueh et al, 2009; ?).
HR0011-06-2-0001.
Some early formalisations, c.f.
We are using Atro Voutilainen's   improved part-of-speech disambiguation grammar which runs in the CG-2 parser.
Voutilainen and Juha Heikkild created the original ENGCG lexicon.
These sepurposes.
Self-training for SMT was proposed in  .
11 and 12.
10.
DD-5000/DD-250: Dual decomposition with nonprojective head automata, with K = 5000/250.
Meshi et al.  .
581
There are 117,597 Synset nodes.
There are 156,588 TokenPOS nodes.
(hotdog) have un-normalized weights of43.2 and 0.1, respectively.
as computed bythe MarkovLink and MarkovGloss variants.
4.1 Zero-KL Divergence.
R+.
at 8.81.
588
Nymble: A High-Performance Learning Name-Finder
(2.2) Previous approaches have typically used manually constructed finite state patterns (Weischodel, 1995, Appelt et al., 1995).
Bilingual alignment methods (Warwick et al., 1990; Brown et al., 1991a; Brown et al., 1993; Gale and Church, 1991b; Gale and Church, 1991a; Kay and Roscheisen, 1993; Simard et al., 1992; Church, 1993; Kupiec, 1993a; Matsumoto et al., 1993; Dagan et al., 1993). have been used in statistical machine translation  , terminology research and translation aids  , bilingual lexicography  , word-sense disambiguation (Brown et al., 1991b; Gale et al., 1992) and information retrieval in a multilingual environment  .
Forest-Based Translation
Following Liu et al.  , we prepare a phrase-table from a phrase-extractor, e.g.
2006AA010108 (H. M and Q. L.), and by NSF ITR EIA-0205456 (L. H.).
The set U of unique labels constraints contained su, obj1, obj2, sup, ld, vc, predc, predm, pc, pobj1, obcomp and body.
Thanks to Ivan Meza-Ruiz, Ruken C¸ akıcı, Beata Kouchnir and Abhishek Arun for their contribution during the CoNLL shared task and to Mirella Lapata for helpful comments and suggestions.
A number of statistical parsing models have recently been developed for Combinatory Categorial Grammar   and used in parsers applied to the WSJ Penn Treebank (Clark et al., 2002; Hockenmaier and Steedman, 2002; Hockenmaier, 2003b).
Riezler et al.   and Toutanova et al.
Sha and Pereira  .
Tada, nedan-ga chotto takai.
Two polar clauses in the intrasentential and/or inter-sentential context described in Section 4.1.
K=0.83.
It is most fully presented in Wiebe and Rapaport (1986, 1988, 1991) and Wiebe (1990, 1994).
W9-04 W9-10 W9-22 W9-33 freq +prec freq +prec freq +prec freq +prec Unique words 4,794 +.15 4,763 +.16 4,274 +.11 4,567 +.11 Baseline 156,421 .19 156,334 .18 155,135 .13 153,634 .14 but the precision of unique words in these same annotations is 0.20, 0.12 points higher than the baseline.
Let (W1, W2, W3) be a trigram consisting of consecutive words W1, W2, and W3.
The tag set is as follows: CC, CD, CONJ+NEG PART, DT, FW, IN, JJ, NN, NNP, NNPS, NNS, NO FUNC, NUMERIC COMMA, PRP, PRP$, PUNC, RB, UH, VBD, VBN, VBP, WP, WRB .
But...
Joshua was run on the Sun HotSpot JVM, version 1.6.0 12.
All decoders produced a BLEU score between 31.4 and 31.6 (small differences are accounted for by different tie-breaking behavior and OOV handling). formalism=scfg grammar=grammar.mt03.scfg.gz add pass through rules=true scfg max span limit=15 feature function=LanguageModel en.3gram.pruned.lm.gz -o 3 feature function=WordPenalty intersection strategy=cube pruning cubepruning pop limit=30 8 Future work C. Dyer.
2010.
HR0011-06-2-001.
Limitations of "Kimmo" systems The advent of two-level morphology (Koskenniemi [1], Karttunen [2], Antworth [3], Ritchie et al.
OF COLING-92, NA~rr~s, AU6.23-28, 1992 I.
OF COLING-92, NANTEs, AUG. 23-28, 1992 only the last is.
social  0 -d/~mocrate +DPL +masc +pl Ill ill sociau x -d~mocrate  0 0 s Figure 7 AcrEs DE COLING-92, NAgIES, 23-28 ^ot~r 1992 1 4 4 PRoc.
The second stage is the two-level rule sys- tem.
Discussion Finite-state morphology tests on the ob- servation that ordinary morphological al- ternations involve regular elations.
In lin- guistics it is commonly assumed that lexi- AcrEs BE COLING-92, NANTES, 23.28 AOUT 1992 1 4 6 PROC.
References [11 Koskenniemi, K. Two-level Morphol- ogy.
[21 Karttunen, L. K1MMO: a General Morphological Processor.
Texas Lin- guistics Forum, 22:217-228.
[3] Antworth, E. L. PC-KIMMO: a two-level processor for morphological analysis.
[4] Ritchie, G. D., G. J. Russell, A. W. Black, S. G. Pulman.
1991 [5] Barton, E., R. Berwick, E. Ristad.
In Dal- rymple, M. et al.
Kaplan, R. M. and M. Kay.
Phonolog- ical rules and finite~state transducers [Abstract].
Fifty-sixth An- nual Meeting, December 27-30, 1981.
Finite-State Con- straints.
23-28 AO~I 1992 1 4 7 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992 1991.
Universiti Sains Malaysia, Pe- nang, Malaysia.
[11] Ritchie, Graeme D. Languages Gen- erated by Two-level Morphological Rules.
Depart- ment of Artificial intelligence, Uni- versity of Edinburgh, 1990.
R6sum6 Cet article d6crit une nouvelle utilisation des transducteurs reguliers en analyse morphologique.
Les syst6mes Kimmo standard se composent dun lexique en forme darborescence de caract6res (trie) avec des sommets finals annot6s dinformation morphologique et un ensemble de transducteurs qui transcrivent les representations lexicales en formes fl6chies.
Bienque ces syst~mes soient sup6rieurs aux techniques an- t6rieures danalyse morphologique "cut- and-paste", ils ont un certain hombre de d6savantages: les formes lexicales sont souvent arbitraires et diff6rentes des lemmes dun dictionnaire normal; lana- lyse morphologique nest pas encod6e directement dans la forme lexicale.
Le r6sultat est que la synth~se st souvent plus ardue que ianalyse t que les struc- tures ne sont pas optimales.
Les analyseurs morphologiques con- struits a Xerox-PARC pour le franqais et langlais se basent sur deux principles simples: 1. les formes fl6chies dun m6me mot se basent sur un m6me lemme; 2. les cat6gories morphologiques font partie int6grante de la forme lexicale.
Ainsi les formes lexicales sont toujours des s6quences de morphemes.
Il est difficile dachever ces deux r6sultats d6sirables dans le cadre dune description classique/~ deux niveaux parce que la distance ntre les formes lexicales et les formes de surface est longue t tr6s difficile a d6crire avec un seul ensemble de r6gles phonologiques deux niveaux.
I1 est possible de r6soudre ces probl6mes en exploitant dune faqon plus approfondie l s principes de la phonologie deux niveaux.
En guise dexemple, larticle d6crit une cascade de r~gles deux niveaux qui permet une description simple du pluriel des mots compos6s en franqais.
La premi6re serie de r6gles insure des annotations de nombre et de genre apr6s chaque 61ement de mots /~ pluriel double (social-ddmocrate ~ sociaux-ddmo- crates), la s6conde s6rie de ri~gles d6termine la r6alisation du nombre t du genre r6quise par les racines.
Les caract6ristiques math6matiques des transducteurs r6guliers ont bien connues.
Elles permettent la combinaison de trans- ducteurs correspondant a des syst6mes de r6gles a deux niveaux par composition et par intersection.
Ainsi il est possible de r6duire un syst~me ~niveaux multiples un seul transducteur qui contr61e simul- tan6ment toutes les alternances morpho- logiques dun langue.
Vu que dans les lexiques anglais et franqais d6velopp6s Xerox toute linformation morphologique est cod6e directement avec le lemme, il est possible daller plus loin et de composer le lexique entier avec les r6gles.
Le trans- ducteur r6sultant, un lexique a deux niveaux, transcrit les formes lexicales directement en formes de surface et vice versa.
Les r~gles ne sont utilis6es que dans la phase de construction.
Lanalyse t la synth~se ne font usage que du trans- ducteur lexical r6sultant.
ACRES 91i COLING-92, NANTES, 23-28 AOIYr 1992 1 4 8 PROC.
OF COLING-92, NANTES, AUG. 23~28, 1992
Two teams used AdaBoost.MH (Carreras et al., 2003b; Wu et al., 2003) and two other groups employed memory-based learning  .
Another combination of five systems (Carreras et al., 2003b; Mayfield et al., 2003; McCallum and Li, 2003; Munro et al., 2003; Zhang and Johnson, 2003) obtained the best result for the German development data.
Tapanainen@conexor.
0 Introduct ion Intbrmation Extraction is the selective xtrac- tion of specified types of intbrmation from nat- ural language text.
3 Methodo logy 3.1 Pre-processing: Syntact ic Analysis Before at)plying ExDIsco ,  we pre-proeessed the cortms using a general-purpose d pendency parser of English.
C-Person, C-Company, etc.
Itere we present results on the "Man~geme.nt Suc- cession" and "Mergers/Acquisitions" cenarios.
ExDIsco  was seeded with lninimal pattern sets, namely: Subject Verb Direct Object C-Company C-At)point C-Person C-Person C-Resign ibr the Mmmgement task, and Subject Verb Direct Object * C-Buy C-Conlt)any C-Company merge * for Acquisitions.
Tlm seed t)atterns a.re a.
:~ 4 Resu l ts 4 .1  Event  Ext ract ion lhe, most nal;ma.l measme of eflecl;iveness of our discovery procedure is the performmme of ml ex- tract ion systmn using the, discovered t)~tterns.
The results on the training corpus are: Pattern Base Recall Precision Seed 38 83 Ex I ) Isco 62 80 Union 69 __79 Manual-MUC ~ 71 L~1.9~ Manual-NOW 6(3~ 79 L7!~z[)_t_j and on the test cortms: 4There are also a few noun phrase patterns which can give rise to scenario events.
Pattern Base Recall Precision F Seed 27 74 39.58 ExDIsco 52 72 60.16 Union 57 73 63.56 Manual-NOW -- 56 75 6404.
The base called Ultiolt con- tains the union of ExDIScO and Manual-Now.
4.2 Text  f i l ter ing We can obtain a second measure of pertbr- mance by noting that, in addition to growing the tmttern set, ExDIsco  also grows the rele- 944 0.9 0.8 0.7 0.6 0.5 _ .
0.2 0.4 0.6 0.8 Recall Figure l: Management Suc(cssion 0.9 0.8 0.7 0.6 0.5 L_~/r Legend: Acquisition 0.2 0.4 0.6 Recall 0.8 Figme 2: Mergers/A(:quisitions vance rankings of documents.
The latter cnn be evahlated irectly, wil;hollt human intervention.
We tested Exl)IsC, o ~tgainst wo cor])orn: th(; 100 documents from MUC-6 tbrmal training, a:nd the 100 documents from the MUC-6 for- mal test (both are contained anlong the 10,000 ExDIsoO training set) r. Figure 1 shows recall t)]otted against precision on the two corpora, over 100 iterations, starting with the seed pat- te, nls in section 3.d.
These t)rol)lems h~ve t)een impedinmnts to the -wide].
These dit[iculties have stimulate.d resear(h on 1)attel .
Itowever, her work ditfers trom 01217 own in several i lnportant respects.
In contrast, our pro- cedure discovers complete, multi-slot event pat- 945 terns.
References David Fisher, Stephen Soderland, Joseph Mc- Carthy, Fangfang Feng, and Wendy Lelmert.
Description of the UMass system as used fbr MUC-6.
Sixth Message Un- dcrstandin9 Conf.
Morgan Kauflnann.
R.alph Grishman.
The NYU systenl tbr MUC-6, or wheres the syntax?
(MUC- 6), pages 167 176, Columl)ia, MD, Novem- ber.
Morgan Kauflnann.
W. Lehnert, C. Cardie, D. Fisher, J. McCarthy, E. Riloff, and S. Soderland.
Univer- sity of nlassachusetts: MUC-4 test results and analysis.
Fourth Message Un- der.standing Con.
Mor- gan Kauflnaml.
7th Mc.ssagc Understanding Co~:f., FMrfax, VA. 1993.
Morgan Kauflnann.
Morgan Kauflnaml.
Learn- ing dictionaries for infbrmation extraction by multi-level bootstrat)ping.
16th Natl Corderenee on Art~i[icial Intelli9enee (AAA I 99), Orlando, Florida.
I3th Natl Co~~:f. on Art~ificial Intel- ligence (AAAI-96).
The AAAI Press/MIT Press.
A non-t)rojectivc dependency parser.
on Applied Nataral Language P~v- cessiu9, pages 64-71, Washington, D.C. ACL.
Roman Yangarber and RalI)h Grishman.
Customization of intbrmation extraction sys- tems.
In Paola Velardi, editor, I~ttl Work- shop on Lexically Driven I~7:forrnation Extrac- tion, Frascati, Italy.
Universith di Roma.
NYU: Description of thc Protens/PET sys- tem as used tbr MUC-7 ST.
Roman Yangarl)er, Ralph Grishman, Past Tapanainen, and Silja Huttunen.
Un- supervised discovery of scenario-level pat- terns tbr information extraction.
Co~@ on Applied Nataral Langaage Process- tug (ANLP-NAACL), Seattle, WA.
A Semantic-Head-Driven Generation Algorithm For Unification-Based Formalisms
Subcategorization for complements is performed lexically.
1 jobINN contributes one occurrence each to the bigrams AT+JJ, JJ+NN, a+JJ, and to the part-of-speech tag trigram AT+JJ+NN.
ALEK was tested on 20 words.
Backchannels (e.g.
IIS-012196.
Representative systems are described in Boisen et al.  , De Mattia and Giachin  , Niedermair  , Niemann  , and Young  .
2.5.1 Gaps.
This approach resembles the work by Grishman et al.   and Hirschman et al.
Word-Sense Disambiguation Using Decomposable Models
418, June 1992.
TRANSFORMATION-BASED
This has been addressed by subsequent work using hierarchical prediction (Morin and Bengio, 2005; Mnih and Hinton, 2009; Le et al., 2011; Mikolov et al., 2011b; Mikolov et al., 2011a).
. decision, equite en matiere d'emploi, and bourse respectively.
(1e) &quot;Mr. Speaker, our Government has demonstrated its support for these important principles by taking steps to enforce the provisions of the Charter more vigorously.&quot; (10 &quot;Monsieur le Président, notre gouvernement a prouve son adhesion ces importants principes en prenant des mesures pour appliquer plus systematiquement les preceptes de la Charte.&quot; sions of the Charter, and to enforce provisions.
1991; Dagan, Marcus, and Markovitch 1993; Su, Wu, and Chang 1994).
Starting with a source language word group (possibly a single word) W, Champollion identifies all words in the target IanLe depute n' ignore pas que le gouvernement compte presenter, avant la fin de l' armee, un projet de revision de la Loi sur les langues officielles.
Clearly, A1 =- yi = = 1 and Ai = rai for i > 2.
For example, given "went" as the input string, rnorphy returns "go";  given "children," it returns "child," etc.
Approx- imately 63% of the synsets include definitional glosses.
For exam- ple, if a text contains the collocation "took place," the tok- enizer will convert it to "took_place."
ConText can then display the synset for "take place" rather than successive synsets for "take" and "place."
For example, the string "Mr. Charles C. Carpenter" is output as "Mr._Charles_C._Carpenter."
After preprocessing, this sentence is passed to ConText in the following form: br-kl3:109: He/PP went_down/VB the/DT hall/NN to/TO Eugene/NP /POS s/NN bathroom/NN J, to/TO turn_on/VB the/DT hot-water/NN heater/NN ,/, and/CC on/IN the/DT side/NN of/IN the/DT tub/NN he/PP saw/VBD a/DT pair/NN of/IN blue/JJ wool/NN swimming_trunks/NN ./.
Also note "<cmt>WORD_MISSING</cmt>" on line 16 of the output: that comment indicates that the tagger has connected "hot- water" and "heater" to form the collocation "hot- water heater," which was not in WordNet.
For exam- ple, the sentence already dissected provides a context for "hall" that might look like this: hall/5 [noun.artifact.l]: {bathroom/10 [noun.artifact.0]; hot-water heater/15 [noun.artifact.0]; side/19 [noun.location.0]; tub/22 [noun.artifact.l]; pair/25 [noun.quantity.0]; wool/28 [noun.artifact.0]; swimming_trunks/29 [noun.artifact.0]} {go/2 [verb.motion.6]; turn_on/13 [verb.contact.0]; see/23 [verb.perception.0] } {blue/27 [adj.all.col.3] } [] Collecting entries for this sense of "hall" provides valuable information about he contexts in which it can occur.
For example, under "base- ball" a topically organized thesaurus would pull together words like "batter," "team," "lineup," "diamond," "homer," hit," and so on.
The desig- nation, "semantic oncordance," was suggested to us by Susan Chipman.
), WordNet: An on-line lexical data- base.
Miller, G. A. and Fellbaum, C. Semantic networks of English.
Cognition (special issue), 41(1-3):197-229, 1991.
Ku~era, H. and Francis, W. N. Computational nalysis of present-day American English.
Boston, MA: Houghton Mifflin, 1982.
54, February 1993.
Landauer, S. I. Dictionaries: The art and craft of lexi- cography.
New York: Scribners, 1984.
New York: HarpcrCollins, 1992.
Jijkoun and de Rijke   nevertheless managed to extract around 300,000 FAQ pages and 2.8 million question-answer pairs by repeatedly querying search engines with “intitle:faq” and “inurl:faq”.
Append phraseat the end of F. Letbe the start position ofin F. 5.
6 8 10 15 20 Avg.
This work was supported by DARPA-ITO grant N66001-00-1-9814 and by NSFSTTR grant 0128379.
A common approach is to extract word-internal features from unknown words, for example suffix, capitalization, or punctuation features (Mikheev, 1997, Wacholder et al., 1997, Bikel et al., 1997).
Cui et al   measured sentencesimilarity based on similarity measures between de pendency paths among aligned words.
(7) 4.4 Lexical-Semantics Log-Linear Model.
2.2GHz dual-core CPUs and 4GB of memory.
Augmented with the q.-side dependency la bel.grandparent-child Question parent-child pair align respec tively to answer grandparent-child pair.
Augmented withthe tree-distance between the a.-side sib lings.
Our task is the same as Pun yakanok et al   and Cui et al  , where we search for single-sentence answers to factoid questions.
is 1955.
Cui et al.
TreeMatch is our implementation of Punyakanok et al  ; +WN modifies their edit distance function using WordNet.
2,393.
5.3 Results.
NIST MT-05.
IWSLT-04.
Tillmann et. al   also use a MaxEnt model to integrate various features.
Our Hansard corpora consist of the Hansards from 1973 through 1986.
.SP *boMr.
.SP *boSome hon.
17--*boMr.
.SP   s*itLater:*ro) .SP *boMr.
Pareillement.
... en voula.ut 1n6ita.ger la chèvre et le choux Hs n'arrivent pas a. prendre parti.
For memory-based learning, we use TiMBL (Daelemans et al. 2003b) IB1 (k-nearest neighbor).
Table 11.
Polar F-measures for BoosTexter and TiMBL are 3.9% and 4.5% higher.
Research ranges from work on learning the prior polarity (semantic orientation) of words and phrases (e.g., Hatzivassiloglou and McKeown 1997; Kamps and Marx 2002; Turney and Littman 2003; Hu and Liu 2004; Kim and Hovy 2004; Esuli and Sebastiani 2005; Takamura, Inui, and Okumura 2005; Popescu and Etzioni 2005; Andreevskaia and Bergler 2006; Esuli and Sebastiani 2006a; Kanayama and Nasukawa 2006) to characterizing the sentiment of documents, such as recognizing inflammatory messages  , tracking sentiment over time in online discussions  , and classifying the sentiment of online messages  , customer feedback data  , or product and movie reviews  .
Morinaga et al.  , Yu and Hatzivassiloglou  , Kim and Hovy  , Hu and Liu  , and Grefenstette et al.
Using Lexical Chains for Text Summarization Reg ina  Barz i lay Mathematics and Computer S~nence Dept Ben Gunon University m the Negev Beer-Sheva, 84105 Israel regana@cs.bEu ac.
~1 Michae l  E lhadad Mathemat~s and Computer Saence Dept Ben Gunon Umveraty m the Negev Beer-Sheva, 84105 Israel http //mr?
1 "Dr Kenny has sn~ented an anesthetsc maehsne Thss devwe controls the rate at wh:ch an ana- esthctsc ss pumped into the blood" 2 "Dr Kenny has :nvented an anesthet:c machsne The Doctor spent wo years on thu research" ~Dr Kenny ~ appears once m both sequences and I0 I I I I i I II II I !
pie First, a node for the word =Mr" Is created [ lex "ltr  ."
Homogene=ty When ranking CbamR according to thexr score, we evaluated that strong chamR are those winch satlsfy our "Strength Criterion" 5core(Cha:n) > Auerage(Seores) + 2 .
butlon We investigated three alternatives for tlus Step Heurist ic  1 For each chain m the summary rep- resentation choose the sentence that contains the first appearance ofa chain member m the text Thls heuristic produced the following summary for the text shown in Appendix When Mscroaoft Semor Vsce Pressdcnt Steve Ballmer first heard h~ company was planning to make a huge m- vestment m an Internet oermec offering mome remews and local entertainment mformahon m ma3or cstwzs across the nahon, he trent to Cfiasrman Bdl Gates wlth hu concerns M.crasofts compehhve advantage, he re- sponded, tvas its exparhse m Bayesian etworks Bayessan ettvorks an~ cort~pl~ diagraras that o~gamze the body of knowledge m any gwen area by mapping out cause and effect relatmnshlpa among key varmbl~ and encoding them ?vsth numbers that repr~ent the eztent o tvhsch one varmble ss hkely to a~ect another Programmed into computers, these systems can auto.
I I I I Bayesian Networks Text When M~rosoft Semor VICU P~esKhmt Steve BalJm~ fnst heard has company yves planning to m eke a huge mveatment In an Interoet eennca offenng mowe re ins  end Ioca| entu~tainment mfonlnntmn mmajor cmea ao~ea the no?tun he went to Chanmun Bd] Gates wth his concern?
After ell Bellme~ has bflhom of dollars of lus own money m M~osoft stock, and ~tertumment tsn t exactly the compunye strong point Out Gates dmrmesed such re?alva?runs M~:rosofts compehUve advantage, he re- sponded, me mt expertem In Bayeamn etw0cke Asked recently when computers mum fnaagy beipn to understand human speech Gates begun dncussmgthe r .ntal  role of Bay?stun systems Ask any other software executive about anything Bay~mn and youre hable to set ?
tim abm4oundmg technology Mmrosoft ?
Bayeslun netvmrk?
that organize the body of knowledge m any Ipven area by rnapping out cause-and-effect relat~onshnps among key vamblea end encoding them with numbees that represent he extent o which one ramble n 5kth7 to affect another ( ) Programmed into comlmt4m~, these ?ystems can autometzcuHy generate optunzd pre- dlct4ons or deastons even when key pieces of Informabon are m~n g When Miorozoft in 1993 hired Eric Homtz, David H~:kermun and Jack Brine pro- nears m the devdopment of Bay?stun systems, colleagues m the field were ?mlmsed The held was still an obscure, lergdy academic enterlmea Bayesian nets prowde an oeararchmggraphtcal framework" that Imngs togetlmcb- verse elementsof AI and Increasethe range of Ks hkely epphcabon to the real world says Michael Jordon profes~mr of bramand cog?rove menea et the Massachusetts Institute of TechnoloW Mmrosoft ts unquestionably the most aKfFessJve in expkntmg the new epproach The cumpeny offers ?
your grundmothef vnll use it Miorosoft?
Score ffi 9 0 ba~e~l&n-~y~tem 2 ~y~tem 2 baye~za~s-net 2 network 1 baye~z~n-network 5 weapon 1 : CHAIN 3 Score ---- 7 0 m 2 a~ttficzal-mtolhgunce /~ field 7 technology 1 t, czence I CHAIN ~ Score ffi 6 O tochmquo 1 b&ye~tsn-techmque I condztzon I datum 2 model I mformatton 3 area I knowledge 3 ~HAIN S Score = 3 0 computer  4 Acknowledgements Tkts work has been supported by the Israeh Mlmstry of Science We axe grateful to Graeme Ktrst, Dragonnr Radev and Claude Bneson for thezr feedback on a previ- ous vermon References Black, Wflham J 1994 Parsing, lmgmstlc resources and semantic analysis, for abstzactmg and categorization Halhday, lqhchael and Ruqatya Hasan 1976 Cohesion in Enghsh Longman, London 17 Hearst, Marti A 1994 Multi-paragraph segmentation of exposltoZT text In Proceedmgs of the 3~nd Annual Meetmg of the Assocmhon for Computational Lmguts- hcs HLmt, Graeme and Dared St-Onge 1997 (to appear) Lemca] chains as representation of context for the de- tection and correction of malapropisms In Chns- tiane Fellbanm, edxtor, WordNet An electmmc lez- tcal database and some of ,ts appheat:ons Cambridge, MA The MIT Press Hoey, M 1991 Patterns of Leats m Tezt Oxford Um- vermty Press, Oxford Jones,.KarenSpaxck 1993 What mightbe m summary ?
Informahon Retrleval Lulm, H P 1968 The automatxc ereatzon of hterature abstracts In Schultz, edttor, H P Luhn Pioneer of lnformahon Science Spartan Mann, W C and S Thompson 1987 RhetoncaJ.
struc- ture theory description and constructions of text structures In Gerard Kempen, echtor, Natural Lan- guage Generahon New Results m Arhfictal Intellh- gence, Psychology and Lmgutst:cs Maxtmus Nmjhot~ Pubhshers, pages 85-96 McKeown, Kathleen and Dragonur Radev 1995 Gen- eratmg summaries of multiple news articles In SIGIR 95 Proceedings Mdler, George A ,  P,~chard Beckwlth, Chnstiane Fell- bans, Derek Gross, and Kathenne J ~ 1990 Introduction to WordNet An on-lme lexxcal database Internat,onal Journal of Lazwcographg (special issue), 3(4) 23,5,-312 Morns, J and G Hzrst 1991 Lexzcal coheszon com- puted by thesanra] relations as an re&cater of the structure of the text Computahonal Lmgutsttos, 17(1) pp 21.--45 Onq, Ken3h Sunuta Ks?no, and Mnke Seql 1994 Ab- stract genezation based on rhetorical structure extruc- tzon In Proceedings of the International Conference on Computahonal Lmgutshcs (Cohng 9~), pages 344-- 348, Japan Pa~ce, C D and G D Husk 1991 Towards the au- tomatic recognntlon of anaphonc features m enghsh text The nnpexsonal pronoun "zt ~ Computer Speech and Language, (2) pp 109-132 Patce, Chris D 1990 Constructing hterature abstracts by computer techmqu~ and prospects lnformahon Processmg and Management, 26(1) 171-186 Statrmand, Mark A 1996 A Computahonal Analysts of Lexscal Cohesion wtth Apphcattons :n Informatton Re- trievai Ph D thesis, Center for Computational Lm- gmstics, UMIST, Manchester
Wc show that FTAG has an enhanced escriptive capacity compared to TAG formalisnr.
1986, Kasper et al.
1986, Kasper et al.
1.2 Feature  S t ructure  Based  Grammat ica l  Sys tems Several different approaches to natural anguage granunars have devel- oped the notion of feature structures to describe linguistic objects.
8 ./~--.. COMP~ I J "~ wh NP- ~P- dahri ~ NP.
I I S NP_ VP- John ~t tlP- anw ~et  o?
Sec- ondly, ou~ ~irnary ?o~cern ~to sp~ify/tl,?
~,ther, if the form*lima haS t~) incorporate ~heie 4tip~ulatibns, it(can be done so, witbont ,lt~,ng tbe ~ochanlsm s,g~m0~n ly.
The current linguistic theory u~derlying TAGs .
3 A Ca lcu lus  to Represent  FTAG Gram- mars We will now consider a calculus to represent FTAGs by extending on the llogieal formulation oftbature structures given by Rounds and Kasper [Rou Kasper et al.
V e2 {pl ..... P.} where a is an atomic value, el,e2 are well-formed formulae.
NIL and (TOP cl)nvey "no in(ormation" and "inconsistent information" respec- !~ively.
,e~ are encodings of auxiliary trees #h. .
xrn ~ ~ra where e~,..
Therefore, we add ~0 ---- Zt V... V ~tn Assuming that we specify reentrancy using the Variables Yl,...~ Yk and equations Yt : e~ for 1 _ i < k, an FTAG grammar is thus represented by the set of equations of the form .first (ree(xo, xl  .
This space has been characterized by Pereira and Sheiber [Pereira ctal .
References Joshi, A. K. 1985.
1low Mnch Context-Sensitivity ~ Necessary for Chai: acterizing Structural I)escription.~-- lhee Adjohling Crammms.
Karttunen, and A. Zwicl,y, Eds., Nal~tral Lasgaaqe ]Jroce.%ia 3 -- Theoretical, 6om.palaiio~al nd Psychological ()cr:JlJeclie~.
aoshi, A. K t987.
An Introduction to qtec Adjoining (~FalltJli2{l~.
11}2 A. Manaster-II,amer, Ed., Mathematics of Laapuape.
3ohn lienjamins, Antsterdam.
J~shi, A. K., Levy, L. S., mid Ihkahaahi, M. 1975.
Kasper, E.. and Kounds, W. C. 1986.
In: 24 ~h meeting Assoc.
In: A. Manaster-Raumr, I",d., Malhemalics of Language..loire I~enjamh,s, A m sterdam.
Kroch, A. and Josbi, A. K. 1985.
Liuguiatic lgele)Jaaee oj 7?cc Adjoiaiag Grammars.
Technieal Rel)orl; MS-CIS 85-18, Deparl;mcnl of (OItIpULel and hlformatiml Science, University of Pennsylvania, Philadell,hia Pereira, F. C. N. and Shieber, S. 1984.
The Semantics of Gramme1 ~br- malisms Seen aa Computer Languages.
la: IO th luter~talionM C, nfcrenee on Compalalional Linguistics.
A complete Logical (:;dcalm+ 17,L l/ecord Stru(:tures Representing Linguistic hlfornratiou.
11l: tEE/; 5;ym posture os Loyic and Computer Science.
Masters thesis, University el Pcmv sylvania, Philadelphi~ h PA. Schabes, Y. and Joshi, A. K. 198g.
An Earley-Type Parsing Algorithm for ~t~ee Adjoining Grarmnars.
Shieber, S. M. An Introduction to UazficaZioa.
Based Apl,roachc to (/r~m- mar.
Presented as a Tntor[al SalMon 23 d meeting Assoe (onqmi,.
Shieber, S. M. 1985.
Using R~sttiction to Extend Parsieg Algorilhtxm for Comlflex.feature based Formalisms.
In: 23 ra mecii~ 9 A.~soc.
Vijayashanker, K. 1987.
 , Gale et al.  , Lesk  , Smadja and McKeown  , Walker  , Veronis and Ide  , Yarowsky  , Zernik (1990, 1991).
NO0014-91-C-0115, and by Ft. Huachuca under Contract Nos.
DABT63-94-C-0061 and DABT63-94C-0063 .
When the OTC is closed, the number of TLINKs goes up by more than 11 times, from 6147 Event-Event and 4593 Event-Time TLINKs to 91,157 EventEvent and 29,963 Event-Time TLINKs.
The number of BEFORE links goes up from 3170 (51.6%) Event-Event and 1229 Event-Time TLINKs (26.75%) to 68585 (75.2%) EventEvent and 18665 (62.3%) Event-Time TLINKs, making BEFORE the majority class in the closed data for both Event-Event and Event-Time TLINKs.
An example of the latter is the French sentence (translated from German): Il a gratt´e une planche de b´eton, perdit des pi`eces du v´ehicule.
For inter-annotator agreements, the range is 0.176 to 0.336, while intra-annotator agreement ranges from 0.279 to 0.648.
Our own concern are semantic judgments concerning the interpretation of noun phrases with the definite article the, that we will call definite descriptions, following  .2 These noun phrases are one of the most common constructs in English,' and have been extensively studied by linguists, philosophers, psychologists, and computational linguists (Russell 1905; Christophersen 1939; Strawson 1950; Clark 1977; Grosz 1977; Cohen 1978; Hawkins 1978; Sidner 1979; Webber 1979; Clark and Marshall 1981; Prince 1981; Heim 1982; Appelt 1985; Li5bner 1985; Kadmon 1987; Carter 1987; Bosch and Geurts 1989; Neale 1990; Kronfeld 1990; Fraurud 1990; Barker 1991; Dale 1992; Cooper 1993; Kamp and Reyle 1993; Poesio 1993).
Hearer-New/Hearer-Old.
Discourse-New/Discourse-Old.
Inferrables.
Containing Inferrables.
Larger situation/unfamiliar.
3.3.4 Per-Class Agreement.
3.4.1 Distribution.
/unfamiliar.
In-domain TMs and RMs were estimated on three different versions of the full parallel EP corpus, namely EP, S¯E-EP, and ¯SE-EP.
Quant aux eaux minerales et aux limonades, elles rencontrent toujours plus d'adeptes.
En effet, notre sondage fait ressortir des ventes nettement superieures a celles de 1987, pour les boissons a base de cola notamment.
La progression des chiffres d'affaires resulte en grande partie de l'accroissement du volume des ventes.
L'emploi et les investissements ont egalement augment& La nouvelle ordonnance federale sur les denrees alimentaires concernant entre autres les eaux minerales, entrée en vigueur le ler avril 1988 apres une periode transitoire de deux ans, exige surtout une plus grande constance dans la qualite et une garantie de la purete. language and sentences in the other language.
Quant aux eaux minerales et aux limonades, elles rencontrent toujours plus d'adeptes.
En effet, notre sondage fait ressortir des ventes nettement superieures a celles de 1987, pour les boissons a base de cola notamment.
La progression des chiffres d'affaires resulte en grande partie de l'accroissement du volume des ventes.
Employment and investment levels also L'emploi et les investissements ont egaleclimbed. ment augmente.
La nouvelle ordonnance federale sur les denrees alimentaires concernant entre autres les eaux minerales, entrée en vigueur le ler avril 1988 apres une periode transitoire de deux ans, exige surtout une plus grande constance dans la qualite et une garantie de la purete.
A bilingual concordance. bank/banque (&quot;money&quot; sense) it could also be a place where we would have a ftre le lieu oii se retrouverait une espece de f finance (mr. wilson) and the governor of the es finances ( m . wilson ) et le gouverneur de la reduced by over 800 per cent in one week through us de 800 p. 100 en une semaine A cause d'une bank of experts.
SENT je connais plusieurs pers bank of canada have frequently on behalf of the ca banque du canada ont frequemment utilise au co bank action.
SENT such was the case in the georges entre les etats-unis et le canada a propos du han i did.
SENT he said the nose and tail of the gouvernement avait cede les extremites du he fishing privileges on the nose and tail of the les privileges de peche aux extremites du bank issue which was settled between canada and th banc de george.
SENT c'est dans le but de re bank were surrendered by this government.
SENT th banc.
We obtain 81105/73481 1.1.
The result for English—German is s2 = 7.3, and for English— French is s2 5.6.
The function takes four arguments: xl, yi, X2, Y2.
The English—French errors were increased from 36 to 84, and the English—German errors from 19 to 86.
Lawrence Erlbaum.
Addison-Wesley.
Addison-Wesley.
*/
amples.
The hypergraph isfiltered and weighted according to some associa tion rules.
system All nouns verbs I2R 3.08 3.11 3.06 UBC-AS?
System R. All Nouns Verbs FSc.
Pur.
Entr.
FSc.
FSc.
1c1word 1 78.9 79.8 45.4 80.7 76.8 UBC-AS?
2 78.7 80.5 43.8 80.8 76.3 upv si 3 66.3 83.8 33.2 69.9 62.2 UMND2 4 66.1 81.7 40.5 67.1 65.0 I2R 5 63.9 84.0 32.8 68.0 59.3 UofL??
UBC-AS?
System Rank Supervised evaluation All Nouns Verbs I2R 1 81.6 86.8 75.7 UMND2 2 80.6 84.5 76.2 upv si 3 79.1 82.5 75.3 MFS 4 78.7 80.9 76.2 UBC-AS?
5 78.5 80.7 76.0 UOY 6 77.7 81.6 73.3 UofL??
UBC-AS?
Pre vious Senseval evaluation exercises have shown thatthe MFS baseline is very hard to beat by unsuper vised systems.
1996, Vossen 1995), and even general coverage syntactic parsers  .
For example, some of the top semrel paths in MindNet between pen and pencil, are shown below: penf--Means--draw—Means--4pencil penf-Means—write—Means->pencil pen—Hyp-4instrument*-Hyp—pencil pen—Hyp-->write—Means---*pencil pen‹-Means—write(-Hyp--pencil pencil In the above example, a pattern of semrel symmetry clearly emerges in many of the paths.
Specifically, tive vs. objective sentences in newswire text.
hwPhwPhwP iAiBi ??
2.2 Bag-of-words Query Models.
4.2 Data: GigaWord Corpora.
4.3 Bag-of-Words Query Models.
1-Best/NIST Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline 1-Best/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-2: NIST and Bleu scores 1TQ We see that each corpus gives an improvement over the baseline.
100-Best/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline 100-Best/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-3: NIST and Bleu scores from TNQ Using the translation alternatives to retrieve the data for language model adaptation gives an improvement over using the first-best translation only for query construction.
Lattice/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Lattice/BLEU-Scores 0.1900 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 AFE APW NYT XIE Top1 Top10 Top100 Top1000 Baseline Figure-4: NIST and Bleu scores from TMQ 4.4 Structured Query Models.
Structured query/NIST-Scores 7.7500 7.8000 7.8500 7.9000 7.9500 8.0000 8.0500 8.1000 8.1500 Baseline Top100 Top500 Top1000 Top2000 Top4000 1-Best 100-Best TM-Lattice Structured query/BLEU-Scores 0.1920 0.1940 0.1960 0.1980 0.2000 0.2020 0.2040 0.2060 0.2080 Baseline Top100 Top500 Top1000 Top2000 Top4000 1-Best 100-Best TM-Lattice Figure-5: NIST and Bleu scores from the structured query models The really interesting result is that the structured query model TMQ gives now the best translation results.
4.5 Example.
(Marcus 19801, (Church 801 and (Berwick 821).
[Hornstein and Weinberg 811 and [Bresnan 821.
2005; Collins et al., 2005).
moved by passivization, is denoted by ? <NP NULL="NONE" ref="i55"/>?
or ?aug mented?
<NP SYN="COOD"> <NP><ADJP>IL-1- <ADJP NULL="QSTN"/></ADJP> <NP NULL="RNR" ref="i20"/></NP> and <NP>IL-18-mediated <NP NULL="RNR" ref="i20"/></NP> <NP id="i20">function </NP> Other disagreements are more general type such as regarding ?-ed?
or ?-SBJ) or the position of <PRN> tags <NP> <ADJP SYN="COOD"> <ADJP>IL-1- <ADJP NULL="QSTN"/></ADJP> and <ADJP>IL-18-mediated </ADJP></ADJP> function </NP> NP ADJP Function ADJP and ADJP IL-1 * IL-18 mediated Figure 2a.
</NP> NP NP And NP ADJP *20 IL-18 meidiated NP IL-1 * function20 Figure 2b.
denotes coindexing.
224
Insertion du rendez-vous: Avant de commencer, accomplir cette tciche.
Executer les actions suivantes.
French: Insertion du rendez-vous: Avant de commencer, ouvrir la fenetre Appointment Editor en choisissant l'option Appointment dans le menu Edit.
Executer les actions suivantes: 1 Choisir l'heure de fin du rendezvous.
2 Inserer la description du rendezvous dans la zone de texte What.
3 Cliquer sur le bouton Insert.
Indices for indefinites are generated from X1, .. •
1987; Sampson 1986; Sharman et al. 1988).
Pseudo-disambiguation tasks (e.g.
2,852,300 lemmatised  .
Such features might work well and lead to high accuracy results in identifying synthetic implicit relations, but are unlikely to be useful in a realistic setting of actual implicits. the-but s-but the-in of-but for-but but-but in-but was-but it-but to-but that-but the-it* and-and the-the in-in to-the of-and a-of said-but they-but of-in in-and in-of s-and Also note that the only two features predictive of the comparison class (indicated by * in Table 1): the-it and to-it, contain only function words rather than semantically related nonfunction words.
Lin et al.   and Gao et al.
Sentence Fusion For Multidocument News Summarization
On the other hand, redundancy can be exploited to identify important and accurate information for applications such as summarization and question answering (Mani and Bloedorn 1997; Radev and McKeown 1998; Radev, Prager, and Samn 2000; Clarke, Cormack, and Lynam 2001; Dumais et al. 2002; Chu-Carroll et al.
3.1.2 Alignment.
3.3.1 Statistical versus Symbolic Linearization.
4.1.3 Baselines.
4.1.5 Grammaticality Assessment.
System Last1 summer1 a1 government1 study1 abruptly1 was1 halted1 after1 finding1 the2 risk2 of2 dementia2 in1 women1 who1 took1 one1 type1 of1 combined1 hormone1 pill1. studies are involved and that fusion should not take place.
An Empirical Model Of Multiword Expression Decomposability
Multiword expressions  .
Ramshaw and Marcus used transformationbased learning  .
An axiom is built to link the head of the noun phrases in the apposition such that they share the same argument: all x12 x13 x14 x15 x17 x18 x19 (italian nn(x12) & andrea nn(x13) & pfister NN(x14) & nn nnc(x15,x12,x13,x14) designer nn(x15) & of in(x15,x17) & 1979 nn(x17) & bird nn(x18) & cage nn(x19)) A question/answer substitutes the use of a possesive by using an of or by preposition.
Note that for this axiom to be effective, an axiom linking the heads of the apposition is built: all x8 x9 x10 x11 x12 (mother nn(x8) & of in(x8,x9) & forest nn(x9) big nn(x10) & basin nn(x11) & nn nnc(x12,x10,x11) & s pos(x8,x12) & tall jj(x8) & redwood nn(x8))
-(exists e1 x2 x3 x5 x6 ( organization at(x2) & company nn(x2) & create vb(e1,x2,x6) & internet nn(x3) & browser nn(x4) & mosaic nn(x5) & nn nnc(x6,x3,x4,x5))).
ALF: In IN(x1,x28) & particular JJ(x29) & program NN(x1) & call VB(e1,x27,x30) & Mosaic NN(x2) & develop VB(e2,x2,x31) & by IN(e2,x8) & National NN(x3) & Center NN(x4) & for NN(x5) & Supercomputing NN(x6) & application NN(x7) & nn NNC(x8,x3,x4,x5,x6,x7) & NCSA NN(x9) & at IN(e2,x15) & University NN(x10) & of NN(x11) & Illinois NN(x12) & at NN(x13) & Urbana NN(x14) & nn NNC(x15,x10,x11,x12,x13,x14) & Champaign NN(x16) & gain VB(e3,x1,x17) & popularity NN(x17) & as IN(e3,x32) & easy JJ(x33) & use VB(e4,x34,x26) & point NN(x18) & and CC(x26,x18,x21) & click NN(x19) & interface NN(x20) & nn NNC(x21,x19,x20) & for IN(x26,e5) & search VB(e5,x26x22) & portion NN(x22) & of IN(x22,x23) & Internet NN(x23) gram nn(x1) & call vb(e1,x27,x1) & mosaic nn(x2) & develop vb(e2,x8,x2) & by in(e2,x8) & national nn(x3) & center nn(x4) & for nn(x5) & supercomputing nn(x6) & application nn(x7) & nn nnc(x8,x3,x4,x5,x6,x7) & ncsa nn(x9) & at in(x8,x15) & university nn(x10) & of nn(x11) & illinois nn(x12) & at nn(x13) & urbana nn(x14) & nn nnc(x15,x10,x11,x12,x13,x14) & champaign nn(x16) & gain vb(e3,x2,x17) & popularity nn(x17) & as in(e3,x32) & easy jj(x33) & use vb(e4,x9,x2) & point nn(x18) & and cc(x26,x18,x21) & click nn(x19) & interface nn(x20) & nn nnc(x21,x19,x20) & for in(x26,e5) & search vb(e5,x2,x22) & portion nn(x22) & of in(x22,x23) & internet nn(x23)).
(7) all x1 x2 x3 x4 (mosaic nn(x1) & internet nn(x1) & browser nn(x1) nn nnc(x1,x1,x1,x1)).
The question is negated to invoke the proof by contradiction -(exists e1 x2 x3 x5 x6 ( organization at(x2) & company nn(x2) & create vb(e1,x2,x6) & internet nn(x3) & browser(x4) & mosaic nn(x5) & nn nnc(x6,x3,x4,x5))).
1996.
1994.
Robert Endre Tarjan.
1981a.
Robert Endre Tarjan.
1981b.
G. van Noord and D. Gerdemann.
2001.
In Impleno.
1a?
1a.
Such approaches have been tried recently in restricted cases (McCallum et al., 2000; Eisner, 2001b; Lafferty et al., 2001).
2.1 Probabilistic context-free grammars.
2.2 Bayesian inference for PCFGs.
is increasingly concen trated around 0.
becomes increasingly concen trated around 0.
WordNet average Gra vp sim- Hindle, 0.008021 0.000428 sim-cosine 0.012798 0.000386 Hindle, -cosine 0.004777 0.000561 Roget average Cravg sim-Hindle„ 0.002415 0.000401 sim -cosine 0.013349 0.000375 Hindle, -cosine 0.010933 0.000509
Recently, Watanabe et al.   and Chiang et al.
Typically this gold function is BLEU  , though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a).
We tried various dimensionalities from 10 to 1000.
Thanks to Markus Dreyer, Kevin Knight, Saiyam Kohli, Greg Langmead, Daniel Marcu, Dragos Munteanu, and Wei Wang for their assistance.
∗This work was partially supported by NSF grants IIS0803159, IIS-0705671 and IGERT 0504487.
The authors thank Dimitra Vergyri, Andreas Stolcke, and Pat Schone for useful discussions during the JHU’02 workshop.
The dataset is divided into four author-specific corpora, containing 1770, 902, 1307, and 1027 documents.
We systematically vary labeled set size |L |E 10.9n, 800, 400, 200,100, 50, 25,12, 6} to observe the effect of semi-supervised learning.
|L |= 0.9n is included to match 10-fold cross validation used by  .
In recent work, a number of researchers have cast thisproblem as a tagging problem and have applied vari ous supervised machine learning techniques to it (Gildea and Jurafsky (2000, 2002); Blaheta and Charniak  ; Gildea and Palmer  ; Surdeanu et al  ; Gildea and Hockenmaier  ; Chen and Rambow  ; Fleischman and Hovy  ; Hacioglu and Ward  ; Thompson et al  ; Pradhan et al  ).
Some examples are ARGMLOC, for locatives, and ARGM-TMP, for temporals.
In thissystem, the overlap-removal decisions are taken indepen dently of each other.
Head Word POS ? Surdeanu et al   showed.
The verbs were clustered into 64 classes using the probabilistic co-occurrence modelof Hofmann and Puzicha  .
10.
11.
12.
Addition ofnamed entities improves the F1 score for adjunctive arguments ARGM-LOC from 59% to ?68% and ARGM TMP from 78.8% to ?83.4%.
P R F1 Baseline 87.9 93.7 88.9 91.3+ Named entities 88.1 - - + Head POS ?88.6 94.4 90.1 ?92.2 + Verb cluster 88.1 94.1 89.0 91.5 + Partial path 88.2 93.3 88.9 91.1 + Verb sense 88.1 93.7 89.5 91.5 + Noun head PP (only POS) ?88.6 94.4 90.0 ?92.2 + Noun head PP (only head) ?89.8 94.0 89.4 91.7 + Noun head PP (both) ?89.9 94.7 90.5 ?92.6 + First word in constituent ?89.0 94.4 91.1 ?92.7 + Last word in constituent ?89.4 93.8 89.4 91.6 + First POS in constituent 88.4 94.4 90.6 ?92.5 + Last POS in constituent 88.3 93.6 89.1 91.3 + Ordinal const.
pos.
concat.
87.7 93.7 89.2 91.4 + Const.
We lemmatized the predicate using the XTAG morphology database5  .
The Surdeanu et al System.
We call this ?SurdeanuSystem I.?
+ Classification 65.2 61.5 63.3 CORE Id. 88.4 74.4 80.8 ARGs Classification - - - 84.0Id.
These may include named entity taggers, WordNet, parsers, hand-tagged corpora, and ontology lists (Srihari and Li, 00; Harabagiu et al., 01; Hovy et al., 01; Prager et al., 01).
Global Thresholding And Multiple-Pass Parsing
Similarly for the node PRP, Pright, haVB-PRPand Pkarehe.
TOPIC : term limit HOLDER : First Congress OPINION REGION: soundly/RB defeated/VBD two/CD subsequent/JJ term-limit/JJ proposals./NN SENTIMENT_POLARITY: negative
Human1 and human2 each classified 462 adjectives, and human2 and human3 502 verbs.
3.3 Problems.
3.4 Discussion.
Inthis context, this paper empirically shows that incor porating machine learning-based techniques devisedfor predicate-argument structure analysis and bridg ing reference resolution improve the performanceof both aspect-evaluation and aspect-of relation extraction.
LM re-scoring might alleviate this problem.
30 Minuten vor der Entleerung beginnt der Rechner 5 Sekunden zu piepen.
Approximately 30 minutes before discharge the computer beeps for 5 seconds. d. 5 Minuten bevor er sich ausschaltet, fangt die Low-Battery-LED an zu blinken.
BFP-algorithm.
5.1.1 Data.
5.1.3 Results.
5.1.4 Interpretation.
Der Satz, mit dem Ruth Messinger eine der Fernsehdebatten im Burgermeisterwahlkampf in New York eroffnete, wird der einzige sein, der von ihr in Erinnerung bleibt.
Am nahezu sicheren Wahlsieg des Amtsinhabers Rudolph Giuliani am Dienstag wird er nichts andern.
Of the officeholder Rudolph Giuliani's almost certain victory in the election on Tuesday, it will alter nothing. c. Alle Zeitungen der Stadt unterstiitzen ihn.
5.2.1 Data.
EXP-CONT.
RET.
SMOOTH-S. EXP-SMOOTH-S. ROUGH-S. - cheap - exp.
Coarse-To-Fine N-Best Parsing And MaxEnt Discriminative Reranking
Discriminative reranking is one method for constructing high-performance statistical parsers  .
N66001-99-2-8916.
We used the following five treebanks of this type: German: TIGER treebank17  ; Japanese: Japanese Verbmobil treebank18  ; Portuguese: The Bosque part of the Floresta sint´a(c)tica19  ; Dutch: Alpino treebank20 (van der Beek et al., 2002b; van der Beek et al., 2002a); Chinese: Sinica 17Many thanks to the TIGER team for allowing us to use the treebank for the shared task and to Amit Dubey for converting the treebank.
27Many thanks to Kiril Simov and Petya Osenova for allowing us to use the BulTreeBank for CoNLL-X.
Canisius et al.   are six and Schiehlen and Spranger   even eight ranks higher for Dutch than overall, while Riedel et al.
Even though McDonald et al.   and Nivre et al.
First-Order Probabilistic Models for Coreference Resolution
For the First-Order model, an undirected graphical model can be defined as where Zx is the input-dependent normalizer and factor fc parameterizes the cluster-wise noun phrase compatibility as fc(yj, xj) = exp(Ek λkfk(yj, xj)).
Nicolae and Nicolae   combine pairwise classification with graph-cut algorithms.
True Ungrammaticalities.
(7a) Well if they'd-- if they'd had a knife / wou-- I wouldn't be here today.
Learnability.
[ro] Dorint¸a de a-i da lui Broglio cˆat mai multe starturi posibile.
[ro] S˘a presupunem c˘a ar fi as¸ezat al˘aturi de Lenin, oare va fi pentru totdeauna?
[ro] Pirat¸ii au un palmares de 9 la 6 anul acesta si P˘as˘arile Ros¸ii au 7 la 9.
[ro] Unul dintre obstacolele in controlarea unui copil de 2 ani este lipsa comunic˘arii verbale.
[ro] Am tr˘ait mult¸i ani intr-un oras¸ din apropiere de Connecticut ce avea o mare proport¸ie de [...] oameni de afaceri cu gusturi intelectuale.
A Classifier-Based Parser With Linear Run-Time Complexity
Contextual resolution of underspecified QLF expressions involves the instantiation of QLF meta-variables.
Restr is a first-order, one-place predicate.
For an 'unresolved' term, Quant and Reft may be meta-variables (_x,_y,...).
[+i,+j] if term +i outscopes +j.
Veltman 1991).
89 show vAny +pAl# AlvAnyp secondWords WordNet the 2nd 2d pointed +pwvyqAl#+tA$Arw# wA$Art AlwvyqpWords Segm.
91 3.2.3 WordNet Features WordNet features provide normalization on the English words.
Anno.
1 96.5 92.4 91.7 Anno.
The reduction in AER over theGIZA++ system is 40.5% and over the HMM sys tem is 48.5%.
The experiments in machine translation are carriedout on a phrase based decoder similar to the one de 94 MT03 MT04 MT05 GIZA++ 0.454 ? ?
N66001-99-2-8916.
| t�1 of original sentences xt and their compressions yt.
Formally, sentence compression aims to shorten a sentence x = x1 ... xn into a substring y = y1 ... ym, where yi E {x1, ... , xn}.
The fi rst new product .
(12870844) Curcumin down-regulates Ki67, PCNA and mutant p53 mRNAs in breast cancer cells, these properties may underlie chemopreventive action.
HvsLvsD SvsD HvsL geneReg 0.53 0.68 0.03 crohns 0.63 0.63 na 'Pun intended.
LEXAS was based on PEBLS, a publically available exemplar-based learning algorithm.
LEXAS correctly disambiguated 54% of words in BC50 and 68.6% in WSJ6.
1080) and Earley  .
Two main approaches have generally been considered: Derouault and Merialdo 1986; DeRose 1988; Church 1989; Beale 1988; Marcken 1990; Merialdo 1991; Cutting et al. 1992).
All unigrams, bigrams, and trigrams were extracted.
For valuable comments and suggestions: Be´ata Megyesi, Henrik Bostr¨om, Jussi Karlgren, Harko Verhagen, Fredrik Kilander, and the anonymous EMNLP reviewers.
Yess!
Following Collins and Singer  , Downey et al.   and Elsner et al.
Also ing topic models (e.g.
In addition Finin et. al.
This research was supported in part beled text (Etzioni et al., 2005; Carlson et al., 2010; by NSF grant IIS-0803481, ONR grant N00014-11Kozareva and Hovy, 2010; Talukdar and Pereira, 1-0294, Navy STTR contract N00014-10-M-0304, a 2010; McIntosh, 2010).
Us1532
2.1 Extracting Sentential Paraphrases.
Then we have: || ||precision A PA ? = || || recall S SA ? = || ||AER SA SAPA + ?+?
The most common paraphrase alternations that we observed fell into the following broad categories: ? Elaboration: Sentence pairs can differ in total information content, with an added word, phrase or clause in one sentence that has no Training Data Type: L12 F2 L12 F2 Test Data Type: 250 Edit Dist 250 Edit Dist 116 F2 Heuristic 116 F2 Heuristic Precision 87.46% 86.44% 85.07% 84.16% Recall 89.52% 82.64% 88.70% 86.55% AER 11.58% 15.41% 13.24% 14.71% Identical word precision 89.36% 88.79% 92.92% 93.41% Identical word recall 89.50% 83.10% 93.49% 92.47% Identical word AER 10.57% 14.14% 6.80% 7.06% Non-Identical word precision 76.99% 71.86% 60.54% 53.69% Non-Identical word recall 90.22% 69.57% 59.50% 50.41% Non-Identical word AER 20.88% 28.57% 39.81% 47.46% Table 1.
Sample human-aligned paraphrase L12 F2 Elaboration 0.83 1.3 Phrasal 0.14 0.69 Spelling 0.12 0.01 Synonym 0.18 0.25 Anaphora 0.1 0.13 Reordering 0.02 0.41 Table 2.
Ford, Bresnan, and Kaplan 1982; Marcus 1980).
LA actual N actual V precision recall N guess 496 89 N .848 .846 V guess 90 205 V .695 .697 neither 0 0 combined .797 .797 Judge 1 actual N actual V precision recall N guess 527 48 N .917 .899 V guess 59 246 V .807 .837 neither 0 0 combined .878 .878 Judge 2 actual N actual V precision recall N guess 482 29 N .943 .823 V guess 104 265 V .718 .901 neither 0 0 combined .849 .849 Now consider the performance of our lexical association (LA) procedure for the 880 standard test sentences.
We devise a simple-yet-effective algorithm to non-duplicate translations rescoring.
We devise a simple-yet-effective algorithm to generate non-duplicate k-best translations for n-gram rescoring.
Most of the recent corpus-based POS taggers in the literature are either statistically based, and use Markov Model(Weischedel et al., 1993, Merialdo, 1994) or Statistical Decision Tree(Jelinek et al., 1994, Magerman, 1995) (TBL).
D-Tree Grammars
(2) rameshan kyaa dyutnay tse RameshERG whatNom gave youoAr What did you give Ramesh? b. rameshan kyaa, chu baasaan what is believeNPertthat kor 'ERG do What does Ramesh believe that I did?
D-edges and i-edges are not distributed arbitrarily in d-trees.
D-edges and i-edges are not distributed arbitrarily in d-trees.
Only substitutable components of -y1,...,-yk can be substituted in these subsertions.
Let r1, , kbe the SA-trees for 71, , 7k, respectively.
It is straightforward to adapt the polynomial-time CKY-style recognition algorithm for a lexicalized UVG-DL of ftarnhow (199419) for DTG.
Chinese-English.
French Quant aux eaux minerales et aux limonades, elles rencontrent toujours plus d'adeptes.
En effet, noire sondage fait ressortir des ventes nettement sup6rieures a celles de 1987, pour les boissons a base de cola notamment.
La progression des chiffres d'affaires resulte en grande partie de l'accroissement du volume des ventes.
L'emploi et les investissements ont egalement augmente.
La nouvelle ordonnance federale sur les denrees alimentaires concemant entre autres les eaux minerales, entree en vigueur le ler avril 1988 apres une periode transitoire de deux ans, exige surtout une plus grande constance dam la qualite et une garantie de la purete.
Quant aux eaux minexales et aux limonades, elles rencontrent toujours plus d'adeptes.
En effet, notre sondage fait ressortir des ventes nettement supdrieures a celles de 1987, pour les boissons base de cola notamment.
An Entry in a Probabilistic Dictionary   English French Prob (French I English) the le 0.610 the la 0.178 the 0.083 the les 0.023 the ce 0.013 the il 0.012 the de 0.009 the a 0.007 the que 0.007 and the governor of the bank of canada have frequently et le gouvemeur de la banque du canada ont froquemm 800 per cent in one week through bank action .
SENT there % en une semaine a cause d une banque .
La progression des chiffres d'affaires r6sulte en grande partie de l'accroissement du volume des ventes. such was the case in the georges ats-unis et le canada a propos du he said the nose and tail of the cedd les extrdmite.s du bank issue which was settled betw banc de george . bank were surrendered by banc .
L'emploi et les investissements ont egalement augment.
La nouvelle ordonnance federale sur les denrees alimentaires concernant entre autres les eaux minerales, entree en vigueur le ler awl!
1988 apres une periode transitoire de deux ans, exige surtout une plus grande constance dans la qualite et une garantie de la purete.
We obtain 81105/73481 = 1.1.
The result for English-German is s2 = 7.3, and for English-French is s2 = 5.6.
We will call this non-terminal Ak.
The following PCFG subderivation is isomorphic: S = NPA1 VP©2 PN PN VP@2 PN PN V NP.
Ai -4 BC (11a3) A -4 BC (11a) —> BkC (bklaj) A —> BkC (bkla) Ai -4 BC, (cilai) A -4 BC, (cila) BkC, (bkCliaj) A BkC, (bkel /a) We will show that subderivations headed by A with external non-terminals at the roots and leaves, internal non-terminals elsewhere have probability 1/a.
... ?
... ... ?
... ... ?
...
Examples of such techniques are Markov Random Fields (Abney 1997; Della Pietra et al. 1997; Johnson et al.
1999), and boosting algorithms (Freund et al. 1998; Collins 2000; Walker et al.
al 1998; McCallum et al. 2000).
This would give QF= and QF2= .
Kupiec   extends Baum-Welch re-estimation to arbitrary (nonCNF) CFGs.
Lan i and Young 1990).
Garside, Leech, and Sampson 1987; de Rose 1988; Meteer, Schwartz, and Weischedel 1991; Cutting et al. 1992).
Gazdar et al. 1985; Pollard and Sag 1987; Zeevat, Calder, and Klein 1987).
Pereira and Shieber 1987), an alternative treatment of UBCs.
Briscoe 1987:125ff).
Schabes 1991b).
Pollack and Pereira 1988).
Broder   first introduced LSH.
Theorem 1 op is a function If a1 = a3 and a2 = a4, then a5 = op(a1, a2) = op(a3, a4) = a6.
Scopal relationships are represented by EPs with handle-taking arguments.
[he : expect(ee, x0e, h0e)][h0e =q hc]{} expect 2 (Kim expected that Sandy would sleep) [he, ee, x0e]{[hs, x0e, x0s]subj, [hc, ec, x0c]comp1,..
In all these cases, stochastic ("empiricist") methods pro- vide an alternative to hand-crafted ("rational- ist") approaches to NLG.
In Section 2, we present he underlying rammat- ical tbrmalism, lexicalized tree-adjoining gram- mar (LTAG).
wa.s u,o to.st {:stim,,tc .fi)r the .second phase.
aoshi (1987b) claims that TAGs properties make it particularly suited as a syntactic rep- resentation tbr generation.
tbr ~t node dei)ends only on its daughter nodes, thus allow- ing ]or a tot)-(lown dynamic l)rogrmnlning algo- ril;hln.
Secondly, Sul)ert;ags nl~y h~ve been (:hose.n incorre(:l;ly or not at ;ill.
Each node, in the deriw> tion tree consisl;s of ~t lexi(:al item m~d a su- pertag.
The latti(e~ at the.
Unra.veha" en- codes all t)ossible word sequences l)erniitted 1)y the derivation strueialre.
This mo(M has 1)ee.n (onstructed froln 1,000,0000 words of W~dl Stre, et Journal (:orpus.
This model gener- ates Th, crc no est imate Jor the second phase was cost .
Fm- thermore we use the supertag in~brmation provided by the XTAG grammar to or- der the dependents.
46 Tree Model Simt)le Go, ner~rtion Ac(:ura(y Accuracy Average time per scnten(:(; Baseline LR Model 41.2% 56.2% 186ms ~l?
(;cbank derived LI/.
Model 52.9% 66.8% 129ms Sut)ertag-bascd Model 58.!
As can be seen, tim sut)crtng-1)ased mo(M |rot)roves over the LR model derived from mmotated ata ~md both models improv(; over the baseline LR mod(:l. Sul)ertngs incorl)or~te richer infbrmation st|oh as argunmnt mid a(tjunci: disl;in(:tion, and nmnbcr and types of argunmnts.
5 Compar i son  w i th  Langk i lde  8z Kn ight Langkildc and Knight (1998a) use a hand- (:rafted grmmmu: that maps semantic represen- tations to sequences of words with lino, arization constraints.
In FEI{GUS, in|tied (hoices arc, ma(tc stochastically t)ascd on tim tree rcl)rcscntation in the "I?ce Chooser.
This allows us to capture stochastically certain long- (tisl;ance cfli,(:ts which n-grmns camlot, such as sct)~ration of p;nts of a collocations (such as peT:form an ope~ution) through interl)osing ad- juncts (John peT:formed a long, .somewhat e- dious, and quite frustrating opcration on hi,s border collie).
Second, tim hand-(rafl;cd gram- ln;tr llSCd in FEll.
References Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.
Automatic acquisition of hi- erarchical transduction models tbr machine tr anslation.
Srinivas Bangalore and Aravind Joshi.
Supertagging: An approach to ahnost pars- ing.
Aravind K. Joshi.
In A. Manaster- Ramer, editor, Mathematics of Language, pages 87-115.
Aravind K. Joshi.
Kluwer Academic Publishers, Dor- drecht /Boston /Lancaster.
Gen- eration that exploits corpus-based statistical knowledge.
In 36th Meeting of the Associa- tion .for Computational Linguistics and 17th International Cor~:[crcnce on Computational Linguistics (COLING-A CL98), pages 704- 710, Montrdal, Canada.
The practical value of n-grams in genera- tion.
In Proceedings of the Ninth Interna- tional Natural Language Generation Work- shop (INLG98), Niagara-on-the-Lake, On- tario.
Two methods tbr 1)re- dieting the order of prenonfinal t~djectives in english.
In Pwceedings of CLINg9.
David D. McDonMd and James D. Pusteiovsky.
Owen l:[ambow and Tany~ Korelsky.
Adwait t/.atllaparkhi.
Has a consensus NL gen- eration architecture appeared, and is it psy- cholinguistically plausible?
The XTAG-Group.
Technical Report ht tp  ://w~rw.
upenn, edu/~xtag/ tech- repor t / tech- repor t  .htral, The Insti- tute for Research in Cognitive Science, Uni- versity of Pennsylvania.
We expect random NCSs to be normally-distributed according to .A.r(0,1).
2004; Xue and Palmer 2004).
This corresponds to the ALL CLS F-Measure of 95.7 versus the CORE CLS F-Measure of 98.0.
Some researchers (Pradhan et al. 2004; Punyakanok et al.
2005; Punyakanok, Roth, and Yih 2005).
The F-Measure obtained was 99.0.
2005; Punyakanok, Roth, and Yih 2005; Yi and Palmer 2005; Finkel, Manning, and Ng 2006).
Input Preproc.
WER[%] PER[Vo] SSER[%] Single-Word Based Approach Text No 53.4 38.3 35.7 Yes 56.0 41.2 35.3 Speech No 67.8 50.1 54.8 Yes 67.8 51.4 52.7 Alignnient Templates Text No 49.5 35.3 31.5 Yes 48.3 35.1 27.2 Speech No 63.5 45.6 52.4 Yes 62.8 45.6 50.3 particularly a problem for the Verbmobil task, where the word order of the German- English sentence pair can be quite different.
We are given a source string f fi...fj...fj, which is to be translated into a target string ef = ei...e,...el.
In Eq.
Alshawi  ), to simpler finite-state or statistical systems such as Hobbs et al.   and Miller et al.
  and Lafferty et al.  .
NameHum is hand-tagged named entity.
The following performance improvements of the AnsWdRecall metric were statistically significant results at a confidence level of 95%: Base vs. NameStem, NameStem vs. FiltNameHumStem, and FiltNameHumStem vs. FiltProHumNameHumStem.
However, Li et al.   and Hatori et al.
The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al.  .
Whereas Lee et al.   and Li et al.
Both Li et al.   and Hatori et al.
Top-down merging.
Assigning Time-Stamps To Event-Clauses
::CAT features that indicate new events are: S-CLAUSE, S-SNT, SSUB-CLAUSE, S-PART-CLAUSE, S-RELCLAUSE.
Online Large-Margin Training Of Dependency Parsers
Nivre and Scholz   developed a history-based learning model.
J. Eisner and G. Satta.
1999.
Efficient parsing for bilexical context-free grammars and head-automaton grammars.
In Proc.
Class-Based N-Gram Models Of Natural Language
Source-channel setup.
The values of Pk-1, prk_i, and qk_...1 can be obtained easily from Pk, plk, prk, and qk.
9-14.
Edmundson, H.  .
Grefenstett, G.  .
time expressions = 77/316 (24%) trailing PPs = 184/316 (58%) trailing SBARs = 49/316 (16%) each story.
11, we use the GIS  .
The renormalization needed in Eq.
11.
Pseudo-Projectivity A Polynomially Parsable Non-Projective Dependency Grammar
Call this multiset the rewrite-multiset.
„rans which requires a Nobj.
Call this multiset LM.
IIS-0329064 and CCR-0122581; SRI International under subcontract no.
Many existing systems for statistical machine translation (Garcia-Varea and Casacuberta 2001; Germann et al. 2001; Nießen et al.
1.3.1 Morphology.
The translation models they presented in various papers between 1988 and 1993 (Brown et al. 1988; Brown et al.
Input: Wir wollen nach dem Abendessen nach Essen aufbrechen.
7.1.1 Verbmobil.
7.1.2 Nespole!.
2000; Lavie et al. 2001).
7.5.1 Results on the Verbmobil Task.
Input sind Sie mit einem Doppelzimmer einverstanden?
Input mit dem Zug ist es bequemer.
Input wir haben zwei Zimmer.
Input ich w¨urde das Hilton vorschlagen denn es ist das beste.
7.5.2 Results on the Nespole!
Aligning parallel texts has recently received considerable attention (Warwick et al., 1990; Brown et al., 1991a; Gale and Church, 1991b; Gale and Church, 1991a; Kay and Rosenschein, 1993; Simard et al., 1992; Church, 1993; Kupiec, 1993; Matsumoto et al., 1993).
WordNet   is usedas the knowledge source for synonymy and deriva tions.
drs(T): x1 x2 x3 book(x1) book(x2) ? x1=x2 clinton(x3) of(x1,x3) ? e4 x5 big(x5) seller(x5) be(e4) agent(e4,x1) patient(e4,x5) loc(e4,here) drs(H): x1 x2 e3 x4 book(x1) clinton(x2) of(x1,x2) big(x4) seller(x4) be(e3) agent(e3,x1) patient(e3,x4) 629 Proper names and definite descriptions are treated as anaphoric, and bound to previously introduceddiscourse referents if possible, otherwise accommodated.
4.1 Dataset Design and Evaluation Measures.
The organisers?
Q3.
1..
