{"resultcitation": {"58.0": 0.05063291139240506, "introduction": 0.13924050632911392, "experiments. ": 0.02531645569620253, "0.834  336": 0.06329113924050633, "grammar development. ": 0.012658227848101266, "paper": 0.06329113924050633, "syntactic ambiguity in arabic. ": 0.02531645569620253, "standard parsing experiments. ": 0.012658227848101266, "system description. ": 0.0379746835443038, "feature description. ": 0.012658227848101266, "abstract": 0.0759493670886076, "our tagger. ": 0.012658227848101266, "evaluation. ": 0.11392405063291139, "conclusions. ": 0.012658227848101266, "the proposal. ": 0.012658227848101266, "the  problem. ": 0.012658227848101266, "related work. ": 0.06329113924050633, "features. ": 0.0379746835443038, "those words that have the semantic classes \u201cparent\u201d,. ": 0.012658227848101266, "our chinese word segmentation process. ": 0.012658227848101266, "markov clustering. ": 0.012658227848101266, "five methods for  spelling correction. ": 0.05063291139240506, "0.827": 0.012658227848101266, "the data. ": 0.012658227848101266, "potential for improvement. ": 0.0379746835443038, "experimental results. ": 0.012658227848101266, "experimental classes and verbs. ": 0.012658227848101266, "apply  the antecedent  indicators  to each  poten\u00ad. ": 0.012658227848101266, "miscategorization  of  entity  as. ": 0.02531645569620253}, "methodcitation": {"58.0": 0.007736943907156673, "introduction": 0.18375241779497098, "generative story. ": 0.0038684719535783366, "method. ": 0.007736943907156673, "abstract": 0.1470019342359768, "results. ": 0.009671179883945842, "discussion. ": 0.029013539651837523, "evaluation. ": 0.025145067698259187, "semantic. ": 0.0019342359767891683, "approach. ": 0.0019342359767891683, "conclusion. ": 0.029013539651837523, "previous work. ": 0.0038684719535783366, "supersenses. ": 0.0038684719535783366, "confusion network decoding. ": 0.007736943907156673, "log-linear combination with arbitrary. ": 0.0038684719535783366, "conclusions. ": 0.017408123791102514, "evaluation metrics. ": 0.0038684719535783366, "multiple confusion network decoding. ": 0.0019342359767891683, "learning and inference. ": 0.0019342359767891683, "paper": 0.03868471953578337, "formal description of the problem. ": 0.0019342359767891683, "the espresso algorithm. ": 0.005802707930367505, "relevant work. ": 0.0038684719535783366, "experimental results. ": 0.02127659574468085, "0.834  336": 0.007736943907156673, "grammar development. ": 0.0019342359767891683, "standard parsing experiments. ": 0.005802707930367505, "feature description. ": 0.015473887814313346, "system description. ": 0.0019342359767891683, "related work. ": 0.02321083172147002, "the result is spliced between the states rep-. ": 0.009671179883945842, "finite-state  morphology. ": 0.0019342359767891683, "intersective levin classes. ": 0.0038684719535783366, "nora  pushed  the  package.. ": 0.0019342359767891683, "materials and methods. ": 0.0019342359767891683, "conclusions and future  work. ": 0.0019342359767891683, "the dialogue act labeling task. ": 0.005802707930367505, "practice. ": 0.0038684719535783366, "decision trees. ": 0.005802707930367505, "experiment. ": 0.0019342359767891683, "our approach. ": 0.0038684719535783366, "transliterated foreign  names such  as . 3r:\u00aeelli  ma3-lai2-xil-ya3. ": 0.025145067698259187, "the proposal. ": 0.02321083172147002, "some  phonological rules  depend upon correct  word  segmentation,. ": 0.0019342359767891683, "those words that have the semantic classes \u201cparent\u201d,. ": 0.025145067698259187, "features. ": 0.025145067698259187, "support vector machines. ": 0.0019342359767891683, "experimentation. ": 0.0038684719535783366, "wroblewski's incremental copy graph unifitation method and its problems. ": 0.0019342359767891683, "our chinese word segmentation process. ": 0.0019342359767891683, "experiments. ": 0.02321083172147002, "40.0\u2217\u2217": 0.02127659574468085, "systems used. ": 0.015473887814313346, "layers of annotation. ": 0.0019342359767891683, "past, present, future applications. ": 0.007736943907156673, "building a graph of similar words. ": 0.0038684719535783366, "word sense clustering algorithm. ": 0.0038684719535783366, "markov clustering. ": 0.0019342359767891683, "applications and future research. ": 0.0019342359767891683, "dp algorithm for statistical. ": 0.007736943907156673, "basic approach. ": 0.0019342359767891683, "experimental method. ": 0.0019342359767891683, "five methods for  spelling correction. ": 0.009671179883945842, "context-sensitive spelling correction. ": 0.0019342359767891683, "0.827": 0.0019342359767891683, "available at. ": 0.0019342359767891683, "available at http://www.cs.pitt.edu/\u02dcwiebe/. ": 0.005802707930367505, "available   at   http://www.comp.leeds.ac.uk/. ": 0.0019342359767891683, "potential for improvement. ": 0.009671179883945842, "the data. ": 0.0038684719535783366, "other verb clustering work. ": 0.0038684719535783366, "experimental classes and verbs. ": 0.0019342359767891683, "clustering and evaluation methods. ": 0.005802707930367505, "conclusions and future work. ": 0.0019342359767891683, "the feature space. ": 0.0019342359767891683, "appropriateness for, malisms. ": 0.005802707930367505, "quasi-synchronous. ": 0.0038684719535783366, "model. ": 0.0019342359767891683, "decoding. ": 0.0038684719535783366, "algorithm. ": 0.0038684719535783366, "the approach. ": 0.015473887814313346, "apply  the antecedent  indicators  to each  poten\u00ad. ": 0.02321083172147002, "adapting the robust  approach for other. ": 0.0019342359767891683, "identifying lexical cohesion. ": 0.0038684719535783366, "gibbs sampling for fertility hmm. ": 0.007736943907156673, "fertility hidden markov model. ": 0.0019342359767891683, "pps containing \u201cby\u201d and a gerund followed by \u201cit\u201d. ": 0.007736943907156673, "miscategorization  of  entity  as. ": 0.0019342359767891683}, "aimcitation": {"related work. ": 0.02564102564102564, "our approach: topic-sensitive lexrank. ": 0.07692307692307693, "lexrank versus the baseline system. ": 0.02564102564102564, "introduction": 0.23076923076923078, "0.1973852892722677 milan fire brigade officials said that... ": 0.05128205128205128, "conclusion. ": 0.02564102564102564, "0.834  336": 0.10256410256410256, "nora  pushed  the  package.. ": 0.02564102564102564, "prior and related work. ": 0.02564102564102564, "paper": 0.05128205128205128, "dialogue act classification. ": 0.02564102564102564, "the dialogue act labeling task. ": 0.02564102564102564, "tightness of the maximum-likelihood estimator. ": 0.02564102564102564, "abstract": 0.05128205128205128, "transliterated foreign  names such  as . 3r:\u00aeelli  ma3-lai2-xil-ya3. ": 0.02564102564102564, "the lazy incremental copy graph unification method. ": 0.02564102564102564, "context-sensitive spelling correction. ": 0.05128205128205128, "five methods for  spelling correction. ": 0.02564102564102564, "available at http://www.cs.pitt.edu/\u02dcwiebe/. ": 0.02564102564102564, "pps containing \u201cby\u201d and a gerund followed by \u201cit\u201d. ": 0.07692307692307693}, "implicationcitation": {"abstract": 0.08, "system description. ": 0.02, "nora  pushed  the  package.. ": 0.06, "introduction": 0.18, "evaluation. ": 0.04, "the proposal. ": 0.04, "discussion. ": 0.08, "transliterated foreign  names such  as . 3r:\u00aeelli  ma3-lai2-xil-ya3. ": 0.06, "the  problem. ": 0.02, "experimentation. ": 0.04, "those words that have the semantic classes \u201cparent\u201d,. ": 0.04, "related work. ": 0.06, "paper": 0.04, "wroblewski's incremental copy graph unifitation method and its problems. ": 0.02, "conclusions. ": 0.02, "our chinese word segmentation process. ": 0.02, "dp algorithm for statistical. ": 0.02, "building a feature set of bigrams. ": 0.02, "potential for improvement. ": 0.02, "other verb clustering work. ": 0.02, "conclusions and future work. ": 0.02, "algorithm. ": 0.02, "apply  the antecedent  indicators  to each  poten\u00ad. ": 0.02, "pps containing \u201cby\u201d and a gerund followed by \u201cit\u201d. ": 0.02, "miscategorization  of  entity  as. ": 0.02}, "hypothesiscitation": {"abstract": 0.25, "classifying verbs. ": 0.25, "nora  pushed  the  package.. ": 0.16666666666666666, "introduction": 0.08333333333333333, "those words that have the semantic classes \u201cparent\u201d,. ": 0.08333333333333333, "five methods for  spelling correction. ": 0.08333333333333333, "conclusions and future work. ": 0.08333333333333333}}