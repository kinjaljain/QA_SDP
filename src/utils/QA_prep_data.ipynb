{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_prep_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtbQOciVeuFv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzs54VrWfJ3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install -y python-enchant"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTwzHMaff1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# content of requirements.txt:\n",
        "# numpy\n",
        "# pyenchant\n",
        "# tqdm\n",
        "# nltk\n",
        "# gensim\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5t6ugQKdxr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_2018_filename = \"/content/drive/My Drive/QA/processed-data-2018.json\"\n",
        "dataset_2019_filename = \"/content/drive/My Drive/QA/processed-data-2019.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgIBGcxkdrUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from tqdm import tqdm\n",
        "# from dataloaders.load_and_parse import load_all\n",
        "from jaccard import get_similarity_score as j\n",
        "import enchant\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "d = enchant.Dict(\"en_US\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVvSYoOKg5p-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "import pickle\n",
        "Datum = namedtuple('Datum', 'ref cite offsets author is_test facet year')\n",
        "Offsets = namedtuple('Offsets', 'marker cite ref')\n",
        "Article = namedtuple('Article', 'id xml sentences sections')\n",
        "\n",
        "with open(dataset_2018_filename, 'rb') as f:\n",
        "   dataset = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqF3_U1jf546",
        "colab_type": "code",
        "outputId": "bf74c28e-589f-4e55-de62-55c0fc567385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 2018 - data for main task\n",
        "import pickle\n",
        "\n",
        "d = enchant.Dict(\"en_US\")\n",
        "\n",
        "# DATA_ROOT = '../../data'\n",
        "\n",
        "# dataset = load_all(DATA_ROOT)\n",
        "\n",
        "\n",
        "meaningless_file = open(\"meaningless_sentences.txt\", \"w\")\n",
        "alphabet_file = open(\"alphabet_sentences.txt\", \"w\")\n",
        "\n",
        "\n",
        "bad_ratios = []\n",
        "bad_count = 0\n",
        "total_count = 0\n",
        "bad_sentences = []\n",
        "\n",
        "def filter_meaningless(ref_article, i, jargon):\n",
        "    line = ref_article[i]\n",
        "    # line.replace(\";\", \" \").replace(\",\", \" \")\n",
        "    enc_line = line.encode('unicode_escape').decode()\n",
        "    line = re.sub(r\"\\\\u....\", \"\", enc_line)\n",
        "    # Table caption\n",
        "    if re.search(r'Table [0-9]+: ', line):\n",
        "        start_idx = line.index(\"Table \")\n",
        "        line = line[start_idx:]\n",
        "        return True, line\n",
        "\n",
        "    # Figure caption\n",
        "    elif re.search(r'Figure [0-9]+: ', line):\n",
        "        start_idx = line.index(\"Figure \")\n",
        "        line = line[start_idx:]\n",
        "        return True, line\n",
        "\n",
        "    words = np.array(nltk.word_tokenize(ref_article[i]))\n",
        "    num_singles = np.array([len(word) < 2 for word in words])\n",
        "    count = words[num_singles].shape[0]\n",
        "    ratio = count / len(words)\n",
        "\n",
        "    if ratio > 0.53:\n",
        "        # ff.write(ref_article[i])\n",
        "        alphabet_file.write(ref_article[i] + \"\\n\")\n",
        "        return False, \"\"\n",
        "\n",
        "    is_valid = []\n",
        "    check = words\n",
        "    for word in words:\n",
        "        if d.check(word) or word in jargon:\n",
        "            is_valid.append(True)\n",
        "        else:\n",
        "            is_valid.append(False)\n",
        "    is_valid = np.array(is_valid)\n",
        "    check = np.array(check)\n",
        "    count = check[is_valid].shape[0]\n",
        "    ratio = count / check.shape[0]\n",
        "    # print(ratio, line)\n",
        "    if ratio <= 0.72:\n",
        "        # print(\"Ignoring Meaningless Sentence with ratio:\", ratio, line)\n",
        "        meaningless_file.write(ref_article[i] +  \"\\n\")\n",
        "        return False, \"\"\n",
        "    return True, line\n",
        "\n",
        "def clean_citing_sentence(sentence):\n",
        "    if re.search(r\"\\\\u....\", sentence):\n",
        "        sentence = re.sub(r\"\\\\u....\", \"\", sentence)\n",
        "    return sentence\n",
        "\n",
        "def prepare(dataset, reference_context):\n",
        "    result = []\n",
        "    jargon = open(\"jargon.txt\", 'r').readlines()\n",
        "    jargon = [word[:-1] for word in jargon]\n",
        "    for data in tqdm(dataset):\n",
        "        ref_article = data.ref.sentences\n",
        "        try:\n",
        "            ref_title = ref_article[0]\n",
        "        except:\n",
        "            ref_title = \"No title\"\n",
        "        ref_sections = data.ref.sections\n",
        "        citing_article = data.cite.sentences\n",
        "        offsets = data.offsets\n",
        "        positives = offsets.ref\n",
        "        for k,v in ref_article:\n",
        "            is_meaningful, ref_article[k] = filter_meaningless(ref_article, k, jargon) \n",
        "            if not is_meaningful:\n",
        "                count_bad += 1\n",
        "            \n",
        "        negatives = ref_article.keys() - set(positives)\n",
        "        if len(negatives) < 3 or not citing_article:\n",
        "            continue\n",
        "        positive_ids = []\n",
        "        for x in positives:\n",
        "            positive_ids.extend(\n",
        "                [i for i in range(max(1, x - reference_context), min(x + reference_context, len(ref_article) - 1) + 1)])\n",
        "        complete_citing_sentence = \" \".join([citing_article[c] for c in offsets.cite])\n",
        "        complete_citing_sentence = clean_citing_sentence(complete_citing_sentence.encode('unicode_escape').decode())\n",
        "        negatives = set(negatives) - set(positives)\n",
        "        r = {}\n",
        "        negs = []\n",
        "        for i in negatives:\n",
        "            is_meaningful, line = filter_meaningless(ref_article, i, jargon)\n",
        "            if is_meaningful:\n",
        "                r[i] = line\n",
        "                negs.append(i)\n",
        "        negatives = negs\n",
        "        text_sim_negatives = sorted(negatives, key=lambda x: j(r[x], complete_citing_sentence), reverse=True)[:1]\n",
        "        rand_negs = np.random.choice(list(set(negatives) - set(text_sim_negatives)), size=2)\n",
        "        negatives = text_sim_negatives + list(rand_negs)\n",
        "\n",
        "        result.extend([(\" \".join([r[i] for i in range(max(1, x - reference_context),\n",
        "                                                                min(x + reference_context, len(ref_article)-1) + 1)]),\n",
        "                        complete_citing_sentence, 0) for x in negatives])\n",
        "        try:\n",
        "            result.extend([(\" \".join([ref_article[i] for i in range(max(1, x - reference_context),\n",
        "                                                                    min(x + reference_context, len(ref_article)-1) + 1)]),\n",
        "                            complete_citing_sentence, 1) for x in positives])\n",
        "        except:\n",
        "            print(\"hello\")\n",
        "    return result\n",
        "\n",
        "reference_context = 0\n",
        "result = prepare(dataset, reference_context)\n",
        "with open(\"prepared_data_2018.json\", \"w\") as f:\n",
        "    json.dump(result, f)\n",
        "\n",
        "# with open(\"ratios_0.53.txt\", \"w\") as f:\n",
        "#     f.write(\"count: {}\\n\".format(bad_count))\n",
        "#     f.write(\"count: {}\\n\".format(total_count))\n",
        "#     for i, j in zip(bad_sentences, bad_ratios):\n",
        "#         f.write(\"S: {}, \\t R: {}\\n\".format(i, str(j)))\n",
        "#\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 753/753 [01:20<00:00,  9.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNPztvMYlugk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "Datum = namedtuple('Datum', 'ref cite offsets author is_test facet year')\n",
        "Offsets = namedtuple('Offsets', 'marker cite ref')\n",
        "Article = namedtuple('Article', 'id xml sentences sections')\n",
        "\n",
        "with open(dataset_2019_filename, 'rb') as f:\n",
        "   dataset = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxltZ8tDrJHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nsp data for 2019 dataset\n",
        "meaningless_file = open(\"meaningless_sentences_2019.txt\", \"w\")\n",
        "alphabet_file = open(\"alphabet_sentences_2019.txt\", \"w\")\n",
        "\n",
        "\n",
        "bad_ratios = []\n",
        "bad_count = 0\n",
        "total_count = 0\n",
        "bad_sentences = []\n",
        "\n",
        "def filter_meaningless(ref_article, i, jargon):\n",
        "    line = ref_article[i]\n",
        "    # line.replace(\";\", \" \").replace(\",\", \" \")\n",
        "    enc_line = line.encode('unicode_escape').decode()\n",
        "    line = re.sub(r\"\\\\u....\", \"\", enc_line)\n",
        "    # Table caption\n",
        "    if re.search(r'Table [0-9]+: ', line):\n",
        "        start_idx = line.index(\"Table \")\n",
        "        line = line[start_idx:]\n",
        "        return True, line\n",
        "\n",
        "    # Figure caption\n",
        "    elif re.search(r'Figure [0-9]+: ', line):\n",
        "        start_idx = line.index(\"Figure \")\n",
        "        line = line[start_idx:]\n",
        "        return True, line\n",
        "\n",
        "    words = np.array(nltk.word_tokenize(ref_article[i]))\n",
        "    if len(words) == 0:\n",
        "      return False, None\n",
        "    num_singles = np.array([len(word) < 2 for word in words])\n",
        "    count = words[num_singles].shape[0]\n",
        "    ratio = count / len(words)\n",
        "\n",
        "    if ratio > 0.53:\n",
        "        # ff.write(ref_article[i])\n",
        "        alphabet_file.write(ref_article[i] + \"\\n\")\n",
        "        return False, None\n",
        "\n",
        "    is_valid = []\n",
        "    check = words\n",
        "    for word in words:\n",
        "        if d.check(word) or word in jargon:\n",
        "            is_valid.append(True)\n",
        "        else:\n",
        "            is_valid.append(False)\n",
        "    is_valid = np.array(is_valid)\n",
        "    check = np.array(check)\n",
        "    count = check[is_valid].shape[0]\n",
        "    ratio = count / check.shape[0]\n",
        "    # print(ratio, line)\n",
        "    if ratio <= 0.72:\n",
        "        # print(\"Ignoring Meaningless Sentence with ratio:\", ratio, line)\n",
        "        meaningless_file.write(ref_article[i] +  \"\\n\")\n",
        "        return False, None\n",
        "    return True, line\n",
        "\n",
        "def clean_citing_sentence(sentence):\n",
        "    if re.search(r\"\\\\u....\", sentence):\n",
        "        sentence = re.sub(r\"\\\\u....\", \"\", sentence)\n",
        "    return sentence\n",
        "\n",
        "def prepare_nsp(dataset, reference_context):\n",
        "    result = []\n",
        "    jargon = open(\"jargon.txt\", 'r').readlines()\n",
        "    jargon = [word[:-1] for word in jargon]\n",
        "    for data in tqdm(dataset):\n",
        "        ref_article = data.ref.sentences\n",
        "        try:\n",
        "            ref_title = ref_article[0]\n",
        "        except:\n",
        "            ref_title = \"No title\"\n",
        "        ref_sections = data.ref.sections\n",
        "        citing_article = data.cite.sentences\n",
        "        offsets = data.offsets\n",
        "        positives = offsets.ref\n",
        "        negatives = ref_article.keys() - set(positives)\n",
        "        if len(negatives) < 3 or not citing_article:\n",
        "            continue\n",
        "        positive_ids = []\n",
        "        for x in positives:\n",
        "            positive_ids.extend(\n",
        "                [i for i in range(max(1, x - reference_context), min(x + reference_context, len(ref_article) - 1) + 1)])\n",
        "        complete_citing_sentence = \" \".join([citing_article[c] for c in offsets.cite])\n",
        "        complete_citing_sentence = clean_citing_sentence(complete_citing_sentence.encode('unicode_escape').decode())\n",
        "        negatives = set(negatives) - set(positives)\n",
        "        r = {}\n",
        "        negs = []\n",
        "        for i in negatives:\n",
        "            is_meaningful, line = filter_meaningless(ref_article, i, jargon)\n",
        "            if is_meaningful:\n",
        "                r[i] = line\n",
        "                negs.append(i)\n",
        "        negatives = negs\n",
        "        text_sim_negatives = sorted(negatives, key=lambda x: j(r[x], complete_citing_sentence), reverse=True)[:1]\n",
        "        rand_negs = np.random.choice(list(set(negatives) - set(text_sim_negatives)), size=2)\n",
        "        negatives = text_sim_negatives + list(rand_negs)\n",
        "\n",
        "        result.extend([(\" \".join([r[i] for i in range(max(1, x - reference_context),\n",
        "                                                                min(x + reference_context, len(ref_article)-1) + 1)]),\n",
        "                        complete_citing_sentence, 0) for x in negatives])\n",
        "        try:\n",
        "            result.extend([(\" \".join([ref_article[i] for i in range(max(1, x - reference_context),\n",
        "                                                                    min(x + reference_context, len(ref_article)-1) + 1)]),\n",
        "                            complete_citing_sentence, 1) for x in positives])\n",
        "        except:\n",
        "            print(\"hello\")\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0FjApZPr9sN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = prepare_nsp(dataset, reference_context=0)\n",
        "with open(\"prepared_data_nsp_main_2019.txt\", \"w\") as f1:\n",
        "    for sentence in result:\n",
        "        f1.write(sentence + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3--S21GKEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEvnOEZbGk3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(\"prepared_data_nsp_main_2019.json\", \"w\") as f:\n",
        "    json.dump(result, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ3X7ozQGtKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls -al --block-size=M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xX3gRKwJ3zp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/prepared_data_2018.json \"/content/drive/My Drive/QA/Prepared data for tasks/prepared_data_nsp_main_2018.json\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}