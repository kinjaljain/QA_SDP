Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,C10-1045,J13-1007,['72'],Green and Manning 2010,['72'],dummy,dummy,'14',"<S ssid=""1"" sid=""14"">But Arabic contains a variety of linguistic phenomena unseen in English.</S>",methodcitation
3,C10-1045,J13-1007,['148'],Green and Manning 2010,"['148','149']",dummy,dummy,"'240','24'","<S ssid=""1"" sid=""240"">The Stanford parser includes both the manually annotated grammar (§4) and an Arabic unknown word model with the following lexical features: 1.</S><S ssid=""1"" sid=""24"">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6).</S>",methodcitation
4,C10-1045,J13-1007,['479'],Green and Manning 2010,"['479','480']",dummy,dummy,"'81','307'","<S ssid=""1"" sid=""81"">Also surprising is the low test set OOV rate given the possibility of morphological variation in Arabic.</S><S ssid=""1"" sid=""307"">Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew.</S>",methodcitation
5,C10-1045,J13-1007,['511'],2010,"['510','511']",dummy,dummy,"'277','8','6','2','23'","<S ssid=""1"" sid=""277"">Lattice parsing (Chappelier et al., 1999) is an alternative to a pipeline that prevents cascading errors by placing all segmentation options into the parse chart.</S><S ssid=""1"" sid=""8"">Certainly these linguistic factors increase the difficulty of syntactic disambiguation.</S><S ssid=""1"" sid=""6"">Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2–5% F1.</S><S ssid=""1"" sid=""2"">First, we identify sources of syntactic ambiguity understudied in the existing parsing literature.</S><S ssid=""1"" sid=""23"">To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5).</S>",methodcitation
6,C10-1045,J13-1007,['670'],2010,['670'],dummy,dummy,'6',"<S ssid=""1"" sid=""6"">Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2–5% F1.</S>",methodcitation
7,C10-1045,J13-1007,['672'],Green and Manning 2010,['672'],dummy,dummy,'225',"<S ssid=""1"" sid=""225"">(2009b) evaluated the Bikel parser using the same ATB split, but only reported dev set results with gold POS tags for sentences of length ≤ 40.</S>",methodcitation
8,C10-1045,J13-1008,['195'],Green and Manning 2010,['195'],dummy,dummy,"'71','113'","<S ssid=""1"" sid=""71"">A better approach would be to distin guish between these cases, possibly by drawing on the vast linguistic work on Arabic connectives (AlBatal, 1990).</S><S ssid=""1"" sid=""113"">We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).</S>",methodcitation
9,C10-1045,J13-1008,['196'],2010,['196'],dummy,dummy,"'113','84'","<S ssid=""1"" sid=""113"">We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).</S><S ssid=""1"" sid=""84"">Annotation consistency is important in any supervised learning task.</S>",methodcitation
10,C10-1045,J13-1008,['665'],2010,['665'],dummy,dummy,'23',"<S ssid=""1"" sid=""23"">To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5).</S>",methodcitation
11,C10-1045,J13-1009,['190'],2010,['190'],dummy,dummy,"'117','113','14','22'","<S ssid=""1"" sid=""117"">We start with noun features since written Arabic contains a very high proportion of NPs.</S><S ssid=""1"" sid=""113"">We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).</S><S ssid=""1"" sid=""14"">But Arabic contains a variety of linguistic phenomena unseen in English.</S><S ssid=""1"" sid=""22"">We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (§4).</S>",methodcitation
12,C10-1045,J13-1009,['193'],2010,['193'],dummy,dummy,"'128','113','22','129'","<S ssid=""1"" sid=""128"">8 We use head-finding rules specified by a native speaker.</S><S ssid=""1"" sid=""113"">We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).</S><S ssid=""1"" sid=""22"">We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (§4).</S><S ssid=""1"" sid=""129"">of Arabic.</S>",methodcitation
13,C10-1045,J13-1009,['316'],Green and Manning 2010,['316'],dummy,dummy,"'0','64','26'","<S ssid=""1"" sid=""0"">Better Arabic Parsing: Baselines, Evaluations, and Analysis</S><S ssid=""1"" sid=""64"">We propose a limit of 70 words for Arabic parsing evaluations.</S><S ssid=""1"" sid=""26"">To our knowledge, ours is the first analysis of this kind for Arabic parsing.</S>",methodcitation
14,C10-1045,J13-1009,['397'],Green and Manning 2010,['397'],dummy,dummy,"'301','6','276'","<S ssid=""1"" sid=""301"">Table 9 shows that MADA produces a high quality segmentation, and that the effect of cascading segmentation errors on parsing is only 1.92% F1.</S><S ssid=""1"" sid=""6"">Finally, we show that in application settings, the absence of gold segmentation lowers parsing performance by 2–5% F1.</S><S ssid=""1"" sid=""276"">Segmentation errors cascade into the parsing phase, placing an artificial limit on parsing performance.</S>",methodcitation
15,C10-1045,J13-1009,['406'],Green and Manning 2010,['406'],dummy,dummy,"'247','224'","<S ssid=""1"" sid=""247"">Modifying the Berkeley parser for Arabic is straightforward.</S><S ssid=""1"" sid=""224"">Maamouri et al.</S>",methodcitation
17,C10-1045,P11-1159,['109'],2010,['109'],dummy,dummy,"'84','21'","<S ssid=""1"" sid=""84"">Annotation consistency is important in any supervised learning task.</S><S ssid=""1"" sid=""21"">Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (§3).</S>",methodcitation
18,C10-1045,P11-2037,['34'],"Green and Manning, 2010",['34'],dummy,dummy,'23',"<S ssid=""1"" sid=""23"">To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5).</S>",methodcitation
19,C10-1045,P11-2122,['7'],"Green and Manning, 2010",['7'],dummy,dummy,"'173','23'","<S ssid=""1"" sid=""173"">12 For English, our Evalb implementation is identical to the most recent reference (EVALB20080701).</S><S ssid=""1"" sid=""23"">To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5).</S>",methodcitation
20,C10-1045,P11-2122,['73'],2010,['73'],dummy,dummy,"'3','84','21','113','22'","<S ssid=""1"" sid=""3"">Second, we show that although the Penn Arabic Treebank is similar to other tree- banks in gross statistical terms, annotation consistency remains problematic.</S><S ssid=""1"" sid=""84"">Annotation consistency is important in any supervised learning task.</S><S ssid=""1"" sid=""21"">Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (§3).</S><S ssid=""1"" sid=""113"">We can use the preceding linguistic and annotation insights to build a manually annotated Arabic grammar in the manner of Klein and Manning (2003).</S><S ssid=""1"" sid=""22"">We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (§4).</S>",methodcitation
21,C10-1045,P11-2122,['109'],2010,['109'],dummy,dummy,"'41','44'","<S ssid=""1"" sid=""41"">Even with vocalization, there are linguistic categories that are difficult to identify without semantic clues.</S><S ssid=""1"" sid=""44"">However, when grammatical relations like subject and object are evaluated, parsing performance drops considerably (Green et al., 2009).</S>",methodcitation
22,C10-1045,P11-2124,['18'],2010,['18'],dummy,dummy,"'0','64','26'","<S ssid=""1"" sid=""0"">Better Arabic Parsing: Baselines, Evaluations, and Analysis</S><S ssid=""1"" sid=""64"">We propose a limit of 70 words for Arabic parsing evaluations.</S><S ssid=""1"" sid=""26"">To our knowledge, ours is the first analysis of this kind for Arabic parsing.</S>",methodcitation
23,C10-1045,P12-1016,['196'],"Green and Manning, 2010",['196'],dummy,dummy,"'227','247','240','279','167'","<S ssid=""1"" sid=""227"">We are unaware of prior results for the Stanford parser.</S><S ssid=""1"" sid=""247"">Modifying the Berkeley parser for Arabic is straightforward.</S><S ssid=""1"" sid=""240"">The Stanford parser includes both the manually annotated grammar (§4) and an Arabic unknown word model with the following lexical features: 1.</S><S ssid=""1"" sid=""279"">We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.</S><S ssid=""1"" sid=""167"">able at http://nlp.stanford.edu/projects/arabic.shtml.</S>",methodcitation
24,C10-1045,P12-2002,['12'],"Green and Manning, 2010",['12'],dummy,dummy,'24',"<S ssid=""1"" sid=""24"">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6).</S>",methodcitation
25,C10-1045,P12-2002,['34'],2010,"['34','35']",dummy,dummy,'14',"<S ssid=""1"" sid=""14"">But Arabic contains a variety of linguistic phenomena unseen in English.</S>",methodcitation
26,C10-1045,P12-2002,['39'],"Green and Manning, 2010","['38','39']",dummy,dummy,'24',"<S ssid=""1"" sid=""24"">Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (§6).</S>",methodcitation
27,C10-1045,W13-4904,['115'],2010,['115'],dummy,dummy,"'141','61'","<S ssid=""1"" sid=""141"">mark- ContainsVerb is especially effective for distinguishing root S nodes of equational sentences.</S><S ssid=""1"" sid=""61"">English parsing evaluations usually report results on sentences up to length 40.</S>",methodcitation
28,C10-1045,W13-4904,['234'],2010,['234'],dummy,dummy,"'27','0'","<S ssid=""1"" sid=""27"">Arabic is a morphologically rich language with a root-and-pattern system similar to other Semitic languages.</S><S ssid=""1"" sid=""0"">Better Arabic Parsing: Baselines, Evaluations, and Analysis</S>",methodcitation
29,C10-1045,W13-4904,['244'],2010,['244'],dummy,dummy,'23',"<S ssid=""1"" sid=""23"">To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (§5).</S>",methodcitation
31,C10-1045,W13-4917,['260'],2010,['260'],dummy,dummy,"'115','279'","<S ssid=""1"" sid=""115"">A simple lexicalized PCFG with second order Markovization gives relatively poor performance: 75.95% F1 on the test set.8 But this figure is surprisingly competitive with a recent state-of-the-art baseline (Table 7).</S><S ssid=""1"" sid=""279"">We extend the Stanford parser to accept pre-generated lattices, where each word is represented as a finite state automaton.</S>",methodcitation
32,C10-1045,W13-4917,['262'],2010,['262'],dummy,dummy,"'154','109'","<S ssid=""1"" sid=""154"">At the phrasal level, we remove all function tags and traces.</S><S ssid=""1"" sid=""109"">7 Unlike Dickinson (2005), we strip traces and only con-.</S>",methodcitation
33,C10-1045,W13-4917,['218'],"Green and Manning, 2010",['218'],dummy,dummy,'3',"<S ssid=""1"" sid=""3"">Second, we show that although the Penn Arabic Treebank is similar to other tree- banks in gross statistical terms, annotation consistency remains problematic.</S>",methodcitation
