Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
3,J96-3004,C00-2095,['80'],"Sproat ct a.l., 1996",['80'],dummy,dummy,'228',"<S ssid=""1"" sid=""228"">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S>",methodcitation
4,J96-3004,C02-1049,['58'],"Sproat et al, 1996",['58'],dummy,dummy,'115',"<S ssid=""1"" sid=""115"">Others depend upon various lexical heuris­ tics: for example Chen and Liu (1992) attempt to balance the length of words in a three-word window, favoring segmentations that give approximately equal length for each word.</S>",methodcitation
5,J96-3004,C02-1049,['127'],"Sproat et al, 1996","['124','127']",dummy,dummy,"'233','242'","<S ssid=""1"" sid=""233"">na me =>1 ha nzi fa mi ly 1 ha nzi gi ve n 4.</S><S ssid=""1"" sid=""242"">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S>",methodcitation
6,J96-3004,C02-1080,['20'],Sproat et al. 96,"['20','21']",dummy,dummy,"'137','0'","<S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
7,J96-3004,C02-1143,['107'],"Sproat et al., 1996",['107'],dummy,dummy,"'112','305'","<S ssid=""1"" sid=""112"">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S><S ssid=""1"" sid=""305"">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S>",methodcitation
8,J96-3004,E09-1063,['107'],"Sproat et al., 1996",['107'],dummy,dummy,"'93','101'","<S ssid=""1"" sid=""93"">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S><S ssid=""1"" sid=""101"">(See Sproat and Shih 1995.)</S>",methodcitation
9,J96-3004,I05-3031,['7'],"Sproat et al., 1996","['6','7']",dummy,dummy,"'20','0'","<S ssid=""1"" sid=""20"">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
10,J96-3004,J00-3004,['42'],1996,['42'],dummy,dummy,"'70','185'","<S ssid=""1"" sid=""70"">This latter evaluation compares the performance of the system with that of several human judges since, as we shall show, even people do not agree on a single correct way to segment a text.</S><S ssid=""1"" sid=""185"">Both of these analyses are shown in Figure 4; fortunately, the correct analysis is also the one with the lowest cost, so it is this analysis that is chosen.</S>",methodcitation
11,J96-3004,J00-3004,['96'],1996,"['96','97']",dummy,dummy,"'65','57'","<S ssid=""1"" sid=""65"">In this paper we present a stochastic finite-state model for segmenting Chinese text into words, both words found in a (static) lexicon as well as words derived via the above-mentioned productive processes.</S><S ssid=""1"" sid=""57"">Morphologically derived words such as, xue2shengl+men0.</S>",methodcitation
12,J96-3004,J04-1004,['53'],Sproat et al. 1996,['53'],dummy,dummy,"'0','91'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""91"">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S>",methodcitation
13,J96-3004,J04-1004,['113'],Sproat et al. 1996,['113'],dummy,dummy,"'112','108'","<S ssid=""1"" sid=""112"">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S><S ssid=""1"" sid=""108"">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S>",methodcitation
14,J96-3004,J04-1004,['211'],Sproat et al. 1996,['211'],dummy,dummy,"'365','191'","<S ssid=""1"" sid=""365"">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S><S ssid=""1"" sid=""191"">each word in the lexicon whether or not each string is actually an instance of the word in question.</S>",methodcitation
15,J96-3004,J04-1004,['321'],Sproat et al. 1996,['321'],dummy,dummy,"'130','133','70'","<S ssid=""1"" sid=""130"">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S><S ssid=""1"" sid=""133"">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S><S ssid=""1"" sid=""70"">This latter evaluation compares the performance of the system with that of several human judges since, as we shall show, even people do not agree on a single correct way to segment a text.</S>",methodcitation
16,J96-3004,J05-4005,['88'],1996,"['88','89']",dummy,dummy,"'138','398','87','67'","<S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S ssid=""1"" sid=""398"">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S><S ssid=""1"" sid=""87"">Previous Work.</S><S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S>",methodcitation
17,J96-3004,J05-4005,['126'],1996,"['125','126']",dummy,dummy,"'245','350'","<S ssid=""1"" sid=""245"">There are two weaknesses in Chang et al.'s model, which we improve upon.</S><S ssid=""1"" sid=""350"">Under this scheme, n human judges are asked independently to segment a text.</S>",methodcitation
18,J96-3004,J05-4005,['132'],1996,"['131','132']",dummy,dummy,"'350','365'","<S ssid=""1"" sid=""350"">Under this scheme, n human judges are asked independently to segment a text.</S><S ssid=""1"" sid=""365"">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S>",methodcitation
19,J96-3004,J05-4005,['490'],1996,"['489','490']",dummy,dummy,'458',"<S ssid=""1"" sid=""458"">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>",methodcitation
20,J96-3004,J11-1005,['123'],Sproat et al. 1996,['123'],dummy,dummy,"'352','0'","<S ssid=""1"" sid=""352"">For a given ""word"" in the automatic segmentation, if at least k of the hu­ man judges agree that this is a word, then that word is considered to be correct.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
21,J96-3004,J11-3001,['326'],Sproat et al. 1996,['326'],dummy,dummy,'348',"<S ssid=""1"" sid=""348"">However, this result is consistent with the results of ex­ periments discussed in Wu and Fung (1994).</S>",methodcitation
23,J96-3004,J97-4004,['9'],Sproat et al. 1996,['9'],dummy,dummy,"'21','101'","<S ssid=""1"" sid=""21"">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces; a Chinese sentence is shown in Figure 1.3 Partly as a result of this, the notion ""word"" has never played a role in Chinese philological tradition, and the idea that Chinese lacks any­ thing analogous to words in European languages has been prevalent among Western sinologists; see DeFrancis (1984).</S><S ssid=""1"" sid=""101"">(See Sproat and Shih 1995.)</S>",methodcitation
25,J96-3004,J97-4004,['613'],1996,"['612','613']",dummy,dummy,"'138','67','458'","<S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S ssid=""1"" sid=""458"">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S>",methodcitation
26,J96-3004,J97-4004,['621'],1996,"['621','622']",dummy,dummy,"'101','110'","<S ssid=""1"" sid=""101"">(See Sproat and Shih 1995.)</S><S ssid=""1"" sid=""110"">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S>",methodcitation
27,J96-3004,N10-1068,['6'],"Sproat et al., 1996",['6'],dummy,dummy,"'138','67'","<S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S>",methodcitation
28,J96-3004,P03-1035,['41'],1996,"['41','42']",dummy,dummy,"'138','398','67','104'","<S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S ssid=""1"" sid=""398"">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S><S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S ssid=""1"" sid=""104"">Nonstochastic lexical-knowledge-based approaches have been much more numer­ ous.</S>",methodcitation
29,J96-3004,P03-1035,['122'],1996,['122'],dummy,dummy,"'230','242'","<S ssid=""1"" sid=""230"">Given names are most commonly two hanzi long, occasionally one hanzi long: there are thus four possible name types, which can be described by a simple set of context-free rewrite rules such as the following: 1.</S><S ssid=""1"" sid=""242"">The first probability is estimated from a name count in a text database, and the rest of the probabilities are estimated from a large list of personal names.n Note that in Chang et al.'s model the p(rule 9) is estimated as the product of the probability of finding G 1 in the first position of a two-hanzi given name and the probability of finding G2 in the second position of a two-hanzi given name, and we use essentially the same estimate here, with some modifications as described later on.</S>",methodcitation
30,J96-3004,P03-1035,['155'],1996,"['154','155']",dummy,dummy,"'281','280'","<S ssid=""1"" sid=""281"">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S><S ssid=""1"" sid=""280"">4.5 Transliterations of Foreign Words.</S>",methodcitation
31,J96-3004,P06-1010,['43'],"Sproat et al., 1996","['42','43']",dummy,dummy,"'227','170'","<S ssid=""1"" sid=""227"">4.4 Chinese Personal Names.</S><S ssid=""1"" sid=""170"">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S>",methodcitation
32,J96-3004,P06-1126,['7'],"Sproat et al., 1996",['7'],dummy,dummy,"'0','137'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S>",methodcitation
33,J96-3004,P07-1015,['113'],"Sproat et al., 1996",['113'],dummy,dummy,"'236','227'","<S ssid=""1"" sid=""236"">For a sequence of hanzi that is a possible name, we wish to assign a probability to that sequence qua name.</S><S ssid=""1"" sid=""227"">4.4 Chinese Personal Names.</S>",methodcitation
34,J96-3004,P07-1016,['70'],"Sproat et al., 1996",['70'],dummy,dummy,"'170','320'","<S ssid=""1"" sid=""170"">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S><S ssid=""1"" sid=""320"">from the subset of the United Informatics corpus not used in the training of the models.</S>",methodcitation
35,J96-3004,P12-1110,['105'],"Sproat et al., 1996",['105'],dummy,dummy,"'0','398'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""398"">In this paper we have argued that Chinese word segmentation can be modeled ef­ fectively using weighted finite-state transducers.</S>",methodcitation
36,J96-3004,P12-1111,['91'],"Sproat et al., 1996",['91'],dummy,dummy,"'108','89'","<S ssid=""1"" sid=""108"">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S ssid=""1"" sid=""89"">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexi­ cal rule-based approaches, and approaches that combine lexical information with sta­ tistical information.</S>",methodcitation
37,J96-3004,P97-1041,['12'],1996,['12'],dummy,dummy,"'402','101','0','137'","<S ssid=""1"" sid=""402"">(For some recent corpus-based work on Chinese abbreviations, see Huang, Ahrens, and Chen [1993].)</S><S ssid=""1"" sid=""101"">(See Sproat and Shih 1995.)</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S>",methodcitation
38,J96-3004,P98-1076,['145'],1996,"['144','145']",dummy,dummy,"'110','138'","<S ssid=""1"" sid=""110"">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S><S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S>",methodcitation
39,J96-3004,P98-1076,['150'],1996,"['149','150']",dummy,dummy,"'365','101'","<S ssid=""1"" sid=""365"">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S><S ssid=""1"" sid=""101"">(See Sproat and Shih 1995.)</S>",methodcitation
40,J96-3004,P99-1036,['6'],"Sproat et al., 1996","['5','6']",dummy,dummy,"'0','23'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""23"">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S>",methodcitation
41,J96-3004,P99-1036,['8'],"Sproat et al., 1996",['8'],dummy,dummy,"'415','245'","<S ssid=""1"" sid=""415"">The major problem for our seg­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S><S ssid=""1"" sid=""245"">There are two weaknesses in Chang et al.'s model, which we improve upon.</S>",methodcitation
42,J96-3004,P99-1036,['10'],"Sproat et al., 1996",['10'],dummy,dummy,'170',"<S ssid=""1"" sid=""170"">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S>",methodcitation
43,J96-3004,P99-1036,['178'],"Sproat et al., 1996",['178'],dummy,dummy,"'296','128','405'","<S ssid=""1"" sid=""296"">Previous reports on Chinese segmentation have invariably cited performance either in terms of a single percent-correct score, or else a single precision-recall pair.</S><S ssid=""1"" sid=""128"">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S><S ssid=""1"" sid=""405"">First of all, most previous articles report perfor­ mance in terms of a single percent-correct score, or else in terms of the paired measures of precision and recall.</S>",methodcitation
44,J96-3004,W00-0803,['29'],"Sproat et al., 1996",['29'],dummy,dummy,"'186','0'","<S ssid=""1"" sid=""186"">4.3 Morphological Analysis.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
45,J96-3004,W00-1207,['10'],Sproat et al 1996,['10'],dummy,dummy,"'125','55'","<S ssid=""1"" sid=""125"">Some of these approaches (e.g., Lin, Chiang, and Su [1993]) attempt to identify unknown words, but do not ac­ tually tag the words as belonging to one or another class of expression.</S><S ssid=""1"" sid=""55"">For novel texts, no lexicon that consists simply of a list of word entries will ever be entirely satisfactory, since the list will inevitably omit many constructions that should be considered words.</S>",methodcitation
46,J96-3004,W01-0513,['41'],"Sproat, et al, 1996","['40','41']",dummy,dummy,"'20','55'","<S ssid=""1"" sid=""20"">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S ssid=""1"" sid=""55"">For novel texts, no lexicon that consists simply of a list of word entries will ever be entirely satisfactory, since the list will inevitably omit many constructions that should be considered words.</S>",methodcitation
47,J96-3004,W02-1117,['13'],Sproat et al. 1996,['13'],dummy,dummy,"'110','112'","<S ssid=""1"" sid=""110"">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S><S ssid=""1"" sid=""112"">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S>",methodcitation
48,J96-3004,W02-1808,['5'],1996,['5'],dummy,dummy,"'120','365'","<S ssid=""1"" sid=""120"">More complex approaches such as the relaxation technique have been applied to this problem Fan and Tsai (1988}.</S><S ssid=""1"" sid=""365"">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S>",methodcitation
49,J96-3004,W03-1025,['17'],"Sproat et al., 1996",['17'],dummy,dummy,"'303','245'","<S ssid=""1"" sid=""303"">(See also Wu and Fung [1994].)</S><S ssid=""1"" sid=""245"">There are two weaknesses in Chang et al.'s model, which we improve upon.</S>",methodcitation
50,J96-3004,W03-1025,['180'],"Sproat et al., 1996",['180'],dummy,dummy,'137',"<S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S>",methodcitation
51,J96-3004,W03-1025,['187'],1996,"['186','187']",dummy,dummy,"'0','138'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""138"">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S>",methodcitation
52,J96-3004,W03-1728,['3'],"Sproat et al., 1996",['3'],dummy,dummy,"'120','3'","<S ssid=""1"" sid=""120"">More complex approaches such as the relaxation technique have been applied to this problem Fan and Tsai (1988}.</S><S ssid=""1"" sid=""3"">For a language like English, this problem is generally regarded as trivial since words are delimited in English text by whitespace or marks of punctuation.</S>",methodcitation
53,J96-3004,W05-0709,['83'],"Sproat et al., 1996",['83'],dummy,dummy,"'107','134'","<S ssid=""1"" sid=""107"">The second concerns the methods used (if any) to ex­ tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S><S ssid=""1"" sid=""134"">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S>",methodcitation
54,J96-3004,W06-1630,['118'],"Sproat et al., 1996",['118'],dummy,dummy,"'170','230'","<S ssid=""1"" sid=""170"">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S><S ssid=""1"" sid=""230"">Given names are most commonly two hanzi long, occasionally one hanzi long: there are thus four possible name types, which can be described by a simple set of context-free rewrite rules such as the following: 1.</S>",methodcitation
55,J96-3004,W10-3212,['16'],"Sproat et al., 1996",['16'],dummy,dummy,"'107','67'","<S ssid=""1"" sid=""107"">The second concerns the methods used (if any) to ex­ tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S><S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S>",methodcitation
56,J96-3004,W10-3708,['16'],"Sproat et al., 1996",['16'],dummy,dummy,"'352','0'","<S ssid=""1"" sid=""352"">For a given ""word"" in the automatic segmentation, if at least k of the hu­ man judges agree that this is a word, then that word is considered to be correct.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
57,J96-3004,W11-0823,['174'],1996,['174'],dummy,dummy,"'93','103'","<S ssid=""1"" sid=""93"">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S><S ssid=""1"" sid=""103"">Church and Hanks [1989]), and we have used lists of character pairs ranked by mutual information to expand our own dictionary.</S>",methodcitation
58,J96-3004,W12-1011,['41'],"Sproat et al., 1996",['41'],dummy,dummy,"'0','24'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""24"">2 Chinese ?l* han4zi4 'Chinese character'; this is the same word as Japanese kanji..</S>",methodcitation
59,J96-3004,W12-1011,['204'],"Sproat et al., 1996",['204'],dummy,dummy,"'0','137'","<S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S>",methodcitation
60,J96-3004,W12-2303,['12'],1996,"['11','12']",dummy,dummy,'121',"<S ssid=""1"" sid=""121"">Note that Chang, Chen, and Chen (1991), in addition to word-frequency information, include a constraint-satisfication model, so their method is really a hybrid approach.</S>",methodcitation
61,J96-3004,W12-2303,['157'],1996,"['155','156','157']",dummy,dummy,"'67','0'","<S ssid=""1"" sid=""67"">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
62,J96-3004,W97-0120,['26'],"Sproat et al., 1996",['26'],dummy,dummy,"'134','188'","<S ssid=""1"" sid=""134"">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S><S ssid=""1"" sid=""188"">One class comprises words derived by productive morphologi­ cal processes, such as plural noun formation using the suffix ir, menD.</S>",methodcitation
63,J96-3004,W97-0120,['69'],"Sproat et al., 1996",['69'],dummy,dummy,'307',"<S ssid=""1"" sid=""307"">An anti-greedy algorithm, AG: instead of the longest match, take the.</S>",methodcitation
64,J96-3004,W97-0120,['73'],"Sproat et al., 1996",['73'],dummy,dummy,'170',"<S ssid=""1"" sid=""170"">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S>",methodcitation
65,J96-3004,W97-0120,['86'],"Sproat et al., 1996",['86'],dummy,dummy,"'137','0'","<S ssid=""1"" sid=""137"">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S ssid=""1"" sid=""0"">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S>",methodcitation
66,J96-3004,W97-0120,['121'],"Sproat et al., 1996",['121'],dummy,dummy,'128',"<S ssid=""1"" sid=""128"">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S>",methodcitation
67,J96-3004,W97-0316,['11'],"Sproat et al., 1996","['10','11']",dummy,dummy,"'2','53'","<S ssid=""1"" sid=""2"">An initial step of any text­ analysis task is the tokenization of the input into words.</S><S ssid=""1"" sid=""53"">There are thus some very good reasons why segmentation into words is an important task.</S>",methodcitation
