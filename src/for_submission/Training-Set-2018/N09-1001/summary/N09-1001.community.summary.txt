We supplement WordNet entries with information on the subjectivity of its word senses. We propose a semi-supervised minimum cut framework that makes use of both WordNet definitions and its relation structure. Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%. Also, WordNet connections between different parts of the WordNet hierarchy can also be sparse, leading to relatively isolated senses in a graph in a supervised framework. Semi-supervised Mincuts allow us to import unlabeled data that can serve as bridges to isolated components. More importantly, as the unlabeled data can be chosen to be related to the labeled and test data, they might help pull test data to the right cuts (categories). We propose semi-supervised mincuts for subjectivity recognition on senses for several reasons. "<S sid ="72" ssid = "25">We define two vertices s (source) and t (sink),.</S> which correspond to the “subjective” and “objective” category, respectively. Following the definition in Blum and Chawla (2001), we call the vertices s and t classification vertices, and all other vertices (labeled, test, and unlabeled data) example vertices. Each example vertex corresponds to one WordNet sense and is connected to both s and t via a weighted edge. Assigning weights to WordNet relations: We connect two vertices that are linked by one of the ten WordNet relations in Table 1 via an edge. Not all WordNet relations we use are subjectivity- preserving to the same degree: for example, hyponyms (such as simpleton) of objective senses (such as person) do not have to be objective. However, we aim for high graph connectivity and we can assign different weights to different relations 4 We employ LIBSVM, available at http://www.csie.. We conduct the experiments on two different gold standard datasets. One is the MicroWNOp corpus, ntu.edu.tw/˜cjlin/libsvm/. It includes 298 words with 703 objective and 358 subjective WordNet senses. Our best result from Mincuts is significantly better at 84.6% (see LRMSL in Table 2). 