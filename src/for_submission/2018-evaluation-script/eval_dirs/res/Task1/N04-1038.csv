Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,N04-1038,H05-1003,['35'],2004,"['35','36']",dummy,dummy,"'2','27','19'","<S ssid=""1"" sid=""2"">BABAR uses information extraction patterns to identify contextual roles and creates four contextual role knowledge sources using unsupervised learning.</S><S ssid=""1"" sid=""27"">Section 4 presents experimen tal results on two corpora: the MUC4 terrorism corpus, and Reuters texts about natural disasters.</S><S ssid=""1"" sid=""19"">BABAR employs information extraction techniques to represent and learn role relationships.</S>",methodcitation
3,N04-1038,N13-1104,['109'],2004,['109'],dummy,dummy,"'103','120'","<S ssid=""1"" sid=""103"">For each case- frame, BABAR collects the head nouns of noun phrases that were extracted by the caseframe in the training corpus.</S><S ssid=""1"" sid=""120"">For each caseframe, BABAR collects the semantic classes associated with the head nouns of NPs that were extracted by the caseframe.</S>",methodcitation
4,N04-1038,N13-1110,['207'],2004,"['207','208','209']",dummy,dummy,"'8','5','9'","<S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""5"">Experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.</S><S ssid=""1"" sid=""9"">A contextual role represents the role that a noun phrase plays in an event or relationship.</S>",methodcitation
5,N04-1038,P05-1020,['202'],2004,['202'],dummy,dummy,'45',"<S ssid=""1"" sid=""45"">In previous work (Bean and Riloff, 1999), we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood.</S>",methodcitation
6,N04-1038,P06-1005,['124'],"Bean and Riloff, 2004",['124'],dummy,dummy,"'84','45'","<S ssid=""1"" sid=""84"">The learned patterns are then normalized and applied to the corpus.</S><S ssid=""1"" sid=""45"">In previous work (Bean and Riloff, 1999), we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood.</S>",methodcitation
7,N04-1038,P06-1005,['177'],2004,"['177','178','179']",dummy,dummy,"'1','22'","<S ssid=""1"" sid=""1"">We present a coreference resolver called BABAR that uses contextual role knowledge to evaluate possible antecedents for an anaphor.</S><S ssid=""1"" sid=""22"">Training examples are generated automatically by identifying noun phrases that can be easily resolved with their antecedents using lexical and syntactic heuristics.</S>",methodcitation
8,N04-1038,P07-1067,['46'],2004,"['46','47','48','49']",dummy,dummy,"'1','86','87','64','76'","<S ssid=""1"" sid=""1"">We present a coreference resolver called BABAR that uses contextual role knowledge to evaluate possible antecedents for an anaphor.</S><S ssid=""1"" sid=""86"">The contextual role knowledge that BABAR uses for coreference resolution is derived from this caseframe data.</S><S ssid=""1"" sid=""87"">2.2.2 The Caseframe Network The first type of contextual role knowledge that BABAR learns is the Caseframe Network (CFNet), which identifies caseframes that co-occur in anaphor/antecedent resolutions.</S><S ssid=""1"" sid=""64"">Table 1: Syntactic Seeding Heuristics BABAR’s reliable case resolution heuristics produced a substantial set of anaphor/antecedent resolutions that will be the training data used to learn contextual role knowledge.</S><S ssid=""1"" sid=""76"">We applied the AutoSlog system (Riloff, 1996) to our unannotated training texts to generate a set of extraction patterns for each domain.</S>",methodcitation
9,N04-1038,P07-1068,['11'],2004,['11'],dummy,dummy,"'67','0','9','8','24'","<S ssid=""1"" sid=""67"">2.2 Contextual Role Knowledge.</S><S ssid=""1"" sid=""0"">Unsupervised Learning of Contextual Role Knowledge for Coreference Resolution</S><S ssid=""1"" sid=""9"">A contextual role represents the role that a noun phrase plays in an event or relationship.</S><S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""24"">In this paper, Section 2 begins by explaining how contextual role knowledge is represented and learned.</S>",methodcitation
10,N04-1038,P08-1090,['35'],2004,"['35','38']",dummy,dummy,"'8','86','248'","<S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""86"">The contextual role knowledge that BABAR uses for coreference resolution is derived from this caseframe data.</S><S ssid=""1"" sid=""248"">The goal of our research was to explore the use of contextual role knowledge for coreference resolution.</S>",methodcitation
11,N04-1038,P09-1068,['17'],"Bean and Riloff, 2004",['17'],dummy,dummy,"'45','91'","<S ssid=""1"" sid=""45"">In previous work (Bean and Riloff, 1999), we developed an unsupervised learning algorithm that automatically recognizes definite NPs that are existential without syntactic modification because their meaning is universally understood.</S><S ssid=""1"" sid=""91"">For example, co-occurring caseframes may reflect synonymy (e.g., “<patient> kidnapped” and “<patient> abducted”) or related events (e.g., “<patient> kidnapped” and “<patient> released”).</S>",methodcitation
12,N04-1038,P09-1074,['223'],2004,['223'],dummy,dummy,"'246','154'","<S ssid=""1"" sid=""246"">These systems rely on a training corpus that has been manually annotated with coreference links.</S><S ssid=""1"" sid=""154"">Given a document to process, BABAR uses four modules to perform coreference resolution.</S>",methodcitation
13,N04-1038,P10-1142,['72'],2004,['72'],dummy,dummy,"'244','155'","<S ssid=""1"" sid=""244"">(Kehler, 1997) also used a DempsterShafer model to merge evidence from different sources for template-level coreference.</S><S ssid=""1"" sid=""155"">First, a non-anaphoric NP classifier identifies definite noun phrases that are existential, using both syntactic rules and our learned existential NP recognizer (Bean and Riloff, 1999), and removes them from the resolution process.</S>",methodcitation
14,N04-1038,P11-1082,['129'],2004,['129'],dummy,dummy,"'8','230','2','67','248'","<S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""230"">We also performed experiments to evaluate the impact of each type of contextual role knowledge separately.</S><S ssid=""1"" sid=""2"">BABAR uses information extraction patterns to identify contextual roles and creates four contextual role knowledge sources using unsupervised learning.</S><S ssid=""1"" sid=""67"">2.2 Contextual Role Knowledge.</S><S ssid=""1"" sid=""248"">The goal of our research was to explore the use of contextual role knowledge for coreference resolution.</S>",methodcitation
15,N04-1038,P13-1121,['63'],2004,['63'],dummy,dummy,"'8','248','25'","<S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""248"">The goal of our research was to explore the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""25"">Section 3 describes the complete coreference resolution model, which uses the contextual role knowledge as well as more traditional coreference features.</S>",methodcitation
16,N04-1038,P13-2015,['46'],"Bean and Riloff, 2004","['46','47']",dummy,dummy,"'86','0','8','201','102'","<S ssid=""1"" sid=""86"">The contextual role knowledge that BABAR uses for coreference resolution is derived from this caseframe data.</S><S ssid=""1"" sid=""0"">Unsupervised Learning of Contextual Role Knowledge for Coreference Resolution</S><S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""201"">We evaluated BABAR on two domains: terrorism and natural disasters.</S><S ssid=""1"" sid=""102"">2.2.3 Lexical Caseframe Expectations The second type of contextual role knowledge learned by BABAR is Lexical Caseframe Expectations, which are used by the CFLex knowledge source.</S>",methodcitation
17,N04-1038,W05-0612,['33'],"Bean and Riloff, 2004",['33'],dummy,dummy,"'0','234','2','8','86'","<S ssid=""1"" sid=""0"">Unsupervised Learning of Contextual Role Knowledge for Coreference Resolution</S><S ssid=""1"" sid=""234"">This result suggests that all of contextual role KSs can provide useful information for resolving anaphora.</S><S ssid=""1"" sid=""2"">BABAR uses information extraction patterns to identify contextual roles and creates four contextual role knowledge sources using unsupervised learning.</S><S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S><S ssid=""1"" sid=""86"">The contextual role knowledge that BABAR uses for coreference resolution is derived from this caseframe data.</S>",methodcitation
18,N04-1038,W06-0106,['181'],2004,['181'],dummy,dummy,"'68','2','76','71','19'","<S ssid=""1"" sid=""68"">Our representation of contextual roles is based on information extraction patterns that are converted into simple caseframes.</S><S ssid=""1"" sid=""2"">BABAR uses information extraction patterns to identify contextual roles and creates four contextual role knowledge sources using unsupervised learning.</S><S ssid=""1"" sid=""76"">We applied the AutoSlog system (Riloff, 1996) to our unannotated training texts to generate a set of extraction patterns for each domain.</S><S ssid=""1"" sid=""71"">2.2.1 The Caseframe Representation Information extraction (IE) systems use extraction patterns to identify noun phrases that play a specific role in 1 Our implementation only resolves NPs that occur in the same document, but in retrospect, one could probably resolve instances of the same existential NP in different documents too.</S><S ssid=""1"" sid=""19"">BABAR employs information extraction techniques to represent and learn role relationships.</S>",methodcitation
19,N04-1038,W06-0206,['10'],"Bean and Riloff, 2004",['10'],dummy,dummy,"'155','0'","<S ssid=""1"" sid=""155"">First, a non-anaphoric NP classifier identifies definite noun phrases that are existential, using both syntactic rules and our learned existential NP recognizer (Bean and Riloff, 1999), and removes them from the resolution process.</S><S ssid=""1"" sid=""0"">Unsupervised Learning of Contextual Role Knowledge for Coreference Resolution</S>",methodcitation
20,N04-1038,W10-3909,['23'],2004,"['22','23']",dummy,dummy,'8',"<S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S>",methodcitation
21,N04-1038,W10-3909,['36'],2004,"['36','37','38']",dummy,dummy,"'64','86','0','1','25'","<S ssid=""1"" sid=""64"">Table 1: Syntactic Seeding Heuristics BABAR’s reliable case resolution heuristics produced a substantial set of anaphor/antecedent resolutions that will be the training data used to learn contextual role knowledge.</S><S ssid=""1"" sid=""86"">The contextual role knowledge that BABAR uses for coreference resolution is derived from this caseframe data.</S><S ssid=""1"" sid=""0"">Unsupervised Learning of Contextual Role Knowledge for Coreference Resolution</S><S ssid=""1"" sid=""1"">We present a coreference resolver called BABAR that uses contextual role knowledge to evaluate possible antecedents for an anaphor.</S><S ssid=""1"" sid=""25"">Section 3 describes the complete coreference resolution model, which uses the contextual role knowledge as well as more traditional coreference features.</S>",methodcitation
22,N04-1038,W10-3909,['50'],2004,"['50','51']",dummy,dummy,"'98','27','8'","<S ssid=""1"" sid=""98"">During coreference resolution, the caseframe network provides evidence that an anaphor and prior noun phrase might be coreferent.</S><S ssid=""1"" sid=""27"">Section 4 presents experimen tal results on two corpora: the MUC4 terrorism corpus, and Reuters texts about natural disasters.</S><S ssid=""1"" sid=""8"">The focus of our work is on the use of contextual role knowledge for coreference resolution.</S>",methodcitation
