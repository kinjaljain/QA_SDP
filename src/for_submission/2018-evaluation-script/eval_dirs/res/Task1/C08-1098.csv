Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,C08-1098,D12-1133,['208'],"Schmid and Laws, 2008",['208'],dummy,dummy,"'223','210'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""210"">The tagging accuracy reported by Kempe was below that of a traditional trigram tagger.</S>",methodcitation
3,C08-1098,D12-1133,['228'],"Schmid and Laws, 2008",['228'],dummy,dummy,"'100','23'","<S ssid=""1"" sid=""100"">The tagger may use an external lexicon which supplies entries for additional words which are not found in the training corpus, and additional tags for words which did occur in the training data.</S><S ssid=""1"" sid=""23"">Unfortunately, the POS trigram consisting of the tags of the first three words does not occur in the Tiger corpus.</S>",methodcitation
4,C08-1098,D13-1032,['212'],"Schmid and Laws, 2008",['212'],dummy,dummy,"'219','4'","<S ssid=""1"" sid=""219"">Morcˇe’s tagging accuracy was 95.12%, 0.3% better than the n-gram tagger.</S><S ssid=""1"" sid=""4"">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S>",methodcitation
5,C08-1098,D13-1033,['176'],"Schmid and Laws, 2008",['176'],dummy,dummy,"'223','171'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""171"">The best results are obtained with a context size of 10.</S>",methodcitation
6,C08-1098,E09-1079,['121'],"Schmid and Laws, 2008",['121'],dummy,dummy,"'67','39'","<S ssid=""1"" sid=""67"">All context attributes other than the base POS are always used in combination with the base POS.</S><S ssid=""1"" sid=""39"">Discriminatively trained taggers, on the other hand, have difficulties to handle the huge number of features which are active at the same time if any possible combination of context attributes defines a separate feature.</S>",methodcitation
7,C08-1098,P10-1020,['159'],"Schmid and Laws, 2008",['159'],dummy,dummy,"'199','219'","<S ssid=""1"" sid=""199"">Contrary to them, we applied pruning and found that some pruning (threshold=6) gives better results than no pruning (threshold=0).</S><S ssid=""1"" sid=""219"">Morcˇe’s tagging accuracy was 95.12%, 0.3% better than the n-gram tagger.</S>",methodcitation
8,C08-1098,P10-1068,['42'],"Schmid and Laws, 2008",['42'],dummy,dummy,"'12','126'","<S ssid=""1"" sid=""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S><S ssid=""1"" sid=""126"">The German Tiger treebank (Brants et al., 2002) contains over 888,000 tokens.</S>",methodcitation
9,C08-1098,P10-1068,['74'],"Schmid and Laws, 2008",['74'],dummy,dummy,"'19','204'","<S ssid=""1"" sid=""19"">Qc 2008.</S><S ssid=""1"" sid=""204"">The best accuracy of the TnT tagger was 88.2% with a maximal suffix length of 5.</S>",methodcitation
10,C08-1098,P10-1068,['81'],"Schmid and Laws, 2008",['81'],dummy,dummy,"'7','19'","<S ssid=""1"" sid=""7"">The additional information may also help to disambiguate the (base) part of speech.</S><S ssid=""1"" sid=""19"">Qc 2008.</S>",methodcitation
11,C08-1098,W10-1704,['32'],"Schmid and Laws, 2008",['32'],dummy,dummy,"'223','12'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S>",methodcitation
12,C08-1098,W10-1727,['41'],"Schmid and Laws, 2008",['41'],dummy,dummy,"'127','5'","<S ssid=""1"" sid=""127"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S><S ssid=""1"" sid=""5"">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S>",methodcitation
13,C08-1098,W11-2135,['49'],"Schmid and Laws, 2008",['49'],dummy,dummy,"'223','211'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""211"">Unlike him, we found that our tagging method outperformed state-of-the-art POS taggers on fine-grained POS tagging even if only a trigram context was used.</S>",methodcitation
14,C08-1098,W11-2145,['101'],"Schmid and Laws, 2008","['101','102']",dummy,dummy,"'127','12'","<S ssid=""1"" sid=""127"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S><S ssid=""1"" sid=""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S>",methodcitation
15,C08-1098,W11-2147,['26'],"Schmid and Laws, 2008",['26'],dummy,dummy,"'127','5'","<S ssid=""1"" sid=""127"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S><S ssid=""1"" sid=""5"">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S>",methodcitation
16,C08-1098,W12-3141,['89'],"Schmid and Laws, 2008",['89'],dummy,dummy,"'223','0'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""0"">Estimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging</S>",methodcitation
17,C08-1098,W12-3144,['127'],"Schmid and Laws, 2008",['127'],dummy,dummy,"'127','223'","<S ssid=""1"" sid=""127"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S><S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S>",methodcitation
18,C08-1098,W12-3402,['78'],"Schmid and Laws, 2008",['78'],dummy,dummy,"'211','213'","<S ssid=""1"" sid=""211"">Unlike him, we found that our tagging method outperformed state-of-the-art POS taggers on fine-grained POS tagging even if only a trigram context was used.</S><S ssid=""1"" sid=""213"">Magerman (1994) applied probabilistic decision trees to parsing, but not with a generative model.</S>",methodcitation
19,C08-1098,W13-2204,['35'],"Schmid and Laws, 2008",['35'],dummy,dummy,"'223','0'","<S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S><S ssid=""1"" sid=""0"">Estimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging</S>",methodcitation
20,C08-1098,W13-2210,['37'],"Schmid and Laws, 2008",['37'],dummy,dummy,"'23','2'","<S ssid=""1"" sid=""23"">Unfortunately, the POS trigram consisting of the tags of the first three words does not occur in the Tiger corpus.</S><S ssid=""1"" sid=""2"">It is based on three ideas: (1) splitting of the POS tags into attribute vectors and decomposition of the contextual POS probabilities of the HMM into a product of attribute probabilities, (2) estimation of the contextual probabilities with decision trees, and (3) use of high-order HMMs.</S>",methodcitation
21,C08-1098,W13-2210,['85'],"Schmid and Laws, 2008",['85'],dummy,dummy,"'22','133'","<S ssid=""1"" sid=""22"">Table 1: Correct POS tags for the German sentence Das zu versteuernde Einkommen sinkt.</S><S ssid=""1"" sid=""133"">Note that only the words, but not the POS tags from the test and development data were used, here.</S>",methodcitation
22,C08-1098,W13-2211,['84'],"Schmid and Laws, 2008",['84'],dummy,dummy,"'1','12'","<S ssid=""1"" sid=""1"">We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.</S><S ssid=""1"" sid=""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S>",methodcitation
23,C08-1098,W13-2228,['134'],"Schmid and Laws, 2008",['134'],dummy,dummy,"'0','223'","<S ssid=""1"" sid=""0"">Estimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging</S><S ssid=""1"" sid=""223"">The German tagging results are, to the best of our knowledge, the first published results for fine- grained POS tagging with the Tiger tagset.</S>",methodcitation
24,C08-1098,W13-2230,['35'],"Schmid and Laws, 2008",['35'],dummy,dummy,"'58','4'","<S ssid=""1"" sid=""58"">In a second step, the decision tree may be pruned in order to avoid overfit- ting to the training data.</S><S ssid=""1"" sid=""4"">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tˆN = tˆ1, ..., tˆN for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S>",methodcitation
25,C08-1098,W13-2230,['58'],"Schmid and Laws, 2008",['58'],dummy,dummy,"'12','224'","<S ssid=""1"" sid=""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S><S ssid=""1"" sid=""224"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",methodcitation
26,C08-1098,W13-2230,['83'],"Schmid and Laws, 2008",['83'],dummy,dummy,"'19','71'","<S ssid=""1"" sid=""19"">Qc 2008.</S><S ssid=""1"" sid=""71"">This restriction improved the tagging accuracy for large contexts.</S>",methodcitation
28,C08-1098,W13-2302,['87'],"Schmid and Laws, 2008",['87'],dummy,dummy,"'19','84'","<S ssid=""1"" sid=""19"">Qc 2008.</S><S ssid=""1"" sid=""84"">Thus, the simpler pruning strategy presented here was chosen.</S>",methodcitation
29,C08-1098,W13-2708,['111'],"Schmid and Laws, 2008",['111'],dummy,dummy,"'1','185'","<S ssid=""1"" sid=""1"">We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.</S><S ssid=""1"" sid=""185"">By far the most frequent tagging error was the confusion of nominative and accusative case.</S>",methodcitation
