Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
3,P05-1004,J07-4005,['229'],2005,['229'],dummy,dummy,"'68','14'","<S ssid=""1"" sid=""68"">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S ssid=""1"" sid=""14"">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S>",methodcitation
4,P05-1004,J09-3004,['446'],Curran 2005,['446'],dummy,dummy,"'92','19'","<S ssid=""1"" sid=""92"">Curran and Moens (2002b) compared several context extraction methods and found that the shallow pipeline and grammatical relation extraction used in SEXTANT was both extremely fast and produced high-quality results.</S><S ssid=""1"" sid=""19"">Broad semantic classification is currently used by lexicographers to or- ganise the manual insertion of words into WORDNET, and is an experimental precursor to automatically inserting words directly into the WORDNET hierarchy.</S>",methodcitation
5,P05-1004,N06-1017,['26'],"Curran, 2005",['26'],dummy,dummy,"'62','1'","<S ssid=""1"" sid=""62"">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S ssid=""1"" sid=""1"">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S>",methodcitation
6,P05-1004,N06-1017,['189'],"Curran, 2005",['189'],dummy,dummy,"'62','223'","<S ssid=""1"" sid=""62"">Widdows (2003) uses a similar technique to insert words into the WORDNET hierarchy.</S><S ssid=""1"" sid=""223"">We would like to move onto the more difficult task of insertion into the hierarchy itself and compare against the initial work by Widdows (2003) using latent semantic analysis.</S>",methodcitation
7,P05-1004,N07-1024,['83'],Curran 2005,['83'],dummy,dummy,"'1','94'","<S ssid=""1"" sid=""1"">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S><S ssid=""1"" sid=""94"">The efficiency of the SEXTANT approach makes the extraction of contextual information from over 2 billion words of raw text feasible.</S>",methodcitation
8,P05-1004,P12-2050,['15'],"Curran, 2005",['15'],dummy,dummy,"'68','14'","<S ssid=""1"" sid=""68"">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S ssid=""1"" sid=""14"">Ciaramita and Johnson (2003) found that common nouns missing from WORDNET 1.6 occurred every 8 sentences in the BLLIP corpus.</S>",methodcitation
9,P05-1004,S07-1032,['16'],"Curran, 2005",['16'],dummy,dummy,"'42','58'","<S ssid=""1"" sid=""42"">Ciaramita and Johnson (2003) believe that the key sense distinctions are still maintained by supersenses.</S><S ssid=""1"" sid=""58"">Hearst and Schu¨ tze (1993) flatten WORDNET into 726 categories using an algorithm which attempts to minimise the variance in category size.</S>",methodcitation
10,P05-1004,S10-1090,['16'],"Curran, 2005",['16'],dummy,dummy,"'229','71'","<S ssid=""1"" sid=""229"">Using this approach we have significantly outperformed the supervised multi-class perceptron Ciaramita and Johnson (2003).</S><S ssid=""1"" sid=""71"">Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003).</S>",methodcitation
11,P05-1004,S12-1011,['6'],"Curran, 2005",['6'],dummy,dummy,"'101','210'","<S ssid=""1"" sid=""101"">Curran and Moens (2002a) introduced the TTEST weight function, which is used in collocation extraction.</S><S ssid=""1"" sid=""210"">How are words with multiple supersenses handled?</S>",methodcitation
12,P05-1004,S12-1011,['50'],"Curran, 2005",['50'],dummy,dummy,"'68','20'","<S ssid=""1"" sid=""68"">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S ssid=""1"" sid=""20"">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S>",methodcitation
13,P05-1004,S12-1023,['234'],"Curran, 2005",['234'],dummy,dummy,"'101','198'","<S ssid=""1"" sid=""101"">Curran and Moens (2002a) introduced the TTEST weight function, which is used in collocation extraction.</S><S ssid=""1"" sid=""198"">This is not surprising since these concrete words tend to have very fewer other senses, well constrained contexts and a relatively high frequency.</S>",methodcitation
14,P05-1004,W06-1670,['94'],"Curran, 2005",['94'],dummy,dummy,"'68','20'","<S ssid=""1"" sid=""68"">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S><S ssid=""1"" sid=""20"">Ciaramita and Johnson (2003) call this supersense tagging and describe a multi-class perceptron tagger, which uses WORDNET’s hierarchical structure to create many annotated training instances from the synset glosses.</S>",methodcitation
