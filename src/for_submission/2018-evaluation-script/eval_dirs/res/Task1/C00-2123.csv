Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,C00-2123,C02-1050,['8'],"Tillman and Ney, 2000",['8'],dummy,dummy,"'25','5','1','2','6'","<S ssid=""1"" sid=""25"">To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</S><S ssid=""1"" sid=""5"">The goal of machine translation is the translation of a text given in some source language into a target language.</S><S ssid=""1"" sid=""1"">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S><S ssid=""1"" sid=""2"">Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÆcient search algorithm.</S><S ssid=""1"" sid=""6"">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S>",methodcitation
3,C00-2123,C02-1050,['43'],2000,['43'],dummy,dummy,"'170','33'","<S ssid=""1"" sid=""170"">We show translation results for three approaches: the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</S><S ssid=""1"" sid=""33"">We use a solution to this problem similar to the one presented in (Och et al., 1999), where target words are joined during training.</S>",methodcitation
4,C00-2123,C02-1050,['80'],2000,['80'],dummy,dummy,'82',"<S ssid=""1"" sid=""82"">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S>",methodcitation
5,C00-2123,C04-1091,['22'],"Tillman and Ney, 2000",['22'],dummy,dummy,"'14','193'","<S ssid=""1"" sid=""14"">In Section 3, we introduce our novel concept to word reordering and a DP-based search, which is especially suitable for the translation direction from German to English.</S><S ssid=""1"" sid=""193"">The approach assumes that the word reordering is restricted to a few positions in the source sentence.</S>",methodcitation
6,C00-2123,E06-1004,['22'],"Tillman, 2000","['21','22']",dummy,dummy,"'21','112','31','30'","<S ssid=""1"" sid=""21"">The alignment model uses two kinds of parameters: alignment probabilities p(aj jaj􀀀1; I; J), where the probability of alignment aj for position j depends on the previous alignment position aj􀀀1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</S><S ssid=""1"" sid=""112"">Covering the first uncovered position in the source sentence, we use the language model probability p(ej$; $).</S><S ssid=""1"" sid=""31"">For the inverted alignment probability p(bijbi􀀀1; I; J), we drop the dependence on the target sentence length I. 2.2 Word Joining.</S><S ssid=""1"" sid=""30"">The sentence length probability p(JjI) is omitted without any loss in performance.</S>",methodcitation
7,C00-2123,H01-1062,['113'],20,['113'],dummy,dummy,"'171','0','4','170','14'","<S ssid=""1"" sid=""171"">Table 4 shows translation results for the three approaches.</S><S ssid=""1"" sid=""0"">Word Re-ordering and DP-based Search in Statistical Machine Translation</S><S ssid=""1"" sid=""4"">The experimental tests are carried out on the Verbmobil task (GermanEnglish, 8000-word vocabulary), which is a limited-domain spoken-language task.</S><S ssid=""1"" sid=""170"">We show translation results for three approaches: the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</S><S ssid=""1"" sid=""14"">In Section 3, we introduce our novel concept to word reordering and a DP-based search, which is especially suitable for the translation direction from German to English.</S>",methodcitation
8,C00-2123,J03-1005,['117'],2000,"['115','117']",dummy,dummy,"'192','0','14','3','1'","<S ssid=""1"" sid=""192"">In this paper, we have presented a new, eÆcient DP-based search procedure for statistical machine translation.</S><S ssid=""1"" sid=""0"">Word Re-ordering and DP-based Search in Statistical Machine Translation</S><S ssid=""1"" sid=""14"">In Section 3, we introduce our novel concept to word reordering and a DP-based search, which is especially suitable for the translation direction from German to English.</S><S ssid=""1"" sid=""3"">A search restriction especially useful for the translation direction from German to English is presented.</S><S ssid=""1"" sid=""1"">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S>",methodcitation
9,C00-2123,J04-2003,['35'],Tillmann and Ney 2000,['35'],dummy,dummy,"'25','8','5','193'","<S ssid=""1"" sid=""25"">To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</S><S ssid=""1"" sid=""8"">Our approach uses word-to-word dependencies between source and target words.</S><S ssid=""1"" sid=""5"">The goal of machine translation is the translation of a text given in some source language into a target language.</S><S ssid=""1"" sid=""193"">The approach assumes that the word reordering is restricted to a few positions in the source sentence.</S>",methodcitation
11,C00-2123,J04-4002,['282'],Tillmann and Ney 2000,['282'],dummy,dummy,"'25','110'","<S ssid=""1"" sid=""25"">To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</S><S ssid=""1"" sid=""110"">The details are given in (Tillmann, 2000).</S>",methodcitation
12,C00-2123,N03-1010,['16'],"Tillmann and Ney, 2000",['16'],dummy,dummy,'1',"<S ssid=""1"" sid=""1"">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S>",methodcitation
13,C00-2123,P01-1027,['127'],"Tillmann and Ney, 2000",['127'],dummy,dummy,"'195','170'","<S ssid=""1"" sid=""195"">Future extensions of the system might include: 1) An extended translation model, where we use more context to predict a source word.</S><S ssid=""1"" sid=""170"">We show translation results for three approaches: the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</S>",methodcitation
14,C00-2123,P03-1039,['113'],"Tillmann and Ney, 2000",['113'],dummy,dummy,"'0','2'","<S ssid=""1"" sid=""0"">Word Re-ordering and DP-based Search in Statistical Machine Translation</S><S ssid=""1"" sid=""2"">Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÆcient search algorithm.</S>",methodcitation
15,C00-2123,P03-1039,['120'],"Tillman and Ney, 2000",['120'],dummy,dummy,"'21','6'","<S ssid=""1"" sid=""21"">The alignment model uses two kinds of parameters: alignment probabilities p(aj jaj􀀀1; I; J), where the probability of alignment aj for position j depends on the previous alignment position aj􀀀1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</S><S ssid=""1"" sid=""6"">We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability: ^eI 1 = arg max eI 1 fPr(eI 1jfJ 1 )g = arg max eI 1 fPr(eI 1) Pr(fJ 1 jeI 1)g : (1) The argmax operation denotes the search problem, i.e. the generation of the output sentence in the target language.</S>",methodcitation
17,C00-2123,W01-1404,['5'],"Tillmann and Ney, 2000",['5'],dummy,dummy,"'21','25'","<S ssid=""1"" sid=""21"">The alignment model uses two kinds of parameters: alignment probabilities p(aj jaj􀀀1; I; J), where the probability of alignment aj for position j depends on the previous alignment position aj􀀀1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</S><S ssid=""1"" sid=""25"">To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</S>",methodcitation
18,C00-2123,W01-1407,['110'],"Tillmann and Ney, 2000",['110'],dummy,dummy,"'122','170','0','25','125'","<S ssid=""1"" sid=""122"">Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).</S><S ssid=""1"" sid=""170"">We show translation results for three approaches: the monotone search (MonS), where no word reordering is allowed (Tillmann, 1997), the quasimonotone search (QmS) as presented in this paper and the IBM style (IbmS) search as described in Section 3.2.</S><S ssid=""1"" sid=""0"">Word Re-ordering and DP-based Search in Statistical Machine Translation</S><S ssid=""1"" sid=""25"">To explicitly handle the word reordering between words in source and target language, we use the concept of the so-called inverted alignments as given in (Ney et al., 2000).</S><S ssid=""1"" sid=""125"">A procedural definition to restrict1In the approach described in (Berger et al., 1996), a mor phological analysis is carried out and word morphemes rather than full-form words are used during the search.</S>",methodcitation
19,C00-2123,W01-1408,['47'],"Tillmann, 2001; Tillmann and Ney, 2000",['47'],dummy,dummy,"'21','165'","<S ssid=""1"" sid=""21"">The alignment model uses two kinds of parameters: alignment probabilities p(aj jaj􀀀1; I; J), where the probability of alignment aj for position j depends on the previous alignment position aj􀀀1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</S><S ssid=""1"" sid=""165"">We apply a beam search concept as in speech recognition.</S>",methodcitation
20,C00-2123,W02-1020,['62'],"Tillmann and Ney, 2000","['61','62']",dummy,dummy,'1',"<S ssid=""1"" sid=""1"">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S>",methodcitation
