Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,N09-1025,C10-2052,'22',"Chiang et al., 2009",'22',dummy,dummy,"'165','97'","<S ssid=""1"" sid=""165"">In Table 6 are shown feature weights learned for the word-context features.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S>",['methodcitation']
1,N09-1025,D11-1081,'6',"Chiang et al., 2009",'6',dummy,dummy,"'182','8','1'","<S ssid=""1"" sid=""182"">When training over 10,000 features on a modest amount of data, we, like Watanabe et al.</S><S ssid=""1"" sid=""8"">In this paper, we address these questions by experimenting with a large number of new features.</S><S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S>",['methodcitation']
1,N09-1025,D11-1081,'9',"Chiang et al., 2009",'9',dummy,dummy,"'182','97','173','103','65'","<S ssid=""1"" sid=""182"">When training over 10,000 features on a modest amount of data, we, like Watanabe et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""173"">(2007) that with on the order of 10,000 features, overfitting is possible, but we can still improve accuracy on new data.</S><S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
1,N09-1025,D11-1081,'25',"Chiang et al., 2009",'25',dummy,dummy,"'97','65'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
1,N09-1025,D11-1081,'159',"Chiang et al., 2009",'159',dummy,dummy,"'65','165','97','164','101'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""165"">In Table 6 are shown feature weights learned for the word-context features.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""164"">6.2 Word context features.</S><S ssid=""1"" sid=""101"">(If a rule is observed with more than one set of word alignments, we keep only the most frequent one.)</S>",['methodcitation']
1,N09-1025,D11-1081,'239',"Chiang et al., 2009",'239',dummy,dummy,"'97','65'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
1,N09-1025,D11-1125,'13',"Chiang et al., 2009",'13',dummy,dummy,"'65','97','20','103','1'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""20"">A third difficulty with Och et al.’s study was that it used MERT, which is not an ideal vehicle for feature exploration because it is observed not to perform well with large feature sets.</S><S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S>",['methodcitation']
1,N09-1025,D11-1125,"'78', '79'","Chiang et al., 2009","'77', '78', '79'",dummy,dummy,"'103','65','97','172'","<S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""172"">This seems in line with the finding of Watanabe et al.</S>",['methodcitation']
1,N09-1025,D11-1125,'208',"Chiang et al., 2009","'207', '208', '209'",dummy,dummy,"'65','103','97','74'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""74"">A rule like: IN(at) ↔ zai will have feature rule-root-IN set to 1 and all other rule-root features set to 0.</S>",['methodcitation']
1,N09-1025,D11-1125,'210',"Chiang et al., 2009","'210', '211'",dummy,dummy,"'146','65','97','84'","<S ssid=""1"" sid=""146"">Table 4 shows weights for rule-overlap features.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""84"">Insertion features Among the rules we extract from bilingual corpora are target-language insertion rules, which have a word on the English side, but no words on the source Chinese side.</S>",['methodcitation']
1,N09-1025,D11-1125,'227',"Chiang et al., 2009","'227', '228', '229'",dummy,dummy,"'55','66','1'","<S ssid=""1"" sid=""55"">, ein, which are the 10-best translations according to each of: h(e) · w B(e) + h(e) · w −B(e) + h(e) · w • For each i, select an oracle translation: (1) 4.1 Target-side.</S><S ssid=""1"" sid=""66"">(2008), we calculate the sentence B scores in (1), (2), and (3) in the context of some previous 1-best translations.</S><S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S>",['methodcitation']
1,N09-1025,N12-1006,'102',"Chiang et al., 2009","'102', '103'",dummy,dummy,"'103','65','97','182','124'","<S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""182"">When training over 10,000 features on a modest amount of data, we, like Watanabe et al.</S><S ssid=""1"" sid=""124"">We implemented the source-side context features for Hiero and the target-side syntax features for the syntax-based system, and the discount features for both.</S>",['methodcitation']
1,N09-1025,P12-1001,'147',"Chiang et al., 2009",'147',dummy,dummy,'1',"<S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S>",['methodcitation']
1,N09-1025,P13-1110,'36',"Chiang et al., 2009",'36',dummy,dummy,"'97','20'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""20"">A third difficulty with Och et al.’s study was that it used MERT, which is not an ideal vehicle for feature exploration because it is observed not to perform well with large feature sets.</S>",['methodcitation']
2,N09-1025,P13-1110,'102',"Chiang et al., 2009",'102',dummy,dummy,"'97','65'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
3,N09-1025,P13-1110,'115',"Chiang et al., 2009",'115',dummy,dummy,"'66','175'","<S ssid=""1"" sid=""66"">(2008), we calculate the sentence B scores in (1), (2), and (3) in the context of some previous 1-best translations.</S><S ssid=""1"" sid=""175"">Scores on the tuning set were obtained from the 1-best output of the online learning algorithm, whereas scores on the test set were obtained using averaged weights.</S>",['methodcitation']
4,N09-1025,P13-1110,'120',"Chiang et al., 2009",'120',dummy,dummy,"'75','74'","<S ssid=""1"" sid=""75"">Our rule root features range over the original (non-split) nonterminal set; we have 105 in total.</S><S ssid=""1"" sid=""74"">A rule like: IN(at) ↔ zai will have feature rule-root-IN set to 1 and all other rule-root features set to 0.</S>",['methodcitation']
5,N09-1025,P28-N09,'51',"Chiang et al., 2009",'51',dummy,dummy,"'43','100'","<S ssid=""1"" sid=""43"">For example, there is a pair of features to punish rules that drop Chinese content words or introduce spurious English content words.</S><S ssid=""1"" sid=""100"">Word context During rule extraction, we retain word alignments from the training data in the extracted rules.</S>",['methodcitation']
6,N09-1025,P134-N09,'27',"Chiang et al., 2009","'27', '28'",dummy,dummy,'126',"<S ssid=""1"" sid=""126"">We chose a stopping iteration based on the B score on the tuning set, and used the averaged feature weights from all iter Syntax-based Hiero count weight count weight 1 +1.28 1 +2.23 2 +0.35 2 +0.77 3–5 −0.73 3 +0.54 6–10 −0.64 4 +0.29 5+ −0.02 Table 2: Weights learned for discount features.</S>",['methodcitation']
7,N09-1025,PMERT-N09,'15',"Chiang et al., 2009",'15',dummy,dummy,"'97','65'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
8,N09-1025,PMERT-N09,'16',"Chiang et al., 2009",'16',dummy,dummy,"'44','31','184','180'","<S ssid=""1"" sid=""44"">All features are linearly combined and their weights are optimized using MERT.</S><S ssid=""1"" sid=""31"">The baseline model includes 12 features whose weights are optimized using MERT.</S><S ssid=""1"" sid=""184"">Third, we have shown that syntax-based machine translation offers possibilities for features not available in other models, making syntax-based MT and MIRA an especially strong combination for future work.</S><S ssid=""1"" sid=""180"">First, we have shown that these new features can improve the performance even of top-scoring MT systems.</S>",['methodcitation']
9,N09-1025,PMTS-N09,'218',"Chiang et al., 2009",'218',dummy,dummy,"'97','175'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""175"">Scores on the tuning set were obtained from the 1-best output of the online learning algorithm, whereas scores on the test set were obtained using averaged weights.</S>",['methodcitation']
10,N09-1025,PMTS-N09,'245',"Chiang et al., 2009",'245',dummy,dummy,"'65','97','20'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""20"">A third difficulty with Och et al.’s study was that it used MERT, which is not an ideal vehicle for feature exploration because it is observed not to perform well with large feature sets.</S>",['methodcitation']
11,N09-1025,PMTS-N09,'252',"Chiang et al., 2009",'252',dummy,dummy,"'1','97'","<S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S>",['methodcitation']
12,N09-1025,PSMPT-N09,'73',"Chiang et al., 2009","'73', '74'",dummy,dummy,"'1','105','15','29'","<S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S><S ssid=""1"" sid=""105"">(2007); here, we are incorporating some of its features directly into the translation model.</S><S ssid=""1"" sid=""15"">The work of Och et al (2004) is perhaps the best- known study of new features and their impact on translation quality.</S><S ssid=""1"" sid=""29"">Hiero (Chiang, 2005) is a hierarchical, string-to- string translation system.</S>",['methodcitation']
13,N09-1025,PTASL-N09,'79',"Chiang et al., 2009",'79',dummy,dummy,"'56','65','97','4','124'","<S ssid=""1"" sid=""56"">features String-to-tree MT offers some unique levers to pull, in terms of target-side features.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""4"">What linguistic features can improve statistical machine translation (MT)?</S><S ssid=""1"" sid=""124"">We implemented the source-side context features for Hiero and the target-side syntax features for the syntax-based system, and the discount features for both.</S>",['methodcitation']
14,N09-1025,PTASL-N09,'86',"Chiang et al., 2009",'86',dummy,dummy,"'65','97','103'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S>",['methodcitation']
15,N09-1025,W10-1757,'48',"Chiang et al., 2009",'48',dummy,dummy,"'103','8','1'","<S ssid=""1"" sid=""103"">These features are somewhat similar to features used by Watanabe et al.</S><S ssid=""1"" sid=""8"">In this paper, we address these questions by experimenting with a large number of new features.</S><S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S>",['methodcitation']
16,N09-1025,W10-1757,'209',"Chiang et al., 2009",'209',dummy,dummy,"'1','19','160','15','29'","<S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S><S ssid=""1"" sid=""19"">By contrast, we incorporate features directly into hierarchical and syntax- based decoders.</S><S ssid=""1"" sid=""160"">Therefore, the new features work to discourage these hypotheses.</S><S ssid=""1"" sid=""15"">The work of Och et al (2004) is perhaps the best- known study of new features and their impact on translation quality.</S><S ssid=""1"" sid=""29"">Hiero (Chiang, 2005) is a hierarchical, string-to- string translation system.</S>",['methodcitation']
17,N09-1025,W10-1761,'53',"Chiang et al., 2009","'53', '54'",dummy,dummy,"'65','97','1','177','19'","<S ssid=""1"" sid=""65"">Following Chiang et al.</S><S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""1"">We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase- based translation system and our syntax-based translation system.</S><S ssid=""1"" sid=""177"">We have described a variety of features for statistical machine translation and applied them to syntax- based and hierarchical systems.</S><S ssid=""1"" sid=""19"">By contrast, we incorporate features directly into hierarchical and syntax- based decoders.</S>",['methodcitation']
18,N09-1025,W10-1761,'92',"Chiang et al., 2009",'92',dummy,dummy,"'30','176'","<S ssid=""1"" sid=""30"">Its rules, which are extracted from unparsed, word-aligned parallel text, are synchronous CFG productions, for example: X → X1 de X2, X2 of X1 As the number of nonterminals is limited to two, the grammar is equivalent to an inversion transduction grammar (Wu, 1997).</S><S ssid=""1"" sid=""176"">Early stopping would have given +0.2 B over the results reported in Table 1.1 7 Conclusion.</S>",['methodcitation']
19,N09-1025,W10-1761,'97',"Chiang et al., 2009",'97',dummy,dummy,"'97','65'","<S ssid=""1"" sid=""97"">To remedy this problem, Chiang et al.</S><S ssid=""1"" sid=""65"">Following Chiang et al.</S>",['methodcitation']
