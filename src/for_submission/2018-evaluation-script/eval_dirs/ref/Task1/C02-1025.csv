Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,C02-1025,C10-2104,['115'],"Chieu and Ng, 2002",['115'],dummy,dummy,['63'],"<S sid =""63"" ssid = ""3"">Global features are extracted from other occurrences of the same token in the whole document.</S>",['methodcitation']
2,C02-1025,C10-2167,['65'],"Chieu et al., 2002",['65'],dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC6 and MUC7 test data.</S>",['resultcitation']
3,C02-1025,I05-3013,['88'],"Chieu and Ng, 2002",['88'],dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC6 and MUC7 test data.</S>",['resultcitation']
4,C02-1025,I05-3030,['33'],Chieu 2002,['33'],dummy,dummy,['196'],"<S sid =""196"" ssid = ""1"">We have shown that the maximum entropy framework is able to use global information directly.</S>",['resultcitation']
6,C02-1025,P02-1061,['51'],"Chieu and Ng, 2002",['51'],dummy,dummy,['86'],"<S sid =""86"" ssid = ""26"">Case and Zone of and",['methodcitation']
7,C02-1025,P03-1028,['161'],"Chieu and Ng, 2002a",['161'],dummy,dummy,['6'],"<S sid =""6"" ssid = ""6"">A named entity recognizer (NER) is useful in many NLP applications such as information extraction, question answering, etc. On its own, a NER can also provide users who are looking for person or organization names with quick information.</S>",['implicationcitation']
10,C02-1025,P03-1028,['52'],2002a,['52'],dummy,dummy,"['2','3']","<S sid =""2"" ssid = ""2"">It differs from previous machine learning-based NERs in that it uses information from the whole document to classify each word, with just one classifier.</S><S sid =""3"" ssid = ""3"">Previous work that involves the gathering of information from the whole document often uses a secondary classifier, which corrects the mistakes of a primary sentence- based classifier.</S>",['methodcitation']
12,C02-1025,P05-1045,['174'],2002,['174'],dummy,dummy,['63'],"<S sid =""63"" ssid = ""3"">Global features are extracted from other occurrences of the same token in the whole document.</S>",['methodcitation']
13,C02-1025,P05-1051,['27'],"Chieu and Ng, 2002",['27'],dummy,dummy,['63'],"<S sid =""63"" ssid = ""3"">Global features are extracted from other occurrences of the same token in the whole document.</S>",['methodcitation']
15,C02-1025,W03-0423,['12'],"Chieu and Ng, 2002b",['12'],dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC6 and MUC7 test data.</S>",['resultcitation']
16,C02-1025,W03-0423,['32'],"Chieu and Ng, 2002a",['32'],dummy,dummy,"['102','103','104']","<S sid =""102"" ssid = ""42"">For all lists except locations, the lists are processed into a list of tokens (unigrams).</S><S sid =""103"" ssid = ""43"">Location list is processed into a list of unigrams and bigrams (e.g., New York).</S><S sid =""104"" ssid = ""44"">For locations, tokens are matched against unigrams, and sequences of two consecutive tokens are matched against bigrams.</S>",['methodcitation']
17,C02-1025,W03-0423,['44'],"Chieu and Ng, 2002b",['44'],dummy,dummy,"['61','63']","<S sid =""61"" ssid = ""1"">The features we used can be divided into 2 classes",['methodcitation']
18,C02-1025,W03-0423,['62'],"Chieu and Ng, 2002b",['62'],dummy,dummy,['86'],"<S sid =""86"" ssid = ""26"">Case and Zone of and",['methodcitation']
19,C02-1025,W03-0423,['46'],"Chieu and Ng, 2002b",['46'],dummy,dummy,"['61','62','63']","<S sid =""61"" ssid = ""1"">The features we used can be divided into 2 classes",['methodcitation']
20,C02-1025,W03-0432,['44'],"Chieu and Ng, 2002a",['44'],dummy,dummy,"['136','137']","<S sid =""136"" ssid = ""76"">The global feature groups are",['methodcitation']
21,C02-1025,W04-0705,['8'],Chieu and Ng 2002,['8'],dummy,dummy,['11'],"<S sid =""11"" ssid = ""11"">We will refer to our system as MENERGI (Maximum Entropy Named Entity Recognizer using Global Information).</S>",['methodcitation']
22,C02-1025,W04-0705,['147'],Chieu and Ng 2002,['147'],dummy,dummy,['63'],"<S sid =""63"" ssid = ""3"">Global features are extracted from other occurrences of the same token in the whole document.</S>",['methodcitation']
23,C02-1025,W06-0119,['11'],Chieu et al. 2002,['11'],dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">In this paper, we show that the maximum entropy framework is able to make use of global information directly, and achieves performance that is comparable to the best previous machine learning-based NERs on MUC6 and MUC7 test data.</S>",['resultcitation']
