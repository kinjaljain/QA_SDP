Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,C08-1098,C10-2023,['122'],"Schmid and Laws, 2008",['122'],dummy,dummy,"['5','6','127']","<S sid =""5"" ssid = ""5"">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S><S sid =""6"" ssid = ""6"">For languages with a rich morphology such as German or Czech, more fine-grained tagsets are often considered more appropriate.</S><S sid =""127"" ssid = ""7"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S>","['implicationcitation', 'resultcitation']"
2,C08-1098,D12-1133,['208'],"Schmid and Laws, 2008",['208'],dummy,dummy,['100'],"<S sid =""100"" ssid = ""6"">The tagger may use an external lexicon which supplies entries for additional words which are not found in the training corpus, and additional tags for words which did occur in the training data.</S>",['methodcitation']
3,C08-1098,D12-1133,['228'],"Schmid and Laws, 2008",['228'],dummy,dummy,['167'],"<S sid =""167"" ssid = ""47"">3 9 97.57 97.97 Table 3",['resultcitation']
4,C08-1098,D13-1032,['212'],"Schmid and Laws, 2008",['212'],dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tË†N = tË†1, ..., tË†N for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S>",['methodcitation']
5,C08-1098,D13-1033,['176'],"Schmid and Laws, 2008",['176'],dummy,dummy,['95'],"<S sid =""95"" ssid = ""1"">Our tagger is a HMM tagger which decomposes the context probabilities into a product of attribute probabilities.</S>",['methodcitation']
6,C08-1098,E09-1079,['121'],"Schmid and Laws, 2008",['121'],dummy,dummy,['59'],"<S sid =""59"" ssid = ""20"">Our tagger generates a predictor for each feature (such as base POS, number, gender etc.) Instead of using a single tree for the prediction of all possible values of a feature (such as noun, article, etc. for base POS), the tagger builds a separate decision tree for each value.</S>",['methodcitation']
7,C08-1098,P10-1020,['159'],"Schmid and Laws, 2008",['159'],dummy,dummy,"['59','68']","<S sid =""59"" ssid = ""20"">Our tagger generates a predictor for each feature (such as base POS, number, gender etc.) Instead of using a single tree for the prediction of all possible values of a feature (such as noun, article, etc. for base POS), the tagger builds a separate decision tree for each value.</S><S sid =""68"" ssid = ""29"">A typical context attribute is â€œ1",['methodcitation']
8,C08-1098,P10-1068,['42'],"Schmid and Laws, 2008",['42'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
9,C08-1098,P10-1068,['74'],"Schmid and Laws, 2008",['74'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets</S>",['methodcitation']
10,C08-1098,P10-1068,['81'],"Schmid and Laws, 2008",['81'],dummy,dummy,"['5', '224']","<S sid =""5"" ssid = ""5"">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S><S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
11,C08-1098,W10-1704,['32'],"Schmid and Laws, 2008",['32'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
12,C08-1098,W10-1727,['41'],"Schmid and Laws, 2008",['41'],dummy,dummy,['127'],"<S sid =""127"" ssid = ""7"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S>",['resultcitation']
13,C08-1098,W11-2135,['49'],"Schmid and Laws, 2008",['49'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
14,C08-1098,W11-2145,['101'],"Schmid and Laws, 2008","['101','102']",dummy,dummy,"['12','127']","<S sid =""12"" ssid = ""12"">The German Tiger treebank (Brants et al., 2002) is an example of a corpus with a more fine-grained tagset (over 700 tags overall).</S><S sid =""127"" ssid = ""7"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S>",['resultcitation']
15,C08-1098,W11-2147,['26'],"Schmid and Laws, 2008",['26'],dummy,dummy,"['4','5']","<S sid =""4"" ssid = ""4"">A Hidden-Markov-Model part-of-speech tagger (Brants, 2000, e.g.) computes the most probable POS tag sequence tË†N = tË†1, ..., tË†N for a given word sequence wN . POS taggers are usually trained on corpora with between 50 and 150 different POS tags.</S><S sid =""5"" ssid = ""5"">Tagsets of this size contain little or no information about number, gender, case and similar morphosyntac- tic features.</S>",['implicationcitation']
16,C08-1098,W12-3141,['89'],"Schmid and Laws, 2008",['89'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
17,C08-1098,W12-3144,['127'],"Schmid and Laws, 2008",['127'],dummy,dummy,['127'],"<S sid =""127"" ssid = ""7"">It is annotated with POS tags from the coarse-grained STTS tagset and with additional features encoding information about number, gender, case, person, degree, tense, and mood.</S>",['resultcitation']
18,C08-1098,W12-3402,['78'],"Schmid and Laws, 2008",['78'],dummy,dummy,"['124','224']","<S sid =""124"" ssid = ""4"">We took standard features from a 5 word window and M4LRL training without optimization of the regular- ization parameter C</S><S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
19,C08-1098,W13-2204,['35'],"Schmid and Laws, 2008",['35'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
20,C08-1098,W13-2210,['37'],"Schmid and Laws, 2008",['37'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
21,C08-1098,W13-2210,['85'],"Schmid and Laws, 2008",['85'],dummy,dummy,['54'],"<S sid =""54"" ssid = ""15"">The probability of an attribute (such as â€œNomâ€) is always conditioned on the respective base POS (such as â€œNâ€) (unless the predicted attribute is theFigure 1",['methodcitation']
22,C08-1098,W13-2211,['84'],"Schmid and Laws, 2008",['84'],dummy,dummy,['0'],"<S sid =""0"">Estimation of Conditional ProbabilitiesWith Decision Trees and an Application to Fine-Grained POS Tagging</S>",['aimcitation']
23,C08-1098,W13-2228,['134'],"Schmid and Laws, 2008",['134'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
24,C08-1098,W13-2230,['35'],"Schmid and Laws, 2008",['35'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
25,C08-1098,W13-2230,['58'],"Schmid and Laws, 2008",['58'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
26,C08-1098,W13-2230,['83'],"Schmid and Laws, 2008",['83'],dummy,dummy,['224'],"<S sid =""224"" ssid = ""1"">We presented a HMM POS tagger for fine-grained tagsets which splits the POS tags into attribute vectors and estimates the conditional probabilities of the attributes with decision trees.</S>",['methodcitation']
28,C08-1098,W13-2302,['87'],"Schmid and Laws, 2008",['87'],dummy,dummy,"['1','167']","<S sid =""1"" ssid = ""1"">We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.</S><S sid =""167"" ssid = ""47"">3 9 97.57 97.97 Table 3","['methodcitation', 'resultcitation']"
29,C08-1098,W13-2708,['111'],"Schmid and Laws, 2008",['111'],dummy,dummy,['1'],"<S sid =""1"" ssid = ""1"">We present a HMM part-of-speech tagging method which is particularly suited for POS tagsets with a large number of fine-grained tags.</S>",['methodcitation']
