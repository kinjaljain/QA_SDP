Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,N09-1001,N09-CSL2013,'147',2009.0,"'146', '147'",dummy,dummy,"['126', '127', '133', '207']","<S sid =""126"" ssid = ""39"">We conduct the experiments on two different gold standard datasets.</S>			<S sid =""127"" ssid = ""40"">One is the MicroWNOp corpus, ntu.edu.tw/cjlin/libsvm/.</S><S sid =""133"" ssid = ""5"">It includes 298 words with 703 objective and 358 subjective WordNet senses.</S><S sid =""207"" ssid = ""49"">Our best result from Mincuts is significantly better at 84.6% (see LRMSL in Table 2).</S>",['resultcitation']
2,N09-1001,N09-QWN,'22',"Su and Markert, 2009",'22',dummy,dummy,"['58', '59' 60']","<S sid =""58"" ssid = ""11"">Also, WordNet connections between different parts of the WordNet hierarchy can also be sparse, leading to relatively isolated senses in a graph in a supervised framework.</S>			<S sid =""59"" ssid = ""12"">Semi-supervised Mincuts allow us to import unlabeled data that can serve as bridges to isolated components.</S>			<S sid =""60"" ssid = ""13"">More importantly, as the unlabeled data can be chosen to be related to the labeled and test data, they might help pull test data to the right cuts (categories).</S>",['methodcitation']
3,N09-1001,N09-QWN,'22',"Su and Markert, 2009",'22',dummy,dummy,['20'],"<S sid =""20"" ssid = ""20"">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S>",['methodcitation']
4,N09-1001,N09PROD,'35',5.0,'35',dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">We propose a semi-supervised minimum cut framework that makes use of both WordNet definitions and its relation structure.</S>",['methodcitation']
5,N09-1001,N09PROD,'121',5.0,'121',dummy,dummy,['4'],"<S sid =""4"" ssid = ""4"">We propose a semi-supervised minimum cut framework that makes use of both WordNet definitions and its relation structure.</S>",['aimcitation']
6,N09-1001,N15-1071,'147',2009.0,'147',dummy,dummy,['1'],"<S sid =""1"" ssid = ""1"">We supplement WordNet entries with information on the subjectivity of its word senses.</S>",['methodcitation']
7,N09-1001,P101167,'146',2009.0,'146',dummy,dummy,"['104', '105' ,'106']","<S sid =""104"" ssid = ""17"">Assigning weights to WordNet relations",['methodcitation']
8,N09-1001,P1018,'10,2009.0,'10',dummy,dummy,"['72', '73', '74', '75']","<S sid =""72"" ssid = ""25"">We define two vertices s (source) and t (sink),.</S>			<S sid =""73"" ssid = ""26"">which correspond to the subjective and objective category, respectively.</S>			<S sid =""74"" ssid = ""27"">Following the definition in Blum and Chawla (2001), we call the vertices s and t classification vertices, and all other vertices (labeled, test, and unlabeled data) example vertices.</S>			<S sid =""75"" ssid = ""28"">Each example vertex corresponds to one WordNet sense and is connected to both s and t via a weighted edge.</S>",['methodcitation']
9,N09-1001,P1018,'180',2009.0,'180',dummy,dummy,"['4', '207']","<S sid =""4"" ssid = ""4"">We propose a semi-supervised minimum cut framework that makes use of both WordNet definitions and its relation structure.</S><S sid =""207"" ssid = ""49"">Our best result from Mincuts is significantly better at 84.6% (see LRMSL in Table 2).</S>","['methodcitation', 'resultcitation']"
10,N09-1001,PEAAI-N09,'70',2009.0,'70',dummy,dummy,['65'],"<S sid =""65"" ssid = ""18"">We propose semi-supervised mincuts for subjectivity recognition on senses for several reasons.</S>",['methodcitation']
11,N09-1001,PPROC2014-N09,'33',2009.0,'33',dummy,dummy,['20'],"<S sid =""20"" ssid = ""20"">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S>",['methodcitation']
12,N09-1001,PPROC2014-N09,'70',2009.0,'70',dummy,dummy,['20'],"<S sid =""20"" ssid = ""20"">Qc 2009 Association for Computational Linguistics We propose a semi-supervised approach based on minimum cut in a lexical relation graph to assign subjectivity (subjective/objective) labels to word senses.2 Our algorithm outperforms supervised minimum cuts and standard supervised, non-graph classification algorithms (like SVM), reducing the error rate by up to 40%.</S>",['methodcitation']
13,N09-1001,W11-0311,'231',2009.0,'231',dummy,dummy,['1'],"<S sid =""1"" ssid = ""1"">We supplement WordNet entries with information on the subjectivity of its word senses.</S>",['methodcitation']
