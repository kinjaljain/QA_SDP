Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,P06-2124,D11-1084,['50'],2006,"['48','49','50','51']",dummy,dummy,['15'],"<S sid =""15"" ssid = ""15"">In this paper, we propose a probabilistic admixture model to capture latent topics underlying the context of document- pairs.</S>",['methodcitation']
3,P06-2124,D11-1084,['53'],2006,"['52','53','54']",dummy,dummy,"['2','15']","<S sid =""2"" ssid = ""2"">Under this formalism, the parallel sentence-pairs within a document-pair are assumed to constitute a mixture of hidden topics; each word-pair follows a topic-specific bilingual translation model.</S><S sid =""15"" ssid = ""15"">In this paper, we propose a probabilistic admixture model to capture latent topics underlying the context of document- pairs.</S>","['hypothesiscitation', 'methodcitation']"
5,P06-2124,P07-1066,['28'],"Zhao and Xing, 2006","['28','29']",dummy,dummy,"['21', '37', '152']","<S sid =""21"" ssid = ""21"">We propose a new statistical formalism",['methodcitation']
7,P06-2124,P10-2025,['84'],"Zhao and Xing, 2006",['84'],dummy,dummy,['152'],"<S sid =""152"" ssid = ""25"">Topic-specific translation lexicons are learned by a 3-topic BiTAM1.</S>",['resultcitation']
8,P06-2124,P10-2025,['86'],"Zhao and Xing, 2006",['86'],dummy,dummy,"['124', '194']","<S sid =""124"" ssid = ""34"">Two word-alignment retrieval schemes are designed for BiTAMs","['methodcitation', 'resultcitation']"
9,P06-2124,P11-2032,['11'],2006,['11'],dummy,dummy,"['115','116','117']","<S sid =""115"" ssid = ""25"">The translation lexicons Bf,e,k have a potential size of V 2K , assuming the vocabulary sizes for both languages are V . The data sparsity (i.e., lack of large volume of document-pairs) poses a more serious problem in estimating Bf,e,k than the monolingual case, for instance, in (Blei et al., 2003).</S><S sid =""116"" ssid = ""26"">To reduce the data sparsity problem, we introduce two remedies in our models.</S><S sid =""117"" ssid = ""27"">First","['implicationcitation', 'methodcitation']"
10,P06-2124,P12-1048,['17'],"Zhao and Xing, 2006",['17'],dummy,dummy,"['2','3','21']","<S sid =""2"" ssid = ""2"">Under this formalism, the parallel sentence-pairs within a document-pair are assumed to constitute a mixture of hidden topics; each word-pair follows a topic-specific bilingual translation model.</S><S sid =""3"" ssid = ""3"">Three BiTAM models are proposed to capture topic sharing at different levels of linguistic granularity (i.e., at the sentence or word levels).</S><S sid =""21"" ssid = ""21"">We propose a new statistical formalism","['hypothesiscitation', 'methodcitation']"
11,P06-2124,P12-1048,['149'],2006,['149'],dummy,dummy,"['7', '10']","<S sid =""7"" ssid = ""7"">Our preliminary experiments show that the proposed models improve word alignment accuracy, and lead to better translation quality.</S><S sid =""10"" ssid = ""10"">Beyond the sentence-level, corpus- level word-correlation and contextual-level topical information may help to disambiguate translation candidates and word-alignment choices.</S>",['implicationcitation']
12,P06-2124,P12-1048,['160'],"Zhao and Xing, 2006",['160'],dummy,dummy,"['10', '83']","<S sid =""10"" ssid = ""10"">Beyond the sentence-level, corpus- level word-correlation and contextual-level topical information may help to disambiguate translation candidates and word-alignment choices.</S><S sid =""83"" ssid = ""44"">Specifically, the latent Dirichlet allocation (LDA) in (Blei et al., 2003) can be viewed as a special case of the BiTAM3, in which the target sentence 1 n p(f n n j=1 |eanj , Bzn ).</S>",['methodcitation']
13,P06-2124,P12-1079,['8'],"Zhao and Xing, 2006",['8'],dummy,dummy,"['10','13']","<S sid =""10"" ssid = ""10"">Beyond the sentence-level, corpus- level word-correlation and contextual-level topical information may help to disambiguate translation candidates and word-alignment choices.</S><S sid =""13"" ssid = ""13"">For example, the word shot in â€œIt was a nice shot.â€ should be translated differently depending on the context of the sentence",['implicationcitation']
14,P06-2124,P12-1079,['40'],"Zhao and Xing, 2006",['40'],dummy,dummy,['21'],"<S sid =""21"" ssid = ""21"">We propose a new statistical formalism","['hypothesiscitation', 'aimcitation']"
15,P06-2124,P12-2023,['30'],"Zhao and Xing, 2006",['30'],dummy,dummy,"['17', '21']","<S sid =""17"" ssid = ""17"">Previous works on topical translation models concern mainly explicit logical representations of semantics for machine translation.</S><S sid =""21"" ssid = ""21"">We propose a new statistical formalism","['hypothesiscitation', 'aimcitation']"
16,P06-2124,P13-2122,['27'],"Zhao and Xing, 2006",['27'],dummy,dummy,['21'],"<S sid =""21"" ssid = ""21"">We propose a new statistical formalism","['hypothesiscitation', 'aimcitation']"
17,P06-2124,W07-0722,['13'],"Zhao and Xing, 2006","['13','14','15']",dummy,dummy,"['21', '39','45','192','203']","<S sid =""21"" ssid = ""21"">We propose a new statistical formalism","['methodcitation', 'resultcitation']"
18,P06-2124,W07-0722,['62'],"Zhao and Xing, 2006",['62'],dummy,dummy,"['116','119','120']","<S sid =""116"" ssid = ""26"">To reduce the data sparsity problem, we introduce two remedies in our models.</S><S sid =""119"" ssid = ""29"">Second",['methodcitation']
