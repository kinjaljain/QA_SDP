Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,H89-2014,W93-0111,['178'],"Kupiec, 1989",['178'],dummy,dummy,['27'],"<S sid =""27"" ssid = ""27"">The work described here also makes use of a hidden Markov model.</S>",['methodcitation']
2,H89-2014,A92-1018,['47'],"Kupiec, 1989a",['47'],dummy,dummy,"['124', '125']","<S sid =""124"" ssid = ""124"">A model containing all of the refinements described, was tested using a magazine article containing 146 sentences (3,822 words).</S><S sid =""125"" ssid = ""125"">A 30,000 word dictionary was used, supplemented by inflectional analysis for words not found directly in the dictionary.</S>",['methodcitation']
3,H89-2014,A92-1018,['108'],"Kupiec, 1989a",['108'],dummy,dummy,"['87', '88', '89']","<S sid =""87"" ssid = ""87"">An alternative to uniformly increasing the order of the conditioning is to extend it selectively.</S><S sid =""88"" ssid = ""88"">Mixed higher- order context can be modeled by introducing explicit state sequences.</S><S sid =""89"" ssid = ""89"">In the arrangement the basic first-order network remains, permitting all possible category sequences, and modeling first-order dependency.</S>",['methodcitation']
4,H89-2014,J93-2006,['41'],Kupiec 1989,"['40','41']",dummy,dummy,['1'],"<S sid =""1"" ssid = ""1"">The paper describes refinements that are currently being investigated in a model for part-of-speech assignment to words in unrestricted text.</S>",['aimcitation']
5,H89-2014,H91-1046,['21'],1989,['21'],dummy,dummy,"['88', '90']","<S sid =""88"" ssid = ""88"">Mixed higher- order context can be modeled by introducing explicit state sequences.</S><S sid =""90"" ssid = ""90"">The basic network is then augmented with the extra state sequences which model certain category sequences in more detail.</S>",['methodcitation']
6,H89-2014,H91-1046,['60'],"Kupiec, 1989",['60'],dummy,dummy,"['29', '30']","<S sid =""29"" ssid = ""29"">In this regard, word equivalence classes were used (Kupiec, 1989).</S><S sid =""30"" ssid = ""30"">There it is assumed that the distribution of the use of a word depends on the set of categories it can assume, and words are partitioned accordingly.</S>",['methodcitation']
7,H89-2014,C00-1081,['85'],"Kupiec, 1989",['85'],dummy,dummy,"['69', '70']","<S sid =""69"" ssid = ""69"">In a ranked list of words in the corpus the most frequent 100 words account for approximately 50% of the total tokens in the corpus, and thus data is available to estimate them reliably.</S><S sid =""70"" ssid = ""70"">The most frequent 100 words of the corpus were assigned individually in the model, thereby enabling them to have different distributions over their categories.</S>",['methodcitation']
8,H89-2014,H92-1022,['18'],11,['18'],dummy,dummy,['2'],"<S sid =""2"" ssid = ""2"">The model has the advantage that a pre-tagged training corpus is not required.</S>",['implicationcitation']
9,H89-2014,H92-1022,['9'],11,['9'],dummy,dummy,['145'],"<S sid =""145"" ssid = ""145"">A stochastic method for assigning part-of-speech categories to unrestricted English text has been described.</S>",['methodcitation']
10,H89-2014,C92-1060,['124'],"Kupiec, 1989",['124'],dummy,dummy,"['29', '30']","<S sid =""29"" ssid = ""29"">In this regard, word equivalence classes were used (Kupiec, 1989).</S><S sid =""30"" ssid = ""30"">There it is assumed that the distribution of the use of a word depends on the set of categories it can assume, and words are partitioned accordingly.</S>",['methodcitation']
