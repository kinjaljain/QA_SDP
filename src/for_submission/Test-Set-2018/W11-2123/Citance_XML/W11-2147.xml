<PAPER>
	<S sid="0">Experiments with word alignment normalization and clause reordering for SMT between English and German</S><ABSTRACT>
		<S sid="1" ssid="1">This paper presents the LIU system for theWMT 2011 shared task for translation be tween German and English.</S>
		<S sid="2" ssid="2">For English?German we attempted to improve the trans lation tables with a combination of standard statistical word alignments and phrase-basedword alignments.</S>
		<S sid="3" ssid="3">For German?English trans lation we tried to make the German text moresimilar to the English text by normalizing Ger man morphology and performing rule-basedclause reordering of the German text.</S>
		<S sid="4" ssid="4">This resulted in small improvements for both transla tion directions.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="5" ssid="5">In this paper we present the LIU system for theWMT11 shared task, for translation between En glish and German in both directions.</S>
			<S sid="6" ssid="6">We added anumber of features that address problems for translation between German and English such as word or der differences, incorrect alignment of certain words such as verbs, and the morphological complexity of German compared to English, as well as dealing with previously unseen words.In both translation directions our systems include compound processing, morphological se quence models, and a hierarchical reordering model.For German?English translation we also added mor phological normalization, source side reordering, and processing of out-of-vocabulary words (OOVs).</S>
			<S sid="7" ssid="7">For English?German translation, we extracted word alignments with a supervised method and combined these alignments with Giza++ alignments in various ways to improve the phrase table.</S>
			<S sid="8" ssid="8">We experimented with different ways of combining the two alignmentssuch as using heuristic symmetrization and interpo lating phrase tables.Results are reported on three metrics, BLEU (Pa pineni et al, 2002), NIST (Doddington, 2002) and Meteor ranking scores (Agarwal and Lavie, 2008) based on truecased output.</S>
	</SECTION>
	<SECTION title="Baseline System. " number="2">
			<S sid="9" ssid="1">This years improvements were added to the LIUbaseline system (Stymne et al, 2010).</S>
			<S sid="10" ssid="2">Our base line is a factored phrase based SMT system that usesthe Moses toolkit (Koehn et al, 2007) for transla tion model training and decoding, GIZA++ (Ochand Ney, 2003) for word alignment, SRILM (Stol cke, 2002) an KenLM (Heafield, 2011) for language modelling and minimum error rate training (Och, 2003) to tune model feature weights.</S>
			<S sid="11" ssid="3">In addition, the LIU baseline contains: ? Compound processing, including compound splitting and for translation into German also compound merging ? Part-of-speech and morphological sequence modelsAll models were trained on truecased data.</S>
			<S sid="12" ssid="4">Trans lation and reordering models were trained using the bilingual Europarl and News Commentary corpora that were concatenated before training.</S>
			<S sid="13" ssid="5">We created two language models.</S>
			<S sid="14" ssid="6">The first model is a 5-gram model that we created by interpolating two language 393models from bilingual News Commentary and Eu roparl with more weight on the News Commentary model.</S>
			<S sid="15" ssid="7">The second model is a 4-gram model trainedon monolingual News only.</S>
			<S sid="16" ssid="8">All models were cre ated using entropy-based pruning with 10?8 as the threshold.</S>
			<S sid="17" ssid="9">Due to time constraints, all tuning and evaluation were performed on half of the provided shared task data.</S>
			<S sid="18" ssid="10">Systems were tuned on 1262 sentences from newstest2009 and all results reported in Tables 1 and 2 are based on a devtest set of 1244 sentences from newstest2010.</S>
			<S sid="19" ssid="11">2.1 Sequence models with part-of-speech and.</S>
			<S sid="20" ssid="12">morphology To improve target word order and agreement in the translation output, we added an extra output factor in our translation models consisting of tags with POS and morphological features.</S>
			<S sid="21" ssid="13">For English we used tags that were obtained by enriching POS tags fromTreeTagger (Schmid, 1994) with additional morpho logical features such as number for determiners.</S>
			<S sid="22" ssid="14">ForGerman, the POS and morphological tags were ob tained from RFTagger (Schmid and Laws, 2008) which provides morphological information such as case, number and gender for nouns and tense for verbs.</S>
			<S sid="23" ssid="15">We trained two sequence models for each system over this output factor and added them as features in our baseline system.</S>
			<S sid="24" ssid="16">The first sequence model is a 7-gram model interpolated from models of bilingual Europarl and News Commentary.</S>
			<S sid="25" ssid="17">Thesecond model is a 6-gram model trained on mono lingual News only.</S>
			<S sid="26" ssid="18">2.2 Compound processing.</S>
			<S sid="27" ssid="19">In both translation directions we split compounds,using a modified version of the corpus-based split ting method of Koehn and Knight (2003).</S>
			<S sid="28" ssid="20">We split nouns, verb, and adjective compounds into known parts that were content words or cardinal numbers, based on the arithmetic mean of the frequency ofthe parts in the training corpus.</S>
			<S sid="29" ssid="21">We allowed 10 com mon letter changes (Langer, 1998) and hyphens atsplit points.</S>
			<S sid="30" ssid="22">Compound parts were kept in their surface form and compound modifiers received a partof-speech tag based on that of the tag of the full com pound.</S>
			<S sid="31" ssid="23">For translation into German, compounds were merged using the POS-merging strategy of Stymne (2009).</S>
			<S sid="32" ssid="24">A compound part in the translation output, identified by the special part-of-speech tags, wasmerged with the next word if that word had a match ing part-of-speech tag.</S>
			<S sid="33" ssid="25">If the compound part was followed by the conjunction und (and), we added ahyphen to the part, to account for coordinated com pounds.</S>
			<S sid="34" ssid="26">2.3 Hierarchical reordering.</S>
			<S sid="35" ssid="27">In our baseline system we experimented with two lexicalized reordering models.</S>
			<S sid="36" ssid="28">The standard modelin Moses (Koehn et al, 2005), and the hierarchi cal model of Galley and Manning (2008).</S>
			<S sid="37" ssid="29">In both models the placement of a phrase is compared tothat of the previous and/or next phrase.</S>
			<S sid="38" ssid="30">In the stan dard model up to three reorderings are distinguished,monotone, swap, and discontinuous.</S>
			<S sid="39" ssid="31">In the hierarchical model the discontinuous class can be further subdivided into two classes, left and right dis continuous.</S>
			<S sid="40" ssid="32">The hierarchical model further differsfrom the standard model in that it compares the or der of the phrase with the next or previous block of phrases, not only with the next or previous single phrase.</S>
			<S sid="41" ssid="33">We investigated one configuration of eachmodel.</S>
			<S sid="42" ssid="34">For the standard model we used the msdbidirectional-fe setting, which uses three orienta tions, is conditioned on both the source and target language, and considers both the previous and next phrase.</S>
			<S sid="43" ssid="35">For the hierarchical model we used all four orientations, and again it is conditioned on both the source and target language, and considers both the previous and next phrase.</S>
			<S sid="44" ssid="36">The result of replacing the standard reordering model with an hierarchical model is shown in Table1 and 2.</S>
			<S sid="45" ssid="37">For translation into German adding the hierarchical model led to small improvements as mea sured by NIST and Meteor.</S>
			<S sid="46" ssid="38">For translation in the other direction, the differences on automatic metricswere very small.</S>
			<S sid="47" ssid="39">Still, we decided to use the hierar chical model in all our systems.</S>
	</SECTION>
	<SECTION title="German?English. " number="3">
			<S sid="48" ssid="1">For translation from German into English we focused on making the German source text more sim ilar to English by removing redundant morphology 394 and changing word order before training translation models.</S>
			<S sid="49" ssid="2">3.1 Normalization.</S>
			<S sid="50" ssid="3">We performed normalization of German words to re move distinctions that do not exist in English, suchas case distinctions on nouns.</S>
			<S sid="51" ssid="4">This strategy is sim ilar to that of El-Kahlout and Yvon (2010), but we used a slightly different set of transformations, that we thought better mirrored the English structure.</S>
			<S sid="52" ssid="5">For morphological tags we used RFTagger and for lemmas we used TreeTagger.</S>
			<S sid="53" ssid="6">The morphological transformations we performed were the following: ? Nouns: ? Replace with lemma+s if plural number ? Replace with lemma otherwise ? Verbs: ? Replace with lemma if present tense, not third person singular ? Replace with lemma+p if past tense ? Adjectives: ? Replace with lemma+c if comparative ? Replace with lemma+sup if superlative ? Replace with lemma otherwise ? Articles: ? Definite articles: ? Replace with des if genitive ? Replace with der otherwise ? Indefinite articles: ? Replace with eines if genitive ? Replace with ein otherwise ? Pronouns: ? Replace with RELPRO if relative?</S>
			<S sid="54" ssid="7">Replace with lemma if indefinite, interrog ative, or possessive pronouns?</S>
			<S sid="55" ssid="8">Add +g to all pronouns which are geni tive, unless they are possessive For all word types that are not mentioned in the list, surface forms were kept.</S>
			<S sid="56" ssid="9">BLEU NIST Meteor Baseline 21.01 6.2742 41.32 +hier reo 20.94 6.2800 41.24 +normalization 20.85 6.2370 41.04 +source reordering 21.06 6.3082 41.40 + OOV proc.</S>
			<S sid="57" ssid="10">21.22 6.3692 41.51 Table 1: German?English translation results.</S>
			<S sid="58" ssid="11">Results are cumulative.</S>
			<S sid="59" ssid="12">We also performed those tokenization and spelling normalizations suggested by El-Kahlout and Yvon (2010), that we judged could safely bedone for translation from German without collect ing corpus statistics.</S>
			<S sid="60" ssid="13">We split words with numbers and letters, such as 40-ja?hrigen or 40ja?hrigen (40year-old), unless the suffix indicates that it is a ordi nal, such as 70sten (70th).</S>
			<S sid="61" ssid="14">We also did some spelling normalization by exchanging ? with ss and replacing tripled consonants with doubled consonants.</S>
			<S sid="62" ssid="15">These changes would have been harmful for translation into German, since they change the language into a normalized variant, but for translation from German we considered them safe.</S>
			<S sid="63" ssid="16">3.2 Source side reordering.</S>
			<S sid="64" ssid="17">To make the word order of German input sen tences more English-like a version of the rules of(Collins et al, 2005) were partially implemented us ing tagged output from the RFTagger.</S>
			<S sid="65" ssid="18">Basically, beginnings of subordinate clauses, their subjects (if present) and final verb clusters were identified based on tag sequences, and the clusters were moved to the beginning of the clause, and reordered so thatthe finite verb ended up in the second clause posi tion.</S>
			<S sid="66" ssid="19">Also, some common adverbs were moved withthe verb cluster and placed between finite and non finite verbs.</S>
			<S sid="67" ssid="20">After testing, we decided to apply theserules only to subordinate clauses at the end of sen tences, since these were the only ones that could be identified with good precision.</S>
			<S sid="68" ssid="21">Still, some 750,000 clauses were reordered.</S>
			<S sid="69" ssid="22">3.3 OOV Processing.</S>
			<S sid="70" ssid="23">We also added limited processing of OOVs.</S>
			<S sid="71" ssid="24">In a pre processing step we replaced unknown words with known cased variants if available, removed markupfrom normalized words if that resulted in an un 395 known token, and split hyphened words.</S>
			<S sid="72" ssid="25">We alsosplit suspected names in cases where we had a pat tern with a single upper-case letter in the middle of a word, such as ConocoPhillips into Conoco Phillips.</S>
			<S sid="73" ssid="26">In a post-processing step we changed the numberformatting of unknown numbers by changing dec imal points and thousand separators, to agree with English orthography.</S>
			<S sid="74" ssid="27">This processing only affects a small number of words, and cannot be expected to make a large impact on the final results.</S>
			<S sid="75" ssid="28">Out of 884 OOVs in the devtest, 39 had known cased options, 126 hyphened words were split, 147 cases had markup from the normalization removed, and 13 suspected names were split.</S>
			<S sid="76" ssid="29">3.4 Results.</S>
			<S sid="77" ssid="30">The results of these experiments can be seen in Table 1 where each new addition is added to the previous system.</S>
			<S sid="78" ssid="31">When we compare the new additions with the baseline with hierarchical reordering, we see thatwhile the normalization did not seem to have a posi tive effect on any metric, both source reordering and OOV processing led to small increases on all scores.</S>
	</SECTION>
	<SECTION title="English?German. " number="4">
			<S sid="79" ssid="1">For translation from English into German we at tempted to improve the quality of the phrase table by adding new word alignments to the standard Giza++ alignments.</S>
			<S sid="80" ssid="2">4.1 Phrase-based word alignment.</S>
			<S sid="81" ssid="3">We experimented with different ways of combining word alignments from Giza++ with align ments created using phrase-based word alignment (PAL) which previously has been shown to improve alignment quality for English?Swedish (Holmqvist, 2010).</S>
			<S sid="82" ssid="4">The idea of phrase-based word alignment is to use word and part-of-speech sequence patterns from manual word alignments to align new texts.</S>
			<S sid="83" ssid="5">First, parallel phrases containing a source segment, a target segment and links between source and target words are extracted from word aligned texts (Figure 1).</S>
			<S sid="84" ssid="6">In the second step, these phrases are matched against new parallel text and if a matching phrase is found, word links from the phrase are added to the corresponding words in the new text.</S>
			<S sid="85" ssid="7">In orderto increase the number of matching phrases and im prove word alignment recall, words in the parallel En: a typical example De: ein typisches Beispiel Links: 0-0 1-1 2-2 En: a JJ example De: ein ADJA Beispiel Links: 0-0 1-1 2-2 En: DT JJ NN De: ART ADJA N Links: 0-0 1-1 2-2 Figure 1: Examples of parallel phrases used in word alignment.</S>
			<S sid="86" ssid="8">BLEU NIST Meteor Baseline 16.16 6.2742 50.89 +hier reo 16.06 6.2800 51.25 +pal-gdfa 16.14 5.6527 51.10 +pal-dual 15.71 5.5735 50.43 +pal-inter 15.92 5.6230 50.73 Table 2: English?German translation results, resultsare cumulative except for the three alternative PAL configurations.</S>
			<S sid="87" ssid="9">segments were replaced by POS/morphological tags from RFTagger.Alignment patterns were extracted from 1000 sen tences in the manually word aligned sample ofEnglish?German Europarl texts from Pado and Lap ata (2006).</S>
			<S sid="88" ssid="10">All parallel phrases were extracted fromthe word aligned texts, as when extracting a trans lation model.</S>
			<S sid="89" ssid="11">Parallel phrases that contain at least 3 words were generalized with POS tags to form word/POS patterns for alignment.</S>
			<S sid="90" ssid="12">A subset of these patterns, with high alignment precision (&gt; 0.80) on the 1000 sentences, were used to align the entire training corpus.</S>
			<S sid="91" ssid="13">We combined the new word alignments with the Giza++ alignments in two ways.</S>
			<S sid="92" ssid="14">In the first method, we used a symmetrization heuristic similarto grow-diag-final-and to combine three word align ments into one, the phrase-based alignment and two Giza++ alignments in different directions.</S>
			<S sid="93" ssid="15">In thesecond method we extracted a separate phrase ta ble from the sparser phrase-based alignment usinga constrained method of phrase extraction that lim ited the number of unaligned words in each phrase pair.</S>
			<S sid="94" ssid="16">The reason for constraining the phrase table 396 extraction was that the standard extraction method does not work well for the sparse word alignments that PAL produces, but we think it could still be useful for extracting highly reliable phrases.</S>
			<S sid="95" ssid="17">Aftersome experimentation we decided to allow an unlimited number of internal unaligned words, that is un aligned words that are surrounded by aligned words, but limit the number of external unaligned words, i.e., unaligned words at the beginning or end of the phrase, to either one each in the source and target phrase, or to zero.We used two ways to include the sparse phrase table into the translation process:?</S>
			<S sid="96" ssid="18">Have two separate phrase-tables, the sparse table, and the standard GIZA++ based phrase table, and use Moses?</S>
			<S sid="97" ssid="19">dual decoding paths.</S>
			<S sid="98" ssid="20">Interpolate the sparse phrase-table with the standard phrase-table, using the mixture model formulation of Ueffing et al (2007), with equal weights, in order to boost the probabilities of highly reliable phrases.</S>
			<S sid="99" ssid="21">4.2 Results.</S>
			<S sid="100" ssid="22">We evaluated our systems on devtest data and foundthat the added phrase-based alignments did not produce large differences in translation quality compared to the baseline system with hierarchical re ordering as shown in Table 2.</S>
			<S sid="101" ssid="23">The system created with a heuristic combination of PAL and Giza++(pal-gdfa) had a small increase in BLEU, but no im provement on the other metrics.</S>
			<S sid="102" ssid="24">Systems using a phrase table extracted from the sparse alignmentsdid not produce better results than baseline.</S>
			<S sid="103" ssid="25">The sys tem using dual decoding paths (pal-dual) produced worse results than the system using an interpolated phrase table (pal-inter).</S>
	</SECTION>
	<SECTION title="Submitted systems. " number="5">
			<S sid="104" ssid="1">The LIU system participated in German?English and English?German translation in the WMT 2011shared task.</S>
			<S sid="105" ssid="2">The new additions were a combination of unsupervised and supervised word align ments, spelling normalization, clause reordering and OOV processing.</S>
			<S sid="106" ssid="3">Our submitted systems containall additions described in this paper.</S>
			<S sid="107" ssid="4">For English German we used the best performing method of BLEU System Devtest Test en-de baseline +hier 16.1 14.5 submitted 16.1 14.8 de-en baseline +hier 20.9 19.3 submitted 21.2 19.9 Table 3: Summary of devtest results and shared task testresults for submitted systems and LIU baseline with hier archical reordering.</S>
			<S sid="108" ssid="5">word alignment combination which was the methodthat uses heuristic combination similar to grow-diag final-and.</S>
			<S sid="109" ssid="6">The results of our submitted systems are shownin Table 3 where we compare them to the LIU base line system with hierarchical reordering models.</S>
			<S sid="110" ssid="7">We report modest improvements on the devtest set forboth translation directions.</S>
			<S sid="111" ssid="8">We also found small im provements of our submitted systems in the official shared task evaluation on the test set newstest2011.</S>
	</SECTION>
</PAPER>
