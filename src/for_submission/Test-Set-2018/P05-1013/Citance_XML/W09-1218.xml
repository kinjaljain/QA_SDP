<PAPER>
  <S sid="0">Multilingual Syntactic-Semantic Dependency Parsing with Three-Stage Approximate Max-Margin Linear Models</S>
  <ABSTRACT>
    <S sid="1" ssid="1">This paper describes a system for syntacticsemantic dependency parsing for multiple languages.</S>
    <S sid="2" ssid="2">The system consists of three parts: a state-of-the-art higher-order projective dependency parser for syntactic dependency parsing, a predicate classifier, and an argument classifier for semantic dependency parsing.</S>
    <S sid="3" ssid="3">For semantic dependency parsing, we explore use of global features.</S>
    <S sid="4" ssid="4">All components are trained with an approximate max-margin learning algorithm.</S>
    <S sid="5" ssid="5">In the closed challenge of the CoNLL-2009 Shared Task (Haji&#711;c et al., 2009), our system achieved the 3rd best performances for English and Czech, and the 4th best performance for Japanese.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="6" ssid="1">In recent years, joint inference of syntactic and semantic dependencies has attracted attention in NLP communities.</S>
    <S sid="7" ssid="2">Ideally, we would like to choose the most plausible syntactic-semantic structure among all possible structures in that syntactic dependencies and semantic dependencies are correlated.</S>
    <S sid="8" ssid="3">However, solving this problem is too difficult because the search space of the problem is extremely large.</S>
    <S sid="9" ssid="4">Therefore we focus on improving performance for each subproblem: dependency parsing and semantic role labeling.</S>
    <S sid="10" ssid="5">In the past few years, research investigating higher-order dependency parsing algorithms has found its superiority to first-order parsing algorithms.</S>
    <S sid="11" ssid="6">To reap the benefits of these advances, we use a higher-order projective dependency parsing algorithm (Carreras, 2007) which is an extension of the span-based parsing algorithm (Eisner, 1996), for syntactic dependency parsing.</S>
    <S sid="12" ssid="7">In terms of semantic role labeling, we would like to capture global information about predicateargument structures in order to accurately predict the correct predicate-argument structure.</S>
    <S sid="13" ssid="8">Previous research dealt with such information using re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008).</S>
    <S sid="14" ssid="9">We explore a different approach to deal with such information using global features.</S>
    <S sid="15" ssid="10">Use of global features for structured prediction problem has been explored by several NLP applications such as sequential labeling (Finkel et al., 2005; Krishnan and Manning, 2006; Kazama and Torisawa, 2007) and dependency parsing (Nakagawa, 2007) with a great deal of success.</S>
    <S sid="16" ssid="11">We attempt to use global features for argument classification in which the most plausible semantic role assignment is selected using both local and global information.</S>
    <S sid="17" ssid="12">We present an approximate max-margin learning algorithm for argument classifiers with global features.</S>
  </SECTION>
  <SECTION title="2 Dependency Parsing" number="2">
    <S sid="18" ssid="1">As in previous work, we use a linear model for dependency parsing.</S>
    <S sid="19" ssid="2">The score function used in our dependency parser is defined as follows. where h and m denote the head and the dependent of the dependency edge in y, and F(h, m, x) is a Factor that specifies dependency edge scores.</S>
    <S sid="20" ssid="3">We used a second-order factorization as in (Carreras, 2007).</S>
    <S sid="21" ssid="4">The second-order factor F is defined as follows. where w is a parameter vector, &#934; is a feature vector, ch is the child of h in the span [h...m] that is closest to m, cmz is the child of m in the span [h...m] that is farthest from m and cmo is the child of m outside the span [h...m] that is farthest from m. For more details of the second-order parsing algorithm, see (Carreras, 2007).</S>
    <S sid="22" ssid="5">For parser training, we use the Passive Aggressive Algorithm (Crammer et al., 2006), which is an approximate max-margin variant of the perceptron algorithm.</S>
    <S sid="23" ssid="6">Also, we apply an efficient parameter averaging technique (Daum&#180;e III, 2006).</S>
    <S sid="24" ssid="7">The resulting learning algorithm is shown in Algorithm 1.</S>
    <S sid="25" ssid="8">Algorithm 1 A Passive Aggressive Algorithm with parameter averaging return w &#8722; v/c We set p(yt, &#710;y) as the number of incorrect head predictions in the &#710;y, and C as 1.0.</S>
    <S sid="26" ssid="9">Among the 7 languages of the task, 4 languages (Czech, English, German and Japanese) contain non-projective edges (13.94 %, 3.74 %, 25.79 % and 0.91 % respectively), therefore we need to deal with non-projectivity.</S>
    <S sid="27" ssid="10">In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005).</S>
    <S sid="28" ssid="11">However, growth of the number of dependency labels by pseudo-projective transformation increases the dependency parser training time, so we did not adopt transformations.</S>
    <S sid="29" ssid="12">Therefore, the parser ignores the presence of non-projective edges in the training and the testing phases.</S>
    <S sid="30" ssid="13">The features used for our dependency parser are based on those listed in (Johansson, 2008).</S>
    <S sid="31" ssid="14">In addition, distance features are used.</S>
    <S sid="32" ssid="15">We use shorthand notations in order to simplify the feature representations: &#8217;h&#8217;, &#8217;d&#8217;, &#8217;c&#8217;, &#8217;l&#8217;, &#8217;p&#8217;, &#8217;&#8722;1&#8217; and &#8217;+1&#8217; correspond to head, dependent, head&#8217;s or dependent&#8217;s child, lemma, POS, left position and right position respectively.</S>
  </SECTION>
  <SECTION title="First-order Features" number="3">
    <S sid="33" ssid="1">Head-Dependent-Head&#8217;s or Dependent&#8217;s Child: hl+cl, hl+cl+cp, hp+cl, hp+cp, hp+dp+cp, dp+cp, dp+cl+cp, dl+cp, dl+cp+cl</S>
  </SECTION>
  <SECTION title="3 Semantic Role Labeling" number="4">
    <S sid="34" ssid="1">Our SRL module consists of two parts: a predicate classifier and an argument classifier.</S>
    <S sid="35" ssid="2">First, our system determines the word sense for each predicate with the predicate classifier, and then it detects the highest scored argument assignment using the argument classifier with global features.</S>
    <S sid="36" ssid="3">The first phase of SRL in our system is to detect the word sense for each predicate.</S>
    <S sid="37" ssid="4">WSD can be formalized as a multi-class classification problem given lemmas.</S>
    <S sid="38" ssid="5">We created a linear model for each lemma and used the Passive Aggressive Algorithm with parameter averaging to train the models.</S>
  </SECTION>
  <SECTION title="3.1.1 Features for Predicate Classification" number="5">
    <S sid="39" ssid="1">Word features: Predicted lemma and the predicted POS of the predicate, predicate&#8217;s head, and its conjunctions.</S>
    <S sid="40" ssid="2">Dependency label: The dependency label between the predicate and the predicate&#8217;s head. in Algorithm 2.</S>
    <S sid="41" ssid="3">In this algorithm, the weights correspond to local factor features &#934;L and global factor features &#934;G are updated simultaneously.</S>
    <S sid="42" ssid="4">Dependency label sequence: The concatenation of the dependency labels of the predicate dependents.</S>
    <S sid="43" ssid="5">Since effective features for predicate classification are different for each language, we performed greedy forward feature selection.</S>
    <S sid="44" ssid="6">Algorithm 2 Learning with Global Features for Argument Classification In order to capture global clues of predicateargument structures, we consider introducing global features for linear models.</S>
    <S sid="45" ssid="7">Let A(p) be a joint assignment of role labels for argument candidates given the predicate p. Then we define a score function s(A(p)) for argument label assignments A(p).</S>
    <S sid="46" ssid="8">We introduce two factors: Local Factor FL and Global Factor FG defined as follows. where &#934;L, &#934;G denote feature vectors for the local factor and the global factor respectively.</S>
    <S sid="47" ssid="9">FL scores a particular role assignment for each argument candidate individually, and FG treats global features that capture what structure the assignment A has.</S>
    <S sid="48" ssid="10">Resulting scoring function for the assignment A(p) is as follows.</S>
    <S sid="49" ssid="11">Use of global features is problematic, because it becomes difficult to find the highest assignment efficiently.</S>
    <S sid="50" ssid="12">In order to deal with the problem, we use a simple approach, n-best relaxation as in (Kazama and Torisawa, 2007).</S>
    <S sid="51" ssid="13">At first we generate n-best assignments using only the local factor, and then add the global factor score for each n-best assignment, finally select the best scoring assignment from them.</S>
    <S sid="52" ssid="14">In order to generate n-best assignments, we used a beam-search algorithm.</S>
    <S sid="53" ssid="15">As in dependency parser and predicate classifier, we train the model using the PA algorithm with parameter averaging.</S>
    <S sid="54" ssid="16">The learning algorithm is shown We set the margin value &#961;(A, &#710;A) as the number of incorrect assignments plus S(A, &#710;A), and C as 1.0.</S>
    <S sid="55" ssid="17">The delta function returns 1 if at least one assignment is different from the correct assignment and 0 otherwise.</S>
    <S sid="56" ssid="18">The model is similar to re-ranking (Toutanova et al., 2005; Johansson and Nugues, 2008).</S>
    <S sid="57" ssid="19">However in contrast to re-ranking, we only have to prepare one model.</S>
    <S sid="58" ssid="20">The re-ranking approach requires other training datasets that are different from the data used in local model training.</S>
  </SECTION>
  <SECTION title="3.2.2 Features for Argument Classification" number="6">
    <S sid="59" ssid="1">The local features used in our system are the same as our previous work (Watanabe et al., 2008) except for language dependent features.</S>
    <S sid="60" ssid="2">The global features that used in our system are based on (Johansson and Nugues, 2008) that used for re-ranking.</S>
  </SECTION>
  <SECTION title="Local Features" number="7">
    <S sid="61" ssid="1">Distance: The number of dependency edges between the predicate and the argument candidate.</S>
    <S sid="62" ssid="2">Predicate-argument label sequence: The sequence of the predicate sense and argument labels in the predicate-argument strucuture.</S>
    <S sid="63" ssid="3">Presence of labels defined in frame files: Whether the semantic roles defined in the frame present in the predicate-argument structure (e.g.</S>
    <S sid="64" ssid="4">MISSING:A1 or CONTAINS:A1.)</S>
    <S sid="65" ssid="5">We observe that most arguments tend to be not far from its predicate, so we can prune argument candidates to reduce search space.</S>
    <S sid="66" ssid="6">Since the characteristics of the languages are slightly different, we apply two types of pruning algorithms.</S>
    <S sid="67" ssid="7">Pruning Algorithm 1: Let S be an argument candidate set.</S>
    <S sid="68" ssid="8">Initially set S &#8592; &#981; and start at predicate node.</S>
    <S sid="69" ssid="9">Add dependents of the node to S, and move current node to its parent.</S>
    <S sid="70" ssid="10">Repeat until current node reaches to ROOT.</S>
    <S sid="71" ssid="11">Pruning Algorithm 2: Same as the Algorithm 1 except that added nodes are its grandchildren as well as its dependents.</S>
    <S sid="72" ssid="12">The pruning results are shown in Table 2.</S>
    <S sid="73" ssid="13">Since we could not prune arguments in Japanese accurately using the two algorithms, we pruned argument candidates simply by POS.</S>
  </SECTION>
  <SECTION title="4 Results" number="8">
    <S sid="74" ssid="1">The submitted results on the test data are shown in the upper part of Table 1.</S>
    <S sid="75" ssid="2">Due to a bug, we mistakenly used the gold lemmas in the dependency parser.</S>
    <S sid="76" ssid="3">Corrected results are shown in the part marked with *.</S>
    <S sid="77" ssid="4">The lower part shows the post evaluation results with the gold lemmas and POSs.</S>
    <S sid="78" ssid="5">For some of the 7 languages, since the global model described in Section 3.2 degraded performance compare to a model trained with only FL, we did NOT use the model for all languages.</S>
    <S sid="79" ssid="6">We used the global model for only three languages: Chinese, English and Japanese.</S>
    <S sid="80" ssid="7">The remaining languages (Catalan, Czech, German and Spanish) used a model trained with only FL.</S>
    <S sid="81" ssid="8">The parser achieved relatively high accuracies for Czech, English and Japanese, and for each language, the difference between the performance with correct POS and predicted POS is not so large.</S>
    <S sid="82" ssid="9">However, in Catalan, Chinese German and Spanish, the parsing accuracies was seriously degraded by replacing correct POSs with predicted POSs (6.3 - 11.2 %).</S>
    <S sid="83" ssid="10">This is likely because these languages have relatively low predicted POS accuracies (92.3 - 95.5 %) ; Chinese has especially low accuracy (92.3%).</S>
    <S sid="84" ssid="11">The POS accuracy may affect the parsing performances.</S>
    <S sid="85" ssid="12">In order to highlight the effect of the global features, we compared two models.</S>
    <S sid="86" ssid="13">The first model is trained with only the local factor FL.</S>
    <S sid="87" ssid="14">The second model is trained with both the local factor FL and the global factor FG.</S>
    <S sid="88" ssid="15">The results are shown in Table 3.</S>
    <S sid="89" ssid="16">In the experiments, we used the development data with gold parse trees.</S>
    <S sid="90" ssid="17">For Chinese and Japanese, significant improvements are obtained using the global features (over +1.0% in labeled recall and the slightly better labeled precision).</S>
    <S sid="91" ssid="18">However, for Catalan, Czech, German and Spanish, the global features degraded the performance in labeled F1.</S>
    <S sid="92" ssid="19">Especially, in German, the precision is substantially degraded (-7.27% in labeled F1).</S>
    <S sid="93" ssid="20">These results indicate that it is necessary to introduce language dependent features.</S>
    <S sid="94" ssid="21">Table 4 and 5 shows the training/evaluation times and the memory consumption of the second-order dependency parsers and the global argument classifiers respectively.</S>
    <S sid="95" ssid="22">The training times of the predicate classifier were less than one day, and the testing times were mere seconds.</S>
    <S sid="96" ssid="23">As reported in (Carreras, 2007; Johansson and Nugues, 2008), training and inference of the secondorder parser are very expensive.</S>
    <S sid="97" ssid="24">For Chinese, we could only complete 2 iterations.</S>
    <S sid="98" ssid="25">In terms of the argument classifier, since N-best generation time account for a substantial proportion of the training time (in this work N = 100), changing N affects the training and evaluation times significantly.</S>
    <S sid="99" ssid="26">All modules of our system are implemented in Java.</S>
    <S sid="100" ssid="27">The required memory spaces shown in Table 4 and 5 are calculated by subtracting free memory size from the total memory size of the Java VM.</S>
    <S sid="101" ssid="28">Note that we observed that the value fluctuated drastically while measuring memory usage, so the value may not indicate precise memory requirements of our system.</S>
  </SECTION>
  <SECTION title="5 Conclusion" number="9">
    <S sid="102" ssid="1">In this paper, we have described our system for syntactic and semantic dependency analysis in multilingual.</S>
    <S sid="103" ssid="2">Although our system is not a joint approach but a pipeline approach, the system is comparable to the top system for some of the 7 languages.</S>
    <S sid="104" ssid="3">A further research direction we are investigating is the application of various types of global features.</S>
    <S sid="105" ssid="4">We believe that there is still room for improvements since we used only two types of global features for the argument classifier.</S>
    <S sid="106" ssid="5">Another research direction is investigating joint approaches.</S>
    <S sid="107" ssid="6">To the best of our knowledge, three types of joint approaches have been proposed: N-best based approach (Johansson and Nugues, 2008), synchronous joint approach (Henderson et al., 2008), and a joint approach where parsing and SRL are performed simultaneously (Llu&#180;&#305;s and M`arquez, 2008).</S>
    <S sid="108" ssid="7">We attempted to perform Nbest based joint approach, however, the expensive computational cost of the 2nd-order projective parser discouraged it.</S>
    <S sid="109" ssid="8">We would like to investigate syntactic-semantic joint approaches with reasonable time complexities.</S>
  </SECTION>
  <SECTION title="Acknowledgments" number="10">
    <S sid="110" ssid="1">We would like to thank Richard Johansson for his advice on parser implementation, and the CoNLL2009 organizers (Haji&#711;c et al., 2009; Taul&#180;e et al., 2008; Palmer and Xue, 2009; Haji&#711;c et al., 2006; Surdeanu et al., 2008; Burchardt et al., 2006; Kawahara et al., 2002; Taul&#180;e et al., 2008).</S>
  </SECTION>
</PAPER>
