The paper “Improved Word-Level System Combination for Machine Translation” by Antti-Veikko I. Rosti and Spyros Matsoukas and Richard Schwartz describes an improved confusion network based method to combine outputs from multiple MT systems. In this approach, arbitrary features may be added log-linearly into the objective function, thus allowing language model expansion and  re-scoring.Confusion network decoding in MT  picks one hypothesis as the skeleton which determines the word order of the combination. The other hypotheses are aligned against the skeleton. Either votes or some form of confidences are assigned to each word in the network.An improved confusion network decoding method combining the word posteriors with arbitrary features was presented. This allows the addition of language model scores by expanding the lattices or re-scoring N-best lists.The new method improves the BLEU scores significantly. The combination weights were tuned to optimize three automatic evaluation metrics: TER,BLEU and METEOR. The TER tuning seems to yield very good results on Arabic - the BLEU tuning seems to be better on Chinese. It also seems like METEOR should not be used in tuning due to high insertion rate and low precision. 