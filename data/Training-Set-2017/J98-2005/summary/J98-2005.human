This paper talks about estimated production probabilities of a context-free grammar that always yield proper distributions.they picked Context-free grammar because it is useful because of its relatively broad coverage
and because of the availability of efficient parsing algorithms.there is a simple maximum-likelihood prescription for estimating the production probabilities
from a corpus of trees that results in a PCFG.The maximum-likelihood estimator is the natural, "relative frequency," estimator.for them this is the best estimator to simplify the treatment by assuming that there are no null or unit productions.The iterative approach for unparsed corpus is an instance of the EM Algorithm.EM stands for Expectation-Maximization.they showed that in both cases when the corpus was unparsed and when the corpus was parsed,the estimated probability for both was tight(by tight they meant equality of total probability mass to one).