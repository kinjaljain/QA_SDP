Parallel texts (bitexts) have properties that distinguish them from other kinds of parallel data.
First, most words translate to only one other word.
Second, bitext correspondence is typically only partial - many words in each text have no clear equivalent in the other text.
This article presents methods for biasing statistical translation models to reflect these properties.
Evaluation with respect to independent human judgments has confirmed that translation models biased in this fashion are significantly more accurate than a baseline knowledge-free model.
This article also shows how a statistical translation model can take advantage of preexisting knowledge that might be available about particular language pairs.
Even the simplest kinds of language-specific knowledge, such as the distinction between content words and function words, are shown to reliably boost translation model performance on some tasks.
Statistical models that reflect knowledge about the model domain combine the best of both the rationalist and empiricist paradigms.