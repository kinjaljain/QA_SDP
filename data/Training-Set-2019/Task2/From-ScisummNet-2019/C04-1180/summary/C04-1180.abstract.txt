This paper shows how to construct semantic representations from the derivations produced by a wide-coverage CCG parser.
Unlike the dependency structures returned by the parser itself, these can be used directly for semantic interpretation.
We demonstrate that well-formed semantic representations can be produced for over 97% of the sentences in unseen WSJ text.
We believe this is a major step towards wide-coverage semantic interpretation, one of the key objectives of the field of NLP.
