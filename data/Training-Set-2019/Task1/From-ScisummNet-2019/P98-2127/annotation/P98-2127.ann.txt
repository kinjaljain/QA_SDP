Citance Number: 1 | Reference Article:  P98-2127.txt | Citing Article:  P99-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['39','108'] | Reference Text:  <S sid = 39 ssid = >For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.</S><S sid = 108 ssid = >This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P98-2127.txt | Citing Article:  P06-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Amongst the many proposals for distributional similarity measures, (Lin, 1998) is maybe the most widely used one, while (Weeds et al, 2004) provides a typical example for recent research.</S> | Reference Offset:  ['32','66'] | Reference Text:  <S sid = 32 ssid = >The similarity measure can then be used to create a thesaurus.</S><S sid = 66 ssid = >The measures simeosine, simdice and SiMJacard are versions of similarity measures commonly used in information retrieval (Frakes and Baeza-Yates, 1992).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P98-2127.txt | Citing Article:  P06-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This scheme utilizes the symmetric similarity measure of (Lin, 1998) to induce improved feature weights via bootstrapping.</S> | Reference Offset:  ['70','73'] | Reference Text:  <S sid = 70 ssid = >The similarity measure simwN is based on the proposal in (Lin, 1997).</S><S sid = 73 ssid = >The similarity between two words is then defined as the cosine coefficient of the two feature vectors.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P98-2127.txt | Citing Article:  N06-3007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We will take advantage of the flexibility provided by our framework and use syntax based measure of similarity in the computation of the verb vectors, following (Lin, 1998).</S> | Reference Offset:  ['2','70'] | Reference Text:  <S sid = 2 ssid = >We first define a word similarity measure based on the distributional pattern of words.</S><S sid = 70 ssid = >The similarity measure simwN is based on the proposal in (Lin, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P98-2127.txt | Citing Article:  C08-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chantree et al (2005) applied the distributional similarity proposed by Lin (1998) to coordination disambiguation.</S> | Reference Offset:  ['29','101'] | Reference Text:  <S sid = 29 ssid = >It was shown in (Dagan et al., 1997) that a similarity-based smoothing method achieved much better results than backoff smoothing methods in word sense disambiguation.</S><S sid = 101 ssid = >In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P98-2127.txt | Citing Article:  D09-1084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Accurate measurement of semantic similarity between lexical units such as words or phrases is important for numerous tasks in natural language processing such as word sense disambiguation (Resnik, 1995), synonym extraction (Lin, 1998a), and automatic thesauri generation (Curran, 2002).</S> | Reference Offset:  ['1','27'] | Reference Text:  <S sid = 1 ssid = >Bootstrapping semantics from text is one of the greatest challenges in natural language learning.</S><S sid = 27 ssid = >Another application of automatically extracted similar words is to help solve the problem of data sparseness in statistical natural language processing (Dagan et al., 1994; Essen and Steinbiss, 1992).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P98-2127.txt | Citing Article:  D09-1084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['39','108'] | Reference Text:  <S sid = 39 ssid = >For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.</S><S sid = 108 ssid = >This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P98-2127.txt | Citing Article:  D09-1084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['39','108'] | Reference Text:  <S sid = 39 ssid = >For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.</S><S sid = 108 ssid = >This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P98-2127.txt | Citing Article:  W03-0418.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Lin (1998) created a thesaurus using syntactic relationships with other words.</S> | Reference Offset:  ['65','106'] | Reference Text:  <S sid = 65 ssid = >The measure simHindiâ€ž is the same as sim H indle except that all types of dependency relationships are used, instead of just subject and object relationships.</S><S sid = 106 ssid = >The results show that our automatically created thesaurus is significantly closer to WordNet than Roget Thesaurus is.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P98-2127.txt | Citing Article:  W08-2211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Like McCarthy et al (2004) we use k= 50 and obtain our thesaurus using the distributional similarity metric described by Lin (1998).</S> | Reference Offset:  ['3','101'] | Reference Text:  <S sid = 3 ssid = >The similarity measure allows us to construct a thesaurus using a parsed corpus.</S><S sid = 101 ssid = >In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P98-2127.txt | Citing Article:  W08-2211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The thesaurus was acquired using the method described by Lin (1998).</S> | Reference Offset:  ['3','14'] | Reference Text:  <S sid = 3 ssid = >The similarity measure allows us to construct a thesaurus using a parsed corpus.</S><S sid = 14 ssid = >This paper presents a method for making this first step.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P98-2127.txt | Citing Article:  W08-2211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For every pair of nouns, where each noun had a total frequency in the triple data of 10 or more, we computed their distributional similarity using the measure given by Lin (1998).</S> | Reference Offset:  ['2','56'] | Reference Text:  <S sid = 2 ssid = >We first define a word similarity measure based on the distributional pattern of words.</S><S sid = 56 ssid = >We computed the pairwise similarity between all the nouns, all the verbs and all the adjectives/adverbs, using the above similarity measure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P98-2127.txt | Citing Article:  P13-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['39','108'] | Reference Text:  <S sid = 39 ssid = >For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.</S><S sid = 108 ssid = >This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P98-2127.txt | Citing Article:  P13-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in (Lin, 1998) or (Cur ran and Moens, 2002a), this building is based on the definition of a semantic similarity measure from a corpus.</S> | Reference Offset:  ['2','70'] | Reference Text:  <S sid = 2 ssid = >We first define a word similarity measure based on the distributional pattern of words.</S><S sid = 70 ssid = >The similarity measure simwN is based on the proposal in (Lin, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P98-2127.txt | Citing Article:  P13-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This seems to be a reasonable compromise between the approach of (Freitag et al, 2005), in which none normalization of words is done, and the more widespread use of syntactic parsers in work such as (Lin, 1998).</S> | Reference Offset:  ['34','101'] | Reference Text:  <S sid = 34 ssid = >Section 4 briefly discuss future work in clustering similar words.</S><S sid = 101 ssid = >In (Dagan et al., 1993) and (Pereira et al., 1993), clusters of similar words are evaluated by how well they are able to recover data items that are removed from the input corpus one at a time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P98-2127.txt | Citing Article:  P13-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, the results of Table 2 are compatible with those of (Lin, 1998) for instance (R-prec. = 11.6 and MAP = 8.1 with WM as reference for all entries of the thesaurus at http://webdocs.cs.ualberta.ca/lindek/Downloads/sim.tgz) if we take into account the fact that the thesaurus of Lin was built from a much larger corpus and with syntactic co-occurrences.</S> | Reference Offset:  ['5','76'] | Reference Text:  <S sid = 5 ssid = >The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is.</S><S sid = 76 ssid = >Suppose two thesaurus entries for the same word are as follows: For example, (5) is the entry for &quot;brief (noun)&quot; in our automatically generated thesaurus and (6) and (7) are corresponding entries in WordNet thesaurus and Roget thesaurus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P98-2127.txt | Citing Article:  W09-1123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, one of the 8 senses of company in WordNet is a visitor/visitant, which is a hyponym of person (Lin, 1998).</S> | Reference Offset:  ['21','89'] | Reference Text:  <S sid = 21 ssid = >For example, one of the 8 senses of &quot;company&quot; in WordNet 1.5 is a &quot;visitor/visitant&quot;, which is a hyponym of &quot;person&quot;.</S><S sid = 89 ssid = >For example, one can go a step further by constructing a tree structure among the most similar words so that different senses of a given word can be identified with different subtrees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P98-2127.txt | Citing Article:  D07-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, Lin (1998) used dependency relation as word features to compute word similarities from large corpora, and compared the thesaurus created in such a way with WordNet and Roget classes.</S> | Reference Offset:  ['97','106'] | Reference Text:  <S sid = 97 ssid = >Ours is similar to (Grefenstette, 1994; Hindle, 1990; Ruge, 1992) in the use of dependency relationship as the word features, based on which word similarities are computed.</S><S sid = 106 ssid = >The results show that our automatically created thesaurus is significantly closer to WordNet than Roget Thesaurus is.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P98-2127.txt | Citing Article:  P11-1148.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One of the most important approaches is Lin (1998).</S> | Reference Offset:  ['12','96'] | Reference Text:  <S sid = 12 ssid = >It has been argued that similarity plays an important role in word acquisition (Gentner, 1982).</S><S sid = 96 ssid = >There have been many approaches to automatic detection of similar words from text corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P98-2127.txt | Citing Article:  H05-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['39','108'] | Reference Text:  <S sid = 39 ssid = >For example, the triples extracted from the sentence &quot;I have a brown dog&quot; are: We use the notation 11w, r, w' II to denote the frequency count of the dependency triple (w, r, w') in the parsed corpus.</S><S sid = 108 ssid = >This research has also been partially supported by NSERC Research Grant 0GP121338 and by the Institute for Robotics and Intelligent Systems.</S> | Discourse Facet:  NA | Annotator: Automatic


