Citance Number: 1 | Reference Article:  A00-2009.txt | Citing Article:  N01-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have presented an ensemble approach to word sense disambiguation (Pedersen, 2000) where multiple Naive Bayesian classiers, each based on co-occurrence features from varying sized windows of context, is shown to perform well on the widely studied nouns interest and line.</S> | Reference Offset:  ['1','151'] | Reference Text:  <S sid = 1 ssid = >This paper presents a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co—occurring words in varying sized windows of context.</S><S sid = 151 ssid = >A methodology for formulating an ensemble of Naive Bayesian classifiers is presented, where each member classifier is based on co—occurrence features extracted from a different sized window of context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  A00-2009.txt | Citing Article:  P14-2087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pedersen (2000) proposed an ensemble model with multiple NB classifiers differing by context window size.</S> | Reference Offset:  ['13','67'] | Reference Text:  <S sid = 13 ssid = >It has also been shown that the combined accuracy of an ensemble of multiple classifiers is often significantly greater than that of any of the individual classifiers that make up the ensemble (e.g., (Dietterich, 1997)).</S><S sid = 67 ssid = >The size and range of the left window of context is indicated along the horizontal margin in Tables 3 and 4 while the right window size and range is shown along the vertical margin.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  A00-2009.txt | Citing Article:  C04-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is similar to the ordinary Naive Bayes model for WSD (Pedersen, 2000).</S> | Reference Offset:  ['78','156'] | Reference Text:  <S sid = 78 ssid = >Similar differences in training and testing methodology exist among the other studies.</S><S sid = 156 ssid = >A preliminary version of this paper appears in (Pedersen, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  A00-2009.txt | Citing Article:  W02-0812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The origins of Duluth can be found in an ensemble approach based on multiple Naive Bayesian classifiers that perform disambiguation via a majority vote (Pedersen, 2000).</S> | Reference Offset:  ['6','135'] | Reference Text:  <S sid = 6 ssid = >This paper presents a corpus—based approach that results in high accuracy by combining a number of very simple classifiers into an ensemble that performs disambiguation via a majority vote.</S><S sid = 135 ssid = >In this paper ensemble disambiguation is based on a simple majority vote of the nine member classifiers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  A00-2009.txt | Citing Article:  W04-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The approach used, called combination approach, has known lots of success in speech recognition (Fiscus 1997, Schwenck and Gauvain 2000), part of speech tagging (Halteren and al. 1998, Brill and al. 1998, Marquez et Padro 1998), named entity recognition (Borthwick and al. 1998), word sense disambiguation (Pedersen, 2000) and recently in parsing (Henderson and Brill 1999), Inui and Inui 2000, Monceaux and Robba 2003).</S> | Reference Offset:  ['14','102'] | Reference Text:  <S sid = 14 ssid = >In natural language processing, ensemble techniques have been successfully applied to part— of—speech tagging (e.g., (Brill and Wu, 1998)) and parsing (e.g., (Henderson and Brill, 1999)).</S><S sid = 102 ssid = >The line data was recently revisited by both (Towell and Voorhees, 1998) and (Leacock et al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  A00-2009.txt | Citing Article:  N03-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994).</S> | Reference Offset:  ['14','133'] | Reference Text:  <S sid = 14 ssid = >In natural language processing, ensemble techniques have been successfully applied to part— of—speech tagging (e.g., (Brill and Wu, 1998)) and parsing (e.g., (Henderson and Brill, 1999)).</S><S sid = 133 ssid = >This is discussed in the context of combining part—of—speech taggers in (Brill and Wu, 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  A00-2009.txt | Citing Article:  P02-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They include those using Naive Bayes (Gale et al. 1992a), Decision List (Yarowsky 1994), Nearest Neighbor (Ng and Lee 1996), Transformation Based Learning (Mangu and Brill 1997), Neural Network (Towell and Voorhess 1998), Winnow (Golding and Roth 1999), Boosting (Escudero et al 2000), and Naive Bayesian Ensemble (Pedersen 2000).</S> | Reference Offset:  ['49','53'] | Reference Text:  <S sid = 49 ssid = >This data has since been used in studies by (Mooney, 1996), (Towell and Voorhees, 1998), and (Leacock et al., 1998).</S><S sid = 53 ssid = >This data set was subsequently used for word sense disambiguation experiments by (Ng and Lee, 1996), (Pedersen et al., 1997), and (Pedersen and Bruce, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  A00-2009.txt | Citing Article:  P02-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Among these methods, the one using Naive Bayesian Ensemble (i.e., an ensemble of Naive Bayesian Classifiers) is reported to perform the best for word sense disambiguation with respect to a benchmark data set (Pedersen 2000).</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >A Simple Approach To Building Ensembles Of Naive Bayesian Classifiers For Word Sense Disambiguation</S><S sid = 15 ssid = >When combined with a history of disambiguation success using shallow lexical features and Naive Bayesian classifiers, these findings suggest that word sense disambiguation might best be improved by combining the output of a number of such classifiers into an ensemble.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  A00-2009.txt | Citing Article:  P02-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It actually employs an ensemble of the Naive Bayesian Classifiers (NBC), because an ensemble of NBCs generally performs better than a single NBC (Pedersen 2000).</S> | Reference Offset:  ['6','72'] | Reference Text:  <S sid = 6 ssid = >This paper presents a corpus—based approach that results in high accuracy by combining a number of very simple classifiers into an ensemble that performs disambiguation via a majority vote.</S><S sid = 72 ssid = >The single most accurate classifier for interest is Naive_Bayes(4,1), which attains accuracy of 86% while the ensemble approach reaches 89%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  A00-2009.txt | Citing Article:  P02-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 4 shows the results achieved by some existing supervised learning methods with respect to the benchmark data (cf., Pedersen 2000).</S> | Reference Offset:  ['3','7'] | Reference Text:  <S sid = 3 ssid = >Word sense disambiguation is often cast as a problem in supervised learning, where a disambiguator is induced from a corpus of manually sense—tagged text using methods from statistics or machine learning.</S><S sid = 7 ssid = >This is motivated by the observation that enhancing the feature set or learning algorithm used in a corpus—based approach does not usually improve disambiguation accuracy beyond what can be attained with shallow lexical features and a simple supervised learning algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  A00-2009.txt | Citing Article:  W04-0850.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Duluth-xLSS system was originally inspired by (Pedersen, 2000), which presents an ensemble of eighty-one Naive Bayesian classifiers based on varying sized windows of context to the left and right of the target word that define co-occurrence features.</S> | Reference Offset:  ['1','151'] | Reference Text:  <S sid = 1 ssid = >This paper presents a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co—occurring words in varying sized windows of context.</S><S sid = 151 ssid = >A methodology for formulating an ensemble of Naive Bayesian classifiers is presented, where each member classifier is based on co—occurrence features extracted from a different sized window of context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  A00-2009.txt | Citing Article:  C04-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pedersen (2000) built an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co-occurring words in varying sized windows of context.</S> | Reference Offset:  ['1','131'] | Reference Text:  <S sid = 1 ssid = >This paper presents a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co—occurring words in varying sized windows of context.</S><S sid = 131 ssid = >The lesson taken from these results was that an ensemble should consist of classifiers that represent as differently sized windows of context as possible; this reduces the impact of redundant errors made by classifiers that represent very similarly sized windows of context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  A00-2009.txt | Citing Article:  C04-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Locally weighted NB (LWNB, Frank et al 2003) and Ensemble NB (ENB Pedersen 2000) are two combinational approaches.</S> | Reference Offset:  ['53','137'] | Reference Text:  <S sid = 53 ssid = >This data set was subsequently used for word sense disambiguation experiments by (Ng and Lee, 1996), (Pedersen et al., 1997), and (Pedersen and Bruce, 1997).</S><S sid = 137 ssid = >However, a preliminary study found that the accuracy of a Naive Bayesian ensemble using a weighted vote was poor.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  A00-2009.txt | Citing Article:  W02-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pedersen (2000) presents experiments with an ensemble of Naive Bayes classifiers, which outperform all previous published results on two ambiguous words (line and interest).</S> | Reference Offset:  ['19','74'] | Reference Text:  <S sid = 19 ssid = >Experimental results disambiguating these words with an ensemble of Naive Bayesian classifiers are shown to rival previously published results.</S><S sid = 74 ssid = >These experiments use the same sense-tagged corpora for interest and line as previous studies.</S> | Discourse Facet:  NA | Annotator: Automatic


