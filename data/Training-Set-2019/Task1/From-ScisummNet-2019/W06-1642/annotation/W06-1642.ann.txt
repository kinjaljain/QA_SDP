Citance Number: 1 | Reference Article:  W06-1642.txt | Citing Article:  P14-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Various attempts have been made to incorporate discourse relations into sentiment analysis: Pang and Lee (2004) explored the consistency of subjectivity between neighboring sentences; Mao and Lebanon (2007), McDonald et al (2007), and Tackstrom and McDonald (2011a) developed structured learning models to capture sentiment dependencies between adjacent sentences; Kanayama and Nasukawa (2006) and Zhou et al (2011) use discourse relations to constrain two text segments to have either the same polarity or opposite polarities; Trivedi and Eisenstein (2013) and Lazaridou et al (2013) encode the discourse connectors as model features in supervised classifiers.</S> | Reference Offset:  ['7','57'] | Reference Text:  <S sid = 7 ssid = >Extensive syntactic patterns enable us to detect sentiment expressions and to convert them into semantic structures with high precision, as reported by Kanayama et al. (2004).</S><S sid = 57 ssid = >This section describes the last two processes, which are based on a deep sentiment analysis method analogous to machine translation (Kanayama et al., 2004) (hereafter “the MT method”).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-1642.txt | Citing Article:  C10-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa (2006) posited that polar clauses with the same polarity tend to appear successively in contexts.</S> | Reference Offset:  ['3','21'] | Reference Text:  <S sid = 3 ssid = >As a clue to obtain candidate atoms, we use the tendency for same polarities to appear successively in contexts.</S><S sid = 21 ssid = >For lexical learning from unannotated corpora, our method uses context coherency in terms of polarity, an assumption that polar clauses with the same polarity appear successively unless the context is changed with adversative expressions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-1642.txt | Citing Article:  C10-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned in Section 2, Kanayama and Nasukawa (2006) validated that polar text units with the same polarity tend to appear together to make contexts coherent.</S> | Reference Offset:  ['124','131'] | Reference Text:  <S sid = 124 ssid = >We also observed the coherent density of the domain d with the lexicon L defined as: This indicates the ratio of polar clauses that appear in the coherent context, among all of the polar clauses detected by the system.</S><S sid = 131 ssid = >Then, each candidate atom is validated using the two metrics in the previous section, cp and cd, which are calculated from all of the polar clauses found in the domain corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-1642.txt | Citing Article:  P13-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa (2006) bootstrap subjectivity lexicons for Japanese by generating subjectivity candidates based on word co-occurrence patterns.</S> | Reference Offset:  ['13','187'] | Reference Text:  <S sid = 13 ssid = >Building domain-dependent lexicons for many domains is much harder work than preparing domainindependent lexicons and syntactic patterns, because the possible lexical entries are too numerous, and they may differ in each domain.</S><S sid = 187 ssid = >These lexicons had 0.8, 0.5, 0.2 times the polar atoms, respectively, compared to L. Table 9 shows the precisions and recalls using these lexicons for the learning process.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-1642.txt | Citing Article:  W11-1716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Kanayama and Nasukawa, 2006), the authors propose an algorithm to automatically expand an initial opinion lexicon based on context coherency, the tendency for same polarities to appear successively in contexts.</S> | Reference Offset:  ['3','27'] | Reference Text:  <S sid = 3 ssid = >As a clue to obtain candidate atoms, we use the tendency for same polarities to appear successively in contexts.</S><S sid = 27 ssid = >Our algorithm is fully automatic in the sense that the criteria for the adoption of polar atoms are set automatically by statistical estimation based on the distributions of coherency: coherent precision and coherent density.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-1642.txt | Citing Article:  D10-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, Andreevskaia and Bergler (2006) used WordNet to expand seed lists with fuzzy sentiment categories, in which words could be more central to one category than the other. Finally, Kanayama and Nasukawa (2006) used syntactic features and context coherency, defined as the tendency for same polarities to appear successively, to acquire polar atoms.</S> | Reference Offset:  ['3','21'] | Reference Text:  <S sid = 3 ssid = >As a clue to obtain candidate atoms, we use the tendency for same polarities to appear successively in contexts.</S><S sid = 21 ssid = >For lexical learning from unannotated corpora, our method uses context coherency in terms of polarity, an assumption that polar clauses with the same polarity appear successively unless the context is changed with adversative expressions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-1642.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The second type of relations are word-to-expression relations: e.g., some words appear in expressions that take on a variety of polarities, while other words are associated with expressions of one polarity class or another. In relation to previous research, analyzing word-to-word (intra-expression) relations is most related to techniques that determine expression-level polarity in context (e.g., Wilson et al (2005)), while exploring word-to-expression (inter-expression) relations has connections to techniques that employ more of a global-view of corpus statistics (e.g., Kanayama and Nasukawa (2006)). While most previous research exploits only one or the other type of relation, we propose a unified method that can exploit both types of semantic relation, while adapting a general purpose polarity lexicon into a domain specific one.</S> | Reference Offset:  ['16','97'] | Reference Text:  <S sid = 16 ssid = >A polar atom is a minimum syntactic structure specifying polarity in a predicative expression.</S><S sid = 97 ssid = >The polarities are assumed to be the same in the inter-sentential context, unless there is an adversative expression as those listed in Table 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-1642.txt | Citing Article:  D12-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Hatzivassiloglou (Hatzivassiloglou and McKeown, 1997) and Kanayama (Kanayama and Nasukawa, 2006) used conjunction rules to solve this problem from large domain corpora.</S> | Reference Offset:  ['40','95'] | Reference Text:  <S sid = 40 ssid = >For example, Hatzivassiloglou and McKeown (1997) labeled adjectives as positive or negative, relying on semantic orientation.</S><S sid = 95 ssid = >“Len.&quot; is the average length of sentences (in Japanese characters). ilar to the semantic orientation proposed by Hatzivassiloglou and McKeown (1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-1642.txt | Citing Article:  D07-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Kanayama and Nasukawa, 2006) reported that it was appropriate in 72.2% of cases.</S> | Reference Offset:  ['7','123'] | Reference Text:  <S sid = 7 ssid = >Extensive syntactic patterns enable us to detect sentiment expressions and to convert them into semantic structures with high precision, as reported by Kanayama et al. (2004).</S><S sid = 123 ssid = >Besides the conflicting cases, there are many more cases where a polar clause does not appear in the polar context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-1642.txt | Citing Article:  D07-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa used both intra and inter-sentential co-occurrence to learn polarity of words and phrases (Kanayama and Nasukawa,2006).</S> | Reference Offset:  ['109','119'] | Reference Text:  <S sid = 109 ssid = >Two polar clauses in the intrasentential and/or inter-sentential context described in Section 4.1.</S><S sid = 119 ssid = >The cp values for inter-sentential and intra-sentential contexts are almost the same, and thus both contexts can be used to obtain 2.5 times more clues for the intra-sentential context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-1642.txt | Citing Article:  P10-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa (2006) use syntactic features and context coherency, the tendency for same polarities to appear successively, to acquire polar atoms. Other related work is concerned with subjectivity analysis.</S> | Reference Offset:  ['3','21'] | Reference Text:  <S sid = 3 ssid = >As a clue to obtain candidate atoms, we use the tendency for same polarities to appear successively in contexts.</S><S sid = 21 ssid = >For lexical learning from unannotated corpora, our method uses context coherency in terms of polarity, an assumption that polar clauses with the same polarity appear successively unless the context is changed with adversative expressions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-1642.txt | Citing Article:  P11-2104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa (2006) used syntactic features and context coherency, defined as the tendency for same polarities to appear successively, to acquire polar atoms.</S> | Reference Offset:  ['3','21'] | Reference Text:  <S sid = 3 ssid = >As a clue to obtain candidate atoms, we use the tendency for same polarities to appear successively in contexts.</S><S sid = 21 ssid = >For lexical learning from unannotated corpora, our method uses context coherency in terms of polarity, an assumption that polar clauses with the same polarity appear successively unless the context is changed with adversative expressions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-1642.txt | Citing Article:  P11-2101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kanayama and Nasukawa (2006) improved this work by using the idea of coherency.</S> | Reference Offset:  ['52','128'] | Reference Text:  <S sid = 52 ssid = >Our approach and their work can complement each other.</S><S sid = 128 ssid = >The next section describes the method of our unsupervised learning using this imperfect context coherency.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-1642.txt | Citing Article:  N07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition to individual seed words, Kanayama and Nasukawa (2006) used more complicated syntactic patterns that were manually created.</S> | Reference Offset:  ['7','65'] | Reference Text:  <S sid = 7 ssid = >Extensive syntactic patterns enable us to detect sentiment expressions and to convert them into semantic structures with high precision, as reported by Kanayama et al. (2004).</S><S sid = 65 ssid = >In order to achieve higher recall while maintaining high precision, we apply two types of syntactic patterns, modality patterns and conjunctive patterns4, to the tree structures from the full-parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-1642.txt | Citing Article:  N07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','203'] | Reference Text:  <S sid = 63 ssid = >However, this limitation reduces the recall of sentiment analysis to a very low level.</S><S sid = 203 ssid = >These features allow them to do on-demand analysis of more narrow domains, such as the domain of digital &quot;Perhaps because cameras tend to consume battery power and some users don’t need them. cameras of a specific manufacturer, or the domain of mobile phones from the female users’ point of view.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-1642.txt | Citing Article:  P10-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Next, the target-specific polarity of adjectives is determined using Hearst-like patterns. Kanayama and Nasukawa (2006) introduce polar atoms: minimal human-understandable syntactic structures that specify polarity of clauses.</S> | Reference Offset:  ['2','48'] | Reference Text:  <S sid = 2 ssid = >The lexical entries to be acare called the minimum human-understandable syntactic structures that specify the polarity of clauses.</S><S sid = 48 ssid = >Wilson et al. (2005) proposed supervised learning, dividing the resources into prior polarity and context polarity, which are similar to polar atoms and syntactic patterns in this paper, respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-1642.txt | Citing Article:  P14-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus.</S> | Reference Offset:  ['121','180'] | Reference Text:  <S sid = 121 ssid = >We also observed the coherent precision for each domain corpus.</S><S sid = 180 ssid = >The optimum 0 was 0.3 in the movie domain and 0.1 in the digital camera domain.</S> | Discourse Facet:  NA | Annotator: Automatic


