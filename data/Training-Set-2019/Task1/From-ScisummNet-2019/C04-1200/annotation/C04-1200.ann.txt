Citance Number: 1 | Reference Article:  C04-1200.txt | Citing Article:  H05-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This idea is similar to that of (Kim and Hovy, 2004) and (Hu and Liu, 2004), but instead of using a window of size k or the output of a noun phrase chunker, OPINE takes advantage of the syntactic dependencies computed by the MINIPAR parser.</S> | Reference Offset:  ['76','145'] | Reference Text:  <S sid = 76 ssid = >Table 2 shows several examples of the system output, computed with Equation (2), in which ?+?</S><S sid = 145 ssid = >0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu ra cy Window 1 Window 2 Window 3 Window 4 0.3 0.4 0.5 0.6 0.7 0.8 0.9 m0p1 m0p3 m1p1 m1p2 m1p3 m1p4 m2p1 m2p2 m2p3 m2p4 ac cu rac y Window 1 Window 2 Window 3 Window 4 Human 1 : Machine Human 2 : Machine Figure 2: Results with manually annotated Holder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C04-1200.txt | Citing Article:  P13-2085.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(signed integers representing positive and negative feelings) (Kim and Hovy, 2004).</S> | Reference Offset:  ['55','78'] | Reference Text:  <S sid = 55 ssid = >We assume synonyms of positive words are mostly positive and antonyms mostly negative, e.g., the positive word ?good?</S><S sid = 78 ssid = >negative.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C04-1200.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, they have been an essential ingredient for fine grained sentiment analysis (e.g., Kim and Hovy (2004), Kennedy and Inkpen (2005), Wilson et al (2005)).</S> | Reference Offset:  ['8','54'] | Reference Text:  <S sid = 8 ssid = >(Wiebe et al 2002; Riloff et al 2003), concentrates just on explicit statements of evaluation, such as of films (Turney 2002; Pang et al 2002), or focuses on just one aspect of opinion, e.g., (Hatzivassiloglou and McKeown 1997) on adjectives.</S><S sid = 54 ssid = >The basic approach is to assemble a small amount of seed words by hand, sorted by polarity into two lists?positive and negative?and then to grow this by adding words obtained from WordNet (Miller et al 1993; Fellbaum et al 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C04-1200.txt | Citing Article:  C10-2036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (2004) try to determine the final sentiment orientation of a given sentence by combining sentiment words within it.</S> | Reference Offset:  ['86','132'] | Reference Text:  <S sid = 86 ssid = >2.2 Sentence Sentiment Classifier.</S><S sid = 132 ssid = >3.2 Sentence Sentiment Classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C04-1200.txt | Citing Article:  P06-2079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Antonyms of negative words are added to the positive list, and synonyms to the negative one.</S><S sid = 187 ssid = >Nonetheless, as the experiments show, encouraging results can be obtained even with relatively simple models and only a small amount of manual seeding effort.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C04-1200.txt | Citing Article:  P06-2079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Antonyms of negative words are added to the positive list, and synonyms to the negative one.</S><S sid = 187 ssid = >Nonetheless, as the experiments show, encouraging results can be obtained even with relatively simple models and only a small amount of manual seeding effort.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C04-1200.txt | Citing Article:  W11-1712.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In separate qualitative experiments done by Pang et al (2002), 97 Wilson et al (2005) and Kim and Hovy (2004), the agreement between human judges when given a list of sentiment-bearing words is as low as 58% and no higher than 76%.</S> | Reference Offset:  ['8','54'] | Reference Text:  <S sid = 8 ssid = >(Wiebe et al 2002; Riloff et al 2003), concentrates just on explicit statements of evaluation, such as of films (Turney 2002; Pang et al 2002), or focuses on just one aspect of opinion, e.g., (Hatzivassiloglou and McKeown 1997) on adjectives.</S><S sid = 54 ssid = >The basic approach is to assemble a small amount of seed words by hand, sorted by polarity into two lists?positive and negative?and then to grow this by adding words obtained from WordNet (Miller et al 1993; Fellbaum et al 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C04-1200.txt | Citing Article:  P10-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (2004) start with two lists of positive and negative seed words.</S> | Reference Offset:  ['59','61'] | Reference Text:  <S sid = 59 ssid = >To start the seed lists we selected verbs (23 positive and 21 negative) and adjectives (15 positive and 19 negative), adding nouns later.</S><S sid = 61 ssid = >For each seed word, we extracted from WordNet its expansions and added them back into the appropriate seed lists.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C04-1200.txt | Citing Article:  D09-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (2004) found the polarity of subjective expressions.</S> | Reference Offset:  ['97','106'] | Reference Text:  <S sid = 97 ssid = >A more sophisticated approach would employ a parser to identify syntactic relationships between each Holder and all dependent expressions of sentiment.</S><S sid = 106 ssid = >For this model, we also included negation words such as not and never to reverse the sentiment polarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C04-1200.txt | Citing Article:  P10-2050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Antonyms of negative words are added to the positive list, and synonyms to the negative one.</S><S sid = 187 ssid = >Nonetheless, as the experiments show, encouraging results can be obtained even with relatively simple models and only a small amount of manual seeding effort.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C04-1200.txt | Citing Article:  E06-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The system of Kim and Hovy (2004) tackles orientation detection by attributing, to each term, a positivity score and a negativity score; interestingly, terms may thus be deemed to have both a positive and a negative correlation, maybe with different degrees, and some terms may be deemed to carry a stronger positive (or negative) orientation than others.</S> | Reference Offset:  ['55','78'] | Reference Text:  <S sid = 55 ssid = >We assume synonyms of positive words are mostly positive and antonyms mostly negative, e.g., the positive word ?good?</S><S sid = 78 ssid = >negative.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C04-1200.txt | Citing Article:  E06-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This hypothesis is confirmed by an experiment performed by Kim and Hovy (2004) on testing the agreement of two human coders at tagging words with the Positive, Negative, and Objective labels.</S> | Reference Offset:  ['55','120'] | Reference Text:  <S sid = 55 ssid = >We assume synonyms of positive words are mostly positive and antonyms mostly negative, e.g., the positive word ?good?</S><S sid = 120 ssid = >Table 4 shows inter-human agreement.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C04-1200.txt | Citing Article:  P10-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (2004) select candidate sentiment sentences and use word-based sentiment classifiers to classify unseen words into a negative or positive class.</S> | Reference Offset:  ['69','152'] | Reference Text:  <S sid = 69 ssid = >Given a new word, we use WordNet again to obtain a synonym set of the unseen word to determine how it interacts with our sentiment seed lists.</S><S sid = 152 ssid = >3.3.1 Word Sentiment Classification As mentioned, some words have both strong positive and negative sentiment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C04-1200.txt | Citing Article:  P10-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The lexicons are generated from manually selected seeds for a broad domain such as Health or Business, following an approach similar to (Kim and Hovy, 2004).</S> | Reference Offset:  ['24','126'] | Reference Text:  <S sid = 24 ssid = >(implicit) In this paper we address the following challenge problem.</S><S sid = 126 ssid = >In Table 5, the seed list included just a few manually selected seed words (23 positive and 21 negative verbs and 15 and 19 adjectives, repectively).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C04-1200.txt | Citing Article:  P07-1124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (2004), among others, have combined the two tasks, identifying subjective text and detecting its sentiment polarity.</S> | Reference Offset:  ['1','165'] | Reference Text:  <S sid = 1 ssid = >Identifying sentiments (the affective parts of opinions) is a challenging problem.</S><S sid = 165 ssid = >Although relatively easy task for people, detecting an opinion holder is not simple either.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C04-1200.txt | Citing Article:  D10-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy (Kim and Hovy, 2004) used WordNet synonyms and antonyms to expand two lists of positive and negative seed words.</S> | Reference Offset:  ['55','58'] | Reference Text:  <S sid = 55 ssid = >We assume synonyms of positive words are mostly positive and antonyms mostly negative, e.g., the positive word ?good?</S><S sid = 58 ssid = >Antonyms of negative words are added to the positive list, and synonyms to the negative one.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C04-1200.txt | Citing Article:  C08-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, Kim and Hovy (2004) and Andreevskaia and Bergler (2006) also address the classification into subjective/objective words and show this to be a potentially harder task than polarity classification with lower human agreement and automatic performance. There are only two prior approaches addressing word sense subjectivity or polarity classification.</S> | Reference Offset:  ['53','118'] | Reference Text:  <S sid = 53 ssid = >2.1.1 Word Classification Models For word sentiment classification we developed two models.</S><S sid = 118 ssid = >The classification task is defined as assigning each word to one of three categories: positive, negative, and neutral.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C04-1200.txt | Citing Article:  D07-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kim and Hovy proposed two probabilistic models to estimate the strength of polarity (Kim and Hovy, 2004).</S> | Reference Offset:  ['68','81'] | Reference Text:  <S sid = 68 ssid = >Armed with such a measure, we can also assign strength of sentiment polarity to as yet unseen words.</S><S sid = 81 ssid = >The absolute value of each category represents the strength of its sentiment polarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C04-1200.txt | Citing Article:  N09-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, Kim and Hovy (2004) and Andreevskaiaand Bergler (2006) show that subjectivity recognition might be the harder problem with lower human agreement and automatic performance.</S> | Reference Offset:  ['120','123'] | Reference Text:  <S sid = 120 ssid = >Table 4 shows inter-human agreement.</S><S sid = 123 ssid = >The system achieves lower agreement than humans but higher than the random process.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C04-1200.txt | Citing Article:  W11-1702.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Antonyms of negative words are added to the positive list, and synonyms to the negative one.</S><S sid = 187 ssid = >Nonetheless, as the experiments show, encouraging results can be obtained even with relatively simple models and only a small amount of manual seeding effort.</S> | Discourse Facet:  NA | Annotator: Automatic


