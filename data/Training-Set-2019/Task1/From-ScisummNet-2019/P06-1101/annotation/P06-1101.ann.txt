Citance Number: 1 | Reference Article:  P06-1101.txt | Citing Article:  P07-2042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, Snow, Jurafsky and Ng (2005) generated tens of thousands of hypernym patterns and combined these with noun clusters to generate high-precision suggestions for unknown noun insertion into WordNet (Snow et al, 2006).</S> | Reference Offset:  ['50','72'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 72 ssid = >First, we identify the set of all the word pairs (i, j) over which we have hypernym and/or coordinate evidence, and which might represent additions of a novel hyponym to the WordNet 2.1 taxonomy (i.e., that has a known noun hypernym and an unknown hyponym, or has a known noun coordinate term and an unknown coordinate term).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1101.txt | Citing Article:  P07-2042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Snow et al (2006), we derive two types of evidence from these patterns: H is a hypernym of A, B and C, A, B and C are siblings of each other.</S> | Reference Offset:  ['36','50'] | Reference Text:  <S sid = 36 ssid = >For example, evidence for the hypernym relation EHij might be the set of all observed lexico-syntactic patterns containing i and j in all sentences in some corpus.</S><S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1101.txt | Citing Article:  P14-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['118','119'] | Reference Text:  <S sid = 118 ssid = >Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.</S><S sid = 119 ssid = >This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1101.txt | Citing Article:  W08-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al, 2006), tools and corpora.</S> | Reference Offset:  ['89','111'] | Reference Text:  <S sid = 89 ssid = >We evaluate the quality of our acquired hyponyms by direct judgment.</S><S sid = 111 ssid = >In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1101.txt | Citing Article:  P09-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also compare ASIA on twelve additional benchmarks to the extended Wordnet 2.1 produced by Snow et al (Snow et al, 2006), and show that for these twelve sets, ASIA produces more than five times as many set instances with much higher precision (98% versus 70%).</S> | Reference Offset:  ['50','111'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 111 ssid = >In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1101.txt | Citing Article:  P09-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Snow et al (Snow et al, 2006) use known hypernym / hyponym pairs to generate training data for a machine-learning system, which then learns many lexico-syntactic patterns.</S> | Reference Offset:  ['50','111'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 111 ssid = >In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1101.txt | Citing Article:  P09-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Snow (Snow et al, 2006) has extended the Word Net 2.1 by adding thousands of entries (synsets) at a relatively high precision.</S> | Reference Offset:  ['50','100'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 100 ssid = >We see that our joint algorithm strongly outperforms the baseline, and has high precision for predicting novel hyponyms up to 10,000 links.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1101.txt | Citing Article:  P14-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['118','119'] | Reference Text:  <S sid = 118 ssid = >Rion Snow is supported by an NDSEG Fellowship sponsored by the DOD and AFOSR.</S><S sid = 119 ssid = >This work was supported in part by the Disruptive Technology Office (DTO)’s Advanced Question Answering for Intelligence (AQUAINT) Program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1101.txt | Citing Article:  P14-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Snow et al (2006) add novel terms by greedily maximizing the conditional probability of a set of relational evidence given a taxonomy.</S> | Reference Offset:  ['20','39'] | Reference Text:  <S sid = 20 ssid = >In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity.</S><S sid = 39 ssid = >Applying these two independence assumptions we may express the conditional probability of our evidence given the taxonomy: Within our model we define the goal of taxonomy induction to be to find the taxonomy T� that maximizes the conditional probability of our observations E given the relationships of T, i.e., to find We propose a search algorithm for finding T� for the case of hyponym acquisition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1101.txt | Citing Article:  D10-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006).</S> | Reference Offset:  ['10','50'] | Reference Text:  <S sid = 10 ssid = >Additionally, a wide variety of relationship-specific classifiers have been proposed, including pattern-based classifiers for hyponyms (Hearst, 1992), meronyms (Girju, 2003), synonyms (Lin et al., 2003), a variety of verb relations (Chklovski and Pantel, 2004), and general purpose analogy relations (Turney et al., 2003).</S><S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1101.txt | Citing Article:  P09-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The work by Snow et al (2006) is the most similar to ours because they also took an incremental approach to construct taxonomies.</S> | Reference Offset:  ['13','62'] | Reference Text:  <S sid = 13 ssid = >Past work on semantic taxonomy induction includes the noun hypernym hierarchy created in (Caraballo, 2001), the part-whole taxonomies in (Girju, 2003), and a great deal of recent work described in (Buitelaar et al., 2005).</S><S sid = 62 ssid = >In that work an efficient randomized algorithm is derived for computing clusters of similar nouns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1101.txt | Citing Article:  P09-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compare system performance between (Snow et al, 2006) and our framework in Section 5.</S> | Reference Offset:  ['20','112'] | Reference Text:  <S sid = 20 ssid = >In section 2.1 we introduce our definitions for taxonomies, relations, and the taxonomic constraints that enforce dependencies between relations; in section 2.2 we give a probabilistic model for defining the conditional probability of a set of relational evidence given a taxonomy; in section 2.3 we formulate a local search algorithm to find the taxonomy maximizing this conditional probability; and in section 2.4 we extend our framework to deal with lexical ambiguity.</S><S sid = 112 ssid = >We measured the performance of both our inferred taxonomies and WordNet against this test set.8 The performance and comparison of the best WordNet classifier vs. our taxonomies is given in Table 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1101.txt | Citing Article:  P09-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To have a fair comparison, for PR, we estimate the conditional probability of a relation given the evidence P (Rij|Eij), as in (Snow et al 2006), by using the same set of features as in ME.</S> | Reference Offset:  ['35','40'] | Reference Text:  <S sid = 35 ssid = >We define the probability of the taxonomy as a whole as the joint probability of its component relations; given a partition of all possible relations R = {A, B} where A E T and We assume that we have some set of observed evidence E consisting of observed features over pairs of objects in some domain DE; we’ll begin with the assumption that our features are over pairs of words, and that the objects in the taxonomy also correspond directly to words.4 Given a set of features ERij E E, we assume we have some model for inferring P(Rij E T|ERij), i.e., the posterior probability of the event Rij E T given the corresponding evidence ERij for that relation.</S><S sid = 40 ssid = >We assume we begin with some initial (possibly empty) taxonomy T. We restrict our consideration of possible new taxonomies to those created by the single operation ADD-RELATION(Rij, T), which adds the single relation Rij to T. We define the multiplicative change OT(Rij) to the conditional probability P(E|T) given the addition of a single relation Rij: Here k is the inverse odds of the prior on the event Rij E T; we consider this to be a constant independent of i, j, and the taxonomy T. To enforce the taxonomic constraints in T, for each application of the ADD-RELATION operator we must add all new relations in the implied set I(Rij) not already in T.5 Thus we define the multiplicative change of the full set of implied relations as the product over all new relations: Rewriting the conditional probability in terms of our estimates of the posterior probabilities This definition leads to the following best-first search algorithm for hyponym acquisition, which at each iteration defines the new taxonomy as the union of the previous taxonomy T and the set of novel relations implied by the relation Rij that maximizes AT(I(Rij)) and thus maximizes the conditional probability of the evidence over all possible single relations: Since word senses are not directly observable, if the objects in the taxonomy are word senses (as in WordNet), we must extend our model to allow for a many-to-many mapping (e.g., a word-to-sense mapping) between DE and DT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1101.txt | Citing Article:  P09-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An extension to WordNet was presented by (Snow et al, 2006).</S> | Reference Offset:  ['50','114'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 114 ssid = >We have presented an algorithm for inducing semantic taxonomies which attempts to globally optimize the entire structure of the taxonomy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P06-1101.txt | Citing Article:  P09-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Snow et al (2006) use syntactic path patterns as features for supervised hyponymy and synonymy classifiers, whose training examples are derived automatically from WordNet.</S> | Reference Offset:  ['50','53'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 53 ssid = >The labeled training set is constructed by labeling the collected feature vectors as positive “known hypernym” or negative “known non-hypernym” examples using WordNet 2.0; 49,922 feature vectors were labeled as positive training examples, and 800,828 noun pairs were labeled as negative training examples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P06-1101.txt | Citing Article:  P09-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following the spirit of the fine-grained human evaluation in (Snow et al, 2006), we randomly sampled 800 rules from our rule-base and presented them to an annotator who judged them for correctness, according to the lexical reference notion specified above.</S> | Reference Offset:  ['88','111'] | Reference Text:  <S sid = 88 ssid = >Finally, in section 4.5 we evaluate the taxonomies inferred by our algorithm directly against the WordNet 2.1 taxonomy; we perform this evaluation by testing each taxonomy on a set of human judgments of hypernym and non-hypernym noun pairs sampled from newswire text.</S><S sid = 111 ssid = >In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P06-1101.txt | Citing Article:  P09-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We observed that the likelihood of nouns mentioned in a definition to be referred by the concept title depends greatly on the syntactic path connecting them (which was exploited also in (Snow et al, 2006)).</S> | Reference Offset:  ['38','52'] | Reference Text:  <S sid = 38 ssid = >Further, we assume that each item of observed evidence ERij depends on the taxonomy T only by way of the corresponding relation Rij, i.e., For example, if our evidence EHij is a set of observed lexico-syntactic patterns indicative of hypernymy between two words i and j, we assume that whatever dependence the relations in T have on our observations may be explained entirely by dependence on the existence or non-existence of the single hypernym relation H(i, j).</S><S sid = 52 ssid = >From the resulting dependency trees the evidence EHij for each word pair (i, j) is constructed; the evidence takes the form of a vector of counts of occurrences that each labeled syntactic dependency path was found as the shortest path connecting i and j in some dependency tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P06-1101.txt | Citing Article:  D12-1117.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, (Snow et al 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy.</S> | Reference Offset:  ['50','80'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 80 ssid = >As an example of sense disambiguation in practice, consider our example of continental.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P06-1101.txt | Citing Article:  W09-2508.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recently, Snow et al (2005) and Snow et al (2006) have described a method of hypernymy extraction using machine learning of 53 patterns.</S> | Reference Offset:  ['50','111'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 111 ssid = >In order to compare taxonomies we use a hand-labeled test set of over 5,000 noun pairs, randomly-sampled from newswire corpora (described in (Snow et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P06-1101.txt | Citing Article:  D09-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al, 2006)) or WN in other languages (e.g., (Vintar and Fiser, 2008)).</S> | Reference Offset:  ['50','89'] | Reference Text:  <S sid = 50 ssid = >Our classifier for the hypernym relation is derived from the “hypernym-only” classifier described in (Snow et al., 2005).</S><S sid = 89 ssid = >We evaluate the quality of our acquired hyponyms by direct judgment.</S> | Discourse Facet:  NA | Annotator: Automatic


