Citance Number: 1 | Reference Article:  W04-2401.txt | Citing Article:  W04-2421.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A similar method was used for entity/relation recognition (Roth and Yih, 2004).</S> | Reference Offset:  ['9','152'] | Reference Text:  <S sid = 9 ssid = >In named entity recognition, “no entities can overlap” is a common constraint used in various works (Tjong Kim Sang and De Meulder, 2003).</S><S sid = 152 ssid = >Lt.) name3 the phrase is/has a known person’s name For the relation classifier, there are three sets of features: (1) features similar to those used in the entity classification are extracted from the two argument entities of the relation; (2) conjunctions of the features from the two arguments; (3) some patterns extracted from the sentence or between the two arguments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W04-2401.txt | Citing Article:  P09-2015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Supervised methods such as (Culotta and Sorensen, 2004) and (Roth and Yih, 2004) provide only a partial solution, as there are many possible relations and entities of interest for a given domain, and such approaches require new annotated data each time a new relation or entity type is needed.</S> | Reference Offset:  ['41','198'] | Reference Text:  <S sid = 41 ssid = >Given n entities in a sentence, there are O(n2) possible relations between them.</S><S sid = 198 ssid = >We force the system to determine which of the possible relations in a sentence (i.e., which pair of entities) has this relation by adding a new linear equality.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W04-2401.txt | Citing Article:  P08-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our model for disentanglement fits into the general class of graph partitioning algorithms (Roth and Yih, 2004) which have been used for a variety of tasks inNLP, including the related task of meeting segmentation (Malioutov and Barzilay, 2006).</S> | Reference Offset:  ['55','155'] | Reference Text:  <S sid = 55 ssid = >The correspondence between the relation and entity variables can be represented by a bipartite graph.</S><S sid = 155 ssid = >The learning algorithm used is a variation of the Winnow update rule incorporated in SNoW (Roth, 1998; Roth and Yih, 2002), a multi-class classifier that is specifically tailored for large scale learning tasks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W04-2401.txt | Citing Article:  P08-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) use log probabilities as weights.</S> | Reference Offset:  ['78','159'] | Reference Text:  <S sid = 78 ssid = >The specific cost function we use is defined as follows: Let l be the label assigned to variable u ∈ V. If the marginal probability estimation is p = P(fu = l), then the assignment cost cu(l) is − log p. Constraint cost: the cost imposed by breaking constraints between neighboring nodes.</S><S sid = 159 ssid = >We use softmax (Bishop, 1995) over the raw activation values as conditional probabilities.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W04-2401.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our problem formulation and use of ILP are based on both (Roth and Yih, 2004) and (Barzilay and Lapata, 2006).</S> | Reference Offset:  ['87','99'] | Reference Text:  <S sid = 87 ssid = >Our LP formulation is based on the method proposed by (Chekuri et al., 2001).</S><S sid = 99 ssid = >There are several advantages of representing the problem in an LP formulation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W04-2401.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Also, we minimize rather than maximize due to the fact we transform the model probabilities with? log (like Roth and Yih (2004)).</S> | Reference Offset:  ['64','210'] | Reference Text:  <S sid = 64 ssid = >In fact, as will be clear in Sec.</S><S sid = 210 ssid = >In fact, more classifiers can be added and used within the same framework.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W04-2401.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) use ILP to deal with the joint inference problem of named entity and relation identification.</S> | Reference Offset:  ['34','57'] | Reference Text:  <S sid = 34 ssid = >V. Oswald was murdered at JFK after his assassin, R. U. KFJ...” This task requires making several local decisions, such as identifying named entities in the sentence, in order to support the relation identification.</S><S sid = 57 ssid = >We use N1 and N2 to denote the entity variables of a relation Rij.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W04-2401.txt | Citing Article:  D11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We phrase the inference task as an integer linear program (ILP) following the approach developed in Roth and Yih (2004).</S> | Reference Offset:  ['25','124'] | Reference Text:  <S sid = 25 ssid = >Following this work, we model inference as an optimization problem, and show how to cast it as a linear program.</S><S sid = 124 ssid = >When the coefficient matrix of a given linear program in its standard form is unimodular, it can be shown that the optimal solution to the linear program is in fact integral (Schrijver, 1986).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W04-2401.txt | Citing Article:  D11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The approach we develop in this paper follows the one proposed by Roth and Yih (2004) of training individual models and combining them at inference time.</S> | Reference Offset:  ['32','45'] | Reference Text:  <S sid = 32 ssid = >We develop our models in the context of natural language inferences and evaluate it here on the problem of simultaneously recognizing named entities and relations between them.</S><S sid = 45 ssid = >The rest of the paper is organized as follows.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W04-2401.txt | Citing Article:  D11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) formulated the problem of extracting entities and relations as an integer linear program, allowing them to use global structural constraints at inference time even though the component classifiers were trained independently.</S> | Reference Offset:  ['25','146'] | Reference Text:  <S sid = 25 ssid = >Following this work, we model inference as an optimization problem, and show how to cast it as a linear program.</S><S sid = 146 ssid = >Basic, only tests our entity and relation classifiers, which are trained independently using only local features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W04-2401.txt | Citing Article:  W06-3607.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) combined information from named entities and semantic relation tagging, adopting a similar overall goal but using a quite different approach based on linear programming.</S> | Reference Offset:  ['3','204'] | Reference Text:  <S sid = 3 ssid = >We develop a linear programming formulation for this problem and evaluate it in the context of simultaneously learning named entities and relations.</S><S sid = 204 ssid = >We presented an linear programming based approach for global inference where decisions depend on the outcomes of several different but mutually dependent classifiers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W04-2401.txt | Citing Article:  P11-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >804 task, for which Integer Linear Programming (ILP) introduced to NLP by Roth and Yih (2004) and successfully applied by Denis and Baldridge (2007 ) to the task of jointly inferring anaphoricity and determining the antecedent would be appropriate.</S> | Reference Offset:  ['86','133'] | Reference Text:  <S sid = 86 ssid = >The computational approach we adopt is to develop a linear programming (LP) formulation of the problem, and then solve the corresponding integer linear programming (ILP) problem.</S><S sid = 133 ssid = >In the first, we view the task as a knowledge acquisition task – we let the system read sentences and identify entities and relations among them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W04-2401.txt | Citing Article:  P11-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) advocated ILP as a general solution for a number of NLP tasks that re quire combining multiple classifiers and which the traditional pipeline architecture is not appropriate, such as entity disambiguation and relation extraction.</S> | Reference Offset:  ['105','165'] | Reference Text:  <S sid = 105 ssid = >That is, replacing (6), (7), and (8) with: If LPR returns an integer solution, then it is also the optimal solution to the ILP problem.</S><S sid = 165 ssid = >Note that although the true labels of entities are known here when training the relation identifier, this may not be the case in general NLP problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W04-2401.txt | Citing Article:  N12-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Few of many examples include type constraints between relations and entities (Roth and Yih, 2004), sentential and modifier constraints during sentence compression (Clarke and Lapata,2006), and agreement constraints between word alignment directions (Ganchev et al, 2008) or various parsing models (Koo et al, 2010).</S> | Reference Offset:  ['2','27'] | Reference Text:  <S sid = 2 ssid = >Examples of these constraints include the type of arguments a relation can take, and the mutual activity of different relations, etc.</S><S sid = 27 ssid = >Our approach could be contrasted with other approaches to sequential inference or to general Markov random field approaches (Lafferty et al., 2001; Taskar et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W04-2401.txt | Citing Article:  N12-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We borrow the data and the setting from (Roth and Yih, 2004).</S> | Reference Offset:  ['22','155'] | Reference Text:  <S sid = 22 ssid = >Rather than being restricted on sequential data, we study a fairly general setting.</S><S sid = 155 ssid = >The learning algorithm used is a variation of the Winnow update rule incorporated in SNoW (Roth, 1998; Roth and Yih, 2002), a multi-class classifier that is specifically tailored for large scale learning tasks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W04-2401.txt | Citing Article:  N12-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Refer to (Roth and Yih, 2004) for more statistics on this data and a list of all the type constraints used.</S> | Reference Offset:  ['2','8'] | Reference Text:  <S sid = 2 ssid = >Examples of these constraints include the type of arguments a relation can take, and the mutual activity of different relations, etc.</S><S sid = 8 ssid = >These facts can be used as constraints.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W04-2401.txt | Citing Article:  P10-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Integer linear programs have already been successfully used in related fields including semantic role labelling (Punyakanok et al, 2004), relation and entity classification (Roth and Yih, 2004), sentence compression (Clarke and Lapata, 2008) and dependency parsing (Martins et al, 2009).</S> | Reference Offset:  ['27','87'] | Reference Text:  <S sid = 27 ssid = >Our approach could be contrasted with other approaches to sequential inference or to general Markov random field approaches (Lafferty et al., 2001; Taskar et al., 2002).</S><S sid = 87 ssid = >Our LP formulation is based on the method proposed by (Chekuri et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W04-2401.txt | Citing Article:  W05-1611.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, [Roth and Yih, 2004] applied an ILP model to the task of the simultaneous assignment of semantic roles to the entities mentioned in a sentence and recognition of the relations holding between them.</S> | Reference Offset:  ['65','185'] | Reference Text:  <S sid = 65 ssid = >3 the language for defining constraints is very rich – linear (in)equalities over V. We exemplify the framework using the problem of simultaneous recognition of named entities and relations in sentences.</S><S sid = 185 ssid = >As mentioned in Sec.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W04-2401.txt | Citing Article:  P08-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Roth and Yih (2004) also described a classification-based framework in which they jointly learn to identify named entities and relations.</S> | Reference Offset:  ['36','164'] | Reference Text:  <S sid = 36 ssid = >This, in turn, may help to identify that the kill action is described in the sentence.</S><S sid = 164 ssid = >This approach first trains an entity classifier as described in the basic approach, and then uses the prediction of entities in addition to other local features to learn the relation identifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W04-2401.txt | Citing Article:  P06-2009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Roth and Yih, 2004) suggests a model in which global constraints are taken into account in a later stage to fix mistakes due to the pipeline.</S> | Reference Offset:  ['16','193'] | Reference Text:  <S sid = 16 ssid = >The predictions are taken as input on the inference procedure which then finds the best global prediction.</S><S sid = 193 ssid = >On the other hand, our global inference procedure, LP, takes the natural constraints into account, so it never generates incoherent predictions.</S> | Discourse Facet:  NA | Annotator: Automatic


