Citance Number: 1 | Reference Article:  J99-1003.txt | Citing Article:  P00-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed (1999) aligns texts using correspondence points taken either from orthographic cognates (Michel Simard et al., 1992) or from a seed translation lexicon.</S> | Reference Offset:  ['170','395'] | Reference Text:  <S sid = 170 ssid = >When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a seed translation lexicon— a simple list of word pairs that are believed to be mutual translations.</S><S sid = 395 ssid = >The translation lexicon was automatically extracted from an MRBD (Cousin et al. 1991).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J99-1003.txt | Citing Article:  P00-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The latter approach uses other filtering parameters: maximum point ambiguity level, point dispersion and angle deviation (Melamed, 1999, pp. 115-116).</S> | Reference Offset:  ['214','270'] | Reference Text:  <S sid = 214 ssid = >The remaining chains are filtered using two threshold parameters: maximum point dispersal and maximum angle deviation.</S><S sid = 270 ssid = >SIMR's parameters—the fixed chain size; the LCSR threshold used in the matching predicate; and the thresholds for maximum point dispersal, maximum angle deviation, and maximum point ambiguity—interact in complicated ways.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J99-1003.txt | Citing Article:  P00-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed (1999) also filtered candidate correspondence points obtained from orthographic cognates.</S> | Reference Offset:  ['136','170'] | Reference Text:  <S sid = 136 ssid = >Two words are orthographic cognates if they have the same meaning and similar spellings.</S><S sid = 170 ssid = >When the matching predicate cannot generate enough candidate correspondence points based on cognates, its signal can be strengthened by a seed translation lexicon— a simple list of word pairs that are believed to be mutual translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J99-1003.txt | Citing Article:  P00-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This approach is similar to Melamed (1999) but, in contrast, it is statistically supported and uses no heuristics.</S> | Reference Offset:  ['83','225'] | Reference Text:  <S sid = 83 ssid = >Another interesting approach is possible when part-of-speech taggers are available for both languages.</S><S sid = 225 ssid = >SIMR uses a fixed chain size k, 6 < k < 11.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J99-1003.txt | Citing Article:  P13-1155.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use a similarity function proposed in (Contractor et al, 2010) which is based on Longest Common Subsequence Ratio (LCSR) (Melamed, 1999).</S> | Reference Offset:  ['146','147'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 147 ssid = >The LCSR of two tokens is the ratio of the length of their longest (not necessarily contiguous) common subsequence (LCS) and the length of the longer token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J99-1003.txt | Citing Article:  W05-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The former includes string edit distance (Wagner and Fischer, 1974), longest common subsequence ratio (Melamed, 1999), and measures based on shared character n-grams (Brew and McKelvie, 1996).</S> | Reference Offset:  ['146','423'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 423 ssid = >The cognate heuristic of character-based bitext mapping algorithms also works better at the word level, because cognateness can be defined more precisely in terms of words, e.g., using the Longest Common Subsequence Ratio.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J99-1003.txt | Citing Article:  D08-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Eight baseline systems were prepared for comparison: Levenshtein distance (LD), normalized Levenshtein distance (NLD), Dicecoefficient on letter bigrams (DICE) (Adamson and Boreham, 1974), Longest Common Substring Ratio (LCSR) (Melamed, 1999), Longest Common Prefix Ratio (PREFIX) (Kondrak, 2005), Porter's stemmer (Porter, 1980), Morpha (Minnen et al,2001), and CST's lemmatiser (Dalianis and Jonge 3LRSPL table includes trivial spelling variants that can be handled using simple character/string operations.</S> | Reference Offset:  ['146','147'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 147 ssid = >The LCSR of two tokens is the ratio of the length of their longest (not necessarily contiguous) common subsequence (LCS) and the length of the longer token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J99-1003.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other popular measures include Dice's Coefficient (DICE) (Adamson and Boreham, 1974), and the length-normalized measures Longest Common Subsequence Ratio (LCSR) (Melamed, 1999), and Longest Common Prefix Ratio (PREFIX) (Kondrak,2005).</S> | Reference Offset:  ['146','147'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 147 ssid = >The LCSR of two tokens is the ratio of the length of their longest (not necessarily contiguous) common subsequence (LCS) and the length of the longer token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J99-1003.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We adopt an improved definition (suggested by Melamed (1999) for the French-English Canadian Hansards) that does not over-propose shorter word pairs.</S> | Reference Offset:  ['18','166'] | Reference Text:  <S sid = 18 ssid = >Objective evaluation has shown that SIMR's accuracy is consistently high for language pairs as diverse as French/English and Korean/English.</S><S sid = 166 ssid = >In the nontechnical Canadian Hansards (parliamentary debate transcripts published in English and in French), an LCSR cutoff of .58 finds cognates for roughly one quarter of all text tokens.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J99-1003.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our labelled set is then generated from pairs with LCSR 0.58 (using the cutoff from Melamed (1999)).</S> | Reference Offset:  ['166','277'] | Reference Text:  <S sid = 166 ssid = >In the nontechnical Canadian Hansards (parliamentary debate transcripts published in English and in French), an LCSR cutoff of .58 finds cognates for roughly one quarter of all text tokens.</S><S sid = 277 ssid = >The TBM consists of a set of TPCs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J99-1003.txt | Citing Article:  P01-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A few of the errors were genuine, and could be explained by failures of the sentence alignment program that was used to create the corpus (Melamed, 1999).</S> | Reference Offset:  ['370','407'] | Reference Text:  <S sid = 370 ssid = >SIMR makes errors of omission and errors of commission.</S><S sid = 407 ssid = >To account for the possibility of modularizing the overall alignment task into paragraph alignment followed by sentence alignment, Simard, Foster, and Isabelle (1992) have reported the accuracy of their sentence alignment algorithm when a perfect alignment at the paragraph level is given.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J99-1003.txt | Citing Article:  D09-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Korean-English parallel data was collected from news websites and sentence aligned using two different tools described by Moore (2002) and Melamed (1999).</S> | Reference Offset:  ['2','13'] | Reference Text:  <S sid = 2 ssid = >As with other kinds of data, the value of bitexts largely depends on the efficacy of the available data mining tools.</S><S sid = 13 ssid = >As with other kinds of data, the value of bitexts largely depends on the efficacy of the available data mining tools.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J99-1003.txt | Citing Article:  C04-1137.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['152','446'] | Reference Text:  <S sid = 152 ssid = >A rather more complicated algorithm can compute it in 0(n log log n) time on average (Hunt and Szymanski 1977).</S><S sid = 446 ssid = >The majority of this work was done at the Department of Computer and Information Science of the University of Pennsylvania, where it was supported by an equipment grant from Sun MicroSystems and partially funded by ARO grant DAAL03-89-00031 PRIME and by ARPA grants N00014-90+1863 and N66001-94C-6043.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J99-1003.txt | Citing Article:  D09-1129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed (1999) normalized LCS by dividing the length of the longest common subsequence by the length of the longer string and called it longest common subsequence ratio (LCSR).</S> | Reference Offset:  ['146','147'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 147 ssid = >The LCSR of two tokens is the ratio of the length of their longest (not necessarily contiguous) common subsequence (LCS) and the length of the longer token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J99-1003.txt | Citing Article:  P09-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Longest Common Subsequence Ratio (LCSR) (Melamed, 1999) of two strings is the ratio of the length of their LCS and the length of the longer string.</S> | Reference Offset:  ['146','147'] | Reference Text:  <S sid = 146 ssid = >The matching predicates in SIMR's current implementation threshold the Longest Common Subsequence Ratio (LCSR).</S><S sid = 147 ssid = >The LCSR of two tokens is the ratio of the length of their longest (not necessarily contiguous) common subsequence (LCS) and the length of the longer token.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J99-1003.txt | Citing Article:  P04-3006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our work is based on a modification of the SIMR bitext mapping algorithm (Melamed, 1999).</S> | Reference Offset:  ['34','107'] | Reference Text:  <S sid = 34 ssid = >The article begins with a geometric interpretation of the bitext mapping problem and a discussion of previous work.</S><S sid = 107 ssid = >SIMR borrows several insights from previous work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J99-1003.txt | Citing Article:  W12-0114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For sentence alignment, the length-based Gale & Church aligner (1993) can be used, or - alternatively - Dan Melamed's GSA-algorithm (Geometric Sentence Alignment; Melamed, 1999).</S> | Reference Offset:  ['376','407'] | Reference Text:  <S sid = 376 ssid = >To reduce such errors, GSA asks Gale & Church's length-based alignment algorithm (Gale and Church 1991a; Michel Simard, personal communication) for a second opinion on any aligned block that is not 1 x 1.</S><S sid = 407 ssid = >To account for the possibility of modularizing the overall alignment task into paragraph alignment followed by sentence alignment, Simard, Foster, and Isabelle (1992) have reported the accuracy of their sentence alignment algorithm when a perfect alignment at the paragraph level is given.</S> | Discourse Facet:  NA | Annotator: Automatic


