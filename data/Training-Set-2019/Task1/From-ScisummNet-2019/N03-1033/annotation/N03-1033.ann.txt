Citance Number: 1 | Reference Article:  N03-1033.txt | Citing Article:  C04-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, Toutanova et al (2003) presented a supervised conditional Markov Model part-of-speech tagger (CMM) which exploited information coming from both left and right contexts.</S> | Reference Offset:  ['26','56'] | Reference Text:  <S sid = 26 ssid = >The situation is reversed for the right-to-left CMM in figure 1(b).</S><S sid = 56 ssid = >In essence, there is no difference between inference on this network and a second-order left-to-right CMM or HMM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N03-1033.txt | Citing Article:  C04-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The algorithms were trained and tested using version 3 of the Penn Treebank, using the training, development, and test split described in Collins (2002) and also employed by Toutanova et al (2003) in testing their supervised tagging algorithm.</S> | Reference Offset:  ['78','154'] | Reference Text:  <S sid = 78 ssid = >We extracted tagged sentences from the parse trees.5 We split the data into training, development, and test sets as in (Collins, 2002).</S><S sid = 154 ssid = >Table 6 contrasts our results with those from Collins (2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N03-1033.txt | Citing Article:  C04-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the future, we will consider making an increase the context-size, which helped Toutanova et al (2003).</S> | Reference Offset:  ['61','99'] | Reference Text:  <S sid = 61 ssid = >Consider the two-node network in figure 2(c).</S><S sid = 99 ssid = >Again, with roughly equivalent feature sets, the left context is better than the right, and the centered context is better than either unidirectional context. line for this task high, while substantial annotator noise creates an unknown upper bound on the task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N03-1033.txt | Citing Article:  P14-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the Stanford POS Tagger (Toutanova et al, 2003) to tokenize and POS tag English and German sentences.</S> | Reference Offset:  ['38','67'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 67 ssid = >These issues are further discussed in Heckerman et al. (2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N03-1033.txt | Citing Article:  E12-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then obtain their POS N-grams from the Stanford POS tagger (Toutanova et al 2003), and count how many of them have the POS N-gram.</S> | Reference Offset:  ['38','108'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 108 ssid = >The count cutoff for this feature was 0 in the first model and 2 for the model in the second row.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N03-1033.txt | Citing Article:  P12-2003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the Stanford tagger (Toutanova et al, 2003 ) v3.1, with the MEMM model.</S> | Reference Offset:  ['38','101'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 101 ssid = >Words surrounding the current word have been occasionally used in taggers, such as (Ratnaparkhi, 1996), Brill’s transformation based tagger (Brill, 1995), and the HMM model of Lee et al. (2000), but nevertheless, the only lexicalization consistently included in tagging models is the dependence of the part of speech tag of a word on the word itself.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N03-1033.txt | Citing Article:  N10-1129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the discriminative distortion models, we tag the pre-processed input using the log-linear POS tagger of Toutanova et al (2003).</S> | Reference Offset:  ['84','86'] | Reference Text:  <S sid = 84 ssid = >The per-state models in this paper are log-linear models, building upon the models in (Ratnaparkhi, 1996) and (Toutanova and Manning, 2000), though some models are in fact strictly simpler.</S><S sid = 86 ssid = >In this section, we report experiments using log-linear CMMs to populate nets with various structures, exploring the relative value of neighboring words’ tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N03-1033.txt | Citing Article:  C10-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the log-linear tagger of Toutanova et al (2003), which gives 96.8% accuracy on the test set.</S> | Reference Offset:  ['93','115'] | Reference Text:  <S sid = 93 ssid = >Model L+R, using both tags simultaneously (but with only the individual-direction features) gives a much better accuracy of 96.57%.</S><S sid = 115 ssid = >BEST has a token accuracy on the final test set of 97.24% and a sentence accuracy of 56.34% (see Table 4).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N03-1033.txt | Citing Article:  P08-2012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also added part of speech (POS) tags to the data using the tagger of Toutanova et al (2003), and used the tags to decide if mentions were plural or singular.</S> | Reference Offset:  ['77','98'] | Reference Text:  <S sid = 77 ssid = >The part of speech tagged data used in our experiments is the Wall Street Journal data from Penn Treebank III (Marcus et al., 1994).</S><S sid = 98 ssid = >Models LL, RR, and CR use only the vertical features and a single set of tag-triple features: the left tags (t−2, t−1 and t0), right tags (t0, t+1, t+2), or centered tags (t−1, t0, t+1) respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N03-1033.txt | Citing Article:  W11-1515.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Text is tagged using the Stanford POS tagger (Toutanova et al, 2003).</S> | Reference Offset:  ['38','77'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 77 ssid = >The part of speech tagged data used in our experiments is the Wall Street Journal data from Penn Treebank III (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N03-1033.txt | Citing Article:  D10-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Decoding is performed with the Viterbi algorithm. We also evaluate state-of-the-art Maximum Entropy taggers: the Stanford Left tagger (Toutanova and Manning, 2000).</S> | Reference Offset:  ['84','97'] | Reference Text:  <S sid = 84 ssid = >The per-state models in this paper are log-linear models, building upon the models in (Ratnaparkhi, 1996) and (Toutanova and Manning, 2000), though some models are in fact strictly simpler.</S><S sid = 97 ssid = >High-performance taggers typically also include joint three-tag counts in some way, either as tag trigrams (Brants, 2000) or tag-triple features (Ratnaparkhi, 1996, Toutanova and Manning, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N03-1033.txt | Citing Article:  P08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then perform POS tagging using the Stanford POS tagger (Toutanova et al, 2003).</S> | Reference Offset:  ['38','67'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 67 ssid = >These issues are further discussed in Heckerman et al. (2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N03-1033.txt | Citing Article:  P13-2112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We tag the source language with the Stanford POS tagger (Toutanova et al, 2003).</S> | Reference Offset:  ['38','67'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 67 ssid = >These issues are further discussed in Heckerman et al. (2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N03-1033.txt | Citing Article:  W07-1516.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They surpassed their earlier work in 2003 with acyclic dependency network tagger, achieving 97.2% /89.05% (seen/unseen) (Toutanova et al, 2003).</S> | Reference Offset:  ['38','68'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 68 ssid = >Preliminary work of ours suggests that practical use of dependency networks is not in general immune to these theoretical concerns: a dependency network can choose a sequence model that is bidirectionally very consistent but does not match the data very well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N03-1033.txt | Citing Article:  W11-0710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Text was tagged using the Stanford POS tagger (Toutanova et al., 2003).</S> | Reference Offset:  ['38','77'] | Reference Text:  <S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S><S sid = 77 ssid = >The part of speech tagged data used in our experiments is the Wall Street Journal data from Penn Treebank III (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N03-1033.txt | Citing Article:  P12-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >All data is tokenized, POS tagged (Toutanova et al, 2003) and lemmatized, resulting in 341,557 sense definitions and 3,563,649 words.</S> | Reference Offset:  ['40','77'] | Reference Text:  <S sid = 40 ssid = >In this sense, the semantics are the same as for standard Bayes’ nets.</S><S sid = 77 ssid = >The part of speech tagged data used in our experiments is the Wall Street Journal data from Penn Treebank III (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N03-1033.txt | Citing Article:  P07-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our system reports an error rate of 2.67% on the standard PTB test set, a relative 3.3% error reduction of the previous best system (Toutanova et al, 2003) by using fewer features.</S> | Reference Offset:  ['18','31'] | Reference Text:  <S sid = 18 ssid = >This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins (2002), using the same data splits, and a larger error reduction of 12.1% from the more similar best previous loglinear model in Toutanova and Manning (2000).</S><S sid = 31 ssid = >The word to has only one tag (TO) in the PTB tag set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N03-1033.txt | Citing Article:  P07-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Toutanova et al (2003) reported a POS tagger based on cyclic dependency network.</S> | Reference Offset:  ['0','38'] | Reference Text:  <S sid = 0 ssid = >Feature-Rich Part-Of-Speech Tagging With A Cyclic Dependency Network</S><S sid = 38 ssid = >Rather, it is a more general dependency network (Heckerman et al., 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N03-1033.txt | Citing Article:  P07-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','165'] | Reference Text:  <S sid = 61 ssid = >Consider the two-node network in figure 2(c).</S><S sid = 165 ssid = >IIS-0085896, and by an IBM Faculty Partnership Award.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N03-1033.txt | Citing Article:  P07-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Compared to previous best result on the same dataset, 2.76% by (Toutanova et al, 2003), our best result shows a relative error reduction of 3.3%.</S> | Reference Offset:  ['2','18'] | Reference Text:  <S sid = 2 ssid = >Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result.</S><S sid = 18 ssid = >This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins (2002), using the same data splits, and a larger error reduction of 12.1% from the more similar best previous loglinear model in Toutanova and Manning (2000).</S> | Discourse Facet:  NA | Annotator: Automatic


