Citance Number: 1 | Reference Article:  P08-1066.txt | Citing Article:  D08-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both language-model and translation-model adaptation are implemented on top of a hierarchical Arabic-to-English translation system with string-to dependency rules as described in Shen et al (2008).</S> | Reference Offset:  ['0','198'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 198 ssid = >Charniak et al. (2003) described a two-step stringto-CFG-tree translation model which employed a syntax-based language model to select the best translation from a target parse forest built in the first step.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P08-1066.txt | Citing Article:  D08-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition to the features described in Shen et al (2008), a new feature is added to the model for the bias rule weight, allowing the translation system to effectively tune the probability of the rules added by translation model adaptation in order to improve performance on the tuning set.</S> | Reference Offset:  ['0','165'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 165 ssid = >The values of the first four features are accumulated on the rules used in a translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P08-1066.txt | Citing Article:  W11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The string-to-tree (Galleyet al 2006) and tree-to-tree (Chiang, 2010) methods have also been the subject of experimentation, as well as other formalisms such as Dependency Trees (Shen et al, 2008).</S> | Reference Offset:  ['21','107'] | Reference Text:  <S sid = 21 ssid = >Galley et al. (2006) extended this string-to-tree model by using Context-Free parse trees to represent the target side.</S><S sid = 107 ssid = >Next we introduce the four tree operations on dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P08-1066.txt | Citing Article:  P09-2031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Shen et al (2008) proposed a string-to-dependency model, which restricted the target-side of a rule by dependency structures.</S> | Reference Offset:  ['0','9'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 9 ssid = >We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P08-1066.txt | Citing Article:  N12-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The MT system we used is based on a phrase-based hierarchical model similar to that of Shen et al (2008).</S> | Reference Offset:  ['133','201'] | Reference Text:  <S sid = 133 ssid = >',ï¿½ phrase alignments, where source phrase P ?</S><S sid = 201 ssid = >This dependency LM can also be used in hierarchical MT systems using lexicalized CFG trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P08-1066.txt | Citing Article:  D11-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Shen et al, 2008) presents a string-to-dependency model, which restricts the target side of each hierarchical rule to be a well-formed dependency tree fragment, and employs a dependency language model to make the output more grammatically.</S> | Reference Offset:  ['0','9'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 9 ssid = >We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P08-1066.txt | Citing Article:  D11-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Shen et al, 2008) extends the hierarchical phrase-based model and present a string-to-dependency model, which employs string-to-dependency rules whose source side are string and the target as well-formed dependency structures.</S> | Reference Offset:  ['9','26'] | Reference Text:  <S sid = 9 ssid = >We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.</S><S sid = 26 ssid = >Hiero can be viewed as a hierarchical string-to-string model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P08-1066.txt | Citing Article:  D09-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We take BBN's HierDec, a string-to-dependency decoder as described in (Shen et al, 2008), as our baseline for the following two reasons: It provides a strong baseline, which ensures the validity of the improvement we would obtain.</S> | Reference Offset:  ['12','190'] | Reference Text:  <S sid = 12 ssid = >For comparison purposes, we replicated the Hiero decoder (Chiang, 2005) as our baseline.</S><S sid = 190 ssid = >On decoding output, the string-todependency system achieved 1.48 point improvement in BLEU and 2.53 point improvement in TER compared to the baseline hierarchical stringto-string system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P08-1066.txt | Citing Article:  D09-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the original string-to-dependency model (Shen et al, 2008), a translation rule is composed of a string of words and non-terminals on the source side and a well-formed dependency structure on the target side.</S> | Reference Offset:  ['0','9'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 9 ssid = >We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P08-1066.txt | Citing Article:  D09-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thus, we can compute the source dependency LM score in the same way we compute the target side score, using a procedure described in (Shen et al, 2008).</S> | Reference Offset:  ['156','172'] | Reference Text:  <S sid = 156 ssid = >In order to calculate the dependency language model score, or depLM score for short, on the fly for partial hypotheses in a bottom-up decoding, we need to save more information in categories and states.</S><S sid = 172 ssid = >Rescoring We rescore 1000-best translations (Huang and Chiang, 2005) by replacing the 3-gram LM score with the 5-gram LM score computed offline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P08-1066.txt | Citing Article:  D09-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >When extracting rules with source dependency structures, we applied the same well-formedness constraint on the source side as we did on the target side, using a procedure described by (Shen et al, 2008).</S> | Reference Offset:  ['9','24'] | Reference Text:  <S sid = 9 ssid = >We propose a string-to-dependency model for MT, which employs rules that represent the source side as strings and the target side as dependency structures.</S><S sid = 24 ssid = >Both source and target are strings with NTs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P08-1066.txt | Citing Article:  P13-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Shen et al (2008), we distinguish between fixed, floating, and ill-formed structures.</S> | Reference Offset:  ['84','114'] | Reference Text:  <S sid = 84 ssid = >A dependency structure is well-formed if and only if it is either fixed or floating.</S><S sid = 114 ssid = >We can concatenate two fixed structures, one fixed structure with one floating structure, or two floating structures in the same direction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P08-1066.txt | Citing Article:  P13-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Experiments show that our approach significantly outperforms both phrase-based (Koehn et al, 2007) and string-to dependency approaches (Shen et al, 2008) in terms of BLEU and TER.</S> | Reference Offset:  ['64','179'] | Reference Text:  <S sid = 64 ssid = >Based on the results in previous work (DeNeefe et al., 2007), we want to keep two kinds of dependency structures.</S><S sid = 179 ssid = >All models are tuned on BLEU (Papineni et al., 2001), and evaluated on both BLEU and Translation Error Rate (TER) (Snover et al., 2006) so that we could detect over-tuning on one metric.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P08-1066.txt | Citing Article:  P13-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Shen et al (2008), string-to dependency rules without non-terminals can be extracted from the training example.</S> | Reference Offset:  ['126','186'] | Reference Text:  <S sid = 126 ssid = >Now we explain how we get the string-todependency rules from training data.</S><S sid = 186 ssid = >Table 1 shows the number of transfer rules extracted from the training data for the tuning and test sets.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P08-1066.txt | Citing Article:  P13-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is easy to verify that the reduce left and reduce right actions are equivalent to the left adjoining and right adjoining operations defined by Shen et al (2008).</S> | Reference Offset:  ['87','110'] | Reference Text:  <S sid = 87 ssid = >It is easy to verify that the structures in Figures 2 and 3 are well-formed.</S><S sid = 110 ssid = >Figure 5 shows the four operations to combine partial dependency structures, which are left adjoining (LA), right adjoining (RA), left concatenation (LC) and right concatenation (RC).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P08-1066.txt | Citing Article:  W11-2149.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Given a dependency tree of the target language, we are able to introduce language models that span over longer distances than the usual n-grams, as in (Shen et al, 2008).</S> | Reference Offset:  ['16','107'] | Reference Text:  <S sid = 16 ssid = >Section 3 illustrates of the use of dependency language models.</S><S sid = 107 ssid = >Next we introduce the four tree operations on dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P08-1066.txt | Citing Article:  W11-2149.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Shen et al (2008) use only phrases that meet certain restrictions.</S> | Reference Offset:  ['97','202'] | Reference Text:  <S sid = 97 ssid = >If we can combine two categories with a certain category operation, we can use a corresponding tree operation to combine two dependency structures.</S><S sid = 202 ssid = >The use of a dependency LM in MT is similar to the use of a structured LM in ASR (Xu et al., 2002), which was also designed to exploit long-distance relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P08-1066.txt | Citing Article:  N12-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our machine translation system is a string-to dependency hierarchical decoder based on (Shen et al., 2008) and (Chiang, 2007).</S> | Reference Offset:  ['0','64'] | Reference Text:  <S sid = 0 ssid = >A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model</S><S sid = 64 ssid = >Based on the results in previous work (DeNeefe et al., 2007), we want to keep two kinds of dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P08-1066.txt | Citing Article:  D10-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Furthermore, we used a state of the art string-to-tree decoder (Shen et al, 2008) to establish the strongest possible baseline.</S> | Reference Offset:  ['12','93'] | Reference Text:  <S sid = 12 ssid = >For comparison purposes, we replicated the Hiero decoder (Chiang, 2005) as our baseline.</S><S sid = 93 ssid = >Furthermore, we combine partial dependency structures in a way such that we can obtain all possible well-formed but no ill-formed dependency structures during bottom-up decoding.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P08-1066.txt | Citing Article:  D10-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To establish strong baselines, we used a string-to tree SMT system (Shen et al, 2008), one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data.</S> | Reference Offset:  ['180','201'] | Reference Text:  <S sid = 180 ssid = >We used part of the NIST 2006 ChineseEnglish large track data as well as some LDC corpora collected for the DARPA GALE program (LDC2005E83, LDC2006E34 and LDC2006G05) as our bilingual training data.</S><S sid = 201 ssid = >This dependency LM can also be used in hierarchical MT systems using lexicalized CFG trees.</S> | Discourse Facet:  NA | Annotator: Automatic


