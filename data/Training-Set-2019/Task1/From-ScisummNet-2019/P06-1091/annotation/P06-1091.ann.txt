Citance Number: 1 | Reference Article:  P06-1091.txt | Citing Article:  N07-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >2.</S><S sid = 213 ssid = >The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1091.txt | Citing Article:  N07-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Tillmann and Zhang, 2006) the model is optimized to produce a block orientation and the target sentence is used only for computing a sentence level BLEU.</S> | Reference Offset:  ['36','133'] | Reference Text:  <S sid = 36 ssid = >This block set is used to decode training sentence to obtain block orientation sequences that are used in the discriminative parameter training.</S><S sid = 133 ssid = >1 used in our model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1091.txt | Citing Article:  P13-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It might be the case that a larger k-best, or revisiting previous strategies for y+ and y− selection, such as bold updating, local updating (Liang et al, 2006b), or maxBLEU updating (Tillmann and Zhang, 2006) might have a greater impact.</S> | Reference Offset:  ['142','194'] | Reference Text:  <S sid = 142 ssid = >The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S><S sid = 194 ssid = >The work in this paper substantially differs from previous work in SMT based on the noisy channel approach presented in (Brown et al., 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1091.txt | Citing Article:  P12-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Exceptions where discriminative SMT has been used on large training data are Liang et al. (2006a) who trained 1.5 million features on 67,000 sentences, Blunsom et al. (2008) who trained 7.8 million rules on 100,000 sentences, or Tillmann and Zhang (2006) who used 230,000 sentences for training.</S> | Reference Offset:  ['142','176'] | Reference Text:  <S sid = 142 ssid = >The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S><S sid = 176 ssid = >The ’SWAP’ re-ordering uses the same features as the monotone models plus additional orientation-based and distortionBLEU on the training data ( sentences) and the MT03 test data (670 sentences). based features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1091.txt | Citing Article:  W07-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tillmann and Zhang (2006) use a BLEU oracle decoder for discriminative training of a local reordering model.</S> | Reference Offset:  ['39','154'] | Reference Text:  <S sid = 39 ssid = >Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S><S sid = 154 ssid = >This step does not require the use of a decoder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1091.txt | Citing Article:  P08-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The translation probability can also be discriminatively trained such as in Tillmann and Zhang (2006).</S> | Reference Offset:  ['26','39'] | Reference Text:  <S sid = 26 ssid = >Such probability features include language model, translation or distortion probabilities, which are commonly used in current SMT approaches 1.</S><S sid = 39 ssid = >Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1091.txt | Citing Article:  D07-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tillmann and Zhang (2006) describe a perceptron style algorithm for training millions of features.</S> | Reference Offset:  ['23','52'] | Reference Text:  <S sid = 23 ssid = >The advantage of this approach is that it can easily handle tens of millions of features, e.g. up to million features for the experiments in this paper.</S><S sid = 52 ssid = >Although the training algorithm can handle realvalued features as used in (Och, 2003; Tillmann and Zhang, 2005) the current paper intentionally excludes them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1091.txt | Citing Article:  D07-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both Liang, et al (2006), and Tillmann and Zhang (2006) report on effective machine translation (MT) models involving large numbers of features with discriminatively trained weights.</S> | Reference Offset:  ['63','142'] | Reference Text:  <S sid = 63 ssid = >These features correspond to the use of a language model, but the weights for theses features are trained on the parallel training data only.</S><S sid = 142 ssid = >The block set is generated using a phrase-pair selection algorithm similar to (Koehn et al., 2003; Al-Onaizan et al., 2004), which includes some heuristic filtering to mal statement here.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1091.txt | Citing Article:  D08-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >2.</S><S sid = 213 ssid = >The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >2.</S><S sid = 213 ssid = >The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tillmann and Zhang (2006) trained their feature set using an on line discriminative algorithm.</S> | Reference Offset:  ['39','135'] | Reference Text:  <S sid = 39 ssid = >Rather than predicting local block neighbors as in (Tillmann and Zhang, 2005) , here the model parameters are trained in a global setting.</S><S sid = 135 ssid = >Using this feature representation and the loss function in Eq.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tillmann and Zhang (2006) avoided the problem by precomputing the oracle translations in advance.</S> | Reference Offset:  ['9','67'] | Reference Text:  <S sid = 9 ssid = >A block is a pair of phrases which are translations of each other.</S><S sid = 67 ssid = >In the training data where target translations are given, a BLEU score can be calculated for each against the target translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1091.txt | Citing Article:  D07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >2.</S><S sid = 213 ssid = >The authors would like to thank the anonymous reviewers for their detailed criticism on this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1091.txt | Citing Article:  W07-0716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, some max-margin methods restrict their computations to a set of examples from a feasible set, where they are expected to be maximally discriminative (Tillmann and Zhang, 2006).</S> | Reference Offset:  ['36','96'] | Reference Text:  <S sid = 36 ssid = >This block set is used to decode training sentence to obtain block orientation sequences that are used in the discriminative parameter training.</S><S sid = 96 ssid = >We refer to this formulation as ’costMargin’ (cost-sensitive margin) method: for each training sentence the ’costMargin’ between the ’true’ block sequence set and the ’alternative’ block sequence set is maximized.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P06-1091.txt | Citing Article:  W07-0716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This might prove beneficial for various discriminative training methods (Tillmann and Zhang, 2006).</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >A Discriminative Global Training Algorithm For Statistical MT</S><S sid = 27 ssid = >We are able to achieve comparable performance to (Tillmann and Zhang, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P06-1091.txt | Citing Article:  D10-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is the main motivation of (Tillmann and Zhang,2006), where the authors compute high BLEU hypotheses by running a conventional decoder so as to maximize a per-sentence approximation of BLEU-4, under a simple (local) reordering models.</S> | Reference Offset:  ['40','41'] | Reference Text:  <S sid = 40 ssid = >Starting with a simple model, the training data is decoded multiple times: the weight vector is trained to discriminate block sequences with a high translation score against block sequences with a high BLEU score 2.</S><S sid = 41 ssid = >The high BLEU scoring block sequences are obtained as follows: the regular phrase-based decoder is modified in a way that it uses the BLEU score as optimization criterion (independent of any translation model).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P06-1091.txt | Citing Article:  D09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tillmann and Zhang (2006) present a procedure to directly optimize the global scoring function used by a phrase based decoder on the accuracy of the translations.</S> | Reference Offset:  ['2','178'] | Reference Text:  <S sid = 2 ssid = >The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder.</S><S sid = 178 ssid = >For the results with word-based features, the decoder still generates phrase-to-phrase translations, but all the scoring is done on the word level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P06-1091.txt | Citing Article:  W12-3160.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is referred to in past work as maxBLEU (Tillmann and Zhang, 2006) (MB).</S> | Reference Offset:  ['27','194'] | Reference Text:  <S sid = 27 ssid = >We are able to achieve comparable performance to (Tillmann and Zhang, 2005).</S><S sid = 194 ssid = >The work in this paper substantially differs from previous work in SMT based on the noisy channel approach presented in (Brown et al., 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


