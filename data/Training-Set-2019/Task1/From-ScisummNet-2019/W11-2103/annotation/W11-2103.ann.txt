Citance Number: 1 | Reference Article:  W11-2103.txt | Citing Article:  W11-2139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Despite avoiding language-specific resources and using only the training data provided by the workshop, an extensive manual evaluation determined that the outputs produced were of significantly higher quality than both statistical and rule-based systems that made use of language-specific resources (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','274'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 274 ssid = >This year was also the first time that we included a language pair (Haitian-English) with non-European source language and with very limited resources for the source language side.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W11-2103.txt | Citing Article:  W12-3106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Spearman's rank correlation coefficients on the document (system) level between all the metrics and the human ranking are computed on the English, French, Spanish, German and Czech texts generated by various translation systems in the frame work of the third (Callison-Burch et al, 2008), fourth (Callison-Burch et al, 2009), fifth (Callison Burch et al, 2010) and sixth (Callison-Burch et al, 2011) shared translation tasks.</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W11-2103.txt | Citing Article:  N12-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >And researchers have grown increasingly concerned that automatic metrics have a strong bias towards preferring statistical translation outputs; the NIST (2008, 2010), MATR (Gao et al, 2010) and WMT (Callison-Burch et al, 2011) evaluations held during the last five years have provided ample evidence that automatic metrics yield results that are inconsistent with human evaluations when comparing statistical, rule-based, and human outputs.</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W11-2103.txt | Citing Article:  E12-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Provided for the Sixth EMNLP Workshop on Statistical Machine Translation (Callison-Burch et al 2011) extracted from the annotated NPs in the Penn Tree bank 3.0 corpus.</S> | Reference Offset:  ['0','7'] | Reference Text:  <S sid = 0 ssid = >Findings of the 2011 Workshop on Statistical Machine Translation</S><S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W11-2103.txt | Citing Article:  W12-3146.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These systems have been dominating the area in the recent years (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W11-2103.txt | Citing Article:  P12-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >2 Domain Source Target# Test Language Language sets Europarl (Koehn, 2005) Fr, De, Es En 4 En Fr, De, Es KFTT (Neubig, 2011) Jp, En En, Jp 2 EMEA (Tiedemann, 2009) Da, De En 4 News (Callison-Burch et al, 2011) Cz, En, Fr, De, Es Cz, En, Fr, De, Es 3Table 2: The translation systems used for the curve fitting experiments, comprising 30 language-pair and do main combinations for a total of 96 learning curves.</S> | Reference Offset:  ['24','84'] | Reference Text:  <S sid = 24 ssid = >A total of 110 articles were selected, in roughly equal amounts from a variety of Czech, English, French, German, and Spanish news sites:2 Czech: aktualne.cz (4), Novinky.cz (7), iHNed.cz (4), iDNES.cz (4) French: Canoe (5), Le Devoir (5), Le Monde (5), Les Echos (5), Liberation (5) Spanish: ABC.es (6), Cinco Dias (6), El Periodico (6), Milenio (6), Noroeste (7) English: Economist (4), Los Angeles Times (6), New York Times (4), Washington Post (4) German: FAZ (3), Frankfurter Rundschau (2), Financial Times Deutschland (3), Der Spiegel (5), SÂ¨uddeutsche Zeitung (3) The translations were created by the professional translation agency CEET.3 All of the translations were done directly, and not via an intermediate language.</S><S sid = 84 ssid = >I live Mw rele [FIRSTNAME], mw f`e mason epi mw abite lapl`en.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W11-2103.txt | Citing Article:  W12-3101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Callison-Burch et al, 2011) The workshop's human evaluation component has been gradually refined over several years, and as a consequence it has produced a fantastic collection of publicly available data consisting primarily of pairwise judgements of translation systems made by human assessors across a wide variety of languages and tasks.</S> | Reference Offset:  ['7','277'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 277 ssid = >As in previous years, all data sets generated by this workshop, including the human judgments, system translations and automatic scores, are publicly available for other researchers to analyze.8</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W11-2103.txt | Citing Article:  W12-3101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The tables in the Appendix of Callison-Burch et al (2011) report p-values of up to 1%, computed for every pairwise comparison in the dataset.</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W11-2103.txt | Citing Article:  W12-3102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For comparison, the WMT11 rows contain the results from the European languages individual systems task (Callison-Burch et al (2011), Table 7).</S> | Reference Offset:  ['7','193'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 193 ssid = >We start by examining the results for the individual system track for the European languages (Table 8).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W11-2103.txt | Citing Article:  P12-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >shared pilot task, this did not hold (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W11-2103.txt | Citing Article:  D12-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To measure the impact of different rest costs, we use the Moses chart decoder (Koehn et al 2007) for the WMT 2011 German-English translation task (Callison-Burch et al 2011).</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W11-2103.txt | Citing Article:  W12-4202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although the purely data-driven approaches achieve significant results as shown in the evaluation campaigns (Callison-Burch et al, 2011), according to the human evaluation, the final outputs of the SMT systems are still far from satisfactory.</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W11-2103.txt | Citing Article:  D12-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The goal of our experiments is to demonstrate the behaviour of the decoder and characterise its response to changes in the fundamental search parameters. The SMT models for our experiments were created with a subset of the training data for the English-French shared task at the WMT 2011 workshop (Callison-Burch et al 2011).</S> | Reference Offset:  ['7','256'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 256 ssid = >They ran Z-MERT on the dev set with the provided decoder/models, and created a weight vector for the system parameters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W11-2103.txt | Citing Article:  W12-4403.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The example is taken from the parallel corpus of English and Haitian Kre`yol text messages used in the 2010 Shared Task for the Workshop on Machine Translation (Callison-Burch et al, 2011), which is the corpus used for evaluation in this paper.</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W11-2103.txt | Citing Article:  P12-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W11-2103.txt | Citing Article:  S12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Inter-annotator agreement was computed using an adaptation of the kappa index with pairwise rank comparisons (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','169'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 169 ssid = >First of all, intra-annotator agreement is higher than inter-annotator agreement.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W11-2103.txt | Citing Article:  S12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','204'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 204 ssid = >Our evaluation shared task is similar to the MetricsMATR workshop (Metrics for MAchine TRanslation) that NIST runs (Przybocki et al., 2008; Callison-Burch et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W11-2103.txt | Citing Article:  W12-0704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the Haitian Creole English experiments we used the SMS corpus released for WMT11 (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','45'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 45 ssid = >The featured translation task of WMT11 was to translate Haitian Creole SMS messages into English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W11-2103.txt | Citing Article:  P12-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It has been shown to give better correlations than BLEU for many European languages including English (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','237'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 237 ssid = >The correlations are shown in Table 14 for translations into English, and Table 15 out of English, sorted by average correlation across the four language pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W11-2103.txt | Citing Article:  W12-3124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Extensions of the last two are included in this study together with alignments based on hidden Markov model (HMM) (Vogel et al, 1996) and inversion transduction grammars (ITG) (Wu, 1997). System combinations produced via confusion net work decoding using different hypothesis alignment algorithms have been entered into open evaluations, most recently in 2011 Workshop on Statistical Machine Translation (Callison-Burch et al, 2011).</S> | Reference Offset:  ['7','29'] | Reference Text:  <S sid = 7 ssid = >This workshop builds on five previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010).</S><S sid = 29 ssid = >To lower the barrier of entry for newcomers to the field, we provided two open source toolkits for phrase-based and parsing-based statistical machine translation (Koehn et al., 2007; Li et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


