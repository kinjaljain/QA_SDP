Citance Number: 1 | Reference Article:  W07-1604.txt | Citing Article:  I08-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recently, Han et al (2004, 2006) use a maximum entropy classifier to propose article corrections in TESOL essays, while Izumi et al (2003) and Chodorow et al (2007) present techniques of automatic preposition choice modeling.</S> | Reference Offset:  ['3','36'] | Reference Text:  <S sid = 3 ssid = >To address this problem, we use a maximum entropy classifier combined with rule-based filters to detect preposition errors in a corpus of student essays.</S><S sid = 36 ssid = >Izumi et al. (2003) and (2004) used errorannotated transcripts of Japanese speakers in an interview-based test of spoken English to train a maximum entropy classifier (Ratnaparkhi, 1998) to recognize 13 different types of grammatical and lexical errors, including errors involving prepositions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-1604.txt | Citing Article:  I08-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chodorow et al (2007) present numbers on an independently developed system for detection of preposition error in non-native English.</S> | Reference Offset:  ['1','7'] | Reference Text:  <S sid = 1 ssid = >This paper presents ongoing work on the detection of preposition errors of non-native speakers of English.</S><S sid = 7 ssid = >In particular, preposition usage is one of the most difficult aspects of English grammar for non-native speakers to master.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-1604.txt | Citing Article:  I08-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a first human evaluation of our system prototype, we decided to Chodorow et al (2007) evaluate their system on.</S> | Reference Offset:  ['103','112'] | Reference Text:  <S sid = 103 ssid = >Each preposition in these essays was judged for correctness of usage by one or two human raters.</S><S sid = 112 ssid = >Both precision and recall are low in these comparisons to the human raters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-1604.txt | Citing Article:  W09-2110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chodorow et al (2007) employed a maximum entropy model to estimate the probability of 34 prepositions based on 25 local context features ranging from words to NP/VP chunks.</S> | Reference Offset:  ['43','50'] | Reference Text:  <S sid = 43 ssid = >To detect the first type of error, incorrect selection, we have employed a maximum entropy (ME) model to estimate the probability of each of 34 prepositions, based on the features in their local contexts.</S><S sid = 50 ssid = >The maximum entropy model was trained with 25 contextual features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-1604.txt | Citing Article:  W09-2107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al, 2004) and prepositions (Chodorow et al., 2007).</S> | Reference Offset:  ['9','36'] | Reference Text:  <S sid = 9 ssid = >They represented the largest category, about 29%, of all the errors by 53 intermediate to advanced ESL students (Bitchener et al., 2005), and 18% of all errors reported in an intensive analysis of one Japanese writer (Murata and Ishara, 2004).</S><S sid = 36 ssid = >Izumi et al. (2003) and (2004) used errorannotated transcripts of Japanese speakers in an interview-based test of spoken English to train a maximum entropy classifier (Ratnaparkhi, 1998) to recognize 13 different types of grammatical and lexical errors, including errors involving prepositions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-1604.txt | Citing Article:  C08-2008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Chodorow et al, 2007) present a system for detecting errors in English prepositions using machine learning.</S> | Reference Offset:  ['14','136'] | Reference Text:  <S sid = 14 ssid = >We present an approach that combines machine learning with rule-based filters to detect preposition errors in a corpus of ESL essays.</S><S sid = 136 ssid = >Using more training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-1604.txt | Citing Article:  C10-2103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chodorow and Leacock (2000) and Chodorow et al (2007) argue that precision-oriented is better, but they do not give any concrete reason.</S> | Reference Offset:  ['15','141'] | Reference Text:  <S sid = 15 ssid = >Even though this is work in progress, we achieve precision of 0.8 with a recall of 0.3.</S><S sid = 141 ssid = >That is, prediction is better for prepositions that have many examples in the training set and worse for those with fewer examples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-1604.txt | Citing Article:  C10-2157.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chodorow et al (2007) instead treat it as a classification problem and employed a maximum entropy classifier.</S> | Reference Offset:  ['3','43'] | Reference Text:  <S sid = 3 ssid = >To address this problem, we use a maximum entropy classifier combined with rule-based filters to detect preposition errors in a corpus of student essays.</S><S sid = 43 ssid = >To detect the first type of error, incorrect selection, we have employed a maximum entropy (ME) model to estimate the probability of each of 34 prepositions, based on the features in their local contexts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-1604.txt | Citing Article:  P10-2065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The work of Chodorow et al (2007) and T & C 08 treat the tasks of preposition selection and error detection as a classification problem.</S> | Reference Offset:  ['91','116'] | Reference Text:  <S sid = 91 ssid = >There were two other common sources of classification error: antonyms and benefactives.</S><S sid = 116 ssid = >To address the problem of low recall, we have targeted another type of ESL preposition error: extraneous prepositions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-1604.txt | Citing Article:  P10-2065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A context is represented by 25 lexical features and 4 combination features: Lexical Token and POS n-grams in a 2 word window around the preposition, plus the head verb in the preceding verb phrase (PV), the head noun in the preceding noun phrase (PN) and the head noun in the following noun phrase (FN) when available (Chodorow et al, 2007).</S> | Reference Offset:  ['54','139'] | Reference Text:  <S sid = 54 ssid = >PHR pre is the “preceding phrase” feature that indicates whether the preposition was preceded by a noun phrase (NP) or a verb phrase (VP).</S><S sid = 139 ssid = >Many fairly common combinations of Verb+Preposition+Noun or Noun+Preposition+Noun are simply not attested, even in a sizable corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-1604.txt | Citing Article:  P08-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Research on automatic grammar correction has been conducted on a number of different parts-of speech, such as articles (Knight and Chander, 1994) and prepositions (Chodorow et al, 2007).</S> | Reference Offset:  ['12','19'] | Reference Text:  <S sid = 12 ssid = >The goal of the research described here is to provide software for detecting common grammar and usage errors in the English writing of non-native English speakers.</S><S sid = 19 ssid = >In English, prepositions appear in adjuncts, they mark the arguments of predicates, and they combine with other parts of speech to express new meanings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-1604.txt | Citing Article:  P08-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Automatic error detection has been performed on other parts-of-speech, e.g., articles (Knight and Chander, 1994) and prepositions (Chodorow et al,2007).</S> | Reference Offset:  ['0','19'] | Reference Text:  <S sid = 0 ssid = >Detection of Grammatical Errors Involving Prepositions</S><S sid = 19 ssid = >In English, prepositions appear in adjuncts, they mark the arguments of predicates, and they combine with other parts of speech to express new meanings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-1604.txt | Citing Article:  C08-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We extend our previous work (Chodorow et al., 2007) by experimenting with combination features, as well as features derived from the Google N-Gram corpus and Comlex (Grishman et al, 1994). Second, we discuss drawbacks in current methods of annotating ESL data and evaluating error detection systems, which are not limited to preposition errors.</S> | Reference Offset:  ['53','64'] | Reference Text:  <S sid = 53 ssid = >Some features had only a few values while others had many.</S><S sid = 64 ssid = >Table 2 shows an example of where some of the features are derived from.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-1604.txt | Citing Article:  C08-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The baseline system (described in (Chodorow et al, 2007)) performed at 79.8% precision and 11.7% recall.</S> | Reference Offset:  ['4','15'] | Reference Text:  <S sid = 4 ssid = >Although our work is preliminary, we achieve a precision of 0.8 with a recall of 0.3.</S><S sid = 15 ssid = >Even though this is work in progress, we achieve precision of 0.8 with a recall of 0.3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-1604.txt | Citing Article:  C08-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While this improvement may seem small, it is in part due to the difficulty of the problem, but also the high baseline system score that was established in our prior work (Chodorow et al., 2007).</S> | Reference Offset:  ['16','134'] | Reference Text:  <S sid = 16 ssid = >The paper is structured as follows: in the next section, we describe the difficulty in learning English preposition usage; in Section 3, we discuss related work; in Sections 4-7 we discuss our methodology and evaluation.</S><S sid = 134 ssid = >Given this, we chose to set the threshold for the system so that it ensures high precision which in turn resulted in a recall figure (0.3) that leaves us much room for improvement.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-1604.txt | Citing Article:  C08-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, in our previous work (Chodorow et al, 2007), we found that when our system's output was compared to judgments of two different raters, there was a 10% difference in precision and a 5% difference in recall.</S> | Reference Offset:  ['110','112'] | Reference Text:  <S sid = 110 ssid = >In addition, for both raters, precision was much higher than recall.</S><S sid = 112 ssid = >Both precision and recall are low in these comparisons to the human raters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-1604.txt | Citing Article:  W10-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Typically, data-driven approaches to learner errors use a classifier trained on contextual information such as tokens and part-of-speech tags within a window of the preposition/article (Gamon et al 2008, 2010, DeFelice and Pulman 2007, 2008, Han et al 2006, Chodorow et al 2007, Tetreault and Chodorow 2008).</S> | Reference Offset:  ['50','120'] | Reference Text:  <S sid = 50 ssid = >The maximum entropy model was trained with 25 contextual features.</S><S sid = 120 ssid = >Both used POS tags and chunking information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-1604.txt | Citing Article:  P11-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, web-based models built on Google Web1T 5-gram Corpus (Bergsma et al., 2009) achieve better results when compared to a maximum entropy model that uses a corpus 10,000 times smaller (Chodorow et al, 2007).</S> | Reference Offset:  ['3','98'] | Reference Text:  <S sid = 3 ssid = >To address this problem, we use a maximum entropy classifier combined with rule-based filters to detect preposition errors in a corpus of student essays.</S><S sid = 98 ssid = >Another difference between the training corpus and the testing corpus was that the latter contained grammatical errors.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W07-1604.txt | Citing Article:  C08-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chodorow et al (2007) present an approach to preposition error detection which also uses a model based on a maximum entropy classifier trained on a set of contextual features, together with a rule-based filter.</S> | Reference Offset:  ['50','119'] | Reference Text:  <S sid = 50 ssid = >The maximum entropy model was trained with 25 contextual features.</S><S sid = 119 ssid = >To identify extraneous preposition errors we devised two rule-based filters which were based on analysis of the development set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W07-1604.txt | Citing Article:  W10-2921.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Preposition errors are common among new English speakers (Chodorow et al, 2007).</S> | Reference Offset:  ['1','12'] | Reference Text:  <S sid = 1 ssid = >This paper presents ongoing work on the detection of preposition errors of non-native speakers of English.</S><S sid = 12 ssid = >The goal of the research described here is to provide software for detecting common grammar and usage errors in the English writing of non-native English speakers.</S> | Discourse Facet:  NA | Annotator: Automatic


