Citance Number: 1 | Reference Article:  W07-0403.txt | Citing Article:  D07-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, incorporating WSD predictions into an MT decoder based on inversion transduction grammars (Wu, 1997) such as the Bracketing ITG based models of Wu (1996), Zens et al (2004), or Cherry and Lin (2007) would present an intriguing comparison with the present work.</S> | Reference Offset:  ['1','57'] | Reference Text:  <S sid = 1 ssid = >We present a phrasal inversion transduction grammar as an alternative to joint phrasal translation models.</S><S sid = 57 ssid = >Inversion transduction grammar (Wu, 1997), or ITG, is a wellstudied synchronous grammar formalism.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-0403.txt | Citing Article:  P10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cherry and Lin (2007) incorporate phrase pairs in phrase-based SMT into ITG, and Haghighi et al (2009) introduce Block ITG (BITG), which adds 1-to-many or many-to-1 terminal unary rules.</S> | Reference Offset:  ['18','20'] | Reference Text:  <S sid = 18 ssid = >Phrasal decoders require a phrase table (Koehn et al., 2003), which contains bilingual phrase pairs and scores indicating their utility.</S><S sid = 20 ssid = >It extracts all consistent phrase pairs from word-aligned bitext (Koehn et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-0403.txt | Citing Article:  P09-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our first pruning technique is broadly similar to Cherry and Lin (2007a).</S> | Reference Offset:  ['80','105'] | Reference Text:  <S sid = 80 ssid = >Our phrasal ITG is quite similar to the JPTM.</S><S sid = 105 ssid = >We propose a new ITG pruning method that leverages high-confidence links by pruning all spans that are inconsistent with a provided alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-0403.txt | Citing Article:  D09-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For simplicity, we evaluate the objective using an Inversion Transduction Grammar (ITG) (Wu, 1997) that emits phrases as terminal productions, as in (Cherry and Lin, 2007).</S> | Reference Offset:  ['0','57'] | Reference Text:  <S sid = 0 ssid = >Inversion Transduction Grammar for Joint Phrasal Translation Modeling</S><S sid = 57 ssid = >Inversion transduction grammar (Wu, 1997), or ITG, is a wellstudied synchronous grammar formalism.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-0403.txt | Citing Article:  P10-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cherry and Lin (2007) and Zhang et al (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem.</S> | Reference Offset:  ['57','115'] | Reference Text:  <S sid = 57 ssid = >Inversion transduction grammar (Wu, 1997), or ITG, is a wellstudied synchronous grammar formalism.</S><S sid = 115 ssid = >We can use a linear-time algorithm (Zhang et al., 2006) to detect non-ITG movement in our high-confidence links, and remove the offending sentence pairs from our training corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-0403.txt | Citing Article:  P08-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The scope of iterative phrasal ITG training, therefore, is limited to determining the boundaries of the phrases anchored on the given one-to-one word alignments. The heuristic method is based on the Non Compositional Constraint of Cherry and Lin (2007).</S> | Reference Offset:  ['120','145'] | Reference Text:  <S sid = 120 ssid = >We are interested in phrasal alignment because it may be better suited to heuristic phraseextraction than word-based models.</S><S sid = 145 ssid = >The phrases produced with this constraint are very small, and include only non-compositional context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-0403.txt | Citing Article:  P08-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cherry and Lin (2007) use GIZA++ intersections which have high precision as anchor points in the bitext space to constraint ITG phrases.</S> | Reference Offset:  ['97','168'] | Reference Text:  <S sid = 97 ssid = >Also, ITG algorithms explore their alignment space perfectly, but that space has been reduced by the ITG constraint described in Section 2.3.</S><S sid = 168 ssid = >The first thing to note is that GIZA++ Intersection is indeed very high precision.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-0403.txt | Citing Article:  C10-2084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, researches like Cherry and Lin (2007), Haghighi et al (2009) and Zhang et al (2009) tackle this problem by enriching ITG, in addition to word pairs, with pairs of phrases (or blocks).</S> | Reference Offset:  ['20','115'] | Reference Text:  <S sid = 20 ssid = >It extracts all consistent phrase pairs from word-aligned bitext (Koehn et al., 2003).</S><S sid = 115 ssid = >We can use a linear-time algorithm (Zhang et al., 2006) to detect non-ITG movement in our high-confidence links, and remove the offending sentence pairs from our training corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-0403.txt | Citing Article:  P08-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For some restricted combinatorial spaces of alignments those that arise in ITG-based phrase models (Cherry and Lin, 2007) or local distortion models (Zens et al,2004) inference can be accomplished using polynomial time dynamic programs.</S> | Reference Offset:  ['26','199'] | Reference Text:  <S sid = 26 ssid = >This alignment system is powered by the IBM translation models (Brown et al., 1993), in which one sentence generates the other.</S><S sid = 199 ssid = >This syntactic solution to phrase modeling admits polynomial-time training and alignment algorithms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-0403.txt | Citing Article:  C10-2021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, Cherry and Lin (2007) use ITG for pruning.</S> | Reference Offset:  ['105','195'] | Reference Text:  <S sid = 105 ssid = >We propose a new ITG pruning method that leverages high-confidence links by pruning all spans that are inconsistent with a provided alignment.</S><S sid = 195 ssid = >The two methods also produce similarly-sized tables, despite the ITGâ€™s higher recall.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-0403.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Without initializing by phrases extracted from existing alignments (Cherry and Lin, 2007) or using complicated block features (Haghighi et al, 382 2009), we further reduced AER on the test set to 12.25.</S> | Reference Offset:  ['103','180'] | Reference Text:  <S sid = 103 ssid = >Past approaches have pruned spans using IBM Model 1 probability estimates (Zhang and Gildea, 2005) or using agreement with an existing parse tree (Cherry and Lin, 2006).</S><S sid = 180 ssid = >Results on the provided 2000sentence development set are reported using the BLEU metric (Papineni et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


