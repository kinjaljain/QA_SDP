Citance Number: 1 | Reference Article:  C00-1007.txt | Citing Article:  W08-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >FERGUS (Bangalore and Rambow,2000) took dependency structures as inputs, and produced XTAG derivations by a stochastic tree model automatically acquired from an annotated corpus.</S> | Reference Offset:  ['3','144'] | Reference Text:  <S sid = 3 ssid = >We present initial re- suits showing that a tree-based model derived from a tree-annotated corpus improves on a tree model derived from an unannotated corpus, and that a tree-based stochastic model with a hand- crafted grammar outpertbrms both.</S><S sid = 144 ssid = >There is no stochastic tree model, since, the, re, ~tr(, no trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C00-1007.txt | Citing Article:  W04-2208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, we can automatically estimate English word order by using a language model or an English surface sentence generator such as FERGUS (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['182','196'] | Reference Text:  <S sid = 182 ssid = >Two methods tbr 1)re- dieting the order of prenonfinal t~djectives in english.</S><S sid = 196 ssid = >A lexicalized %ee Adjoining Grammar for English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C00-1007.txt | Citing Article:  W11-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More generally, the NLG problem of non-deterministic decision making has been addressed from many different angles, including PENMAN-style choosers (Mann and Matthiessen,1983), corpus-based statistical knowledge (Langkilde and Knight, 1998), tree-based stochastic models (Bangalore and Rambow, 2000), maximum entropy based ranking (Ratnaparkhi, 2000), combinatorial pattern discovery (Duboue and McKeown, 2001), instance-based ranking (Varges, 2003), chart generation (White, 2004), planning (Koller and Stone, 2007), or probabilistic generation spaces (Belz, 2008) to name just a few.</S> | Reference Offset:  ['174','180'] | Reference Text:  <S sid = 174 ssid = >Gen- eration that exploits corpus-based statistical knowledge.</S><S sid = 180 ssid = >Forest-based statistical sentence generation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C00-1007.txt | Citing Article:  C04-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Fergus system (Bangalore and Rambow, 2000) employs a statistical tree model to select probable trees and a word n-gram model to rank the string candidates generated from the best trees.</S> | Reference Offset:  ['40','144'] | Reference Text:  <S sid = 40 ssid = >Trees t;hat can adjoin to other trees (and have entries in the adjunct|on table) ;~re called gamma-trees, the other trees (which can only t)e substituted into other trees) are alpha-trees.</S><S sid = 144 ssid = >There is no stochastic tree model, since, the, re, ~tr(, no trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C00-1007.txt | Citing Article:  P04-3009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Fergus (Bangalore and Rambow, 2000) used the Penn TreeBank as a corpus, requiring a more substantial transformation algorithm since it requires a lexical predicate-argument structure instead of the TreeBank's representation.</S> | Reference Offset:  ['54','151'] | Reference Text:  <S sid = 54 ssid = >As can be seen, this structure is a dependency tree and resembles a representation of lexical argument structure.</S><S sid = 151 ssid = >FERGUS aS presented in this paper is not ready to be used as a module in applications.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C00-1007.txt | Citing Article:  C02-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Stochastic methods for NLG may provide such automaticity, but most previous work (Knight and Hatzivassiloglou, 1995), (Langkilde and Knight, 1998), (Oh and Rudnicky, 2000), (Uchimotoetal., 2000), (Bangalore and Rambow, 2000) concentrate on the specifics of individual stochastic methods, ignoring other issues such as integrability, portability, and efficiency.</S> | Reference Offset:  ['10','13'] | Reference Text:  <S sid = 10 ssid = >To our knowledge, the first to use stochastic techniques in NLG were Langkilde and Knight (1998a) and (1998b).</S><S sid = 13 ssid = >More recent work on aspects of stochastic gen- eration include (Langkilde and Knight, 2000), (Malouf, 1999) and (Ratnaparkhi, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C00-1007.txt | Citing Article:  C02-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We extend the work of (Walker et al., 2001) and (Bangalore and Rambow, 2000) in various ways.</S> | Reference Offset:  ['13','134'] | Reference Text:  <S sid = 13 ssid = >More recent work on aspects of stochastic gen- eration include (Langkilde and Knight, 2000), (Malouf, 1999) and (Ratnaparkhi, 2000).</S><S sid = 134 ssid = >Ado, tail(~d dis(:ussion of these experiments and results is t)r(,s(mto, d in (Bangalore (,|; al., 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C00-1007.txt | Citing Article:  N03-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al, 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['54','134'] | Reference Text:  <S sid = 54 ssid = >As can be seen, this structure is a dependency tree and resembles a representation of lexical argument structure.</S><S sid = 134 ssid = >Ado, tail(~d dis(:ussion of these experiments and results is t)r(,s(mto, d in (Bangalore (,|; al., 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C00-1007.txt | Citing Article:  N09-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These concepts are then realized into words resulting in a bag of words with syntactic relations (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['63','68'] | Reference Text:  <S sid = 63 ssid = >This step can be seen as analogous to "supertag- ging" (Bangalore and Joshi, 1999), except that now supertags (i.e., names of trees) must be fbund tbr words in a tree rather than tbr words in a linear sequence.</S><S sid = 68 ssid = >a The ~IYee Chooser makes the simplifying as- 2In the system that we used in the experiments de- scribed in Section 4, all words (including flmction words) need to be present in tt, e inlmt representation, flflly in- flected.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C00-1007.txt | Citing Article:  P08-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have introduced a novel type of supertagger, which we have dubbed a hypertagger, that assigns CCG category labels to elementary predications in a structured semantic representation with high accuracy at several levels of tagging ambiguity in a fashion reminiscent of (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['114','153'] | Reference Text:  <S sid = 114 ssid = >These metrics, simple accuracy and generation accuracy, allow us to evaluate without human intervention, automatically and objectively.</S><S sid = 153 ssid = >In all three cases, we will provide both knowledge-based and stochas- tic components, with the aim of comparing their behaviors, and using one type as a back-up tbr the other type.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C00-1007.txt | Citing Article:  C02-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['0','40'] | Reference Text:  <S sid = 0 ssid = >Explo i t ing a Probabi l ist ic  Hierarchical Mode l  for Generat ion Srinivas Bangalore and Owen Rambow AT&T Labs Research 180 Park Avenue F lorham Park, NJ 07932 {sr in?,  rambow}@research,  a r t .</S><S sid = 40 ssid = >Trees t;hat can adjoin to other trees (and have entries in the adjunct|on table) ;~re called gamma-trees, the other trees (which can only t)e substituted into other trees) are alpha-trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C00-1007.txt | Citing Article:  W05-1601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','198'] | Reference Text:  <S sid = 73 ssid = >44 estimate there was no cost for phase the second Figure 4: Inlmt to FEII.GUS Smnl)tions that the (:hoice of n tree.</S><S sid = 198 ssid = >upenn, edu/~xtag/ tech- repor t / tech- repor t  .htral, The Insti- tute for Research in Cognitive Science, Uni- versity of Pennsylvania.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C00-1007.txt | Citing Article:  I05-5012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In recent years, there has been a steady stream of research in statistical text generation (see Langkilde and Knight (1998), and Bangalore and Rambow (2000)).</S> | Reference Offset:  ['13','173'] | Reference Text:  <S sid = 13 ssid = >More recent work on aspects of stochastic gen- eration include (Langkilde and Knight, 2000), (Malouf, 1999) and (Ratnaparkhi, 2000).</S><S sid = 173 ssid = >Irene Langkilde and Kevin Knight.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C00-1007.txt | Citing Article:  W04-2311.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','198'] | Reference Text:  <S sid = 73 ssid = >44 estimate there was no cost for phase the second Figure 4: Inlmt to FEII.GUS Smnl)tions that the (:hoice of n tree.</S><S sid = 198 ssid = >upenn, edu/~xtag/ tech- repor t / tech- repor t  .htral, The Insti- tute for Research in Cognitive Science, Uni- versity of Pennsylvania.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C00-1007.txt | Citing Article:  W04-2311.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In other words, in generating a form f to express an input, one wants to maximize the probability of the form, P (f), with respect to some gold-standard corpus, and thus express the in put in a way that resembles the realizations in the corpus most closely (Bangalore and Rambow, 2000).</S> | Reference Offset:  ['104','107'] | Reference Text:  <S sid = 104 ssid = >for our example input.</S><S sid = 107 ssid = >tbr our example input.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C00-1007.txt | Citing Article:  P02-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >FERGUS (Bangalore and Rambow, 2000), on the other hand, employs a model of syntactic structure during sentence realization.</S> | Reference Offset:  ['19','54'] | Reference Text:  <S sid = 19 ssid = >The structure of the paper is as tbllows.</S><S sid = 54 ssid = >As can be seen, this structure is a dependency tree and resembles a representation of lexical argument structure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C00-1007.txt | Citing Article:  W07-0408.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both the model of Amalgam and that presented here differ considerably from the n-gram models of Langkilde and Knight (1998), the TAG models of Bangalore and Rambow (2000), and the stochastic generation from semantic representation approach of Soricutand Marcu (2006).</S> | Reference Offset:  ['13','179'] | Reference Text:  <S sid = 13 ssid = >More recent work on aspects of stochastic gen- eration include (Langkilde and Knight, 2000), (Malouf, 1999) and (Ratnaparkhi, 2000).</S><S sid = 179 ssid = >Irene Langkilde and Kevin Knight.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C00-1007.txt | Citing Article:  P06-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bangalore and Rambow (2000) use n-gram word sequence statistics in a TAG-based generation model to rank output strings and additional statistical and symbolic resources at intermediate generation stages.</S> | Reference Offset:  ['12','180'] | Reference Text:  <S sid = 12 ssid = >FErtGUS follows Langkilde and Knights seminal work in using an n-gram language model, but; we augment it with a tree-based stochastic model and a traditional tree-based syntactic grammar.</S><S sid = 180 ssid = >Forest-based statistical sentence generation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C00-1007.txt | Citing Article:  W05-1612.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','198'] | Reference Text:  <S sid = 73 ssid = >44 estimate there was no cost for phase the second Figure 4: Inlmt to FEII.GUS Smnl)tions that the (:hoice of n tree.</S><S sid = 198 ssid = >upenn, edu/~xtag/ tech- repor t / tech- repor t  .htral, The Insti- tute for Research in Cognitive Science, Uni- versity of Pennsylvania.</S> | Discourse Facet:  NA | Annotator: Automatic


