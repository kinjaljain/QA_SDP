Citance Number: 1 | Reference Article:  W06-1670.txt | Citing Article:  W07-2051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Supersense tagging A WordNet-based supersense tagger (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['31','82'] | Reference Text:  <S sid = 31 ssid = >We define a tagset based on Wordnet’s lexicographers classes, or supersenses (Ciaramita and Johnson, 2003), cf.</S><S sid = 82 ssid = >We take a sequence labeling approach to learning a model for supersense tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-1670.txt | Citing Article:  P14-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['103','208'] | Reference Text:  <S sid = 103 ssid = >For each observed word xi in the data � extracts the following features: described below.</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-1670.txt | Citing Article:  W08-2121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Columns 1 - 3 were predicted using the tagger of Ciaramita and Altun (2006).</S> | Reference Offset:  ['105','208'] | Reference Text:  <S sid = 105 ssid = >The first sense feature (2) is the label predicted for xi by the baseline model, cf.</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-1670.txt | Citing Article:  W07-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >grained distinctions of WN (Hearst and Schutze,1993) (Peters et al, 1998) (Mihalcea and Moldovan, 2001) (Agirre et al, 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997) (Ciaramita and Johnson, 2003) (Villarejo et al, 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['85','208'] | Reference Text:  <S sid = 85 ssid = >The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al., 2000; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-1670.txt | Citing Article:  S10-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997), (Ciaramita and Johnson, 2003), (Villarejo et al, 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['14','208'] | Reference Text:  <S sid = 14 ssid = >80s (Carreras et al., 2002; Florian et al., 2003), while Bio-NER accuracy ranges between the low 70s and 80s, depending on the data-set used for training/evaluation (Dingare et al., 2005).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-1670.txt | Citing Article:  P08-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wherever applicable, we explore different syntactic and semantic representations of the textual content, e.g., extracting the dependency-based representation of the text or generalizing words to their WordNet supersenses (WNSS) (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['31','190'] | Reference Text:  <S sid = 31 ssid = >We define a tagset based on Wordnet’s lexicographers classes, or supersenses (Ciaramita and Johnson, 2003), cf.</S><S sid = 190 ssid = >We defined a tagset based on Wordnet supersenses, a much simpler and general semantic model than Wordnet which, however, preserves significant polysemy information and includes standard named entity recognition categories.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-1670.txt | Citing Article:  P08-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Sentences were annotated with WNSS categories, using the tagger of Ciaramita and Altun (2006), which annotates text with a 46-label tag set.</S> | Reference Offset:  ['115','181'] | Reference Text:  <S sid = 115 ssid = >Named entities of the categories “person”, “location” and “group” are also annotated.</S><S sid = 181 ssid = >On this four tags the tagger achieves an average 82.46% F-score, not too far from NER results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-1670.txt | Citing Article:  W10-2601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the implementation available from http: //sourceforge.net/projects/supersensetag, more details on this tagger can be found in (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['13','171'] | Reference Text:  <S sid = 13 ssid = >The tagger described in this paper is free software and can be downloaded from http://www.loa-cnr.it/ciaramita.html.</S><S sid = 171 ssid = >The system based on the HMM tagger (Molina et al., 2004), 6Scoring was performed with a re-implementation of the “conlleval” script. achieved an F-score of 60.9%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-1670.txt | Citing Article:  W07-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This result is particularly interesting as a supersense tagger can easily provide a satisfactory accuracy (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['182','205'] | Reference Text:  <S sid = 182 ssid = >The lower portion of Table 5 summarizes the results on the five most frequent noun and verb supersense labels on the Senseval-3 data, providing more specific evidence for the supersense tagger’s disambiguation accuracy.</S><S sid = 205 ssid = >Another interesting issue is the granularity of the tagset.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-1670.txt | Citing Article:  P13-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This annotation was performed automatically using the SuperSense Tagger (Ciaramita and Altun, 2006) and includes 1183 named-entities and WordNet Super-Senses.</S> | Reference Offset:  ['115','116'] | Reference Text:  <S sid = 115 ssid = >Named entities of the categories “person”, “location” and “group” are also annotated.</S><S sid = 116 ssid = >The original annotation with Wordnet 1.6 synset IDs has been converted to the most recent version 2.0 of Wordnet.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-1670.txt | Citing Article:  P13-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We recommend mate-tools (Bjorkelund et al, 2009) and SuperSenseTagger (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['85','208'] | Reference Text:  <S sid = 85 ssid = >The limitations of the generative approach to sequence tagging, i. e. Hidden Markov Models, have been overcome by discriminative approaches proposed in recent years (McCallum et al., 2000; Lafferty et al., 2001; Collins, 2002; Altun et al., 2003).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-1670.txt | Citing Article:  P09-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used Ciaramita and Altun's Su per Sense Tagger (Ciaramita and Altun, 2006) to tag the supersenses.</S> | Reference Offset:  ['43','208'] | Reference Text:  <S sid = 43 ssid = >Since each lexicographer category groups together many synsets they have been also called supersenses (Ciaramita and Johnson, 2003).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-1670.txt | Citing Article:  S12-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is the coarse lexicographic category label, elsewhere denoted supersense (Ciaramita and Altun, 2006), which is the terminology we use.</S> | Reference Offset:  ['43','133'] | Reference Text:  <S sid = 43 ssid = >Since each lexicographer category groups together many synsets they have been also called supersenses (Ciaramita and Johnson, 2003).</S><S sid = 133 ssid = >For this reason, in all obvious cases, we substituted the “noun.Tops” label with the more specific supersense label for the noun4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-1670.txt | Citing Article:  S12-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >we use the out puts of SuperSense Tagger (Ciaramita and Altun,2006), which is optimised for assigning the super senses described above, and can outperform a WNF style baseline on at least some datasets.</S> | Reference Offset:  ['93','142'] | Reference Text:  <S sid = 93 ssid = >These features are described in detail in Section 4.2.</S><S sid = 142 ssid = >The supersense tagger was trained on the Semcor datasets SEM and SEMv.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-1670.txt | Citing Article:  P11-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use SuperSenseTagger (Ciaramita and Altun,2006) as our NER tagger.</S> | Reference Offset:  ['97','208'] | Reference Text:  <S sid = 97 ssid = >We use the perceptron algorithm for sequence tagging (Collins, 2002).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-1670.txt | Citing Article:  W07-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SUPERSENSE LEARNER brings together under one system the features previously used in the SENSELEARNER (Mihalcea and Csomai, 2005) and the SUPERSENSE (Ciaramita and Altun, 2006) all-words word sense disambiguation systems.</S> | Reference Offset:  ['18','208'] | Reference Text:  <S sid = 18 ssid = >Word sense disambiguation (WSD) is the task of deciding the intended sense for ambiguous words in context.</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-1670.txt | Citing Article:  W07-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A detailed description of the features used and the tagger can be foundin (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['93','102'] | Reference Text:  <S sid = 93 ssid = >These features are described in detail in Section 4.2.</S><S sid = 102 ssid = >We used the following combination of spelling/morphological and contextual features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-1670.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al, 1997), (Ciaramita and Johnson, 2003), (Villarejo et al, 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['14','208'] | Reference Text:  <S sid = 14 ssid = >80s (Carreras et al., 2002; Florian et al., 2003), while Bio-NER accuracy ranges between the low 70s and 80s, depending on the data-set used for training/evaluation (Dingare et al., 2005).</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-1670.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >WSD are those reported by (Ciaramita and Altun, 2006).</S> | Reference Offset:  ['198','208'] | Reference Text:  <S sid = 198 ssid = >This indicates that sense granularity is only one of the problems in WSD.</S><S sid = 208 ssid = >(Ciaramita et al., 2005)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-1670.txt | Citing Article:  P13-2083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Relations and POS tags are obtained using a dependency parser Tratz and Hovy (2011), supersense tags using sstlight Ciaramita and Altun (2006), and lemmas us 468.</S> | Reference Offset:  ['108','181'] | Reference Text:  <S sid = 108 ssid = >POS features of the form pos;[0] extract the first character from the POS label, thus providing a simplified representation of the POS tag.</S><S sid = 181 ssid = >On this four tags the tagger achieves an average 82.46% F-score, not too far from NER results.</S> | Discourse Facet:  NA | Annotator: Automatic


