Citance Number: 1 | Reference Article:  N04-1035.txt | Citing Article:  C04-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Galley et al (2004) extract translation rules from a large parsed parallel corpus that extend in scope to tree fragments beyond a single node; we believe that adding such larger-scale operations to the translation model is likely to significantly improve the performance of syntactically supervised alignment.</S> | Reference Offset:  ['0','169'] | Reference Text:  <S sid = 0 ssid = >What's In A Translation Rule?</S><S sid = 169 ssid = >Our first algorithm, which has an exponential running time, cannot scale to process large corpora and extract a sufficient number of rules that a syntax-based statistical MT system would require.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N04-1035.txt | Citing Article:  P12-3022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In terms of tree-to-string translation rule extraction, the toolkit implements the traditional maximum likelihood algorithm using PCFG trees (Galley et al, 2004) and HPSG trees/forests (Wu et al, 2010).</S> | Reference Offset:  ['0','112'] | Reference Text:  <S sid = 0 ssid = >What's In A Translation Rule?</S><S sid = 112 ssid = >Rule extraction: Algorithm 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N04-1035.txt | Citing Article:  P12-3022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, we implemented the GHKM algorithm as proposed by Galley et al (2004) from word-aligned tree string pairs.</S> | Reference Offset:  ['62','64'] | Reference Text:  <S sid = 62 ssid = >In other words, a source word is aligned with a target word if the target word is created during the same step in which the source word is replaced.</S><S sid = 64 ssid = >Now, say that we have a source string, a target tree, and an alignment A.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N04-1035.txt | Citing Article:  P11-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['206','207'] | Reference Text:  <S sid = 206 ssid = >We suspect that such probabilistic rules could be also used in conjunction with statistical decoders, to increase the accuracy of statistical machine translation systems.</S><S sid = 207 ssid = >This work was supported by DARPA contract N6600100-1-9814 and MURI grant N00014-00-1-0617.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N04-1035.txt | Citing Article:  P12-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the tree-to-string model, we parsed English sentences using Stanford parser and extracted rules using the GHKM algorithm (Galley et al, 2004).</S> | Reference Offset:  ['140','144'] | Reference Text:  <S sid = 140 ssid = >We evaluated the coverage of our model of transformation rules with two language pairs: English-French and English-Chinese.</S><S sid = 144 ssid = >We performed experiments with two corpora, the FBIS English-Chinese Parallel Text and the Hansard FrenchEnglish corpus.We parsed the English sentences with a state-of-the-art statistical parser (Collins, 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N04-1035.txt | Citing Article:  N09-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al, 2005), constructing syntactic rules for SMT (Galley et al, 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies.</S> | Reference Offset:  ['12','15'] | Reference Text:  <S sid = 12 ssid = >In the face of these problems, we may choose among several alternatives.</S><S sid = 15 ssid = >Along this line, (Koehn et al., 2003) present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance – the ability to translate nonconstituent phrases (such as “there are”, “note that”, and “according to”) turns out to be critical and pervasive.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N04-1035.txt | Citing Article:  C08-1136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >From word level alignments, such systems extract the grammar rules consistent either with the alignments and parse trees for one of languages (Galley et al., 2004), or with the the word-level alignments alone without reference to external syntactic analysis (Chiang, 2005), which is the scenario we address here.</S> | Reference Offset:  ['1','153'] | Reference Text:  <S sid = 1 ssid = >We propose a theory that gives formal semantics to word-level alignments defined over parallel corpora.</S><S sid = 153 ssid = >For the former, we present results for the three alignments: S alignments, P alignments, and the alignments computed by GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N04-1035.txt | Citing Article:  P09-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >algorithm (Galley et al, 2004) to forest-based by introducing non-deterministic mechanism.</S> | Reference Offset:  ['21','25'] | Reference Text:  <S sid = 21 ssid = >After all, many conventional translation systems are indeed based on syntactic transformations far more expressive than what has been proposed in syntax-based statistical MT.</S><S sid = 25 ssid = >In addition to being motivated by rule-based systems, we also see advantages to English syntax within the statistical framework, such as marrying syntax-based translation models with syntaxbased language models (Charniak et al., 2003) and other potential benefits described by Eisner (2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N04-1035.txt | Citing Article:  D09-1136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >GHKM (Galley et al, 2004) is used to generate the baseline TTS templates based on the word alignments computed using GIZA++ and different combination methods, including union and the diagonal growing heuristic (Koehn et al, 2003).</S> | Reference Offset:  ['25','153'] | Reference Text:  <S sid = 25 ssid = >In addition to being motivated by rule-based systems, we also see advantages to English syntax within the statistical framework, such as marrying syntax-based translation models with syntaxbased language models (Charniak et al., 2003) and other potential benefits described by Eisner (2003).</S><S sid = 153 ssid = >For the former, we present results for the three alignments: S alignments, P alignments, and the alignments computed by GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N04-1035.txt | Citing Article:  P05-3025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Galley et al (2004) describe how to learn hundreds of millions of tree transformation rules from a parsed, aligned Chinese/English corpus, and Galley et al (submitted) describe probability estimators for those rules.</S> | Reference Offset:  ['140','188'] | Reference Text:  <S sid = 140 ssid = >We evaluated the coverage of our model of transformation rules with two language pairs: English-French and English-Chinese.</S><S sid = 188 ssid = >To explain the data in two parallel corpora, one English-French, and one English-Chinese, we are often forced to learn rules involving much larger tree fragments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N04-1035.txt | Citing Article:  P05-3025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In order to test whether good translations can be generated with rules learned by Galley et al (2004), we created DerivTool as an environment for interactively using these rules as a decoder would.</S> | Reference Offset:  ['19','59'] | Reference Text:  <S sid = 19 ssid = >If the same unambiguous English sentence were to appear twice in the corpus, with different Chinese translations, then it could have different learned parses.</S><S sid = 59 ssid = >Similarly, for each node t of T, we can define created(t, D) to be the step of derivation D during which t is created.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N04-1035.txt | Citing Article:  D12-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The grammar rules are extracted from bilingual word alignments using the GHKM algorithm (Galley et al., 2004).</S> | Reference Offset:  ['153','159'] | Reference Text:  <S sid = 153 ssid = >For the former, we present results for the three alignments: S alignments, P alignments, and the alignments computed by GIZA++.</S><S sid = 159 ssid = >If we compare the three kinds of alignments available for the Hansard corpus, we see that much more complex transformation rules are extracted from noisy GIZA++ alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N04-1035.txt | Citing Article:  D12-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We aligned the sentence pairs using the GIZA++ toolkit (Och and Ney, 2003) and extracted tree-to-string rules according to the GHKM algorithm (Galley et al 2004).</S> | Reference Offset:  ['145','147'] | Reference Text:  <S sid = 145 ssid = >For the FBIS corpus (representing eight million English words), we automatically generated word-alignments using GIZA++ (Och and Ney, 2003), which we trained on a much larger data set (150 million words).</S><S sid = 147 ssid = >For the Hansard corpus, we took the human annotation of word alignment described in (Och and Ney, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Galley et al (2004) alleviate this modeling problem and present a method for acquiring millions of syntactic transfer rules from bilingual corpora, which we review below.</S> | Reference Offset:  ['123','171'] | Reference Text:  <S sid = 123 ssid = >Thus we have boiled down the problem of extracting complex rules to the following simple problem: find the set of minimal frontier graph fragments of a given alignment graph.</S><S sid = 171 ssid = >In this section, we present some syntactic transformation rules that our system learns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We contrast our work with (Galley et al, 2004), highlight some severe limitations of probability estimates computed from single derivations, and demonstrate that it is critical to account for many derivations for each sentence pair.</S> | Reference Offset:  ['50','125'] | Reference Text:  <S sid = 50 ssid = >However, it is apparent that one of these derivations seems much more “wrong” than the other.</S><S sid = 125 ssid = >Step 1 can be computed in a single traversal of the alignment graph.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we show that our contextually richer rules provide a 3.63 BLEU point increase over those of (Galley et al, 2004).</S> | Reference Offset:  ['157','191'] | Reference Text:  <S sid = 157 ssid = >Allowing more expansions logically expands the coverage of the model, until the point where it is total: transformation rules no larger than 17, 18, 23, and 43 (in number of rule expansions) respectively provide enough coverage to explain the data at 100% for each of the four cases.</S><S sid = 191 ssid = >Our rules provide a good, realistic indicator of the complexities inherent in translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Galley et al (2004) present one such formalism (henceforth 'GHKM').</S> | Reference Offset:  ['15','171'] | Reference Text:  <S sid = 15 ssid = >Along this line, (Koehn et al., 2003) present convincing evidence that restricting phrasal translation to syntactic constituents yields poor translation performance – the ability to translate nonconstituent phrases (such as “there are”, “note that”, and “according to”) turns out to be critical and pervasive.</S><S sid = 171 ssid = >In this section, we present some syntactic transformation rules that our system learns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Formally, transformational rules ri presented in (Galley et al, 2004) are equivalent to 1-state x Rs transducers mapping a given pattern (subtree to match in pi) to a right hand side string.</S> | Reference Offset:  ['27','45'] | Reference Text:  <S sid = 27 ssid = >It is certainly possible to build such rules by hand, and we have done this to formally explain a number of humantranslation examples.</S><S sid = 45 ssid = >Any subtree of this tree will be called a target subtree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N04-1035.txt | Citing Article:  P06-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this paper, we developed probability models for the multi-level transfer rules presented in (Galley et al, 2004), showed how to acquire larger rules that crucially condition on more syntactic context, and how to pack multiple derivations, including interpretations of unaligned words, into derivation forests.</S> | Reference Offset:  ['26','177'] | Reference Text:  <S sid = 26 ssid = >Our basic idea is to create transformation rules that condition on larger fragments of tree structure.</S><S sid = 177 ssid = >Multi-level reodering as the rule in the figure can prevent crossings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N04-1035.txt | Citing Article:  P11-2073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Typically, by using the GHKM algorithm (Galley et al 2004), translation rules are learned from word-aligned bilingual texts whose source side has been parsed by using a syntactic parser.</S> | Reference Offset:  ['2','62'] | Reference Text:  <S sid = 2 ssid = >We use our theory to introduce a linear algorithm that can be used to derive from word-aligned, parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data.</S><S sid = 62 ssid = >In other words, a source word is aligned with a target word if the target word is created during the same step in which the source word is replaced.</S> | Discourse Facet:  NA | Annotator: Automatic


