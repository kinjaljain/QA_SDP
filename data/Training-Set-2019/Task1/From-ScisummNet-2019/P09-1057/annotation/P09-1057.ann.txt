Citance Number: 1 | Reference Article:  P09-1057.txt | Citing Article:  N10-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bayesian methods (85.2% from Goldwater and Griffiths (2007), who use a trigram model) and close to the best accuracy reported on this task (91.8% from Ravi and Knight (2009b), who use an integer linear program to minimize the model directly).</S> | Reference Offset:  ['126','167'] | Reference Text:  <S sid = 126 ssid = >Previously, researchers working on this task have also reported results for unsupervised tagging with a smaller tagset (Smith and Eisner, 2005; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008; Goldberg et al., 2008).</S><S sid = 167 ssid = >We also note that it might be possible to replicate our models in a Bayesian framework similar to that proposed in (Goldwater and Griffiths, 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ravi and Knight (2009) achieved the best results thus far (92.3% word token accuracy) via a Minimum Description Length approach using an integer program (IP) that finds a minimal bigram grammar that obeys the tag dictionary constraints and covers the observed data.</S> | Reference Offset:  ['50','161'] | Reference Text:  <S sid = 50 ssid = >Our approach is related to minimum description length (MDL).</S><S sid = 161 ssid = >Our method resembles the classic Minimum Description Length (MDL) approach for model selection (Barron et al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The strategies employed in Ravi and Knight (2009) and Baldridge (2008) are complementary.</S> | Reference Offset:  ['126','131'] | Reference Text:  <S sid = 126 ssid = >Previously, researchers working on this task have also reported results for unsupervised tagging with a smaller tagset (Smith and Eisner, 2005; Goldwater and Griffiths, 2007; Toutanova and Johnson, 2008; Goldberg et al., 2008).</S><S sid = 131 ssid = >The InitEM-HMM system from Goldberg et al. (2008) reports an accuracy of 93.8%, followed by the LDA+AC model (Latent Dirichlet Allocation model with a strong Ambiguity Class component) from Toutanova and Johnson (2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Applying the approach of Ravi and Knight (2009) naively to CCG supertagging is intractable due to the high level of ambiguity.</S> | Reference Offset:  ['82','105'] | Reference Text:  <S sid = 82 ssid = >So we see a benefit to our explicit small-model approach.</S><S sid = 105 ssid = >The procedure is simple and proceeds as follows: We notice significant gains in tagging performance when applying this technique.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, the original IP method of Ravi and Knight (2009) is intractable for supertagging, so we propose a new two-stage method that scales to the larger tag sets and data involved.</S> | Reference Offset:  ['75','151'] | Reference Text:  <S sid = 75 ssid = >It might be interesting to see how the performance of the IP method (in terms of time complexity) is affected when scaling up to larger data and bigger tagsets.</S><S sid = 151 ssid = >As the results in Figure 9 illustrate, the IP+EM method clearly does better than all the other systems except for the LDA+AC model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This stage uses the original minimization formulation for the supertagging problem I Poriginal, again using an integer programming method similar to that proposed by Ravi and Knight (2009).</S> | Reference Offset:  ['1','166'] | Reference Text:  <S sid = 1 ssid = >We describe a novel method for the task of unsupervised POS tagging with a dictionary, one that uses integer programming to explicitly search for the smallest model that explains the data, and then uses EM to set parameter values.</S><S sid = 166 ssid = >The method proposed in this paper is the first application of the MDL idea to POS tagging, and the first to use an integer programming formulation rather than heuristic search techniques.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1057.txt | Citing Article:  P10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ravi and Knight (2009) exploited this to iteratively improve their POS tag model: since the first minimization procedure is seeded with a noisy gram mar and tag dictionary, iterating the IP procedure with progressively better grammars further improves the model.</S> | Reference Offset:  ['30','32'] | Reference Text:  <S sid = 30 ssid = >Here we obtain 81.7% accuracy, which is better than the 3-gram model.</S><S sid = 32 ssid = >For the rest of this paper, we will limit ourselves to a 2-gram tag model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1057.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Minimized models for EM-HMM with 100 random restarts (Ravi and Knight, 2009).</S> | Reference Offset:  ['118','119'] | Reference Text:  <S sid = 118 ssid = >When we execute 100 random restarts and select the model with the highest data likelihood, we get 83.8% accuracy.</S><S sid = 119 ssid = >Likewise, when we extend our alternating EM scheme to 100 random restarts at each step, we improve our tagging accuracy from 91.6% to 91.8% (Figure 8).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1057.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Ravi and Knight, 2009) focus on the POS tag collection to find the smallest POS model that explain the data.</S> | Reference Offset:  ['1','70'] | Reference Text:  <S sid = 1 ssid = >We describe a novel method for the task of unsupervised POS tagging with a dictionary, one that uses integer programming to explicitly search for the smallest model that explains the data, and then uses EM to set parameter values.</S><S sid = 70 ssid = >The IP solver finds the smallest grammar set that can explain the given word sequence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1057.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The abuse of the rare tags is presented in Table 5 in a similar fashion with (Ravi and Knight, 2009).</S> | Reference Offset:  ['37','41'] | Reference Text:  <S sid = 37 ssid = >As a result, EM exploits a lot of rare tags (like FW = foreign word, or SYM = symbol) and assigns them to common word types (in, of, etc.).</S><S sid = 41 ssid = >As a result, many word tokens which occur very frequently in the corpus are incorrectly tagged with rare tags in the EM tagging output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1057.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The IP+EM system constructs a model that describes the data by using minimum number of bi gram POS tags then uses this model to reduce the dictionary size (Ravi and Knight, 2009).</S> | Reference Offset:  ['1','27'] | Reference Text:  <S sid = 1 ssid = >We describe a novel method for the task of unsupervised POS tagging with a dictionary, one that uses integer programming to explicitly search for the smallest model that explains the data, and then uses EM to set parameter values.</S><S sid = 27 ssid = >Also, they make other manual adjustments to reduce noise from the word/tag dictionary (e.g., reducing the number of tags for “the” from six to just one).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1057.txt | Citing Article:  P11-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ravi and Knight (2009) instead of the feature-HMM for POS induction on the foreign side.</S> | Reference Offset:  ['37','66'] | Reference Text:  <S sid = 37 ssid = >As a result, EM exploits a lot of rare tags (like FW = foreign word, or SYM = symbol) and assigns them to common word types (in, of, etc.).</S><S sid = 66 ssid = >PRO V” (with 5 tag pairs), whereas the IP tries to minimize the grammar size and picks another solution instead.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1057.txt | Citing Article:  D10-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A more rigid mechanism for modeling sparsity is proposed by Ravi and Knight (2009), who minimize the size of tagging grammar as measured by the number of transition types.</S> | Reference Offset:  ['66','98'] | Reference Text:  <S sid = 66 ssid = >PRO V” (with 5 tag pairs), whereas the IP tries to minimize the grammar size and picks another solution instead.</S><S sid = 98 ssid = >In the process of minimizing the grammar size, IP ends up removing many good tag bigrams from our grammar set (as seen from the low measured recall of 0.57 for the observed grammar).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1057.txt | Citing Article:  D12-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To avoid the need for manually pruning the tag dictionary, Ravi and Knight (2009) proposed that low-probability tags might be automatically filtered from the tag dictionary through a model minimization procedure applied to the raw text and constrained by the full tag dictionary.</S> | Reference Offset:  ['59','80'] | Reference Text:  <S sid = 59 ssid = >We also create variables for every possible tag bigram and word/tag dictionary entry.</S><S sid = 80 ssid = >We still give EM the full word/tag dictionary, but now we constrain its initial grammar model to the 459 tag bigrams identified by IP.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1057.txt | Citing Article:  P10-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ravi and Knight (2009) use a dictionary and an MDL inspired modification to the EM algorithm.</S> | Reference Offset:  ['4','79'] | Reference Text:  <S sid = 4 ssid = >The classic Expectation Maximization (EM) algorithm has been shown to perform poorly on POS tagging, when compared to other techniques, such as Bayesian methods.</S><S sid = 79 ssid = >Fortunately, we can use EM for that.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1057.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This efficient and data-driven approach gives the best reported tagging accuracy for type-supervised sequence models, outperforming the minimized model of Ravi and Knight (2009), the Bayesian LDA-based model of Toutanova and Johnson (2008), and an HMM trained with language-specific initialization described by Goldberg et al (2008).</S> | Reference Offset:  ['121','131'] | Reference Text:  <S sid = 121 ssid = >Their models are trained on the entire Penn Treebank data (instead of using only the 24,115-token test data), and so are the tagging models used by Goldberg et al. (2008).</S><S sid = 131 ssid = >The InitEM-HMM system from Goldberg et al. (2008) reports an accuracy of 93.8%, followed by the LDA+AC model (Latent Dirichlet Allocation model with a strong Ambiguity Class component) from Toutanova and Johnson (2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1057.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['54','173'] | Reference Text:  <S sid = 54 ssid = >We obtain this answer by formulating the problem in an integer programming (IP) framework.</S><S sid = 173 ssid = >For direct comparison to previous works, we also presented results for the case when the dictionaries are incomplete and find the performance of our system to be comparable with current best results reported for the same task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1057.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Columns labeled 973k train describe models trained on the subset of 973k tokens used by Ravi and Knight (2009).</S> | Reference Offset:  ['124','135'] | Reference Text:  <S sid = 124 ssid = >We run EM training again for Model 5 (the best model from Figure 5) but this time using 973k word tokens, and further increase our accuracy to 92.3%.</S><S sid = 135 ssid = >The IP+EM models used in the 17-tagset experiments reported here were not trained on the entire Penn Treebank, but instead used a smaller section containing 77,963 tokens for estimating model parameters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1057.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ravi and Knight (2009) employs integer linear programming to select a minimal set of parameters that can generate the test sentences, followed by EM to set parameter values.</S> | Reference Offset:  ['1','170'] | Reference Text:  <S sid = 1 ssid = >We describe a novel method for the task of unsupervised POS tagging with a dictionary, one that uses integer programming to explicitly search for the smallest model that explains the data, and then uses EM to set parameter values.</S><S sid = 170 ssid = >The method works by explicitly minimizing the grammar size using integer programming, and then using EM to estimate parameter values.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1057.txt | Citing Article:  D12-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, the work of Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via an integer program, hence discarding unlikely transitions that would confuse the model.</S> | Reference Offset:  ['59','62'] | Reference Text:  <S sid = 59 ssid = >We also create variables for every possible tag bigram and word/tag dictionary entry.</S><S sid = 62 ssid = >Finally, we add an objective function that minimizes the number of grammar variables that are assigned a value of 1.</S> | Discourse Facet:  NA | Annotator: Automatic


