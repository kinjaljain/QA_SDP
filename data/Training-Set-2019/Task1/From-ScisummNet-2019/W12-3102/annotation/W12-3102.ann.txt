Citance Number: 1 | Reference Article:  W12-3102.txt | Citing Article:  W12-3108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This contribution has been built based on the data released for the Quality Estimation task of the Workshop on Machine Translation (WMT) 2012 (Callison-Burch et al, 2012).</S> | Reference Offset:  ['0','6'] | Reference Text:  <S sid = 0 ssid = >Findings of the 2012 Workshop on Statistical Machine Translation</S><S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W12-3102.txt | Citing Article:  W12-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The two-scale scoring for adequacy and fluency used in NIST evaluation has been abandoned by some evaluation campaigns, most notably the WMT shared task series, see Koehn and Monz (2006) through Callison-Burch et al (2012) 1.</S> | Reference Offset:  ['6','120'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 120 ssid = >In the first human evaluation, we use fluency and adequacy judgments on a scale from 1 to 5 (Koehn and Monz, 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W12-3102.txt | Citing Article:  W12-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Callison-Burch et al (2012) report for several automatic metrics on the whole WMT12 English-to-Czech dataset, the best of which correlates at?= 0.18.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W12-3102.txt | Citing Article:  W12-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In line with our observation, Czech-to-English correlations reported by Callison-Burch et al (2012) are higher: the best metric achieves 0.28 and aver ages 0.25 across four source languages.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W12-3102.txt | Citing Article:  W12-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On the other hand, it is quite possible that the WMT-style rankings taken as the gold standard are of a disputable quality themselves, see Section 3.1 or the detailed report on inter annotator agreement and a long discussion on interpreting the rankings in Callison-Burch et al (2012).</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W12-3102.txt | Citing Article:  W12-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is possible that Callison-Burch et al (2012) use some what different METEOR settings apart from the different subset of the data.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W12-3102.txt | Citing Article:  W12-3114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Nevertheless, in the context of this Quality Evaluation Shared task (see (Callison-Burch et al, 2012) for a detailed description) we have also used supervised learning as a final stage, in order to submit results which can be compared to other methods (see? 4). We investigate the use of various similarity measures for evaluating the quality of machine translated sentences.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W12-3102.txt | Citing Article:  W12-3114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 2 shows the best results among the configurations we have tested (expressed using the official evaluation measures, see (Callison-Burch et al, 2012) for details).</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W12-3102.txt | Citing Article:  W12-3114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The TCD-M5P-resources-only submission ranked 5th (among 17) in the ranking task, and 5th among 19 (tied with two other systems) in the scoring task (Callison-Burch et al, 2012). Unfortunately the TCD-M5P-all submission contained an error.13 Below are the official results for TCD-M5P-resources-only and the corrected results for TCD-M5P-all: In four cases in which Google n-grams formed the reference data, the scores were computed using the wrong language (Spanish instead of English) as the reference.</S> | Reference Offset:  ['297','302'] | Reference Text:  <S sid = 297 ssid = >TCD (R, S): “TCD M5P-resources-only” uses only the baseline features, while “TCD M5Pall” uses the baseline and additional features.</S><S sid = 302 ssid = >Contrary to what had been observed on the training data using cross-validation, “TCD M5P-resourcesonly” performs better than “TCD M5P-all” on the test data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W12-3102.txt | Citing Article:  W12-3115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The WMT 2012 shared task on QE for MT (Callison-Burch et al, 2012) required participants to score and rank a set of automatic English to Spanish translations output by a state of-the-art phrase based machine translation system.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W12-3102.txt | Citing Article:  W12-3115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An analysis of the Pearson correlation of the baseline features (Callison-Burch et al, 2012) with human quality assessments shows that the two strongest individual predictors of post-editing effort are the n-gram language model perplexities estimated on source and target sentences.</S> | Reference Offset:  ['6','127'] | Reference Text:  <S sid = 6 ssid = >This workshop builds on six previous WMT workshops (Koehn and Monz, 2006; Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; CallisonBurch et al., 2011).</S><S sid = 127 ssid = >In the following years (Callison-Burch et al., 2007; Callison-Burch et al., 2008; Callison-Burch et al., 2009; Callison-Burch et al., 2010; Callison-Burch et al., 2011), we abandoned the idea of using fluency and adequacy judgments, since they showed to be less reliable than simple ranking of system translations.</S> | Discourse Facet:  NA | Annotator: Automatic


