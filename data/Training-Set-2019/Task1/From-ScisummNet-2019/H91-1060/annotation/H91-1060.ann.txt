Citance Number: 1 | Reference Article:  H91-1060.txt | Citing Article:  P14-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To evaluate the parsing performance, we use the three standard ways to measure the performance: unlabeled (i.e., hierarchical spans) and labeled (i.e., nuclearity and relation) F-score, as defined by Black et al (1991).</S> | Reference Offset:  ['24','75'] | Reference Text:  <S sid = 24 ssid = >Our intention is to apply the current metric to more Brown Corpus data "ideally parsed" by us, and then to employ it to measure the performance of our grammars, run automatically, on a 1)enchma.rk set of sentences.</S><S sid = 75 ssid = >So the "Constituents Incompatible With Standard" score for this sentence is I.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  H91-1060.txt | Citing Article:  C04-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['31','85'] | Reference Text:  <S sid = 31 ssid = >has) a good friend" but not "Johns (i.e.</S><S sid = 85 ssid = >Average Recall = (3 /4  + 7 /8 + 2/4  + 518 + 314)  / 5 = .700 Average Precision = (3 /5 + 7 /10  + 2 /5  + 5 /10 + 315)  / 5 = .560 311</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  H91-1060.txt | Citing Article:  W06-3603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We evaluated our parser using the standard PARSEVAL measures (Black et al, 1991): labelled precision, labelled recall, and labelled F-measure (Prec., Rec., and F1, respectively), which are based on the number of non-terminal items in the parser's output that match those in the gold-standard parse.</S> | Reference Offset:  ['76','82'] | Reference Text:  <S sid = 76 ssid = >(b) "Recall" and "Precision" of Parse Being Evaluated As a preliminary to computing Recall: Number of Standard-Parse Constituents in Candidate Total Number of Standard-Parse Constituents and Precision: Number of Candidate-Parse Constituents in Standard Total Number of Candidate-Parse Constituents the total number of constituents in the standard parse, and in the candidate parse, are simply counted.</S><S sid = 82 ssid = >Computing Recall and Precision is accomplished for this parse as follows: Recall = 3 / Precision = 3 / 5 .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  H91-1060.txt | Citing Article:  D08-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The only recipe that is implicitly given in the large literature on parsing to date is to have human annotators build parse trees for a sample set from the domain of interest, and consequently use them to compute a PARSEVAL (Black et al, 1991) score that is indicative of the intrinsic performance of the parser.</S> | Reference Offset:  ['77','83'] | Reference Text:  <S sid = 77 ssid = >Notice that "Number of Standard-Parse Constituents in Candidate" and "Number of Candidate-Parse Constituents in Standard" are merely different names for the same object--the intersection of the set of standard-parse constituents with the set of candidate-parse constituents.</S><S sid = 83 ssid = >(C) Combining Statistics Gathered In order to evaluate a set of parses, first simply compute a distribution over "Incompatible Constituents" scores for the parses in the set, e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  H91-1060.txt | Citing Article:  P04-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Parse trees are commonly scored with the PARSEVAL set of metrics (Black et al, 1991).</S> | Reference Offset:  ['77','83'] | Reference Text:  <S sid = 77 ssid = >Notice that "Number of Standard-Parse Constituents in Candidate" and "Number of Candidate-Parse Constituents in Standard" are merely different names for the same object--the intersection of the set of standard-parse constituents with the set of candidate-parse constituents.</S><S sid = 83 ssid = >(C) Combining Statistics Gathered In order to evaluate a set of parses, first simply compute a distribution over "Incompatible Constituents" scores for the parses in the set, e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  H91-1060.txt | Citing Article:  P04-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Final testing was carried out on section 00, and the PARSEVAL measures (Black et al, 1991) were used to evaluate the performance.</S> | Reference Offset:  ['78','83'] | Reference Text:  <S sid = 78 ssid = >So the final count prel iminary to the computation of Recall and Precision is the number of elements in that intersection.</S><S sid = 83 ssid = >(C) Combining Statistics Gathered In order to evaluate a set of parses, first simply compute a distribution over "Incompatible Constituents" scores for the parses in the set, e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  H91-1060.txt | Citing Article:  N03-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The performance is assessed using labeled recall and labeled precision as defined by the standard Parseval metric (Black et al, 1991).</S> | Reference Offset:  ['76','82'] | Reference Text:  <S sid = 76 ssid = >(b) "Recall" and "Precision" of Parse Being Evaluated As a preliminary to computing Recall: Number of Standard-Parse Constituents in Candidate Total Number of Standard-Parse Constituents and Precision: Number of Candidate-Parse Constituents in Standard Total Number of Candidate-Parse Constituents the total number of constituents in the standard parse, and in the candidate parse, are simply counted.</S><S sid = 82 ssid = >Computing Recall and Precision is accomplished for this parse as follows: Recall = 3 / Precision = 3 / 5 .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  H91-1060.txt | Citing Article:  N06-2019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Consequently, they relaxed standard PARSEVAL (Black et al, 1991) to treat EDITED constituents like punctuation: adjacent EDITED constituents are merged, and the internal structure and attachment of EDITED constituents is not evaluated.</S> | Reference Offset:  ['75','77'] | Reference Text:  <S sid = 75 ssid = >So the "Constituents Incompatible With Standard" score for this sentence is I.</S><S sid = 77 ssid = >Notice that "Number of Standard-Parse Constituents in Candidate" and "Number of Candidate-Parse Constituents in Standard" are merely different names for the same object--the intersection of the set of standard-parse constituents with the set of candidate-parse constituents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  H91-1060.txt | Citing Article:  W08-1301.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Nevertheless, we agree with the widespread sentiment that dependency-based evaluation of parsers avoids many of the problems of the traditional Parseval measures (Black et al, 1991), and to the extent that the Stanford dependency representation is an effective representation for the tasks envisioned, it is perhaps closer to an appropriate task based evaluation than some of the alternative dependency representations available.</S> | Reference Offset:  ['7','73'] | Reference Text:  <S sid = 7 ssid = >We propose an evaluation pro- cedure with these characteristics: it judges a parse based only on the constituent boundaries it stipulates (and not the names it assigns to these constituents); it compares the parse to a "hand-parse" of the same sentence from the University of Pennsylvania Tree- bank; and it yields two principal measures for each parse submitted.</S><S sid = 73 ssid = >Example: Standard parse: ((The prospect) (of (cutting back spending))) Parse for evaluation: (The (prospect (of ((cutting back) spending)))) The (non-unary) constituents of the parse for evaluation are: 310 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  H91-1060.txt | Citing Article:  C10-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, metrics like attachment score for dependency parsers (Buchholz and Marsi, 2006) and Parseval for constituency parsers (Black et al, 1991) suffer from being an average over a highly skewed distribution of different grammatical constructions.</S> | Reference Offset:  ['19','64'] | Reference Text:  <S sid = 19 ssid = >The average Crossing Parentheses rate over all our grammars was .4%, with a corresponding Recall score of 94%.</S><S sid = 64 ssid = >Redefinit ion of Selected Constituents The third step in the process of preparing initial parsed input for evaluation is necessary only if the parse submitted treats any of three particular constructions in a manner different from the canonical analysis currently accepted by the group.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  H91-1060.txt | Citing Article:  W03-1711.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 3 shows the results of 1st-level partial parsing and full parsing, using the PARSEVAL evaluation methodology (Black et al 1991) on the UPENN Chinese Tree Bank of 100k words developed by Univ. of Penn.</S> | Reference Offset:  ['18','22'] | Reference Text:  <S sid = 18 ssid = >Instead of using the UPenn Treebank as a standard, we used the automaticMly computed "ma- jority parse" of each sentence obtained from the set of candidate parses themselves.</S><S sid = 22 ssid = >Even at the current level of fit, we feel comfortable Mlow- ing one of our number, the UPenn parse, to serve as the standard parse, since, crucially, it.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  H91-1060.txt | Citing Article:  P11-2037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The standard PARSEVAL metric (Black et al., 1991) counts labeled nonempty brackets: items are (X, i, j) for each nonempty nonterminal node, where X is its label and i, j are the start and end positions of its span.</S> | Reference Offset:  ['68','69'] | Reference Text:  <S sid = 68 ssid = >Example: If initial analysis is: (It (is (necessary (for us to leave)))) Then change to standard as follows: (It (is necessary) (for us to leave)) NOTE: The fol lowing is not an example of extraposition, and therefore not to be modified, although it seems to differ only minimally from a genuine extraposition sentence such as: "It seemed like a good idea to begin early": (It (seemed (like ((a good meeting) (to begin early))))) (b) Modification of Noun Phrases The treatment accepted at present attaches the modified "core" noun phrase and all of its modifiers from a single (noun phrase) node: Example: If initial analysis is: ((((the tree (that (we saw))) (with (orange leaves))) (that (was (very old)))) Then change to standard as follows: ((the tree) (that (we saw)) (with (orange leaves)) (that (was (very old)))) (c) Sequences of Constituent-Initial Prepositions and~or Constituent-Final Particles For sequences of prepositions occurring at the start of a prepositional phrase, the currently accepted practice is to attach each individually to the preposit ional-phrase node.</S><S sid = 69 ssid = >For sequences of particles which come at the end of a verb phrase or other constituent with a verbal head, the adopted standard is, likewise, to attach each individually to the top node of the constituent: Example: If initial analysis is: (We (were (out (of (oatmeal cookies))))) Then change to standard as follows: (We (were (out of (oatmeal cookies)))) ~.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  H91-1060.txt | Citing Article:  W10-1401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At their time, each of these models improved the state-of-the-art, bringing parsing performance on the standard test set of the Wall-Street-Journal to a performance ceiling of 92% F1-score using the PARSEVAL evaluation metrics (Black et al, 1991).</S> | Reference Offset:  ['24','75'] | Reference Text:  <S sid = 24 ssid = >Our intention is to apply the current metric to more Brown Corpus data "ideally parsed" by us, and then to employ it to measure the performance of our grammars, run automatically, on a 1)enchma.rk set of sentences.</S><S sid = 75 ssid = >So the "Constituents Incompatible With Standard" score for this sentence is I.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  H91-1060.txt | Citing Article:  D07-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >PARSEVAL measures (Black et al, 1991) are used to evaluate a parser's phrase-structure trees against a gold standard.</S> | Reference Offset:  ['18','68'] | Reference Text:  <S sid = 18 ssid = >Instead of using the UPenn Treebank as a standard, we used the automaticMly computed "ma- jority parse" of each sentence obtained from the set of candidate parses themselves.</S><S sid = 68 ssid = >Example: If initial analysis is: (It (is (necessary (for us to leave)))) Then change to standard as follows: (It (is necessary) (for us to leave)) NOTE: The fol lowing is not an example of extraposition, and therefore not to be modified, although it seems to differ only minimally from a genuine extraposition sentence such as: "It seemed like a good idea to begin early": (It (seemed (like ((a good meeting) (to begin early))))) (b) Modification of Noun Phrases The treatment accepted at present attaches the modified "core" noun phrase and all of its modifiers from a single (noun phrase) node: Example: If initial analysis is: ((((the tree (that (we saw))) (with (orange leaves))) (that (was (very old)))) Then change to standard as follows: ((the tree) (that (we saw)) (with (orange leaves)) (that (was (very old)))) (c) Sequences of Constituent-Initial Prepositions and~or Constituent-Final Particles For sequences of prepositions occurring at the start of a prepositional phrase, the currently accepted practice is to attach each individually to the preposit ional-phrase node.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  H91-1060.txt | Citing Article:  W10-4143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >After the release of the Penn Treebank (PTB) (Marcus et al, 1993) and the PARSEVAL metrics (Black et al, 1991), some new corpus based syntactic parsing techniques were explored in the English language.</S> | Reference Offset:  ['10','25'] | Reference Text:  <S sid = 10 ssid = >, ; - ) ;  (2) recur- sively erase all parenthesis pairs enclosing either a sin- gle constituent or word, or nothing at all; (3) compute goodness cores (Crossing Parentheses, and Recall) for the input parse, by comparing it to a similarly- reduced version of the Penn Treebank parse of the same sentence.</S><S sid = 25 ssid = >APPENDIX: EVALUATION PROCEDURE FOR COMPUTER ENGLISH GRAMMARS O.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  H91-1060.txt | Citing Article:  C10-2158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Empty categories were and still are routinely pruned out in parser evaluations (Black et al, 1991).</S> | Reference Offset:  ['9','20'] | Reference Text:  <S sid = 9 ssid = >For each parse to be evaluated: (1) erase from the fully-parsed sentence all instances of: auxiliaries, "not", pre-infinitival "to", null categories, possessive ndings (% and ), and all word-external punctuation (e.g. "</S><S sid = 20 ssid = >We have agreed on three additionM categories of systematic alteration to our input parses which we believe will significantly improve the correlation between our "ideal parses", i.e.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  H91-1060.txt | Citing Article:  C10-2158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Measured by the ParsEval metric (Blacketal., 1991), the parser accuracy stands at 80.3% (F score), with a precision of 81.8% and a recall of 78.8% (recall).</S> | Reference Offset:  ['19','82'] | Reference Text:  <S sid = 19 ssid = >The average Crossing Parentheses rate over all our grammars was .4%, with a corresponding Recall score of 94%.</S><S sid = 82 ssid = >Computing Recall and Precision is accomplished for this parse as follows: Recall = 3 / Precision = 3 / 5 .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  H91-1060.txt | Citing Article:  P12-2001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The parameters lambda i and rho are tuned by the Powell's method (Powell, 1964) on a development set, using the F1 score of PARSEVAL (Black et al, 1991) as objective.</S> | Reference Offset:  ['18','75'] | Reference Text:  <S sid = 18 ssid = >Instead of using the UPenn Treebank as a standard, we used the automaticMly computed "ma- jority parse" of each sentence obtained from the set of candidate parses themselves.</S><S sid = 75 ssid = >So the "Constituents Incompatible With Standard" score for this sentence is I.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  H91-1060.txt | Citing Article:  C00-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As accuracy metric we used the standard PAP, SEVAI, scores (Black et al 1991) to compare a proposed parse P with tile corresponding correct tree bank parse T as follows.</S> | Reference Offset:  ['7','70'] | Reference Text:  <S sid = 7 ssid = >We propose an evaluation pro- cedure with these characteristics: it judges a parse based only on the constituent boundaries it stipulates (and not the names it assigns to these constituents); it compares the parse to a "hand-parse" of the same sentence from the University of Pennsylvania Tree- bank; and it yields two principal measures for each parse submitted.</S><S sid = 70 ssid = >Computation of Evaluation Statistics (a) Number of Constituents Incompatible With Standard Parse For the sentence under analysis, compare the constituents as del imited by the standard parse with those del imited by the parse for evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  H91-1060.txt | Citing Article:  D07-1066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A comparison of unlexicalised PCFG parsing (Ku?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the TuBa D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991).</S> | Reference Offset:  ['18','71'] | Reference Text:  <S sid = 18 ssid = >Instead of using the UPenn Treebank as a standard, we used the automaticMly computed "ma- jority parse" of each sentence obtained from the set of candidate parses themselves.</S><S sid = 71 ssid = >The first statistic computed for each sentence is the number of constituents in the parse being evaluated which "cross", i.e.</S> | Discourse Facet:  NA | Annotator: Automatic


