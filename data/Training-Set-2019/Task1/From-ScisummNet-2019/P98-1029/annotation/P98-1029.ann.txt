Citance Number: 1 | Reference Article:  P98-1029.txt | Citing Article:  W03-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation.</S> | Reference Offset:  ['0','66'] | Reference Text:  <S sid = 0 ssid = >Classifier Combination for Improved Lexical Disambiguation</S><S sid = 66 ssid = >If all taggers made the exact same errors, there would obviously be no chance of improving accuracy through classifier combination.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P98-1029.txt | Citing Article:  W09-0715.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Committee-based approaches to POS tagging have been in focus the last decade: Brill and Wu (1998) combined four different taggers for English using unweighted voting and by exploring contextual cues (essentially a variant of stacking).</S> | Reference Offset:  ['68','74'] | Reference Text:  <S sid = 68 ssid = >We ran experiments to determine whether the outputs of the different taggers could be effectively combined.</S><S sid = 74 ssid = >We tried simple voting, using the Maximum Entropy, Transformation-Based and Trigram taggers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P98-1029.txt | Citing Article:  N03-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994).</S> | Reference Offset:  ['26','97'] | Reference Text:  <S sid = 26 ssid = >In transformation-based tagging (Brill (1995)), every word is first assigned an initial tag, This tag is the most likely tag for a word if the word is known and is guessed based upon properties of the word if the word is not known.</S><S sid = 97 ssid = >For instance, we may learn that the Trigram tagger is most accurate at tagging the word up or that the Unigrarn tagger does best at tagging the word (Daelemans(1996)). race when the word that follows is and.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P98-1029.txt | Citing Article:  P01-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The complementarity between two learners was defined by Brill and Wu (1998) in order to quantify the percentage of time when one system is wrong, that another system is correct, and therefore providing an upper bound on combination accuracy.</S> | Reference Offset:  ['48','50'] | Reference Text:  <S sid = 48 ssid = ># of errors in A only In other words, Comp(A,B) measures the percentage of time when tagger A is wrong that tagger B is correct.</S><S sid = 50 ssid = >For instance, when the maximum entropy tagger is wrong, the transformationbased tagger is right 37.7% of the time, and when the transformation-based tagger is wrong, the maximum entropy tagger is right 41.7% of the time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P98-1029.txt | Citing Article:  N01-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The data used in the experiment was selected from the Penn Treebank Wall Street Journal, and is the same used by Brill and Wu (1998).</S> | Reference Offset:  ['3','39'] | Reference Text:  <S sid = 3 ssid = >Next, we show how this complementary behavior can be used to our advantage.</S><S sid = 39 ssid = >All experiments presented in this paper were run on the Penn Treebank Wall Street Journal corpus (Marcus (1993)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P98-1029.txt | Citing Article:  W02-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The investigated MMVC model proves to be a very effective participant in classifier combination, with substantially different output to Naive Bayes (9.6% averaged complementary rate, as defined in Brill and Wu (1998)).</S> | Reference Offset:  ['49','67'] | Reference Text:  <S sid = 49 ssid = >In Figure 2 we show the complementary rates between the different taggers.</S><S sid = 67 ssid = >However, note that the high complementary rate between tagger errors in itself does not necessarily imply that there is anything to be gained by classifier combination.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P98-1029.txt | Citing Article:  E09-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected.</S> | Reference Offset:  ['0','16'] | Reference Text:  <S sid = 0 ssid = >Classifier Combination for Improved Lexical Disambiguation</S><S sid = 16 ssid = >These taggers are described below.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P98-1029.txt | Citing Article:  P00-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One opossibility is the example-based combiner in Brill and Wu (1998, Sec. 3.2).</S> | Reference Offset:  ['59','82'] | Reference Text:  <S sid = 59 ssid = >For example, when the oracle can examine the output of the Maximum Entropy, Transformation-Based and Trigram taggers, it could achieve an error rate of 1.62%.</S><S sid = 82 ssid = >We used a version of example-based learning to determine whether these tagger differences could be exploited.5 To determine 5 Example-based learning has also been applied succesfully in building a single part of speech tagger the tag of a word, we use the previous word, current word, next word, and the output of each tagger for the previous, current and next word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P98-1029.txt | Citing Article:  W07-1516.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Related work includes learning ensembles of POS taggers, as in the work of Brill and Wu (1998), where an ensemble consisting of a unigram model, an N-gram model, a transformation-based model, and an MEMM for POS tagging achieves substantial results beyond the individual taggers.</S> | Reference Offset:  ['35','37'] | Reference Text:  <S sid = 35 ssid = >Whereas the transformation-based tagger enforces multiple constraints by having multiple rules fire, the maximum-entropy tagger can have all of these constraints play a role at setting the probability estimates for the model's parameters.</S><S sid = 37 ssid = >The tagger uses essentially the same parameters as the transformation-based tagger, but employs them in a different model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P98-1029.txt | Citing Article:  A00-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Van Halteren et al, 1998) and (Brill and Wu, 1998) describe a series of successful experiments for improving the performance of part-of-speech taggers.</S> | Reference Offset:  ['66','68'] | Reference Text:  <S sid = 66 ssid = >If all taggers made the exact same errors, there would obviously be no chance of improving accuracy through classifier combination.</S><S sid = 68 ssid = >We ran experiments to determine whether the outputs of the different taggers could be effectively combined.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P98-1029.txt | Citing Article:  N03-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This suggests that the final accuracy number presented here could be slightly improved upon by classifier combination, it is worth noting that not only is this tagger better than any previous single tagger, but it also appears to outperform Brill and Wu (1998), the best-known combination tagger (they report an accuracy of 97.16% over the same WSJ data, but using a larger training set, which should favor them).</S> | Reference Offset:  ['0','75'] | Reference Text:  <S sid = 0 ssid = >Classifier Combination for Improved Lexical Disambiguation</S><S sid = 75 ssid = >In case of ties (all taggers disagree), the Maximum Entropy tagger output is chosen, since this tagger had the highest overall accuracy (this was determined by using a subset of the training set, not by using the test set).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P98-1029.txt | Citing Article:  W02-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Wu (1998) call this complementary disagreement complementarity.</S> | Reference Offset:  ['49','57'] | Reference Text:  <S sid = 49 ssid = >In Figure 2 we show the complementary rates between the different taggers.</S><S sid = 57 ssid = >Next, we check whether tagger complementarity is additive.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P98-1029.txt | Citing Article:  P06-2060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Numerous methods for combining classifiers have been proposed and utlized to improve the performance of different NLP tasks such as part of speech tagging (Brill and Wu, 1998), identifying base noun phrases (Tjong Kim Sang et al, 2000), named entity extraction (Florian et al, 2003), etc.</S> | Reference Offset:  ['102','103'] | Reference Text:  <S sid = 102 ssid = >In the future, we plan to expand our repertoire of base taggers, to determine whether performance continues to improve as we add additional systems.</S><S sid = 103 ssid = >We also plan to explore different methods for combining classifier outputs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P98-1029.txt | Citing Article:  W99-0608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Comparison of different taggers on the WSJ corpus TBL and ME (Brill and Wu, 1998).</S> | Reference Offset:  ['49','79'] | Reference Text:  <S sid = 49 ssid = >In Figure 2 we show the complementary rates between the different taggers.</S><S sid = 79 ssid = >Next, we try to exploit the idiosyncracies of the different taggers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P98-1029.txt | Citing Article:  N09-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Combination techniques have earlier been applied to various applications including machine translation (Jayaraman and Lavie, 2005), part-of-speech tagging (Brill and Wu, 1998) and base noun phrase identification (Sang et al., 2000).</S> | Reference Offset:  ['10','30'] | Reference Text:  <S sid = 10 ssid = >Another possibility could be that all of the different machine learning techniques are essentially doing the same thing.</S><S sid = 30 ssid = >The rule Change a tag from NOUN to VERB if the previous tag is a MODAL would be applied to the sentence, resulting in the correct tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


