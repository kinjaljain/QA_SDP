Citance Number: 1 | Reference Article:  W03-0424.txt | Citing Article:  P13-2118.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the C&C tools (Curran and Clark, 2003) for POS and NE tagging and the and the Berkeley Parser (Petrov and Klein, 2007), trained with default parameters.</S> | Reference Offset:  ['14','15'] | Reference Text:  <S sid = 14 ssid = >We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.</S><S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-0424.txt | Citing Article:  W07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004).</S> | Reference Offset:  ['6','21'] | Reference Text:  <S sid = 6 ssid = >The papers from the CoNLL-2002 shared task which used such methods (e.g.</S><S sid = 21 ssid = >We used three data sets: the English and German data for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003) and the Dutch data for the CoNLL2002 shared task (Tjong Kim Sang, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-0424.txt | Citing Article:  W07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As the vanilla C&C tagger (Curran and Clark, 2003) is optimised for performance on newswire text, various modifications were applied to improve its performance for biomedical NER.</S> | Reference Offset:  ['56','90'] | Reference Text:  <S sid = 56 ssid = >Some studies found that gazetteers did not improve performance (e.g.</S><S sid = 90 ssid = >Using a wider context window than 2 words may improve performance; a reranking phase using global features may also improve performance (Collins, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-0424.txt | Citing Article:  C10-2041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The named entity recognizer of Curran and Clark (2003) is also used to recognize the standard set of muc entities, including person, location and organisation.</S> | Reference Offset:  ['4','27'] | Reference Text:  <S sid = 4 ssid = >Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.</S><S sid = 27 ssid = >The 2003 data uses a variant of IOB-2, IOB-1, in which I-XXX is used for all words in an entity, including the first word, unless the first word separates contiguous entities of the same type, in which case B-XXX is used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-0424.txt | Citing Article:  P05-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These are based on those found in (Curran and Clark, 2003).</S> | Reference Offset:  ['15','28'] | Reference Text:  <S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S><S sid = 28 ssid = >Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-0424.txt | Citing Article:  W07-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The part-of-speech tagging uses the Curran and Clark POS tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al, 2004), whilst the other preprocessing stages are all rule based.</S> | Reference Offset:  ['5','15'] | Reference Text:  <S sid = 5 ssid = >Thus methods used for part of speech (POS) tagging and chunking can also be used for NER.</S><S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-0424.txt | Citing Article:  W07-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The NER module uses the Curran and Clark NER tagger (Curran and Clark, 2003), augmented with extra features tailored to the biomedical domain.</S> | Reference Offset:  ['15','35'] | Reference Text:  <S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S><S sid = 35 ssid = >These features have been shown to be useful in other NER systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-0424.txt | Citing Article:  P05-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous instance of that same token in a prior sentence of the same document.</S> | Reference Offset:  ['4','33'] | Reference Text:  <S sid = 4 ssid = >Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.</S><S sid = 33 ssid = >Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-0424.txt | Citing Article:  W04-1217.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A number of NER systems have made effective use of how the same token was tagged in different parts of the same document (see (Curran and Clark, 2003) and (Mikheev et al, 1999)).</S> | Reference Offset:  ['20','36'] | Reference Text:  <S sid = 20 ssid = >The tagger uses a Gaussian prior over the weights (Chen et al., 1999) which allows a large number of rare, but informative, features to be used without overfitting.</S><S sid = 36 ssid = >The additional orthographic features have proved useful in other systems, for example Carreras et al. (2002), Borthwick (1999) and Zhou and Su (2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-0424.txt | Citing Article:  W06-2703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['33','92'] | Reference Text:  <S sid = 33 ssid = >Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.</S><S sid = 92 ssid = >This research was supported by a Commonwealth scholarship and a Sydney University Travelling scholarship to the first author, and EPSRC grant GR/M96889.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-0424.txt | Citing Article:  W06-0701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7.</S> | Reference Offset:  ['8','58'] | Reference Text:  <S sid = 8 ssid = >However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.</S><S sid = 58 ssid = >Carreras et al. (2002)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-0424.txt | Citing Article:  S10-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000).</S> | Reference Offset:  ['5','15'] | Reference Text:  <S sid = 5 ssid = >Thus methods used for part of speech (POS) tagging and chunking can also be used for NER.</S><S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-0424.txt | Citing Article:  S10-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&C maximum entropy NER tagger (Curran and Clark, 2003b).</S> | Reference Offset:  ['0','10'] | Reference Text:  <S sid = 0 ssid = >Language Independent NER Using A Maximum Entropy Tagger</S><S sid = 10 ssid = >We demonstrate this to be the case by improving on the best Dutch results from CoNLL-2002 using a maximum entropy (ME) tagger.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-0424.txt | Citing Article:  W04-1907.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non domain-specific ones we use the C&C named entity tagger (Curran and Clark, 2003) trained on the MUC-7 data set.</S> | Reference Offset:  ['8','14'] | Reference Text:  <S sid = 8 ssid = >However, Zhou and Su (2002) have reported state of the art results on the MUC-6 and MUC-7 data using a HMM-based tagger.</S><S sid = 14 ssid = >We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-0424.txt | Citing Article:  W08-0603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The part-of-speech tagging uses the Curran&Clark maximum entropy Markov model tagger (Curran and Clark, 2003) trained on MedPost data (Smith et al., 2004), whilst the other preprocessing stages are all rule-based.</S> | Reference Offset:  ['15','28'] | Reference Text:  <S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S><S sid = 28 ssid = >Table 1 lists the contextual predicates used in our baseline system, which are based on those used in the Curran and Clark (2003) CCG supertagger.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-0424.txt | Citing Article:  W04-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use different strategies for the identification of the two classes of entities: for the domain-specific ones we use hand-crafted LT TTT rules, while for the non-domain-specific ones we use the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the MUC7 data set.</S> | Reference Offset:  ['14','48'] | Reference Text:  <S sid = 14 ssid = >We also use a Gaussian prior on the parameters for effective smoothing over the large feature space.</S><S sid = 48 ssid = >The use of beam-search tagging means that tags can only be recorded from previous sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-0424.txt | Citing Article:  W08-1809.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For this we have used the C&C named entity recogniser (Curran and Clark, 2003), which is run on pos-tagged and chunked documents in the corpus to identify and extract named entities as potential topics.</S> | Reference Offset:  ['2','4'] | Reference Text:  <S sid = 2 ssid = >This paper demonstrates that a maximum entropy tagger can effectively encode such information and identify named entities with very high accuracy.</S><S sid = 4 ssid = >Named Entity Recognition1 (NER) can be treated as a tagging problem where each word in a sentence is assigned a label indicating whether it is part of a named entity and the entity type.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-0424.txt | Citing Article:  P06-1141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Malouf (2002) and Curran and Clark (2003) condition the label of a token at a particular position on the label of the most recent previous in stance of that same token in a previous sentence of the same document.</S> | Reference Offset:  ['33','60'] | Reference Text:  <S sid = 33 ssid = >Note that the NEi−2NEi−1 feature is a composite feature of both the previous and previous-previous NE tags.</S><S sid = 60 ssid = >These gazetteers are used for predicates applied to the current, previous and next word in the window.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-0424.txt | Citing Article:  E09-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >By training the C&C tagger (Curran and Clark, 2003) on the gold-standard corpora an dour new Wikipedia-derived training data, we evaluate the usefulness of the latter and explore the nature of the training corpus as a variable in NER.</S> | Reference Offset:  ['29','52'] | Reference Text:  <S sid = 29 ssid = >The first set of features apply to rare words, i.e. those which appear less than 5 times in the training data.</S><S sid = 52 ssid = >The unigram probabilities are relative frequencies obtained from the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-0424.txt | Citing Article:  E09-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We trained the C&C NER tagger (Curran and Clark,2003) to build separate models for each gold standard corpus.</S> | Reference Offset:  ['15','16'] | Reference Text:  <S sid = 15 ssid = >The ME tagger is based on Ratnaparkhi (1996)’s POS tagger and is described in Curran and Clark (2003) .</S><S sid = 16 ssid = >The tagger uses models of the form: where y is the tag, x is the context and the fi(x, y) are the features with associated weights λi.</S> | Discourse Facet:  NA | Annotator: Automatic


