Citance Number: 1 | Reference Article:  W04-3230.txt | Citing Article:  H05-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The lattice-conditional estimation approach was first used by Kudo et al (2004) for Japanese segmentation and hierarchical POS-tagging and by Smith and Smith (2004) for Korean morphological disambiguation.</S> | Reference Offset:  ['28','46'] | Reference Text:  <S sid = 28 ssid = >A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al., 2004).</S><S sid = 46 ssid = >Japanese part-of-speech (POS) tagsets used in the two major Japanese morphological analyzers ChaSen2 and JUMAN3 take the form of a hierarchical structure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W04-3230.txt | Citing Article:  P13-2033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Japanese WS, unknown words are usu ally dealt with in an on line manner with the unknown word model, which uses heuristics 183 depending on character types (Kudo et al,2004).</S> | Reference Offset:  ['74','119'] | Reference Text:  <S sid = 74 ssid = >Although the performance of unknown words were improved, that of known words degraded due to the label and length bias.</S><S sid = 119 ssid = >For an unknown word, length of the word, up to 2 suffixes/prefixes and character types are used as the features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W04-3230.txt | Citing Article:  P13-2033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Japanese, our unknown word model relies on heuristics based on character types and word length to generate word nodes, similar to that of MeCab (Kudo et al., 2004).</S> | Reference Offset:  ['28','119'] | Reference Text:  <S sid = 28 ssid = >A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al., 2004).</S><S sid = 119 ssid = >For an unknown word, length of the word, up to 2 suffixes/prefixes and character types are used as the features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W04-3230.txt | Citing Article:  P13-2033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['44','178'] | Reference Text:  <S sid = 44 ssid = >The goal is to select a correct path yË† from all candidate paths in the Y(x).</S><S sid = 178 ssid = >We would like to thank Kiyotaka Uchimoto and Masayuki Asahara, who explained the details of their Japanese morphological analyzers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W04-3230.txt | Citing Article:  D10-1079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo et al (2004) use SVMs to morphologically tag Japanese.</S> | Reference Offset:  ['73','129'] | Reference Text:  <S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S><S sid = 129 ssid = >To make a fare comparison, we use exactly the same data as (Uchimoto et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W04-3230.txt | Citing Article:  W12-4208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The four parallel corpora were tokenized and lemmatized, for Japanese with the MeCab morphological analyzer (Kudo et al, 2004), and for English with the Freeling analyzer (Padr? et al, 2010), with MWE, quantities, dates and sentence segmentation turned off.</S> | Reference Offset:  ['73','128'] | Reference Text:  <S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S><S sid = 128 ssid = >In Table 3 (KC data set), the results of a variant of maximum entropy Markov models (MEMMs) (Uchimoto et al., 2001) and a rule-based analyzer (JUMAN7) are also shown.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W04-3230.txt | Citing Article:  I08-4025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In our approach, N-best candidates for each training example are produced with the CRF++ software (Kudo et al, 2004).</S> | Reference Offset:  ['28','73'] | Reference Text:  <S sid = 28 ssid = >A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al., 2004).</S><S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W04-3230.txt | Citing Article:  W08-0609.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Kudo et al (Kudo et al, 2004), we adapted the core engine of the CRF-based morphological analyzer, MeCab1, to our POS/PROTEIN tagging task.</S> | Reference Offset:  ['12','73'] | Reference Text:  <S sid = 12 ssid = >Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).</S><S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W04-3230.txt | Citing Article:  D11-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Segmentation for Japanese is a successful field of research, achieving the F-score of nearly 99% (Kudo et al, 2004).</S> | Reference Offset:  ['12','73'] | Reference Text:  <S sid = 12 ssid = >Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).</S><S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W04-3230.txt | Citing Article:  D11-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One would notice that the baseline score is much lower than the score previously reported regarding newspaper articles (Kudo et al, 2004).</S> | Reference Offset:  ['8','12'] | Reference Text:  <S sid = 8 ssid = >We experiment CRFs on the standard testbed corpus used for Japanese morphological analysis, and evaluate our results using the same experimental dataset as the HMMs and MEMMs previously reported in this task.</S><S sid = 12 ssid = >Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W04-3230.txt | Citing Article:  D08-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This area of research may be considered almost completed, as previous studies reported the F-score of nearly 99% (Kudo et al, 2004).</S> | Reference Offset:  ['11','12'] | Reference Text:  <S sid = 11 ssid = >They are considered to be the state-of-the-art framework to date.</S><S sid = 12 ssid = >Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W04-3230.txt | Citing Article:  C08-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The sequential tagger used in this paper is CRF++ (Kudo et al, 2004).</S> | Reference Offset:  ['73','84'] | Reference Text:  <S sid = 73 ssid = >Uchimoto et al. attempted a variant of MEMMs for Japanese morphological analysis with a number of features including suffixes and character types (Uchimoto et al., 2001; Uchimoto et al., 2002; Uchimoto et al., 2003).</S><S sid = 84 ssid = >Note that our formulation of CRFs is different from the widely-used formulations (e.g., (Sha and Pereira, 2003; McCallum and Li, 2003; Peng et al., 2004; Pinto et al., 2003; Peng and McCallum, 2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W04-3230.txt | Citing Article:  C08-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous work (Kudo et al, 2004) showed CRFs outperform generative Markov models and discriminative history-based methods in JWS.</S> | Reference Offset:  ['17','62'] | Reference Text:  <S sid = 17 ssid = >CRFs offer a solution to the problems in Japanese morphological analysis with hidden Markov models (HMMs) (e.g., (Asahara and Matsumoto, 2000)) or with maximum entropy Markov models (MEMMs) (e.g., (Uchimoto et al., 2001)).</S><S sid = 62 ssid = >It is known that maximum entropy Markov models (MEMMs) (McCallum et al., 2000) or other discriminative models with independently trained nextstate classifiers potentially suffer from the label bias (Lafferty et al., 2001) and length bias.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W04-3230.txt | Citing Article:  P12-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo et al (2004) modified CRFs for non-segmented languages like Japanese which have the problem of word boundary ambiguity.</S> | Reference Offset:  ['14','27'] | Reference Text:  <S sid = 14 ssid = >However, word boundaries are not clear in non-segmented languages.</S><S sid = 27 ssid = >Word boundary ambiguity cannot be ignored when dealing with non-segmented languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W04-3230.txt | Citing Article:  D07-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As conventional sequential tagging problems, such part-of-speech tagging and phrase chunking, we employ the conditional random fields (CRF) as learners (Kudo et al, 2004).</S> | Reference Offset:  ['10','76'] | Reference Text:  <S sid = 10 ssid = >Conditional random fields (CRFs) (Lafferty et al., 2001) applied to sequential labeling problems are conditional models, trained to discriminate the correct sequence from all other candidate sequences without making independence assumption for features.</S><S sid = 76 ssid = >Conditional random fields (CRFs) (Lafferty et al., 2001) overcome the problems described in Section 2.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W04-3230.txt | Citing Article:  D11-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Regarding the two state-of-the-art word segmentation systems, one is JUMAN,  a rule-based word segmentation system (Kurohashi and Nagao, 1994), and the other is MECAB, a supervised word segmentation system based on CRFs (Kudo et al, 2004).</S> | Reference Offset:  ['75','123'] | Reference Text:  <S sid = 75 ssid = >Wrong segmentation had been reported in sentences which are analyzed correctly by naive rule-based or HMMs-based analyzers.</S><S sid = 123 ssid = ># of tokens in system output In the evaluations of F-scores, three criteria of correctness are used: seg: (only the word segmentation is evaluated), top: (word segmentation and the top level of POS are evaluated), and all: (all information is used for evaluation).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W04-3230.txt | Citing Article:  D11-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The performance of the two word segmentation baselines (JUMAN and MECAB) is significantly worse in our task than in the standard word segmentation task, where nearly 99% precision and recall are reported (Kudo et al, 2004).</S> | Reference Offset:  ['8','123'] | Reference Text:  <S sid = 8 ssid = >We experiment CRFs on the standard testbed corpus used for Japanese morphological analysis, and evaluate our results using the same experimental dataset as the HMMs and MEMMs previously reported in this task.</S><S sid = 123 ssid = ># of tokens in system output In the evaluations of F-scores, three criteria of correctness are used: seg: (only the word segmentation is evaluated), top: (word segmentation and the top level of POS are evaluated), and all: (all information is used for evaluation).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W04-3230.txt | Citing Article:  P07-2055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo et al (2004) studied Japanese word segmentation and POS tagging using conditional random fields (CRFs) and rule based unknown word processing.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Applying Conditional Random Fields To Japanese Morphological Analysis</S><S sid = 1 ssid = >This paper presents Japanese morphological analysis based on conditional random fields (CRFs).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W04-3230.txt | Citing Article:  W10-4141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To demonstrate our method, we compare to several well-known structural learning algorithms, like CRF (Kudo et al, 2004), and SVM-HMM (Joachims et al, 2009) on two well-known data, namely, CoNLL-2000 syntactic chunking, SIGHAN-3 Chinese word segmentation tasks.</S> | Reference Offset:  ['12','62'] | Reference Text:  <S sid = 12 ssid = >Empirical successes with CRFs have been reported recently in part-of-speech tagging (Lafferty et al., 2001), shallow parsing (Sha and Pereira, 2003), named entity recognition (McCallum and Li, 2003), Chinese word segmentation (Peng et al., 2004), and Information Extraction (Pinto et al., 2003; Peng and McCallum, 2004).</S><S sid = 62 ssid = >It is known that maximum entropy Markov models (MEMMs) (McCallum et al., 2000) or other discriminative models with independently trained nextstate classifiers potentially suffer from the label bias (Lafferty et al., 2001) and length bias.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W04-3230.txt | Citing Article:  E09-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Kudo et al (2004), we adapted the core engine of the CRF-based morphological analyzer, MeCab2, to our POS tagging task.</S> | Reference Offset:  ['28','128'] | Reference Text:  <S sid = 28 ssid = >A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al., 2004).</S><S sid = 128 ssid = >In Table 3 (KC data set), the results of a variant of maximum entropy Markov models (MEMMs) (Uchimoto et al., 2001) and a rule-based analyzer (JUMAN7) are also shown.</S> | Discourse Facet:  NA | Annotator: Automatic


