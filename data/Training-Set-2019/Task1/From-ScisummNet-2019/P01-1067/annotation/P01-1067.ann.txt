Citance Number: 1 | Reference Article:  P01-1067.txt | Citing Article:  W02-1405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Very recently, Yamada and Knight (2001) described a model in which the noisy-channel takes as input a parsed sentence rather than simple words.</S> | Reference Offset:  ['11','19'] | Reference Text:  <S sid = 11 ssid = >Their models are based on a string-to-string noisy channel model.</S><S sid = 19 ssid = >To incorporate structural aspects of the language, our channel model accepts a parse tree as an input, i.e., the input sentence is preprocessed by a syntactic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P01-1067.txt | Citing Article:  P14-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Zhu et al. (2010) constructed a parallel corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation (Yamada and Knight, 2001).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 1 ssid = >We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P01-1067.txt | Citing Article:  P14-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We refer the reader to (Yamada and Knight, 2001) for more details.</S> | Reference Offset:  ['15','33'] | Reference Text:  <S sid = 15 ssid = >Mathematical details are fully described in (Brown et al., 1993).</S><S sid = 33 ssid = >Following (Brown et al., 1993) and the other literature in TM, this paper only focuses the details of TM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P01-1067.txt | Citing Article:  W06-3601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both Yamada and Knight (2001) and Chiang (2005) use SCFGs as the underlying model, so their translation schemata are syntax-directed as in Fig.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 1 ssid = >We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P01-1067.txt | Citing Article:  W06-3601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This example also shows that, one-level SCFG rule, even if informed by the Treebank as in (Yamada and Knight, 2001), is not enough to capture a common construction like this which is five levels deep (from VP to by).</S> | Reference Offset:  ['38','52'] | Reference Text:  <S sid = 38 ssid = >We first introduce our translation model with an example.</S><S sid = 52 ssid = >That is, a function word like ga is just as likely to be inserted in one place as any other.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P01-1067.txt | Citing Article:  W09-1120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In applications such as the syntax based machine translation model of (Yamada and Knight, 2001), a low quality tree might lead to errorenous translation of the sentence.</S> | Reference Offset:  ['0','148'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 148 ssid = >We have presented a syntax-based translation model that statistically models the translation process from an English parse tree into a foreignlanguage sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P01-1067.txt | Citing Article:  P10-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Additionally, we present novel on-the-fly variants of these algorithms, and compare their performance on a syntax machine translation cascade based on (Yamada and Knight, 2001).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 1 ssid = >We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P01-1067.txt | Citing Article:  P10-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We adapt the Japanese-to-English translation model of Yamada and Knight (2001) by transforming it from an English-tree-to-Japanese-string model to an English-tree-to-Japanese-tree model.</S> | Reference Offset:  ['63','104'] | Reference Text:  <S sid = 63 ssid = >Therefore, the probability of the Japanese sentence given the English parse tree is the sum of all these probabilities.</S><S sid = 104 ssid = >To experiment, we trained our model on a small English-Japanese corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P01-1067.txt | Citing Article:  P06-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yamada and Knight (2001) use a parser in the target language to train probabilities on a set of 609 operations that transform a target parse tree into a source string.</S> | Reference Offset:  ['2','23'] | Reference Text:  <S sid = 2 ssid = >Our model transforms a source-language parse tree into a target-language string by applying stochastic operations at each node.</S><S sid = 23 ssid = >Note that the output of our model is a string, not a parse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P01-1067.txt | Citing Article:  P03-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, we have introduced a variation of the Inside-Outside algorithm as seen in (Yamada and Knight, 2001) for E step computation.</S> | Reference Offset:  ['174','180'] | Reference Text:  <S sid = 174 ssid = >We define an alpha probability and a beta probability for each major-node, in analogy with the measures used in the inside-outside algorithm for probabilistic context free grammars (Baker, 1979).</S><S sid = 180 ssid = >Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P01-1067.txt | Citing Article:  P03-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yamada and Knight (2001) further extended the model to a syntax-to-string translation modeling.</S> | Reference Offset:  ['0','11'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 11 ssid = >Their models are based on a string-to-string noisy channel model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P01-1067.txt | Citing Article:  N10-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','186'] | Reference Text:  <S sid = 58 ssid = >Suppose we obtained the translations shown in the fourth tree of Figure 1.</S><S sid = 186 ssid = >This work was supported by DARPA-ITO grant N66001-00-1-9814.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yamada and Knight (2001) present an algorithm for estimating probabilistic parameters for a similar model which represents translation as a sequence of re-ordering operations over children of nodes in a syntactic tree, using automatic parser output for the initial tree structures.</S> | Reference Offset:  ['4','23'] | Reference Text:  <S sid = 4 ssid = >Model parameters are estimated in polynomial time using an EM algorithm.</S><S sid = 23 ssid = >Note that the output of our model is a string, not a parse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We begin by summarizing the model of Yamada and Knight (2001), which can be thought of as representing translation as an Alexander Calder mobile.</S> | Reference Offset:  ['0','6'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 6 ssid = >A statistical translation model (TM) is a mathematical model in which the process of humanlanguage translation is statistically modeled.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P01-1067.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In part to deal with this problem, Yamada and Knight (2001) flatten the trees in a pre-processing step by collapsing nodes with the same lexical head-word.</S> | Reference Offset:  ['117','180'] | Reference Text:  <S sid = 117 ssid = >Second, a subtree was flattened if the node’s head-word was the same as the parent’s headword.</S><S sid = 180 ssid = >Those formulae replace the step 3 (in Section 2.3) for each training pair, and these counts are used in the step 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P01-1067.txt | Citing Article:  H05-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Based on an example from (Yamada and Knight, 2001), we provide a sample SCFG fragment translating from English to Japanese, specified by means of the following synchronous productions.</S> | Reference Offset:  ['38','109'] | Reference Text:  <S sid = 38 ssid = >We first introduce our translation model with an example.</S><S sid = 109 ssid = >The average sentence length was 6.9 for English and 9.7 for Japanese.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P01-1067.txt | Citing Article:  H05-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Variant of this definition can be found where the input is a single parse tree for w (Yamada and Knight, 2001), or where the output is a single parse tree, chosen according to some specific criteria (Wu and Wong, 1998).</S> | Reference Offset:  ['23','45'] | Reference Text:  <S sid = 23 ssid = >Note that the output of our model is a string, not a parse tree.</S><S sid = 45 ssid = >Here, we instead decide the position on the basis of the nodes of the input parse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P01-1067.txt | Citing Article:  P05-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Syntax-based Statistical Translation (Yamada and Knight, 2001): This model extends the above by allowing all possible permutations of the RHS of the English rules.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 1 ssid = >We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P01-1067.txt | Citing Article:  W09-2310.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, there are three resulting parameter tables analogous to the r-table; as stated in (Yamada and Knight, 2001), consisting of POS and constituent based patterns allowing for reordering and monotone distortion (examples can be found in Table 5).</S> | Reference Offset:  ['41','47'] | Reference Text:  <S sid = 41 ssid = >The probability of reordering it into PRP-VB2-VB1 is 0.723 (the second row in the r-table in Table 1).</S><S sid = 47 ssid = >For simplicity, we split the n-table into two: a table for insert positions and a table for words to be inserted (Table 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P01-1067.txt | Citing Article:  D12-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT (Koehn et al 2005), hierarchical phrase-based translation (Chiang, 2007), syntax-based translation (Yamada and Knight, 2001), or pre ordering (Xia and McCord, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Syntax-Based Statistical Translation Model</S><S sid = 1 ssid = >We present a syntax-based statistical translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


