Citance Number: 1 | Reference Article:  W06-2922.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bick (2006) used the lowercased FORM if the LEMMA is not available, Corston-Oliver and Aue (2006) a prefix and Attardi (2006) a stem derived by a rule-based system for Danish, German and Swedish.</S> | Reference Offset:  ['24','25'] | Reference Text:  <S sid = 24 ssid = >LEMMA was used in features whenever available, otherwise the FORM was used.</S><S sid = 25 ssid = >For Danish, German and Swedish the Snowball stemmer (Porter 2001) was used to generate a value for LEMMA.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-2922.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Use only some components, e.g. Bick (2006) uses only case, mood and pronoun subclass and Attardi (2006) uses only gender, number, person and case.</S> | Reference Offset:  ['29','42'] | Reference Text:  <S sid = 29 ssid = >FEATS were used to extract a single token combining gender, number, person and case, through a language specific algorithm.</S><S sid = 42 ssid = >At each step the parser uses classifiers trained on treebank data in order to predict which action to perform and which dependency label to assign given the current configuration.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-2922.txt | Citing Article:  P13-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The most efficient parsers are greedy transition-based parsers, which only explore a single derivation for each input and relies on a locally trained classifier for predicting the next parser action given a compact representation of the derivation history, as pioneered by Yamada and Matsumoto (2003), Nivre (2003), Attardi (2006), and others.</S> | Reference Offset:  ['5','39'] | Reference Text:  <S sid = 5 ssid = >Recently statistical dependency parsing techniques have been proposed which are deterministic and/or linear (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004).</S><S sid = 39 ssid = >The parser by Yamada and Matsumoto (2003) used the following actions: Shift in a configuration (S, n|I, T, A), pushes n to the stack, producing the configuration (n|S, I, T, A).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-2922.txt | Citing Article:  W11-2308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Speech tagger described in Dell Orletta (2009) and dependency parsed by the DeSR parser (Attardi,2006) using Support Vector Machine as learning algorithm.</S> | Reference Offset:  ['60','64'] | Reference Text:  <S sid = 60 ssid = >Using Memory Based Learning increases considerably the parsing time, while as expected learning time is quite shorter.</S><S sid = 64 ssid = >I also tried alternative machine learning algorithms, including SVM, Winnow, Voted Perceptron.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-2922.txt | Citing Article:  W08-2138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This model is a version of DeSR (Attardi, 2006), a deterministic classifier-based Shift/Reduce parser.</S> | Reference Offset:  ['6','36'] | Reference Text:  <S sid = 6 ssid = >These parsers are based on learning the correct sequence of Shift/Reduce actions used to construct the dependency tree.</S><S sid = 36 ssid = >The parser constructs dependency trees employing a deterministic bottom-up algorithm which performs Shift/Reduce actions while analyzing input sentences in left-to-right order.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-2922.txt | Citing Article:  C10-2129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Transition based parsers typically have a linear or quadratic complexity (Attardi, 2006) .Nivre (2009) introduced a transition based non projective parsing algorithm that has a worst case quadratic complexity and an expected linear parsing time.</S> | Reference Offset:  ['5','60'] | Reference Text:  <S sid = 5 ssid = >Recently statistical dependency parsing techniques have been proposed which are deterministic and/or linear (Yamada and Matsumoto, 2003; Nivre and Scholz, 2004).</S><S sid = 60 ssid = >Using Memory Based Learning increases considerably the parsing time, while as expected learning time is quite shorter.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-2922.txt | Citing Article:  P08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['24','98'] | Reference Text:  <S sid = 24 ssid = >LEMMA was used in features whenever available, otherwise the FORM was used.</S><S sid = 98 ssid = >The following treebanks were used for training the parser: (Afonso et al., 2002; Atalay et al., 2003; Böhmovà et al., 2003; Brants et al., 2002; Chen et al., 2003; Civit Torruella and Martì Antonìn, 2002; Džeroski et al., 2006; Hajiç et al., 2004; Kawata and Bartels, 2000; Kromann, 2003; Nilsson et al., 2005; Oflazer et al., 2003; Simov et al., 2005; van der Beek et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-2922.txt | Citing Article:  P08-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, other non-projective parsers such as (Attardi, 2006) follow a constructive approach and can be analysed deductively.</S> | Reference Offset:  ['0','43'] | Reference Text:  <S sid = 0 ssid = >Experiments With A Multilanguage Non-Projective Dependency Parser</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-2922.txt | Citing Article:  D12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, the goal of that transition is different from ours (selecting between projective and non projective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic for example, the LEFT ARC transition can not be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it.</S> | Reference Offset:  ['17','43'] | Reference Text:  <S sid = 17 ssid = >The overall parsing algorithm is an inductive statistical parser, which extends the approach by Yamada and Matsumoto (2003), by adding six new reduce actions for handling non-projective relations and also performs dependency labeling.</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-2922.txt | Citing Article:  D12-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Non-projective transitions that create dependency arcs between non-contiguous nodes have been used in the transition-based parser by Attardi (2006).</S> | Reference Offset:  ['0','43'] | Reference Text:  <S sid = 0 ssid = >Experiments With A Multilanguage Non-Projective Dependency Parser</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-2922.txt | Citing Article:  D07-1119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >DeSR (Attardi, 2006) is an incremental deterministic classifier-based parser.</S> | Reference Offset:  ['18','36'] | Reference Text:  <S sid = 18 ssid = >Parsing is deterministic and proceeds bottom-up.</S><S sid = 36 ssid = >The parser constructs dependency trees employing a deterministic bottom-up algorithm which performs Shift/Reduce actions while analyzing input sentences in left-to-right order.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This idea is demonstrated by Attardi (2006), who proposes a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency.</S> | Reference Offset:  ['0','43'] | Reference Text:  <S sid = 0 ssid = >Experiments With A Multilanguage Non-Projective Dependency Parser</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The reported coverage in Attardi (2006) is already very high when the system is restricted to transitions of degree two or three.</S> | Reference Offset:  ['89','90'] | Reference Text:  <S sid = 89 ssid = >The high error rate of J (adjective) is expected, mainly due to coordination problems.</S><S sid = 90 ssid = >The error of R (preposition) is also relatively high.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 1 gives additional statistics for treebanks from the CoNLL-X shared task (Buchholz and Marsi, 2006). We now turn to describe our variant of the transition system of Attardi (2006), which is equivalent to the original system restricted to transitions of degree two.</S> | Reference Offset:  ['22','62'] | Reference Text:  <S sid = 22 ssid = >No additional resources are used.</S><S sid = 62 ssid = >Shift/Reduce, one to decide which Reduce action and a third one to choose the dependency in case of Left/Right action For details on the CoNLL-X shared task and the measurements see (Buchholz, et al. 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 1: The number of non-projective relations of various degrees for several treebanks (training sets), as reported by the parser of Attardi (2006).</S> | Reference Offset:  ['14','43'] | Reference Text:  <S sid = 14 ssid = >Finally, I extended the repertoire of actions used by the parser, in order to handle non-projective relations.</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We turn next to describe the equivalence between our system and the system in Attardi (2006).</S> | Reference Offset:  ['20','62'] | Reference Text:  <S sid = 20 ssid = >Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), pages 166–170, New York City, June 2006. c�2006 Association for Computational Linguistics The parser is modular: it can use several learning algorithms: Maximum Entropy, SVM, Winnow, Voted Perceptron, Memory Based Learning, as well as combinations thereof.</S><S sid = 62 ssid = >Shift/Reduce, one to decide which Reduce action and a third one to choose the dependency in case of Left/Right action For details on the CoNLL-X shared task and the measurements see (Buchholz, et al. 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-2922.txt | Citing Article:  D11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While in the previous sections we have described a tabular method for the transition system of Attardi (2006) restricted to transitions of degree up to two, it is possible to generalize the model to include higher degree transitions.</S> | Reference Offset:  ['31','91'] | Reference Text:  <S sid = 31 ssid = >For example, the parameter PosFeatures determines for which tokens the POS tag will be included in the context, PosLeftChi7dren determines how many left outermost children of a token to consider, PastActions tells how many previous actions to include as features.</S><S sid = 91 ssid = >Prepositions are problematic, but their error rate is higher than expected since they are, in terms of surface order, rather regular and close to the noun.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-2922.txt | Citing Article:  W07-2217.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We build upon DeSR, the shift-reduce parser described in (Attardi, 2006).</S> | Reference Offset:  ['6','62'] | Reference Text:  <S sid = 6 ssid = >These parsers are based on learning the correct sequence of Shift/Reduce actions used to construct the dependency tree.</S><S sid = 62 ssid = >Shift/Reduce, one to decide which Reduce action and a third one to choose the dependency in case of Left/Right action For details on the CoNLL-X shared task and the measurements see (Buchholz, et al. 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-2922.txt | Citing Article:  W07-2217.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Attardi, 2006)) have been introduced for handling non-projective dependency trees: i.e., trees that can not be drawn in the plane without crossing edges.</S> | Reference Offset:  ['0','43'] | Reference Text:  <S sid = 0 ssid = >Experiments With A Multilanguage Non-Projective Dependency Parser</S><S sid = 43 ssid = >For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-2922.txt | Citing Article:  W11-0314.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ULISSE was tested against the output of two really different data-driven parsers: the first order Maximum Spanning Tree (MST) parser (McDonald et al., 2006) and the DeSR parser (Attardi, 2006) using Support Vector Machine as learning algorithm.</S> | Reference Offset:  ['9','98'] | Reference Text:  <S sid = 9 ssid = >Using Maximum Entropy (Berger, et al. 1996) classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss in accuracy of about 23 %.</S><S sid = 98 ssid = >The following treebanks were used for training the parser: (Afonso et al., 2002; Atalay et al., 2003; Böhmovà et al., 2003; Brants et al., 2002; Chen et al., 2003; Civit Torruella and Martì Antonìn, 2002; Džeroski et al., 2006; Hajiç et al., 2004; Kawata and Bartels, 2000; Kromann, 2003; Nilsson et al., 2005; Oflazer et al., 2003; Simov et al., 2005; van der Beek et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


