Citance Number: 1 | Reference Article:  P06-1009.txt | Citing Article:  P14-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These models are roughly clustered into two groups: generative models, such as those proposed by Brown et al (1993), Vogel et al (1996), and Och and Ney (2003), and discriminative models, such as those proposed by Taskar et al (2005), Moore (2005), and Blunsom and Cohn (2006).</S> | Reference Offset:  ['10','170'] | Reference Text:  <S sid = 10 ssid = >Most current SMT systems (Och and Ney, 2004; Koehn et al., 2003) use a generative model for word alignment such as the freely available GIZA++ (Och and Ney, 2003), an implementation of the IBM alignment models (Brown et al., 1993).</S><S sid = 170 ssid = >Recently, a number of discriminative word alignment models have been proposed, however these early models are typically very complicated with many proposing intractable problems which require heuristics for approximate inference (Liu et al., 2005; Moore, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1009.txt | Citing Article:  P08-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Such approaches have been shown to be effective in log-linear word alignment models where only a small supervised corpus is available (Blunsom and Cohn, 2006).</S> | Reference Offset:  ['2','188'] | Reference Text:  <S sid = 2 ssid = >We use a Conditional Random Field (CRF), a discriminative model, which is estimated on a small supervised training set.</S><S sid = 188 ssid = >These models allow for the use of arbitrary and overlapping features over the source and target sentences, making the most of small supervised training sets.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1009.txt | Citing Article:  W08-0303.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The one most similar to ours is the one presented by Blunsom and Cohn (2006).</S> | Reference Offset:  ['182','186'] | Reference Text:  <S sid = 182 ssid = >The results presented in this paper were evaluated in terms of AER.</S><S sid = 186 ssid = >We have presented a novel approach for inducing word alignments from sentence aligned data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1009.txt | Citing Article:  D09-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Labeled alignments are also used by Blunsom and Cohn (2006) to train a CRF word alignment model.</S> | Reference Offset:  ['34','187'] | Reference Text:  <S sid = 34 ssid = >We use a CRF to model many-to-one word alignments, where each source word is aligned with zero or one target words, and therefore each target word can be aligned with many source words.</S><S sid = 187 ssid = >We showed how conditional random fields could be used for word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1009.txt | Citing Article:  N10-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The model is similar to the discriminative CRF-based word alignment model of (Blunsom and Cohn, 2006).</S> | Reference Offset:  ['0','20'] | Reference Text:  <S sid = 0 ssid = >Discriminative Word Alignment With Conditional Random Fields</S><S sid = 20 ssid = >This paper presents an alternative discriminative method for word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1009.txt | Citing Article:  D11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Examples include the maximum entropy model of (Ittycheriah and Roukos, 2005) or the conditional random field jointly normalized over the entire sequence of alignments of (Blunsom and Cohn, 2006).</S> | Reference Offset:  ['2','21'] | Reference Text:  <S sid = 2 ssid = >We use a Conditional Random Field (CRF), a discriminative model, which is estimated on a small supervised training set.</S><S sid = 21 ssid = >We use a conditional random field (CRF) sequence model, which allows for globally optimal training and decoding (Lafferty et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1009.txt | Citing Article:  D11-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The model is trained by gradient ascent using the l-BFGS method (Liu and Nocedal, 1989), which has been successfully used for training log linear models (Blunsom and Cohn, 2006) in many natural language tasks, including alignment.</S> | Reference Offset:  ['50','176'] | Reference Text:  <S sid = 50 ssid = >We use L-BFGS, an iterative quasi-Newton optimisation method, which performs well for training log-linear models (Malouf, 2002; Sha and Pereira, 2003).</S><S sid = 176 ssid = >Liu et al. (2005) used a conditional log-linear model with similar features to those we have employed.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1009.txt | Citing Article:  W07-0407.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Blunsom and Cohn, 2006) do word alignment by combining features using conditional random fields.</S> | Reference Offset:  ['0','187'] | Reference Text:  <S sid = 0 ssid = >Discriminative Word Alignment With Conditional Random Fields</S><S sid = 187 ssid = >We showed how conditional random fields could be used for word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1009.txt | Citing Article:  I08-2124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Reported work includes improved model variants (e.g., Jiao et al, 2006) and applications such as web data extraction (Pinto et al, 2003), scientific citation extraction (Peng and McCallum, 2004), word alignment (Blunsom and Cohn, 2006), and discourse level chunking (Feng et al, 2007).</S> | Reference Offset:  ['10','18'] | Reference Text:  <S sid = 10 ssid = >Most current SMT systems (Och and Ney, 2004; Koehn et al., 2003) use a generative model for word alignment such as the freely available GIZA++ (Och and Ney, 2003), an implementation of the IBM alignment models (Brown et al., 1993).</S><S sid = 18 ssid = >Toutanova et al. (2002)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1009.txt | Citing Article:  P13-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006).</S> | Reference Offset:  ['31','92'] | Reference Text:  <S sid = 31 ssid = >Section 5 presents related work, and we describe future work in Section 6.</S><S sid = 92 ssid = >Bilingual dictionary Dictionaries are another source of information for word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


