Citance Number: 1 | Reference Article:  W01-0514.txt | Citing Article:  P03-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['56','226'] | Reference Text:  <S sid = 56 ssid = >The basic keyword search approach retrieves all documents which contain some or all of the query terms.</S><S sid = 226 ssid = >Thanks are due to the anonymous reviewers for their invaluable comments; Masao Utiyama and Hitoshi Isahara for providing the U00 algorithm and detailed results; Marti Hearst for guidance on the evaluation problem; Mary McGee Wood for support and HCRC for making this work possible.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W01-0514.txt | Citing Article:  P13-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >PLSA is the probabilistic variant of latent semantic analysis (LSA) (Choi et al, 2001), and offers a more solid statistical foundation.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >Latent Semantic Analysis For Text Segmentation</S><S sid = 2 ssid = >Inter-sentence similarity is estimated by latent semantic analysis (LSA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Choi at al. used LSA for segmentation (Choi et al., 2001).</S> | Reference Offset:  ['128','205'] | Reference Text:  <S sid = 128 ssid = >Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S><S sid = 205 ssid = >C99 (Choi, 2000a) was used as the test bench.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Choi et al, 2001) used all vocabulary words to compute low-dimensional document vectors.</S> | Reference Offset:  ['79','80'] | Reference Text:  <S sid = 79 ssid = >In other words, the first k columns of U, or Ak, is the best approximation of BBT in k—dimensional space.</S><S sid = 80 ssid = >Ak is the k—dimensional LSA space for A.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W01-0514.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Choi et al, 2001) used clustering to predict boundaries whereas we used the average similarity scores.</S> | Reference Offset:  ['30','205'] | Reference Text:  <S sid = 30 ssid = >Existing algorithms used a sliding window (Hearst, 1994), lexical chains (Morris, 1988; Kan et al., 1998), dynamic programming (Ponte and Croft, 1997; Heinonen, 1998; Utiyama and Isahara, 2001), agglomerative clustering (Yaari, 1997) and divisive clustering (Reynar, 1994; Choi, 2000a) to determine the optimal segmentation.</S><S sid = 205 ssid = >C99 (Choi, 2000a) was used as the test bench.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W01-0514.txt | Citing Article:  H05-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is a very powerful technique already used for NLP applications such as information retrieval (Berry et al, 1995) and text segmentation (Choi et al, 2001) and, more recently, multi and single-document summarization.</S> | Reference Offset:  ['26','128'] | Reference Text:  <S sid = 26 ssid = >Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S><S sid = 128 ssid = >Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W01-0514.txt | Citing Article:  P07-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In CWM (Choi et al, 2001), a variant of C99, each word of a sentence is replaced by its representation in a Latent Semantic Analysis (LSA) space.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >Latent Semantic Analysis For Text Segmentation</S><S sid = 2 ssid = >Inter-sentence similarity is estimated by latent semantic analysis (LSA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W01-0514.txt | Citing Article:  P08-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['56','226'] | Reference Text:  <S sid = 56 ssid = >The basic keyword search approach retrieves all documents which contain some or all of the query terms.</S><S sid = 226 ssid = >Thanks are due to the anonymous reviewers for their invaluable comments; Masao Utiyama and Hitoshi Isahara for providing the U00 algorithm and detailed results; Marti Hearst for guidance on the evaluation problem; Mary McGee Wood for support and HCRC for making this work possible.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W01-0514.txt | Citing Article:  D10-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While extensive research has been conducted in topic segmentation for monologues (e.g., (Malioutov and Barzilay, 2006), (Choi et al, 2001)) and synchronous dialogs (e.g., (Galley et al, 2003), (Hsueh et al, 2006)), none has studied the problem of segmenting asynchronous multi-party conversations (e.g., email).</S> | Reference Offset:  ['26','128'] | Reference Text:  <S sid = 26 ssid = >Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S><S sid = 128 ssid = >Segmentation accuracy is measured by the metric proposed in (Beeferman et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The CWM algorithm (Choi et al, 2001) applies the same procedure to a similarity matrix of LSI vectors.</S> | Reference Offset:  ['110','168'] | Reference Text:  <S sid = 110 ssid = >The input matrix X can either be the similarity matrix M or the rank matrix R, depending on whether ranking is applied to M. Topic boundaries are identified by the divisive clustering procedure in C99.</S><S sid = 168 ssid = >Our new algorithm, CWM, was used in this experiment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As a preliminary test of the error measure, I evaluated two algorithms from Choi et al (2001) on the standard segmentation data set that Choi (2000) compiled.</S> | Reference Offset:  ['4','191'] | Reference Text:  <S sid = 4 ssid = >Test results show LSA is a more accurate similarity measure than the</S><S sid = 191 ssid = >C99 and C99b are the algorithms described in (Choi, 2000a).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The C99 (Choi, 2000) and CWM (Choi et al, 2001) algorithms were evaluated.</S> | Reference Offset:  ['191','205'] | Reference Text:  <S sid = 191 ssid = >C99 and C99b are the algorithms described in (Choi, 2000a).</S><S sid = 205 ssid = >C99 (Choi, 2000a) was used as the test bench.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because of these differences, the implementation of HCWM reported here differs somewhat from the implementation of CWM reported by Choi et al (2001).</S> | Reference Offset:  ['118','153'] | Reference Text:  <S sid = 118 ssid = >For implementation details and optimisations, see (Choi, 2000a).</S><S sid = 153 ssid = >This implementation of C99 has three parameters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(12.5%) matches what Choi et al (2001) reported (12%), while the error for HCWM (12.1%) is higher than that reported for the version with a paragraph-based 500-dimension LSI space (9%) but appears comparable to their sentence-based 400-dimension LSI space.</S> | Reference Offset:  ['172','173'] | Reference Text:  <S sid = 172 ssid = >The values {100, 200, 300, 400, 500} represent the dimensionality of the trained space.</S><S sid = 173 ssid = >For instance, &quot;p, 400&quot; is a 400-dimensional space that was trained on paragraphs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W01-0514.txt | Citing Article:  N10-1143.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >And the result for NONE (46.1%) agrees with Choi et al (2001)'s results for their NONE (46%) base line.</S> | Reference Offset:  ['26','203'] | Reference Text:  <S sid = 26 ssid = >Features are combined using decision trees (Miike et al., 1994; Kurohashi and Nagao, 1994; Litman and Passonneau, 1995), probabilistic models (Hajime et al., 1998) and maximum entropy models (Beeferman et al., 1997; Reynar, 1998).</S><S sid = 203 ssid = >The significance of our results has been confirmed by both t-test and KS-test (Press et al., 1992).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W01-0514.txt | Citing Article:  N04-4025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, LSA has been applied to a number of NLP tasks, such as text segmentation (Choi et al, 2001).</S> | Reference Offset:  ['70','148'] | Reference Text:  <S sid = 70 ssid = >LSA has been shown to match human similarity judgements on a wide range of tasks (Landauer and Dumais, 1997; Wolfe et al., 1998; Wiemer-Hastings et al., 1999, for example).</S><S sid = 148 ssid = >B? serves as the baseline for methods that determines the optimal segmentation, i.e. the number of topic segments in a text.</S> | Discourse Facet:  NA | Annotator: Automatic


