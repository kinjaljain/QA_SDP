Citance Number: 1 | Reference Article:  P93-1041.txt | Citing Article:  W10-2310.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Lexical cohesion techniques include similarity measures between adjacent blocks of text, as in TextTiling (Hearst, 1994, 1997) and lexical chains based on recurrences of a term or related terms, as in Morris and Hirst (1991), Kozima (1993), and Galley, et al.</S> | Reference Offset:  ['0','24'] | Reference Text:  <S sid = 0 ssid = >Text Segmentation Based On Similarity Between Words</S><S sid = 24 ssid = >Morris and Hirst (1991) used Roget's thesaurus to determine whether or not two words have lexical cohesion.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P93-1041.txt | Citing Article:  W01-0909.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in Kozima's work (Kozima, 1993), this computation operates on words belonging to a focus window that is moved all over the text.</S> | Reference Offset:  ['27','49'] | Reference Text:  <S sid = 27 ssid = >Kozima and Furugori (1993) defined lexical cohesiveness as semantic similarity between words, and proposed a method for measuring it.</S><S sid = 49 ssid = >Experiments on several window shapes (e.g. triangle window, etc.) shows that Harming window is best for clarifying the macroscopic features of LCP.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P93-1041.txt | Citing Article:  P98-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Related words have been located using spreading activation on a semantic network (Kozima, 1993), although only one text was segmented.</S> | Reference Offset:  ['4','15'] | Reference Text:  <S sid = 4 ssid = >The similarity of words, which represents their cohesiveness, is computed using a semantic network.</S><S sid = 15 ssid = >Lexical cohesiveness is defined as word similarity (Kozima and Furugori, 1993) computed by spreading activation on a semantic network.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P93-1041.txt | Citing Article:  C02-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >But work such as (Kozima, 1993), (Ferret, 1998) or (Kaufmann, 1999) showed that using a domain independent source of knowledge for text segmentation doesn't necessarily lead to get better results than work that is only based on word distribution in texts.</S> | Reference Offset:  ['0','22'] | Reference Text:  <S sid = 0 ssid = >Text Segmentation Based On Similarity Between Words</S><S sid = 22 ssid = >However, VMP does not work well on a high-density text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P93-1041.txt | Citing Article:  C02-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This significance is defined as in (Kozima, 1993) as its normalized information in a reference corpus.</S> | Reference Offset:  ['27','31'] | Reference Text:  <S sid = 27 ssid = >Kozima and Furugori (1993) defined lexical cohesiveness as semantic similarity between words, and proposed a method for measuring it.</S><S sid = 31 ssid = >The similarity a- depends on the significance s(w) E [0, 1], i.e. normalized information of the word w in West's corpus (1953).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P93-1041.txt | Citing Article:  P99-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >He identified topic boundaries where the LCP score was low (Kozima, 1993).</S> | Reference Offset:  ['55','59'] | Reference Text:  <S sid = 55 ssid = >It is clear that the valleys of the LCP correspond mostly to the dominant segment boundaries.</S><S sid = 59 ssid = >However, some valleys of the LCP do not exactly correspond to segment boundaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P93-1041.txt | Citing Article:  P98-2244.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, the lexical cohesion profile (Kozima, 1993) should be perfectly usable with our fragmentation method.</S> | Reference Offset:  ['13','27'] | Reference Text:  <S sid = 13 ssid = >This paper proposes an indicator, called the lexical cohesion profile (LCP), which locates segment boundaries in a narrative text.</S><S sid = 27 ssid = >Kozima and Furugori (1993) defined lexical cohesiveness as semantic similarity between words, and proposed a method for measuring it.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P93-1041.txt | Citing Article:  H05-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ever since Morris and Hirst (1991)'s ground breaking paper, topic segmentation has been a steadily growing research area in computational linguistics, with applications in summarization (Barzilay and Elhadad, 1997), information retrieval (Salton and Allan, 1994), and text understanding (Kozima, 1993).</S> | Reference Offset:  ['24','64'] | Reference Text:  <S sid = 24 ssid = >Morris and Hirst (1991) used Roget's thesaurus to determine whether or not two words have lexical cohesion.</S><S sid = 64 ssid = >Text segmentation described here provides basic information for text understanding: Segment boundaries provide valuable restriction for determination of the referents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P93-1041.txt | Citing Article:  D07-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, many approaches have concentrated on different ways of estimating lexical coherence of text segments, such as semantic similarity between words (Kozima, 1993), similarity between blocks of text (Hearst, 1994), and adaptive language models (Beeferman et al, 1999).</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >Text Segmentation Based On Similarity Between Words</S><S sid = 27 ssid = >Kozima and Furugori (1993) defined lexical cohesiveness as semantic similarity between words, and proposed a method for measuring it.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P93-1041.txt | Citing Article:  P98-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in Kozima (1993), the second method exploits lexical cohesion to segment exts, but in a different way.</S> | Reference Offset:  ['27','62'] | Reference Text:  <S sid = 27 ssid = >Kozima and Furugori (1993) defined lexical cohesiveness as semantic similarity between words, and proposed a method for measuring it.</S><S sid = 62 ssid = >This paper proposed LCP, all indicator of segment changing, which concentrates on lexical cohesion of a text. segment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P93-1041.txt | Citing Article:  P01-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kozima (1993), for example, used cohesion based on the spreading activation on a semantic network.</S> | Reference Offset:  ['15','28'] | Reference Text:  <S sid = 15 ssid = >Lexical cohesiveness is defined as word similarity (Kozima and Furugori, 1993) computed by spreading activation on a semantic network.</S><S sid = 28 ssid = >Similarity between words is computed by spreading activation on a semantic network which is systematically constructed from an English dictionary (LDOCE).</S> | Discourse Facet:  NA | Annotator: Automatic


