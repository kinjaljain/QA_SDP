Citance Number: 1 | Reference Article:  W03-1728.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The word segmenter we built is similar to the maximum entropy word segmenter of (Xue and Shen, 2003).</S> | Reference Offset:  ['31','52'] | Reference Text:  <S sid = 31 ssid = >A maximum entropy part-oftagger.</S><S sid = 52 ssid = >The ambiguities in Chinese word segmentation is due to the fact that a hanzi can occur in different word-internal positions (Xue, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-1728.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The default feature, boundary tag feature of the previous character, and boundary tag feature of the character two before the current character used in (Xue and Shen, 2003) were dropped from our word segmenter, as they did not improve word segmentation accuracy in our experiments.</S> | Reference Offset:  ['84','86'] | Reference Text:  <S sid = 84 ssid = >Feature templates (b) to (e) represent character features while (f) represents tag features.</S><S sid = 86 ssid = >), the previous two characters ( ), and the next two characters ( ) (e) The previous and the next character ( ) (f) The tag of the previous character ( ), and the tag of the character two before the current character ( ) One potential problem with the MEMM is that it can only scan the input in one direction, from left to right or from right to left.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-1728.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We observed that character features were successfully used to build our word segmenter and that of (Xue and Shen, 2003).</S> | Reference Offset:  ['84','91'] | Reference Text:  <S sid = 84 ssid = >Feature templates (b) to (e) represent character features while (f) represents tag features.</S><S sid = 91 ssid = >This strategy has been successfully used in (Shen and Joshi, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-1728.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our maximum entropy word segmenter is similar to that of (Xue and Shen, 2003), but the additional features we used and the post processing step gave improved word segmentation accuracy.</S> | Reference Offset:  ['46','52'] | Reference Text:  <S sid = 46 ssid = >Chinese word segmentation as tagging.</S><S sid = 52 ssid = >The ambiguities in Chinese word segmentation is due to the fact that a hanzi can occur in different word-internal positions (Xue, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-1728.txt | Citing Article:  P13-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Word segmentation can be formalized as a character classification problem (Xue and Shen, 2003), where each character in the sentence is given a boundary tag representing its position in a word.</S> | Reference Offset:  ['46','86'] | Reference Text:  <S sid = 46 ssid = >Chinese word segmentation as tagging.</S><S sid = 86 ssid = >), the previous two characters ( ), and the next two characters ( ) (e) The previous and the next character ( ) (f) The tag of the previous character ( ), and the tag of the character two before the current character ( ) One potential problem with the MEMM is that it can only scan the input in one direction, from left to right or from right to left.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-1728.txt | Citing Article:  I05-3023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This kind of strategy has been widely used in the applications of machine learning to named entity recognition and has also been used in Chinese word segmentation (Xue and Shen, 2003).</S> | Reference Offset:  ['46','91'] | Reference Text:  <S sid = 46 ssid = >Chinese word segmentation as tagging.</S><S sid = 91 ssid = >This strategy has been successfully used in (Shen and Joshi, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-1728.txt | Citing Article:  I05-3023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 3 compares the three types of kernel for Perceptron, where for the semi quadratic kernel we used the co-occurrences of characters in context window as those used in (Xue and Shen, 2003), namely{ c? 2c? 1, c? 1c0 ,c0c1 ,c1c2, c? 1c1}.</S> | Reference Offset:  ['34','91'] | Reference Text:  <S sid = 34 ssid = >2003.</S><S sid = 91 ssid = >This strategy has been successfully used in (Shen and Joshi, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-1728.txt | Citing Article:  I08-2134.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Character n-gram features have proven their effectiveness in ML-based CWS (Xue and Shen,2003).</S> | Reference Offset:  ['43','84'] | Reference Text:  <S sid = 43 ssid = >2003.</S><S sid = 84 ssid = >Feature templates (b) to (e) represent character features while (f) represents tag features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-1728.txt | Citing Article:  N06-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It was first used in Chinese word segmentation by (Xue and Shen, 2003), where maximum entropy methods were used.</S> | Reference Offset:  ['0','46'] | Reference Text:  <S sid = 0 ssid = >Chinese Word Segmentation As LMR Tagging</S><S sid = 46 ssid = >Chinese word segmentation as tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-1728.txt | Citing Article:  I08-4033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004).</S> | Reference Offset:  ['45','50'] | Reference Text:  <S sid = 45 ssid = >2003.</S><S sid = 50 ssid = >This may sound simple enough but in reality identifying words in Chinese is a non-trivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-1728.txt | Citing Article:  I05-3019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The conditional maximum entropy model in our implementation is based on the one described in Section 2.5 in (Ratnaparkhi, 1998), and features are the same as those described in (Xue and Shen, 2003).</S> | Reference Offset:  ['41','77'] | Reference Text:  <S sid = 41 ssid = >1998.</S><S sid = 77 ssid = >The Maximum Entropy Markov Model used in POS-tagging is described in detail in (Ratnaparkhi, 1996) and the LMR tagger here uses the same probability model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-1728.txt | Citing Article:  P08-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since the typical approach of discriminative models treats segmentation as a labelling problem by assigning each character a boundary tag (Xue and Shen, 2003), Joint S&T can be conducted in a labelling fashion by expanding boundary tags to include POS information (Ngand Low, 2004).</S> | Reference Offset:  ['20','86'] | Reference Text:  <S sid = 20 ssid = >A statistically emergent approach for language processing: Application to modeling context effects in chinese word boundary perception.</S><S sid = 86 ssid = >), the previous two characters ( ), and the next two characters ( ) (e) The previous and the next character ( ) (f) The tag of the previous character ( ), and the tag of the character two before the current character ( ) One potential problem with the MEMM is that it can only scan the input in one direction, from left to right or from right to left.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-1728.txt | Citing Article:  W10-4127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >By casting the problem as a character labeling task, sequence labeling models such as Conditional Random Fields can be applied on the problem (Xue and Shen, 2003).</S> | Reference Offset:  ['24','88'] | Reference Text:  <S sid = 24 ssid = >Conditional random fields: Probabilistic models for stgmenand labeling sequence data.</S><S sid = 88 ssid = >They proposed Conditional Random Fields (CRFs) as a solution to address this problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-1728.txt | Citing Article:  P06-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine Now the second author is affiliated with NTT.</S> | Reference Offset:  ['34','45'] | Reference Text:  <S sid = 34 ssid = >2003.</S><S sid = 45 ssid = >2003.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-1728.txt | Citing Article:  P06-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the third step, we used the maximum entropy (MaxEnt) approach (the results of CRF are given in Section 3.4) to train the IOB tagger (Xue and Shen, 2003).</S> | Reference Offset:  ['31','74'] | Reference Text:  <S sid = 31 ssid = >A maximum entropy part-oftagger.</S><S sid = 74 ssid = >The Maximum Entropy Markov Model (MEMM) has been successfully used in some tagging problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-1728.txt | Citing Article:  P06-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It was first implemented in Chinese word segmentation by (Xue and Shen, 2003) using the maximum entropy methods.</S> | Reference Offset:  ['0','46'] | Reference Text:  <S sid = 0 ssid = >Chinese Word Segmentation As LMR Tagging</S><S sid = 46 ssid = >Chinese word segmentation as tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-1728.txt | Citing Article:  P09-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Xue and Shen (2003) describe for the first time the character classification approach for Chinese word segmentation, where each character is given a boundary tag denoting its relative position in a word.</S> | Reference Offset:  ['46','86'] | Reference Text:  <S sid = 46 ssid = >Chinese word segmentation as tagging.</S><S sid = 86 ssid = >), the previous two characters ( ), and the next two characters ( ) (e) The previous and the next character ( ) (f) The tag of the previous character ( ), and the tag of the character two before the current character ( ) One potential problem with the MEMM is that it can only scan the input in one direction, from left to right or from right to left.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-1728.txt | Citing Article:  I05-3031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this paper, we propose a statistical approach based on the works of (Xue and Shen, 2003), in which the Chinese word segmentation problem is first transformed into a tagging problem, then the Maximum Entropy classifier is applied to solve the problem.</S> | Reference Offset:  ['46','54'] | Reference Text:  <S sid = 46 ssid = >Chinese word segmentation as tagging.</S><S sid = 54 ssid = >In this paper, we model the Chinese word segmentation as a hanzi tagging problem and use a machine-learning algorithm to determine the appropriate position for a hanzi.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-1728.txt | Citing Article:  I05-3031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >we briefly discuss the scheme proposed by (Xue and Shen, 2003), followed by our additional works to improve the performance.</S> | Reference Offset:  ['34','43'] | Reference Text:  <S sid = 34 ssid = >2003.</S><S sid = 43 ssid = >2003.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-1728.txt | Citing Article:  I05-3031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One of the difficulties in Chinese word segmentation is that, Chinese characters can appear in different positions within a word (Xue and Shen, 2003), and LMR Tagging was proposed to solve the problem.</S> | Reference Offset:  ['0','46'] | Reference Text:  <S sid = 0 ssid = >Chinese Word Segmentation As LMR Tagging</S><S sid = 46 ssid = >Chinese word segmentation as tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


