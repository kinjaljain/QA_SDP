Citance Number: 1 | Reference Article:  C02-1150.txt | Citing Article:  W03-0412.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our approach to QC follows that of (Li and Roth, 2002).</S> | Reference Offset:  ['19','21'] | Reference Text:  <S sid = 19 ssid = >The paper is organized as follows: Sec.</S><S sid = 21 ssid = >3 discusses the learning issues involved in QC and presents ourlearning approach; Sec.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C02-1150.txt | Citing Article:  P14-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We will use the TREC dataset provided by Li and Roth (2002), which assigns 6000 questions with both a coarse and a fine-grained label.</S> | Reference Offset:  ['91','101'] | Reference Text:  <S sid = 91 ssid = >The first classifies questions into coarse classes (Coarse Classifier) and the second into fineclasses (Fine Classifier).</S><S sid = 101 ssid = >Then each coarse class label in C 1 is expanded to a fixed set of fine classesdetermined by the class hierarchy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C02-1150.txt | Citing Article:  W11-2401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This scheme is more suitable here than other common answer-typing schemata such as the one in Li and Roth (2002), which tend to focus on questions asking for factual knowledge.</S> | Reference Offset:  ['24','194'] | Reference Text:  <S sid = 24 ssid = >The intension is that this 1We do not address questions like ?Do you have a light??, which calls for an action, but rather only factual Wh-questions.</S><S sid = 194 ssid = >Our feature sensors fail to determine that the focus of the question is ?speed?.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C02-1150.txt | Citing Article:  N07-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is important because while large sets of existing questions can be obtained (Li and Roth, 2002), there are many fewer questions with available answers. Our experiments demonstrate that how-question specific unit lists consistently achieve higher answer identification performance than fixed-type, general purpose answer typing (which propose all numerical entities as answer candidates).</S> | Reference Offset:  ['10','36'] | Reference Text:  <S sid = 10 ssid = >of the sought after answer.</S><S sid = 36 ssid = >Moreover, determin ing the specific semantic type of the answer couldalso be beneficial in locating the answer and veri fying it.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C02-1150.txt | Citing Article:  N07-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Li and Roth (2002) assign one of fifty possible types to a question based on features present in the question.</S> | Reference Offset:  ['70','88'] | Reference Text:  <S sid = 70 ssid = >To avoid this problem,we allow our classifiers to assign multiple class la bels for a single question.</S><S sid = 88 ssid = >A question can be mapped to one of 50 pos sible classes (We call the set of all possible class labels for a given question a confusion set (Golding and Roth, 1999)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C02-1150.txt | Citing Article:  W06-1906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Li and Roth, 2002) propose a system based on SNoW.</S> | Reference Offset:  ['116','117'] | Reference Text:  <S sid = 116 ssid = >Pos tags are extracted using a SNoW-based pos tagger (Even-Zohar and Roth, 2001).</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C02-1150.txt | Citing Article:  W06-1906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The same dataset has been used in other investigations, such as in (Li and Roth, 2002). The distribution of these 5500 training questions, with respect to its interrogative pronoun or the initial word is showed in Table 1.</S> | Reference Offset:  ['152','165'] | Reference Text:  <S sid = 152 ssid = >All 500 TREC 10 questions are used as the test set.</S><S sid = 165 ssid = >Training is done on 5,500 questions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C02-1150.txt | Citing Article:  W06-1906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Li and Roth, 2002) obtain a better performance for English, around a 92.5% in terms of accuracy.</S> | Reference Offset:  ['174','176'] | Reference Text:  <S sid = 174 ssid = >Our original hope was that the hierarchical classifier would have a better performance, given that its fine classifier only needs to deal with a smaller confusion set.</S><S sid = 176 ssid = >As the results show, there is no perfor mance advantage for using a level of coarse classes, and the semantically appealing coarse classes do not contribute to better performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C02-1150.txt | Citing Article:  W06-1906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It could be also interested to test the combination between a better QC system, the current one by Li and Roth's for instance (Li and Roth, 2002), and our machine translation method.</S> | Reference Offset:  ['71','117'] | Reference Text:  <S sid = 71 ssid = >This method is better than only allowing one label because we can apply all the classes in the later precessing steps without any loss.</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C02-1150.txt | Citing Article:  D09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Li and Roth (2002) have developed a machine learning approach which uses the SNoW learning architecture.</S> | Reference Offset:  ['3','199'] | Reference Text:  <S sid = 3 ssid = >This paper presents a machine learning approach toquestion classification.</S><S sid = 199 ssid = >This paper presents a machine learning approach to question classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C02-1150.txt | Citing Article:  D09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Compared to the over feature size of 200000 in Li and Roth (2002), our feature space is much more compact, yet turned out to be more informative as suggested by the experiments.</S> | Reference Offset:  ['105','128'] | Reference Text:  <S sid = 105 ssid = >3.2 Feature Space.</S><S sid = 128 ssid = >Overall, there are about 200; 000 features in the feature space of RelWorddue to the generation of complex features over sim ple feature types.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C02-1150.txt | Citing Article:  H05-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >With the increasing popularity of statistical NLP, Li and Roth (2002), Hacioglu and Ward (2003) and Zhang and Lee (2003) used supervised learning for question classification on a data set from UIUC that is now standard1.</S> | Reference Offset:  ['72','146'] | Reference Text:  <S sid = 72 ssid = >3 Learning a Question Classifier.</S><S sid = 146 ssid = >4.1 Data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C02-1150.txt | Citing Article:  H05-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Li and Roth (2002) used a Sparse Network of Winnows (SNoW) (Khardon et al, 1999).</S> | Reference Offset:  ['6','49'] | Reference Text:  <S sid = 6 ssid = >Open-domain question answering (Lehnert, 1986; Harabagiu et al, 2001; Light et al, 2001) and storycomprehension (Hirschman et al, 1999) have become important directions in natural language pro cessing.</S><S sid = 49 ssid = >How ever, in the context of factual questions that are of interest to us here, conceptual categories do notseem to be helpful; instead, our goal is to se mantically classify questions, as in earlier work on TREC (Singhal et al, 2000; Hovy et al, 2001; Harabagiu et al, 2001; Ittycheriah et al, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C02-1150.txt | Citing Article:  H05-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our findings corroborate Li and Roth (2002), who report little benefit from adding head chunk features for the fine classification task.</S> | Reference Offset:  ['62','115'] | Reference Text:  <S sid = 62 ssid = >One difficulty in the question classification task is that there is no completely clear boundary between classes.</S><S sid = 115 ssid = >Among the 6 primitive feature types, pos tags, chunks and head chunks are syntactic features while named entities and semantically related words are semantic features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C02-1150.txt | Citing Article:  P08-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >in (Li and Roth, 2002) to our basic QA system, YourQA (Quarteroni and Manandhar, 2008) and by gathering the top 20 answer paragraphs.</S> | Reference Offset:  ['10','117'] | Reference Text:  <S sid = 10 ssid = >of the sought after answer.</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C02-1150.txt | Citing Article:  W09-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','202'] | Reference Text:  <S sid = 63 ssid = >Therefore, the classification of a specific question can be quite ambiguous.</S><S sid = 202 ssid = >In future work we plan to investigate further the application of deeper semantic analysis (including better named entity and semantic categorization) to feature extraction, automate the generation of thesemantic features and develop a better understand ing to some of the learning issues involved in thedifference between a flat and a hierarchical classi fier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C02-1150.txt | Citing Article:  D07-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Answer types are determined using classification rules similar to Li and Roth (2002).</S> | Reference Offset:  ['2','117'] | Reference Text:  <S sid = 2 ssid = >These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer.</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C02-1150.txt | Citing Article:  P09-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The classification scheme we propose is based on one dynamic 1 and one static layer, contrasting with previous work that uses static taxonomies (Li and Roth, 2002).</S> | Reference Offset:  ['55','117'] | Reference Text:  <S sid = 55 ssid = >The motiva tion behind adding a level of coarse classes is that of compatibility with previous work?s definitions, andcomprehensibility.</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C02-1150.txt | Citing Article:  P09-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >1500 of those questions come from the Li and Roth corpus (Li and Roth, 2002), 500 questions were taken from the TREC-10 questions and 100 questions were asked over the Italian Opera topic map.</S> | Reference Offset:  ['147','152'] | Reference Text:  <S sid = 147 ssid = >Data are collected from four sources: 4,500 English questions published by USC (Hovy et al, 2001), about 500 manually constructed questions for a few rare classes, 894 TREC 8 and TREC 9 questions, and also 500 questions from TREC 10 which serves as our test set3.These questions were manually labeled accord ing to our question hierarchy.</S><S sid = 152 ssid = >All 500 TREC 10 questions are used as the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C02-1150.txt | Citing Article:  P09-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We followed Li and Roth (Li and Roth, 2002) to implement the features for the EAT classifier.</S> | Reference Offset:  ['67','117'] | Reference Text:  <S sid = 67 ssid = >What do bats eat?.</S><S sid = 117 ssid = >Chunks are extracted using a previously learned classifier (Punyakanok and Roth, 2001; Li and Roth, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


