Citance Number: 1 | Reference Article:  C92-3126.txt | Citing Article:  E93-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a treatment of DOP in more formal terms we refer to (Bod, 1992a).</S> | Reference Offset:  ['97','113'] | Reference Text:  <S sid = 97 ssid = >In [Scholtes 1992] a neural net implementation f DOP is proposed, ltere we will show that conventional rule- based parsing strategies can be applied tn DOP, by converting constructions into rules.</S><S sid = 113 ssid = >An additional remark should be devoted here to formal granlmars and disambiguation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C92-3126.txt | Citing Article:  E93-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Bod, 1992b) super strong equivalence relations between other stochastic grammars are studied.</S> | Reference Offset:  ['51','115'] | Reference Text:  <S sid = 51 ssid = >A New Approach: Data Oriented Parsing The starting-point of our approach is the idea indicated above, that when a human language user analyzes sentences, there is a strong preference for the recognition of sentences, constituents and patterns that occurred before in the experience of the language user.</S><S sid = 115 ssid = >No one has ever succeeded in doing so except in relatively small grammars.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C92-3126.txt | Citing Article:  E93-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is easy to show that an input string can be parsed with conventional parsing techniques, by applying subtrees instead of rules to the input string (Bod, 1992a).</S> | Reference Offset:  ['56','101'] | Reference Text:  <S sid = 56 ssid = >Parsing then does not happen by applying grammatical rules to rite input sentence, but by constructing an optinml analogy between the input sentence and as many corpus sentences ,as possible.</S><S sid = 101 ssid = >Often we are not interested in all parses of an alnbiguous input string, neither in their exact probabilities, but only in which parse is the preferred parse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C92-3126.txt | Citing Article:  P12-2062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In their place we added a new feature, the probability of a rule's source side tree given its root label, which is essentially the same model used in Data-Oriented Parsing (Bod, 1992).</S> | Reference Offset:  ['0','60'] | Reference Text:  <S sid = 0 ssid = >A COMPUTATIONAL MODEL OF LANGUAGE DATA ORIENTED PARSING RENS BOlt* Department of Computational I Jnguistics University of Amsterdmn Spuistraat 134 1012 VII Amsterdam The Netherlands rens@alf.let.uva.nl PERFORMANCE: Abstract 1)ata Oriented Parsing (IX)P) is a model where no abstract rules, but language xt~riences in the ti3ru~ of all ,malyzed COlpUS, constitute the basis for langnage processing.</S><S sid = 60 ssid = >Finally, the preferred parse is added to the corpus, bringing it into a new state.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C92-3126.txt | Citing Article:  C96-2215.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Due to this extension, the one to one mapping between a derivation and a parse tree, which holds in CFGs, does not hold any more; many derivations might generate the same parse-tree ,rl &apos; his seemingly spurious ambiguity turns out crucial for statistical disambiguation as defined in (Bod, 1992) and in (Schabes and Waters, 1993), where the derivations are considered different stochastic processes and their probabilities all contribute to the probability of the generated parse.</S> | Reference Offset:  ['107','108'] | Reference Text:  <S sid = 107 ssid = >In DOP, the probability of a parse depends on all tuples of coustructious that generate that parse.</S><S sid = 108 ssid = >~lhe more different ways in which a parse can be generated, the lligher its probability.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C92-3126.txt | Citing Article:  P01-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >context-free rulesCharniak (1996) Collins (1996), Eisner (1996) context-free rules, headwords Charniak (1997) context-free rules, headwords, grandparent nodes Collins (2000) context-free rules, headwords, grandparent nodes/rules, bi grams, two-level rules, two-level bi grams, non headwords Bod (1992) all fragments within parse trees Scope of Statistical Dependencies Model Figure 4.</S> | Reference Offset:  ['32','132'] | Reference Text:  <S sid = 32 ssid = >A probabilistic grammar is simply a juxtaposition of the most fundamental syntactic notion and the most fundamental statistical notion: it is an "old-fashioned" context free grammar, that describes syntactic structures by means of a set of abstract rewrite rules that are now provided with probabilities that correspond to the application- probabilities of the rules (see e.g.</S><S sid = 132 ssid = >and Mercer, R.I,., B~ic Methods of  Probabilistic Context Free Granmuws, Yorktown tleights: IBM RC 16374 (#72684).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C92-3126.txt | Citing Article:  N06-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It occurs because many systems, such as the ones proposed by (Bod, 1992), (Galley, et .al., 2004), and (Langkilde and Knight, 1998) represent their result space in terms of weighted partial results of various sizes that may be assembled in multiple ways.</S> | Reference Offset:  ['2','42'] | Reference Text:  <S sid = 2 ssid = >Disambiguation occurs as a side-effect.</S><S sid = 42 ssid = >From a linguistic point of view that emphasizes the syntactic complexities caused by idiomatic and semi-idiomatic expressions, Fillmore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C92-3126.txt | Citing Article:  W96-0111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Data-Oriented Parsing (DOP) method suggested in Scha (1990) and developed in Bod (19921995) is a probabilistic parsing strategy which does not single out a narrowly predefined set of structures as the statistically significant ones.</S> | Reference Offset:  ['3','135'] | Reference Text:  <S sid = 3 ssid = >DOP can be implemented by using colivelllional parsing strategies.</S><S sid = 135 ssid = >[Salomaa 1969]: Salomaa, A., Probabilistic and weighted grmnmars, in: lnfomJation and control 15, p. 529-544, [Scha 1990]: Scha, R., Language Theory and Language Technology; Competence and Perfomumce (in Dutch), in: Q.A.M.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C92-3126.txt | Citing Article:  W96-0111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Bod (1992, 1993a), a first instantiation of this model is given, called DOP1, which uses (1) labelled trees for the utterance analyses, (2) subtrees for the fragments, (3) node substitution for combining subtrees, and (4), the sum of the probabilities of all distinct ways of generating an analysis as a def &apos ;mition of the probability of that analysis.</S> | Reference Offset:  ['108','134'] | Reference Text:  <S sid = 108 ssid = >~lhe more different ways in which a parse can be generated, the lligher its probability.</S><S sid = 134 ssid = >[Martin 1979]: M,min, W.A., Preliminary analysis of a bre.adth-tirst parsing algorithin: Theoretical ,and experimental results (Technical Report No.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C92-3126.txt | Citing Article:  W96-0111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bod (1992, 1993a) shows that conventional context-free parsing techniques can be used in creating a parse forest for a sentence in DOP1.</S> | Reference Offset:  ['59','97'] | Reference Text:  <S sid = 59 ssid = >~llte preferred parse out of all parses of the input sentence is obtained by maximizing file conditional probability of a parse given the sentence.</S><S sid = 97 ssid = >In [Scholtes 1992] a neural net implementation f DOP is proposed, ltere we will show that conventional rule- based parsing strategies can be applied tn DOP, by converting constructions into rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C92-3126.txt | Citing Article:  C00-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Data-Oriented Parsing Bothprobabil is tic and non-probabilistic DOP are based on the DOP model in Bod (1992) which extracts a Stochastic Tree-Substitution Grammar.</S> | Reference Offset:  ['3','97'] | Reference Text:  <S sid = 3 ssid = >DOP can be implemented by using colivelllional parsing strategies.</S><S sid = 97 ssid = >In [Scholtes 1992] a neural net implementation f DOP is proposed, ltere we will show that conventional rule- based parsing strategies can be applied tn DOP, by converting constructions into rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C92-3126.txt | Citing Article:  P98-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bod (1992) demonstrated that DOP can be implemented using conventional context-free parsing techniques.</S> | Reference Offset:  ['3','103'] | Reference Text:  <S sid = 3 ssid = >DOP can be implemented by using colivelllional parsing strategies.</S><S sid = 103 ssid = >"llais call be achieved by using Monte Carlo techniques (see e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C92-3126.txt | Citing Article:  P98-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Next, parsing proceeds with the subtrees that are triggered by the dialogue context C (provided that all subtrees are converted into equivalent rewrite rules -see Bod 1992, Sima &apos; an 1995).</S> | Reference Offset:  ['32','38'] | Reference Text:  <S sid = 32 ssid = >A probabilistic grammar is simply a juxtaposition of the most fundamental syntactic notion and the most fundamental statistical notion: it is an "old-fashioned" context free grammar, that describes syntactic structures by means of a set of abstract rewrite rules that are now provided with probabilities that correspond to the application- probabilities of the rules (see e.g.</S><S sid = 38 ssid = >Nevertheless, any approach which ties probabilities to rewrite rules will never be able to acconunodate all statistical dependencies.</S> | Discourse Facet:  NA | Annotator: Automatic


