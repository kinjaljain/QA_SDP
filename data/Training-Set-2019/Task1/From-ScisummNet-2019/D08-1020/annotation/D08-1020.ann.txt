Citance Number: 1 | Reference Article:  D08-1020.txt | Citing Article:  P09-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In any case, this aspect of readability may be worth further investigation (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['141','146'] | Reference Text:  <S sid = 141 ssid = >As in the case of vocabulary features, the presence of more relations will lead to overall lower probabilities so we also consider the number of discourse relations (F14) and the log likelihood combined with the number of relations as features.</S><S sid = 146 ssid = >This fact is disappointing as the explicit relations can be identified much more easily in unannotated text (Pitler et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D08-1020.txt | Citing Article:  N10-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In another related work, (Pitler and Nenkova, 2008) investigated the impact of certain surface linguistic features, syntactic, entity coherence and discourse features on the readability of Wall Street Journal (WSJ) Corpus.</S> | Reference Offset:  ['3','187'] | Reference Text:  <S sid = 3 ssid = >We show that various surface metrics generally expected to be related to readability are not very good predictors of readability judgments in our Wall Street Journal corpus.</S><S sid = 187 ssid = >We have investigated which linguistic features correlate best with readability judgments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D08-1020.txt | Citing Article:  N10-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the syntactic features used in (Pitler and Nenkova, 2008) as baselines for our experiments on grammaticality in this paper.</S> | Reference Offset:  ['5','104'] | Reference Text:  <S sid = 5 ssid = >Our experiments indicate that discourse relations are the one class of features that exhibits robustness across these two tasks.</S><S sid = 104 ssid = >The correlations between readability and syntactic features is shown in Table 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D08-1020.txt | Citing Article:  C10-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pitler and Nenkova (2008) consider a different task of predicting text quality for an educated adult audience.</S> | Reference Offset:  ['0','16'] | Reference Text:  <S sid = 0 ssid = >Revisiting Readability: A Unified Framework for Predicting Text Quality</S><S sid = 16 ssid = >In our work we use texts from the Wall Street Journal intended for an educated adult audience to analyze readability factors including vocabulary, syntax, cohesion, entity coherence and discourse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D08-1020.txt | Citing Article:  W10-1001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pitler and Nenkova (2008) propose a unified framework composed of vocabulary, syntactic, elements of lexical cohesion, entity coherence and discourse relations to measure text quality, which resembles the composition of rubrics in the area of essay scoring (Burstein et al, 2003).</S> | Reference Offset:  ['0','51'] | Reference Text:  <S sid = 0 ssid = >Revisiting Readability: A Unified Framework for Predicting Text Quality</S><S sid = 51 ssid = >The syntactic forms of first mention—when an entity is first introduced in a text—differ from those of subsequent mentions (Poesio and Vieira, 1998; Nenkova and McKeown, 2003) and can be exploited for improving and predicting text coherence (Siddharthan, 2003; Nenkova and McKeown, 2003; Elsner and Charniak, 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D08-1020.txt | Citing Article:  W11-2308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['95','192'] | Reference Text:  <S sid = 95 ssid = >The correlations are positive: the more probable an article was based on its vocabulary, the higher it was generally rated.</S><S sid = 192 ssid = >We thank Aravind Joshi, Bonnie Webber, and the anonymous reviewers for their many helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D08-1020.txt | Citing Article:  W11-2308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >When readability is targeted towards adult competent language users a more prominent role is played by discourse features (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['39','71'] | Reference Text:  <S sid = 39 ssid = >Text coherence is defined as the ease with which a person (tacitly assumed to be a competent language user) understands a text.</S><S sid = 71 ssid = >For competent language users, we view text readability and text coherence as equivalent properties, measuring the extent to which a text is well written.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D08-1020.txt | Citing Article:  W11-2308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['95','192'] | Reference Text:  <S sid = 95 ssid = >The correlations are positive: the more probable an article was based on its vocabulary, the higher it was generally rated.</S><S sid = 192 ssid = >We thank Aravind Joshi, Bonnie Webber, and the anonymous reviewers for their many helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D08-1020.txt | Citing Article:  C10-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pitler and Nenkova (2008) used the Penn Discourse Treebank (Prasad et al, 2008) to examine discourse relations.</S> | Reference Offset:  ['53','55'] | Reference Text:  <S sid = 53 ssid = >In the past, subsections of the Penn Treebank (Marcus et al., 1994) have been annotated for discourse relations (Carlson et al., 2001; Wolf and Gibson, 2005).</S><S sid = 55 ssid = >The Penn Discourse Treebank (Prasad et al., 2008) is a new resource with annotations of discourse connectives and their senses in the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D08-1020.txt | Citing Article:  C10-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pitler and Nenkova (2008) used the same features to evaluate how well a text is written.</S> | Reference Offset:  ['71','102'] | Reference Text:  <S sid = 71 ssid = >For competent language users, we view text readability and text coherence as equivalent properties, measuring the extent to which a text is well written.</S><S sid = 102 ssid = >(Barzilay and Lapata, 2008) found that articles written for adults tended to contain many more entities than articles written for children.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D08-1020.txt | Citing Article:  C10-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This approach was subsequently pursued by Pitler and Nenkova (2008) in their readability study.</S> | Reference Offset:  ['19','32'] | Reference Text:  <S sid = 19 ssid = >Our study is novel in the use of gold-standard discourse features for predicting readability and the simultaneous analysis of various readability factors.</S><S sid = 32 ssid = >A more general and principled approach to using vocabulary information for readability decisions has been the use of language models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D08-1020.txt | Citing Article:  W11-1417.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Measures of cohesion have also been used in a variety of NLP tasks such as measuring text readability (e.g. (Pitler and Nenkova, 2008)), measuring stylistic differences in text (Mccarthy et al, 2006), and for topic segmentation in tutorial dialog (Olney and Cai, 2005).</S> | Reference Offset:  ['71','146'] | Reference Text:  <S sid = 71 ssid = >For competent language users, we view text readability and text coherence as equivalent properties, measuring the extent to which a text is well written.</S><S sid = 146 ssid = >This fact is disappointing as the explicit relations can be identified much more easily in unannotated text (Pitler et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D08-1020.txt | Citing Article:  E09-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To answer this question, we performed an additional experiment on Wall Street Journal articles from the Penn Treebank that were previously used in experiments for assessing overall text quality (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['55','66'] | Reference Text:  <S sid = 55 ssid = >The Penn Discourse Treebank (Prasad et al., 2008) is a new resource with annotations of discourse connectives and their senses in the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1994).</S><S sid = 66 ssid = >We randomly selected thirty articles from the Wall Street Journal corpus that was used in both the Penn Treebank and the Penn Discourse Treebank.1 Each article was read by at least three college students, each of whom was given unlimited time to read the texts and perform the ratings.2 Subjects were asked the following questions: For each question, they provided a rating between 1 and 5, with 5 being the best and 1 being the worst.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D08-1020.txt | Citing Article:  E09-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Five annotators had previously assess the overall text quality of each article on a scale from 1 to 5 (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['72','159'] | Reference Text:  <S sid = 72 ssid = >Thus for all subsequent analysis, we will use only the first question (“On a scale of 1 to 5, how well written is this text?”).</S><S sid = 159 ssid = >We use the squared multiple correlation coefficient (R2) to assess the effectiveness of predictions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D08-1020.txt | Citing Article:  E09-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Discourse apects and language model features that have been extensively studied in prior work are indeed much more indicative of overall text quality (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['92','128'] | Reference Text:  <S sid = 92 ssid = >The vocabulary features we used are article likelihood estimated from a language model from WSJ (F5), and article likelihood according to a unigram language model from NEWS (F6).</S><S sid = 128 ssid = >We computed another language model which is over discourse relations instead of words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D08-1020.txt | Citing Article:  W11-1415.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pitler and Nenkova (2008) and Kate et al (2010), for example, average out results collected from different readers.</S> | Reference Offset:  ['55','146'] | Reference Text:  <S sid = 55 ssid = >The Penn Discourse Treebank (Prasad et al., 2008) is a new resource with annotations of discourse connectives and their senses in the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1994).</S><S sid = 146 ssid = >This fact is disappointing as the explicit relations can be identified much more easily in unannotated text (Pitler et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D08-1020.txt | Citing Article:  W12-2206.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Nevertheless, recent works in the NLP community investigating the impact of entity grids (Barzilay and Lapata, 2008) or of discourse relations (Pitler and Nenkova, 2008) on text coherence and readability go in the same direction as research on Coh-Metrix, in that they aim at identifying the linguistic features that best express readability at syntactic, semantic and discourse level.</S> | Reference Offset:  ['118','190'] | Reference Text:  <S sid = 118 ssid = >We use the Brown Coherence Toolkit6 to compute entity grids (Barzilay and Lapata, 2008) for each article.</S><S sid = 190 ssid = >While using any one out of syntactic, lexical, coherence, or discourse features is substantally better than the baseline surface features on the discrimination task, using a combination of entity coherence and discourse relations produces the best performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D08-1020.txt | Citing Article:  D12-1139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Syntactic features from PCFG parse trees have also been used for gender attribution (Sarawgi et al 2011), genre identification (Stamatatos et al 2000), native language identification (Wong and Dras, 2011) and readability assessment (Pitler and Nenkova, 2008).</S> | Reference Offset:  ['36','53'] | Reference Text:  <S sid = 36 ssid = >Syntactic complexity is an obvious factor: indeed (Heilman et al., 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels.</S><S sid = 53 ssid = >In the past, subsections of the Penn Treebank (Marcus et al., 1994) have been annotated for discourse relations (Carlson et al., 2001; Wolf and Gibson, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D08-1020.txt | Citing Article:  N12-2010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These methods identify regularities in words (Barzilay and Lee, 2004), entity coreference (Barzi lay and Lapata, 2008) and discourse relations (Pitler and Nenkova, 2008) from a large collection of articles and use these patterns to predict the coherence.</S> | Reference Offset:  ['102','118'] | Reference Text:  <S sid = 102 ssid = >(Barzilay and Lapata, 2008) found that articles written for adults tended to contain many more entities than articles written for children.</S><S sid = 118 ssid = >We use the Brown Coherence Toolkit6 to compute entity grids (Barzilay and Lapata, 2008) for each article.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D08-1020.txt | Citing Article:  W12-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An exception to this trend is the work of Pitler and Nenkova (2008) who reported non-significant correlation for the mean number of words per sentence (r= 0.1637, p= 0.3874) and the mean number of characters per word (r= 0.0859, p= 0.6519).</S> | Reference Offset:  ['81','188'] | Reference Text:  <S sid = 81 ssid = >We tested the average number of characters per word, average number of words per sentence, maximum number of words per sentence, and article length (F7).3 Article length (F7) was the only significant baseline factor, with correlation of -0.37.</S><S sid = 188 ssid = >While surface measures such as the average number of words per sentence or the average number of characters per word are not good predictors, there exist syntactic, semantic, and discourse features that do correlate highly.</S> | Discourse Facet:  NA | Annotator: Automatic


