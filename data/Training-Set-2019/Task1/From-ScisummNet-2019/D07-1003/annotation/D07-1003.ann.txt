Citance Number: 1 | Reference Article:  D07-1003.txt | Citing Article:  P08-2037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recently, Wang et al (2007) explored the use a formalism called quasi synchronous grammar (Smith and Eisner, 2006) in order to find a more explicit model for matching the set of dependencies, and yet still allow for looseness in the matching.</S> | Reference Offset:  ['39','77'] | Reference Text:  <S sid = 39 ssid = >Our story makes use of a weighted formalism known as quasi-synchronous grammar (hereafter, QG), originally developed by D. Smith and Eisner(2006) for machine translation.</S><S sid = 77 ssid = >Here, following Smith and Eisner (2006), we usea weighted, quasi-synchronous dependency grammar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D07-1003.txt | Citing Article:  P13-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wang et al (2007) use quasi-synchronous translation to map all parent-child paths in a question to any path in an answer.</S> | Reference Offset:  ['167','170'] | Reference Text:  <S sid = 167 ssid = >Augmented with the q.-side dependency la bel.child-parent Question parent-child pair align respectively to answer child-parent pair.</S><S sid = 170 ssid = >same node Question parent-child pair align to the same answer-word.siblings Question parent-child pair align to sib lings in the answer.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D07-1003.txt | Citing Article:  E12-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, in (Wang et al 2007), a quasi-synchronous grammar (Smith and Eisner,2006) is used to model relations between questions and answer sentences.</S> | Reference Offset:  ['0','77'] | Reference Text:  <S sid = 0 ssid = >What is the Jeopardy Model? A Quasi-Synchronous Grammar for QA</S><S sid = 77 ssid = >Here, following Smith and Eisner (2006), we usea weighted, quasi-synchronous dependency grammar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D07-1003.txt | Citing Article:  D11-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al, 2007), and title generation (Woodsend et al, 2010).</S> | Reference Offset:  ['39','215'] | Reference Text:  <S sid = 39 ssid = >Our story makes use of a weighted formalism known as quasi-synchronous grammar (hereafter, QG), originally developed by D. Smith and Eisner(2006) for machine translation.</S><S sid = 215 ssid = >Cui et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D07-1003.txt | Citing Article:  C10-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['84','270'] | Reference Text:  <S sid = 84 ssid = >The player knows the answer (or at least thinks he knows the answer) and must quickly turn it into a question.2 The question-answer pairs used on Jeopardy!</S><S sid = 270 ssid = >This work is supported in part by ARDA/DTO Advanced Question Answering for Intelligence (AQUAINT) program award number NBCHC040164.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D07-1003.txt | Citing Article:  C10-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We followed the same experimental setup as Wang et al (2007) and Heilman and Smith (2010).</S> | Reference Offset:  ['182','215'] | Reference Text:  <S sid = 182 ssid = >To evaluate our model, we conducted experiments using Text REtrieval Conference (TREC) 8?13 QA dataset.8 5.1 Experimental Setup.</S><S sid = 215 ssid = >Cui et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D07-1003.txt | Citing Article:  C10-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Results of replicated systems for the last two were reported by Wang et al (2007), with lexical-semantic augmentation from WordNet.</S> | Reference Offset:  ['150','225'] | Reference Text:  <S sid = 150 ssid = >Because we are interested in augmenting the QG with additional lexical-semantic knowledge, we also estimate pkid by mixing the base model with a model that exploits WordNet (Miller et al, 1990) lexical-semantic relations.</S><S sid = 225 ssid = >Both results are reported.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D07-1003.txt | Citing Article:  C10-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Results in Table 3 show that our model gives the same level of performance as Wang et al (2007), with no statistically significant difference (p > 5 in sign test).</S> | Reference Offset:  ['201','233'] | Reference Text:  <S sid = 201 ssid = >Any algorithm will get the same performance on these questions, and thereforeobscures the evaluation results.</S><S sid = 233 ssid = >5.3 Results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['84','270'] | Reference Text:  <S sid = 84 ssid = >The player knows the answer (or at least thinks he knows the answer) and must quickly turn it into a question.2 The question-answer pairs used on Jeopardy!</S><S sid = 270 ssid = >This work is supported in part by ARDA/DTO Advanced Question Answering for Intelligence (AQUAINT) program award number NBCHC040164.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Experiments were conducted to evaluate tree edit models for three tasks: recognizing textual entailment (Giampiccolo et al, 2007), paraphrase identification (Dolan et al, 2004), and an answer selection task (Wang et al, 2007) for question answering (Voorhees, 2004).</S> | Reference Offset:  ['184','215'] | Reference Text:  <S sid = 184 ssid = >Our task is the same as Pun yakanok et al (2004) and Cui et al (2005), where we search for single-sentence answers to factoid questions.</S><S sid = 215 ssid = >Cui et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['84','270'] | Reference Text:  <S sid = 84 ssid = >The player knows the answer (or at least thinks he knows the answer) and must quickly turn it into a question.2 The question-answer pairs used on Jeopardy!</S><S sid = 270 ssid = >This work is supported in part by ARDA/DTO Advanced Question Answering for Intelligence (AQUAINT) program award number NBCHC040164.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a given set of questions, the task here is to rank candidate answers (Wang et al, 2007).</S> | Reference Offset:  ['184','186'] | Reference Text:  <S sid = 184 ssid = >Our task is the same as Pun yakanok et al (2004) and Cui et al (2005), where we search for single-sentence answers to factoid questions.</S><S sid = 186 ssid = >We used the questions in TREC 8?12 for training and set aside TREC 13 questions for development(84 questions) and testing (100 questions).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The experimental setup is the same as in Wang et al (2007).</S> | Reference Offset:  ['182','215'] | Reference Text:  <S sid = 182 ssid = >To evaluate our model, we conducted experiments using Text REtrieval Conference (TREC) 8?13 QA dataset.8 5.1 Experimental Setup.</S><S sid = 215 ssid = >Cui et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compare our tree edit model to three other systems as they are reported by Wang et al (2007).</S> | Reference Offset:  ['213','225'] | Reference Text:  <S sid = 213 ssid = >5.2 Baseline Systems.</S><S sid = 225 ssid = >Both results are reported.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D07-1003.txt | Citing Article:  N10-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results for the tree edit model are statistically significantly different (sign test, p < 0.01) from the results for all except the Wang et al (2007) system with WordNet (p > 0.05).</S> | Reference Offset:  ['225','233'] | Reference Text:  <S sid = 225 ssid = >Both results are reported.</S><S sid = 233 ssid = >5.3 Results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D07-1003.txt | Citing Article:  D11-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This includes work on question answering (Wang et al, 2007), sentiment analysis (Nakagawa et al, 2010), MT reordering (Xu et al, 2009), and many other tasks.</S> | Reference Offset:  ['184','215'] | Reference Text:  <S sid = 184 ssid = >Our task is the same as Pun yakanok et al (2004) and Cui et al (2005), where we search for single-sentence answers to factoid questions.</S><S sid = 215 ssid = >Cui et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D07-1003.txt | Citing Article:  P12-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['84','270'] | Reference Text:  <S sid = 84 ssid = >The player knows the answer (or at least thinks he knows the answer) and must quickly turn it into a question.2 The question-answer pairs used on Jeopardy!</S><S sid = 270 ssid = >This work is supported in part by ARDA/DTO Advanced Question Answering for Intelligence (AQUAINT) program award number NBCHC040164.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D07-1003.txt | Citing Article:  D09-1086.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In that paper, QG was applied to word alignment and has since found applications in question answering (Wang et al, 2007), paraphrase detection (Das and Smith, 2009), and machine translation (Gimpel and Smith, 2009).</S> | Reference Offset:  ['39','65'] | Reference Text:  <S sid = 39 ssid = >Our story makes use of a weighted formalism known as quasi-synchronous grammar (hereafter, QG), originally developed by D. Smith and Eisner(2006) for machine translation.</S><S sid = 65 ssid = >translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D07-1003.txt | Citing Article:  P09-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Lately, this formalism has been used as an alternative to phrase-based parsing for a variety of tasks, ranging from machine translation (Ding and Palmer, 2005) to relation extraction (Culotta and Sorensen, 2004) and question answering (Wang et al, 2007).</S> | Reference Offset:  ['45','65'] | Reference Text:  <S sid = 45 ssid = >To model the syntactic transformation process, re searchers in these fields?especially in machine translation?have developed powerful grammatical formalisms and statistical models for representing and learning these tree-to-tree relations (Wu and Wong, 1998; Eisner, 2003; Gildea, 2003; Melamed, 2004; Ding and Palmer, 2005; Quirk et al, 2005;Galley et al, 2006; Smith and Eisner, 2006, in ter alia).</S><S sid = 65 ssid = >translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D07-1003.txt | Citing Article:  C10-2157.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >QG has been applied to some NLP tasks other than MT, including answer selection for question-answering (Wang et al, 2007), paraphrase identification (Das and Smith, 2009), and parser adaptation and projection (Smith and Eisner, 2009).</S> | Reference Offset:  ['77','149'] | Reference Text:  <S sid = 77 ssid = >Here, following Smith and Eisner (2006), we usea weighted, quasi-synchronous dependency grammar.</S><S sid = 149 ssid = >This model is very sim ilar to Smith and Eisner (2006).</S> | Discourse Facet:  NA | Annotator: Automatic


