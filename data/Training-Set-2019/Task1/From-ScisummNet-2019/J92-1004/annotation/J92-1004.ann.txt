Citance Number: 1 | Reference Article:  J92-1004.txt | Citing Article:  P96-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The parsing model is a probabilistic recursive transition network similar to those described in (Miller et ai. 1994) and (Seneff 1992).</S> | Reference Offset:  ['1','8'] | Reference Text:  <S sid = 1 ssid = >new natural language system, been developed for applications involving spoken tasks. key ideas from context free grammars, Augmented Transition (ATN's), and the unification concept. a seamless interface between syntactic and semantic analysis, and also produces a highly constraining probabilistic language model to improve recognition performance.</S><S sid = 8 ssid = >TINA provides a seamless interface between syntactic and semantic analysis, and also produces a highly constraining probabilistic language model to improve recognition performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J92-1004.txt | Citing Article:  W08-0801.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The resulting N-best hypotheses are processed by the TINA language understanding component (Seneff, 1992).</S> | Reference Offset:  ['0','19'] | Reference Text:  <S sid = 0 ssid = >TINA: A Natural Language System For Spoken Language Applications</S><S sid = 19 ssid = >A spoken language system relies on its natural language component to provide the meaning representation of a given sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J92-1004.txt | Citing Article:  P98-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As another way of bringing contextual information to bear in the process of predicting the meaning the following stochastic models, of unparsed inspired in Miller et al (1994) and Seneff (1992), and collectively referred to as hidden understanding model (HUM), are employed.</S> | Reference Offset:  ['26','276'] | Reference Text:  <S sid = 26 ssid = >If the natural language component's computational and memory requirements are not excessive, and if it is organized in such a way that it can easily predict a set of next-word candidates, then it can be incorporated into the active search process of the recognizer, dynamically predicting possible words to follow a hypothesized word sequence, and pruning away hypotheses that cannot be completed in any way.</S><S sid = 276 ssid = >This approach resembles the work by Grishman et al. (1986) and Hirschman et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J92-1004.txt | Citing Article:  W08-0102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Speech recognition results were parsed by the TINA parser (Seneff, 1992) using a hand-crafted grammar.</S> | Reference Offset:  ['311','318'] | Reference Text:  <S sid = 311 ssid = >The results were essentially the same for the training and the test sentences, as shown in Table 2.</S><S sid = 318 ssid = >Their speech was recorded in a simulation mode in which the speech recognition component was excluded.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J92-1004.txt | Citing Article:  A00-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The problem of over-generalization of speech grammars and related issues is well discussed by Seneff (1992).</S> | Reference Offset:  ['15','418'] | Reference Text:  <S sid = 15 ssid = >In addition to continued research on the transcription problem, i.e., the conversion of the speech signal to text, many researchers have begun to address as well the problem of speech understanding.1 This shift is at least partly brought on by the realization that many of the applications involving human/machine interface using speech require an &quot;understanding&quot; of the intended message.</S><S sid = 418 ssid = >This is a problem to be aware of in building grammars from example sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J92-1004.txt | Citing Article:  I08-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Example of WFST for LUcepts from user utterances by keyword spotting or heuristic rules has also been proposed (Seneff, 1992) where utterances can be transformed into concepts without major modifications to the rules.</S> | Reference Offset:  ['319','321'] | Reference Text:  <S sid = 319 ssid = >Instead, an experimenter in a separate room typed in the utterances as spoken by the subject.</S><S sid = 321 ssid = >We were able to collect a total, of nearly 5000 utterances in this fashion.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J92-1004.txt | Citing Article:  W04-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In our case, the log files include the output of the TINA Natural Language Understanding module, meaning that all semantically relevant units present in an input sentence are marked explicitly in the output parse frame (Seneff, 1992).</S> | Reference Offset:  ['0','411'] | Reference Text:  <S sid = 0 ssid = >TINA: A Natural Language System For Spoken Language Applications</S><S sid = 411 ssid = >We have not yet incorporated probabilities from TINA into the search, but they are used effectively to resort the final output sentence candidates.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J92-1004.txt | Citing Article:  N07-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We utilized a parser (Seneff, 1992) that is based on an enhanced probabilistic context-free grammar (PCFG), which captures dependencies beyond context-free rules by conditioning on the external left-context parse categories when predicting the first child of each parent node.</S> | Reference Offset:  ['48','292'] | Reference Text:  <S sid = 48 ssid = >TINA is based on a context-free grammar augmented with a set of features used to enforce syntactic and semantic constraints.</S><S sid = 292 ssid = >The process of conversion to a new grammar involves parsing the new sentences one by one, and adding context-free rules whenever a parse fails.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J92-1004.txt | Citing Article:  N07-4007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The input utterance is processed through the speech recognizer and language under standing (Seneff, 1992) components, to achieve a simple encoding of its meaning.</S> | Reference Offset:  ['32','322'] | Reference Text:  <S sid = 32 ssid = >By encoding meaning in the structural entities of the parse tree, it becomes feasible to realize probabilistic semantic restrictions in an efficient manner.</S><S sid = 322 ssid = >The speech material was then used to train the recognizer component, and the text material was used to train the natural language and back-end components.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J92-1004.txt | Citing Article:  C96-2119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The language understanding system, TINA, described at length in (Seneff, 1992), integrates key ideas context free grammar, augmented transition network and unification concepts.</S> | Reference Offset:  ['1','7'] | Reference Text:  <S sid = 1 ssid = >new natural language system, been developed for applications involving spoken tasks. key ideas from context free grammars, Augmented Transition (ATN's), and the unification concept. a seamless interface between syntactic and semantic analysis, and also produces a highly constraining probabilistic language model to improve recognition performance.</S><S sid = 7 ssid = >TINA integrates key ideas from context free grammars, Augmented Transition Networks (ATN's), and the unification concept.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J92-1004.txt | Citing Article:  W04-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Based on the Galaxyarchitecture (Goddeau et al, 1994), Jupiter recognizes user question over the phone, parses the question with the TINA language understanding system (Seneff,1992).</S> | Reference Offset:  ['228','276'] | Reference Text:  <S sid = 228 ssid = >Furthermore, the same [do-question] grammar node deals with the yes/no question &quot;Did Mike buy the pies?,&quot; except in this case there is no CURRENTFOCUS and hence no gap.</S><S sid = 276 ssid = >This approach resembles the work by Grishman et al. (1986) and Hirschman et al.</S> | Discourse Facet:  NA | Annotator: Automatic


