Citance Number: 1 | Reference Article:  N06-1058.txt | Citing Article:  W11-1609.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kauchak and Barzilay (2006) have shown that creating synthetic reference sentences by substituting synonyms from Wordnet into the original reference sentences can increase the number of exact word matches with an MT system's output and yield significant improvements in correlations of BLEU (Papineni et al., 2002) scores with human judgments of translation adequacy.</S> | Reference Offset:  ['36','94'] | Reference Text:  <S sid = 36 ssid = >This synthetic reference then replaces the original human reference in automatic evaluation.</S><S sid = 94 ssid = >The synthetic reference keeps the meaning of the original reference, but has a higher word overlap with the system output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N06-1058.txt | Citing Article:  W08-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Deriving lexical relatedness between terms has been a topic of interest with applications in word sense disambiguation (Patwardhan et al, 2005), paraphrasing (Kauchak and Barzilay, 2006), question answering (Prager et al, 2001), and machine translation (Blatz et al, 2004) to name a few.</S> | Reference Offset:  ['121','142'] | Reference Text:  <S sid = 121 ssid = >These techniques are widely used in NLP applications, including language modeling, information extraction, and dialogue processing (Haghighi et al., 2005; Serafin and Eugenio, 2004; Miller et al., 2004).</S><S sid = 142 ssid = >The Pearson correlation is calculated over these ten pairs (Papineni et al., 2002; Stent et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N06-1058.txt | Citing Article:  P09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Banerjee and Lavie (2005) and Chan and Ng (2008) use WordNet, and Zhou et al (2006) and Kauchak and Barzilay (2006) exploit large collections of automatically-extracted paraphrases.</S> | Reference Offset:  ['60','142'] | Reference Text:  <S sid = 60 ssid = >Examples of such knowledge sources include stemming and TF-IDF weighting (Babych and Hartley, 2004; Banerjee and Lavie, 2005).</S><S sid = 142 ssid = >The Pearson correlation is calculated over these ten pairs (Papineni et al., 2002; Stent et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N06-1058.txt | Citing Article:  P08-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kauchak and Barzilay (2006) used paraphrases of the reference translations to improve automatic MT evaluation.</S> | Reference Offset:  ['37','48'] | Reference Text:  <S sid = 37 ssid = >The key findings of our work are as follows: (1) Automatically generated paraphrases improve the accuracy of the automatic evaluation methods.</S><S sid = 48 ssid = >For example, Pang et al. (2003) expand a set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N06-1058.txt | Citing Article:  P08-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some researchers extract synonyms as paraphrases (Kauchak and Barzilay, 2006), while some others use looser definitions, such as hypernyms and holonyms (Barzilay and Elhadad, 1997).</S> | Reference Offset:  ['19','26'] | Reference Text:  <S sid = 19 ssid = >As a solution to this problem, researchers use multiple references to refine automatic evaluation.</S><S sid = 26 ssid = >Thus, among many possible paraphrases of the reference, we are interested only in those that use words appearing in the system output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N06-1058.txt | Citing Article:  W11-2403.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Training a classifier for word paraphrasing, Kauchak and Barzilay (2006) used occurrences of the rule's RHS as positive context examples, and randomly picked negative examples.</S> | Reference Offset:  ['82','165'] | Reference Text:  <S sid = 82 ssid = >For the negative examples, a random position in a sentence is selected for extracting the context.</S><S sid = 165 ssid = >To evaluate the accuracy of different paraphrasing methods, we randomly extracted 200 paraphrasing examples from each method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N06-1058.txt | Citing Article:  P07-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Metrics in the Rouge family allow for skip n-grams (Lin and Och, 2004a); Kauchak and Barzilay (2006) take paraphrasing into account; metrics such as METEOR (Banerjee and Lavie, 2005) and GTM (Melamed et al., 2003) calculate both recall and precision; METEOR is also similar to SIA (Liu and Gildea, 2006) in that word class information is used.</S> | Reference Offset:  ['45','57'] | Reference Text:  <S sid = 45 ssid = >Automatic Paraphrasing and Entailment Our work is closely related to research in automatic paraphrasing, in particular, to sentence level paraphrasing (Barzilay and Lee, 2003; Pang et al., 2003; Quirk et al., 2004).</S><S sid = 57 ssid = >Our method for reference paraphrasing can be combined with any of these metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N06-1058.txt | Citing Article:  C10-2048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In text summarization (Zhou et al, 2006) and machine translation (Kauchak and Barzilay, 2006), summaries comparison based on sentence similarity has been applied for automatic evaluation.</S> | Reference Offset:  ['10','55'] | Reference Text:  <S sid = 10 ssid = >In practice, this comparison breaks down to n-gram overlap between the reference and the machine output. machine translation from the NIST 2004 MT evaluation.</S><S sid = 55 ssid = >Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al., 2003; Papineni et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N06-1058.txt | Citing Article:  W07-0411.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, to allow for the possibility of valid lexical differences between the translation and the references, we follow Kauchak and Barzilay (2006) and Owczarzak et al (2006) in adding a number of paraphrases in the process of evaluation to raise the number of matches between the translation and the reference, leading to a higher score.</S> | Reference Offset:  ['20','160'] | Reference Text:  <S sid = 20 ssid = >Papineni et al. (2002) shows that expanding the number of references reduces the gap between automatic and human evaluation.</S><S sid = 160 ssid = >As expected, the more paraphrases identified, the higher the BLEU score for the method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N06-1058.txt | Citing Article:  W07-0411.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kauchak and Barzilay (2006) and Owczarzak et al (2006) use paraphrases during BLEU and NIST evaluation to increase the number of matches between the translation and the reference; the paraphrases are either taken from WordNet in Kauchak and Barzilay (2006) or derived from the test set itself through automatic word and phrase alignment in Owczarzak et al (2006).</S> | Reference Offset:  ['48','55'] | Reference Text:  <S sid = 48 ssid = >For example, Pang et al. (2003) expand a set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.</S><S sid = 55 ssid = >Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al., 2003; Papineni et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N06-1058.txt | Citing Article:  W07-0411.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We introduced synonyms and paraphrases into the process of evaluation, creating new best-matching references for the translations using either paraphrases derived from the test set itself (following Owczarzak et al (2006)) or WordNet synonyms (as in Kauchak and Barzilay (2006)).</S> | Reference Offset:  ['48','71'] | Reference Text:  <S sid = 48 ssid = >For example, Pang et al. (2003) expand a set of reference translations using syntactic alignment, and generate new reference sentences that could be used in automatic evaluation.</S><S sid = 71 ssid = >We consider a pair as a substitution candidate if its members are synonyms in WordNet.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N06-1058.txt | Citing Article:  W07-0411.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To maximize the number of matches between a translation and a reference, Kauchak and Barzilay (2006) use WordNet synonyms during evaluation.</S> | Reference Offset:  ['4','71'] | Reference Text:  <S sid = 4 ssid = >Our experiments show that the use of a paraphrased synthetic reference refines the accuracy of automatic evaluation.</S><S sid = 71 ssid = >We consider a pair as a substitution candidate if its members are synonyms in WordNet.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N06-1058.txt | Citing Article:  P09-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, (Kauchak and Barzilay, 2006) paraphrase references to make them closer to the system translation in order to obtain more reliable results when using automatic evaluation metrics like BLEU (Papineni et al, 2002).</S> | Reference Offset:  ['20','55'] | Reference Text:  <S sid = 20 ssid = >Papineni et al. (2002) shows that expanding the number of references reduces the gap between automatic and human evaluation.</S><S sid = 55 ssid = >Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al., 2003; Papineni et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N06-1058.txt | Citing Article:  P10-2015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, synonym lexicons found with statistical methods might provide a viable alternative for manually constructed lexicons (Kauchak and Barzilay, 2006).</S> | Reference Offset:  ['42','147'] | Reference Text:  <S sid = 42 ssid = >In the following section, we provide an overview of existing work on automatic paraphrasing.</S><S sid = 147 ssid = >The results of statistical significance testing are summarized in Table 5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N06-1058.txt | Citing Article:  W07-0714.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, to allow for the possibility of valid lexical differences between the translation and the references, we follow Kauchak and Barzilay (2006) in adding a number of synonyms in the process of evaluation to raise the number of matches between the translation and the reference, leading to a higher score.</S> | Reference Offset:  ['20','160'] | Reference Text:  <S sid = 20 ssid = >Papineni et al. (2002) shows that expanding the number of references reduces the gap between automatic and human evaluation.</S><S sid = 160 ssid = >As expected, the more paraphrases identified, the higher the BLEU score for the method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N06-1058.txt | Citing Article:  W07-0714.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['72','195'] | Reference Text:  <S sid = 72 ssid = >Applying this step to the two sentences in Table 2, we obtain two candidate pairs (home, place) and (difficult, hard).</S><S sid = 195 ssid = >Any opinions, findings and conclusions expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA or NSF.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N06-1058.txt | Citing Article:  P09-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >PG shows its importance in many areas, such as question expansion in question answering (QA) (Duboueand Chu-Carroll, 2006), text polishing in natural language generation (NLG) (Iordanskaja et al, 1991), text simplification in computer-aided reading (Carroll et al, 1999), and sentence similarity computation in the automatic evaluation of machine translation (MT) (Kauchak and Barzilay, 2006) and summarization (Zhou et al, 2006).</S> | Reference Offset:  ['55','142'] | Reference Text:  <S sid = 55 ssid = >Automatic Evaluation Measures A variety of automatic evaluation methods have been recently proposed in the machine translation community (NIST, 2002; Melamed et al., 2003; Papineni et al., 2002).</S><S sid = 142 ssid = >The Pearson correlation is calculated over these ten pairs (Papineni et al., 2002; Stent et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N06-1058.txt | Citing Article:  P09-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This application is important for the automatic evaluation of machine translation and summarization, since we can paraphrase the human translations/summaries to make them more similar to the system outputs, which can refine the accuracy of the evaluation (Kauchak and Barzilay, 2006).</S> | Reference Offset:  ['0','184'] | Reference Text:  <S sid = 0 ssid = >Paraphrasing For Automatic Evaluation</S><S sid = 184 ssid = >These results have two important implications: (1) refining standard measures such as BLEU with paraphrase information moves the automatic evaluation closer to human evaluation and (2) applying paraphrases to MT evaluation provides a task-based assessment for paraphrasing accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N06-1058.txt | Citing Article:  P09-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Sentence Similarity computation: Kauchak and Barzilay (2006) have tried paraphrasing-based sentence similarity computation.</S> | Reference Offset:  ['9','122'] | Reference Text:  <S sid = 9 ssid = >Ideally, the similarity would reflect the semantic proximity between the two.</S><S sid = 122 ssid = >Both techniques are based on distributional similarity.</S> | Discourse Facet:  NA | Annotator: Automatic


