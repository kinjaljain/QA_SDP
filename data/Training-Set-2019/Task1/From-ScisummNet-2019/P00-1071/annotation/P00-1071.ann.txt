Citance Number: 1 | Reference Article:  P00-1071.txt | Citing Article:  W01-1206.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['40','109'] | Reference Text:  <S sid = 40 ssid = >The Zprise IR engine was built using a cosine vector space model.</S><S sid = 109 ssid = >As we look for the future, in order to address questions of higher classes we need to handle real-time knowledge acquisition and classification from different domains, coreference, metonymy, special-purpose reasoning, semantic indexing and other advanced techniques.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P00-1071.txt | Citing Article:  W01-1206.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Template-based questions and summary asking inquiries cover most of the classes of question complexity proposed in (Moldovan et al, 2000).</S> | Reference Offset:  ['9','10'] | Reference Text:  <S sid = 9 ssid = >Secondly, the search for the answer is based on a novel form of indexing, called paragraph indexing (Moldovan and Mihalcea 2000).</S><S sid = 10 ssid = >Finally, in order to extract answers and to evaluate their correctness, we use a battery of abductive techniques (Hobbs et al.1993), some based on empirical methods, some on lexicosemantic information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P00-1071.txt | Citing Article:  D12-1118.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Correcting this would require a model that jointly models content and bi grams (Hardisty et al., 2010), has a co reference system as its content model (Haghighi and Klein, 2007), or determines the correct question type (Moldovan et al 2000).</S> | Reference Offset:  ['12','40'] | Reference Text:  <S sid = 12 ssid = >2 Overview of the LASSO Q/A System The architecture of LASSO (Moldovan, Harabagiu et. al 1999) comprises three modules: Question Processing module, Paragraph Indexing module and Answer Processing module.</S><S sid = 40 ssid = >The Zprise IR engine was built using a cosine vector space model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P00-1071.txt | Citing Article:  W02-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['40','109'] | Reference Text:  <S sid = 40 ssid = >The Zprise IR engine was built using a cosine vector space model.</S><S sid = 109 ssid = >As we look for the future, in order to address questions of higher classes we need to handle real-time knowledge acquisition and classification from different domains, coreference, metonymy, special-purpose reasoning, semantic indexing and other advanced techniques.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P00-1071.txt | Citing Article:  P01-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some Q&A systems, like (Moldovan et al, 2000) relied both on NE recognizers and some empirical indicators.</S> | Reference Offset:  ['10','103'] | Reference Text:  <S sid = 10 ssid = >Finally, in order to extract answers and to evaluate their correctness, we use a battery of abductive techniques (Hobbs et al.1993), some based on empirical methods, some on lexicosemantic information.</S><S sid = 103 ssid = >Thus we classify the QA systems, not the questions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P00-1071.txt | Citing Article:  P01-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Moldovan et al, 2000) details the empirical methods used in our system for transforming a natural language question into an IR query.</S> | Reference Offset:  ['10','100'] | Reference Text:  <S sid = 10 ssid = >Finally, in order to extract answers and to evaluate their correctness, we use a battery of abductive techniques (Hobbs et al.1993), some based on empirical methods, some on lexicosemantic information.</S><S sid = 100 ssid = >Thus, a mixture of natural language processing and information retrieval methods may be the solution for now.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P00-1071.txt | Citing Article:  P01-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To decide which keywords should be expanded and what form of alternations should be used we rely on a set of heuristics which complement the heuristics that select the question keywords and generate the queries (as described in (Moldovan et al, 2000)): Heuristic 1: Whenever the first feedback loop requires the addition of the main verb of the question as a query keyword, generate all verb conjugations as well as its nominalizations.</S> | Reference Offset:  ['26','29'] | Reference Text:  <S sid = 26 ssid = >Each heuristic returns a set of keywords that are added in the same order to the question keywords.</S><S sid = 29 ssid = >If further keywords are needed in the retrieval loop, keywords provided by the other two heuristics are added.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P00-1071.txt | Citing Article:  W08-1803.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Here, we can distinguish between approaches that only return one passage per relevant document (see, for example, (Robertson et al., 1992)) and the ones that allow multiple passages per document (see, for example (Moldovan et al, 2000)).</S> | Reference Offset:  ['52','56'] | Reference Text:  <S sid = 52 ssid = >To facilitate the identification of the document sources, the engine was required to put the document id in front of each line in the document.</S><S sid = 56 ssid = >The parameter n selects the number of paragraphs, thus controlling the size of the text retrieved from a document considered relevant.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P00-1071.txt | Citing Article:  W04-2108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Falcon system (Moldovan et al, 2000) uses some semantic relations from WordNet when it expands the question.</S> | Reference Offset:  ['8','71'] | Reference Text:  <S sid = 8 ssid = >First, we perform the processing of the question by combining syntactic information, resulting from a shallow parse, with semantic information that characterizes the question (e.g. question type, question focus).</S><S sid = 71 ssid = >First, we have acquired new tagging rules and secondly, we have unified the dictionaries of the tagger with semantic dictionaries derived from the Gazetteers and from WordNet (Miller 1995).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P00-1071.txt | Citing Article:  E06-3005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Moldovan et al (2000), for instance, select as keywords all named entities that were recognized as proper nouns.</S> | Reference Offset:  ['69','73'] | Reference Text:  <S sid = 69 ssid = >The Parser The parser combines information from broad coverage lexical dictionaries with semantic information that contributes to the identification of the named entities.</S><S sid = 73 ssid = >Similar heuristics recognize named entities successfully in IE systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P00-1071.txt | Citing Article:  E06-3005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the work of Moldovan et al (2000), all why-questions share the single answer type reason.</S> | Reference Offset:  ['14','65'] | Reference Text:  <S sid = 14 ssid = >Thus we automatically find (a) the question type from the taxonomy of questions built into the system, (b) the expected answer type from the semantic analysis of the question, and most importantly, (c) the question focus defined as the main information required by that question.</S><S sid = 65 ssid = >Crucial to the identification of the answer is the recognition of the answer type.</S> | Discourse Facet:  NA | Annotator: Automatic


