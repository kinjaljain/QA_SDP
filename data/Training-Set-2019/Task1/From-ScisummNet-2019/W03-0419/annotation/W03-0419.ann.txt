Citance Number: 1 | Reference Article:  W03-0419.txt | Citing Article:  W03-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For comparison, we also computed two baselines: one in which each character is labeled with its most frequent label (Baseline1 in Table 2), and one in which each entity that was seen in training data is labeled with its most frequent classification (Baseline2 in Table 2 this baseline is computed using the software provided with the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)).</S> | Reference Offset:  ['98','104'] | Reference Text:  <S sid = 98 ssid = >Table 4 shows the error reduction of the systems Table 4: Error reduction for the two development data sets when using extra information like gazetteers (G), unannotated data (U) or externally developed named entity recognizers (E).</S><S sid = 104 ssid = >A baseline rate was computed for the English and the German test sets.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-0419.txt | Citing Article:  W04-2401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['42','135'] | Reference Text:  <S sid = 42 ssid = >An extra named entity category called MISC was added to denote all names which are not already in the other categories.</S><S sid = 135 ssid = >De Meulder is supported by a BOF grant supplied by the University of Antwerp.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-0419.txt | Citing Article:  W04-2401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition to the conceptual simplicity of this approach, it also seems to perform better experimentally (Tjong Kim Sang and De Meulder, 2003).</S> | Reference Offset:  ['83','128'] | Reference Text:  <S sid = 83 ssid = >Mayfield et al. (2003) stacked two learners and obtained better performance.</S><S sid = 128 ssid = >(2003) and the approach of Zhang and Johnson (2003) were not significantly worse than the best result for German.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-0419.txt | Citing Article:  D08-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first source is the CoNLL 2003 shared task date (Tjong Kim Sang and De Meulder, 2003) and the second source is the 2004 NIST Automatic Content Extraction (Weischedel, 2004).</S> | Reference Offset:  ['4','11'] | Reference Text:  <S sid = 4 ssid = >Named entity recognition is an important task of information extraction systems.</S><S sid = 11 ssid = >The shared task of CoNLL-2002 dealt with named entity recognition for Spanish and Dutch (Tjong Kim Sang, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-0419.txt | Citing Article:  W04-2412.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Named entities with (Chieu and Ng, 2003), based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003).</S> | Reference Offset:  ['66','113'] | Reference Text:  <S sid = 66 ssid = >Three systems used Maximum Entropy Models in isolation (Bender et al., 2003; Chieu and Ng, 2003; Curran and Clark, 2003).</S><S sid = 113 ssid = >However, the difference between their performance and that of the Maximum Entropy approach of Chieu and Ng (2003) is not significant.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-0419.txt | Citing Article:  P05-3015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Supervised NE Tagging has been studied extensively over the past decade (Bikel et al 1999, Baluja et. al. 1999, Tjong Kim Sang and De Meulder 2003).</S> | Reference Offset:  ['7','41'] | Reference Text:  <S sid = 7 ssid = >They have also produced a scheme for entity annotation (Chinchor et al., 1999).</S><S sid = 41 ssid = >Mostly, MUC conventions were followed (Chinchor et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-0419.txt | Citing Article:  W12-4304.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The annotation is distributed in the standard column based BIO format applied for e.g. CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004) data, among other established datasets.</S> | Reference Offset:  ['69','78'] | Reference Text:  <S sid = 69 ssid = >Hidden Markov Models were employed by four of the systems that took part in the shared task (Florian et al., 2003; Klein et al., 2003; Mayfield et al., 2003; Whitelaw and Patrick, 2003).</S><S sid = 78 ssid = >Transformation-based learning (Florian et al., 2003), Support Vector Machines (Mayfield et al., 2003) and Conditional Random Fields (McCallum and Li, 2003) were applied by one system each.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-0419.txt | Citing Article:  N06-2038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The IOB2 strategy, which is very popular, having been used in public challenges such as those of CoNLL (Tjong Kim Sang and De Meulder, 2003) and JNLPBA (Kim et al, 2004), has been found to be indeed the best of all established tagging strategies.</S> | Reference Offset:  ['67','121'] | Reference Text:  <S sid = 67 ssid = >Two more systems used them in combination with other techniques (Florian et al., 2003; Klein et al., 2003).</S><S sid = 121 ssid = >Another combination of five systems (Carreras et al., 2003b; Mayfield et al., 2003; McCallum and Li, 2003; Munro et al., 2003; Zhang and Johnson, 2003) obtained the best result for the German development data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-0419.txt | Citing Article:  W05-0620.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Named Entities predicted with the Maximum Entropy based tagger of Chieu and Ng (2003). The tagger follows the CoNLL-2003 task setting (Tjong Kim Sang and De Meulder, 2003), and thus is not developed with WSJ data.</S> | Reference Offset:  ['66','113'] | Reference Text:  <S sid = 66 ssid = >Three systems used Maximum Entropy Models in isolation (Bender et al., 2003; Chieu and Ng, 2003; Curran and Clark, 2003).</S><S sid = 113 ssid = >However, the difference between their performance and that of the Maximum Entropy approach of Chieu and Ng (2003) is not significant.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-0419.txt | Citing Article:  W10-2415.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We benchmark the performance of our baseline MaxEnt classifier using the feature set from Section 5.1 (MaxEnt-A henceforth) on the CoNLL 2003 shared task dataset (Tjong Kim Sang and De Meulder, 2003), the de-facto standard for evaluating coarse-grained NERC systems.</S> | Reference Offset:  ['55','107'] | Reference Text:  <S sid = 55 ssid = >The performance in this task is measured with FÎ²=1 rate: Table 3: Main features used by the the sixteen systems that participated in the CoNLL-2003 shared task sorted by performance on the English test data.</S><S sid = 107 ssid = >All systems that participated in the shared task have outperformed the baseline system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-0419.txt | Citing Article:  E06-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This scheme was initially introduced in CoNLL's (Tjong Kim Sang, 2002a) and (Tjong Kim Sang and De Meulder, 2003) NER competitions, and we decided to adapt it for our experimental work.</S> | Reference Offset:  ['11','134'] | Reference Text:  <S sid = 11 ssid = >The shared task of CoNLL-2002 dealt with named entity recognition for Spanish and Dutch (Tjong Kim Sang, 2002).</S><S sid = 134 ssid = >Tjong Kim Sang is financed by IWT STWW as a researcher in the ATraNoS project.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-0419.txt | Citing Article:  P04-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Entity tagging has been thoroughly addressed by many statistical machine learning techniques, obtaining greater than 90% F1 on many datasets (Tjong Kim Sang and De Meulder, 2003).</S> | Reference Offset:  ['61','65'] | Reference Text:  <S sid = 61 ssid = >They employed a wide variety of machine learning techniques as well as system combination.</S><S sid = 65 ssid = >Five systems used this statistical learning method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-0419.txt | Citing Article:  N10-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We consider the problem of named-entity recognition (NER) and use the English data from the CoNLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003).</S> | Reference Offset:  ['0','123'] | Reference Text:  <S sid = 0 ssid = >Introduction To The CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</S><S sid = 123 ssid = >We have described the CoNLL-2003 shared task: language-independent named entity recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-0419.txt | Citing Article:  P10-1144.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The ACE data was morphologically annotated with a tokenizer based on manual rules adapted from the one used in CoNLL (Tjong Kim Sang and De Meulder, 2003), with TnT 2.2, a trigram POS tagger based on Markov models (Brants, 2000), and with the built-in WordNet lemmatizer (Fellbaum, 1998).</S> | Reference Offset:  ['82','125'] | Reference Text:  <S sid = 82 ssid = >Klein et al. (2003) employed a stacked learning system which contains Hidden Markov Models, Maximum Entropy Models and Conditional Markov Models.</S><S sid = 125 ssid = >The best performance for both languages has been obtained by a combined learning system that used Maximum Entropy Models, transformation-based learning, Hidden Markov Models as well as robust risk minimization (Florian et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-0419.txt | Citing Article:  W07-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finaly, combining models has been a successful way of achieving good results, such as those of Florian et al (2003) who had the top performance in the named entity recognition shared task of CoNLL 2003 (Tjong Kim Sang and De Meulder, 2003).</S> | Reference Offset:  ['68','69'] | Reference Text:  <S sid = 68 ssid = >Maximum Entropy Models seem to be a good choice for this kind of task: the top three results for English and the top two results for German were obtained by participants who employed them in one way or another.</S><S sid = 69 ssid = >Hidden Markov Models were employed by four of the systems that took part in the shared task (Florian et al., 2003; Klein et al., 2003; Mayfield et al., 2003; Whitelaw and Patrick, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-0419.txt | Citing Article:  W07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tokenisation and sentence splitting is followed by part-of speech tagging with the Maximum Entropy Markov Model (MEMM) tagger developed by Curran and Clark (2003) (here after referred to as C&C) for the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003), trained on the MedPost data (Smith et al, 2004).</S> | Reference Offset:  ['64','66'] | Reference Text:  <S sid = 64 ssid = >The most frequently applied technique in the CoNLL-2003 shared task is the Maximum Entropy Model.</S><S sid = 66 ssid = >Three systems used Maximum Entropy Models in isolation (Bender et al., 2003; Chieu and Ng, 2003; Curran and Clark, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-0419.txt | Citing Article:  P05-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >All our results for NER are reported on the CoNLL-2003 shared task dataset (Tjong Kim Sangand De Meulder, 2003).</S> | Reference Offset:  ['0','9'] | Reference Text:  <S sid = 0 ssid = >Introduction To The CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</S><S sid = 9 ssid = >The shared task of CoNLL-2003 concerns language-independent named entity recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-0419.txt | Citing Article:  W07-1502.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >language newspaper domain (English data set of the CoNLL-2003 shared task (Tjong Kim Sang and De Meulder, 2003)).</S> | Reference Offset:  ['0','9'] | Reference Text:  <S sid = 0 ssid = >Introduction To The CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition</S><S sid = 9 ssid = >The shared task of CoNLL-2003 concerns language-independent named entity recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-0419.txt | Citing Article:  W10-2925.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['42','135'] | Reference Text:  <S sid = 42 ssid = >An extra named entity category called MISC was added to denote all names which are not already in the other categories.</S><S sid = 135 ssid = >De Meulder is supported by a BOF grant supplied by the University of Antwerp.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-0419.txt | Citing Article:  W12-4405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The fourth type, called miscellaneous, was introduced in the CoNLL NER tasks in 2002 (Tjong Kim Sang, 2002) and 2003 (Tjong Kim Sang and De Meulder, 2003), and includes proper names falling outside the three classic types.</S> | Reference Offset:  ['11','87'] | Reference Text:  <S sid = 11 ssid = >The shared task of CoNLL-2002 dealt with named entity recognition for Spanish and Dutch (Tjong Kim Sang, 2002).</S><S sid = 87 ssid = >However, in the CoNLL-2002 shared task we found out that choice of features is at least as important.</S> | Discourse Facet:  NA | Annotator: Automatic


