Citance Number: 1 | Reference Article:  W05-1203.txt | Citing Article:  P13-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The aggregation strategy proposed by Corley and Mihalcea (2005) has been utilized for extending these word-to-word similarity measures for calculating text-to-text similarities.</S> | Reference Offset:  ['47','54'] | Reference Text:  <S sid = 47 ssid = >The similarity between the input text segments Ti and Tj is then determined using a scoring function that combines the word-to-word similarities and the word specificity: This score, which has a value between 0 and 1, is a measure of the directional similarity, in this case computed with respect to Ti.</S><S sid = 54 ssid = >Starting with each of the two text segments, and for each word in its word class sets, we determine the most similar word from the corresponding set in the other text segment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W05-1203.txt | Citing Article:  P13-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most similar to our approach are the methods of Islam and Inkpen (2008) and Corley and Mihalcea (2005), who performed a word-to-word similarity alignment; however, they did not operate at the sense level.</S> | Reference Offset:  ['15','54'] | Reference Text:  <S sid = 15 ssid = >While there are several methods previously proposed for finding the semantic similarity of words, to our knowledge the application of these word-oriented methods to text similarity has not been yet explored.</S><S sid = 54 ssid = >Starting with each of the two text segments, and for each word in its word class sets, we determine the most similar word from the corresponding set in the other text segment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W05-1203.txt | Citing Article:  P06-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although these implications are uncontroversial, their automatic recognition is complex if we rely on models based on lexical distance (or similarity) between hypothesis and text ,e.g., (Corley and Mihalcea, 2005).</S> | Reference Offset:  ['20','78'] | Reference Text:  <S sid = 20 ssid = >There is a relatively large number of word-to-word similarity metrics that were previously proposed in the literature, ranging from distance-oriented measures computed on semantic networks, to metrics based on models of distributional similarity learned from large text collections.</S><S sid = 78 ssid = >For the task of paraphrase recognition, incorporating semantic information into the text similarity measure increases the likelihood of recognition significantly over the random baseline and over the lexical matching baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W05-1203.txt | Citing Article:  P06-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['31','86'] | Reference Text:  <S sid = 31 ssid = >While the specificity of words is already measured to some extent by their depth in the semantic hierarchy, we are reinforcing this factor with a corpus-based measure of word specificity, based on distributional information learned from large corpora.</S><S sid = 86 ssid = >Future work will consider the investigation of more sophisticated representations of sentence structure, such as first order predicate logic or semantic parse trees, which should allow for the implementation of more effective measures of text semantic similarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W05-1203.txt | Citing Article:  P06-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['31','86'] | Reference Text:  <S sid = 31 ssid = >While the specificity of words is already measured to some extent by their depth in the semantic hierarchy, we are reinforcing this factor with a corpus-based measure of word specificity, based on distributional information learned from large corpora.</S><S sid = 86 ssid = >Future work will consider the investigation of more sophisticated representations of sentence structure, such as first order predicate logic or semantic parse trees, which should allow for the implementation of more effective measures of text semantic similarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W05-1203.txt | Citing Article:  C10-2048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Corley and Mihalcea (2005) proposed a hybrid method by combining six existing knowledge-based methods.</S> | Reference Offset:  ['14','15'] | Reference Text:  <S sid = 14 ssid = >In this paper, we explore a knowledge-based method for measuring the semantic similarity of texts.</S><S sid = 15 ssid = >While there are several methods previously proposed for finding the semantic similarity of words, to our knowledge the application of these word-oriented methods to text similarity has not been yet explored.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W05-1203.txt | Citing Article:  W06-3806.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Then, we use this cross-pair similarity with more traditional intra-pair similarities (e.g., (Corley and Mihalcea, 2005)) to define a novel kernel function.</S> | Reference Offset:  ['40','84'] | Reference Text:  <S sid = 40 ssid = >For a given pair of text segments, we start by creating sets of open-class words, with a separate set created for nouns, verbs, adjectives, and adverbs.</S><S sid = 84 ssid = >Although our method relies on a bag-of-words approach, as it turns out the use of measures of semantic similarity improves significantly over the traditional lexical matching metrics4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W05-1203.txt | Citing Article:  W06-3806.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In line with many other researches (e.g., (Corley and Mihalcea, 2005)), we determine these anchors using different similarity or relatedness dec tors: the exact matching between tokens or lemmas, a similarity between tokens based on their edit distance, the derivation ally related form relation and the verb entailment relation in WordNet, and, finally, a WordNet-based similarity (Jiang and Conrath, 1997).</S> | Reference Offset:  ['24','70'] | Reference Text:  <S sid = 24 ssid = >We use the WordNet-based implementation of these metrics, as available in the WordNet::Similarity package (Patwardhan et al., 2003).</S><S sid = 70 ssid = >For entailment identification, since this is a directional relation, we only measure the semantic similarity with respect to the hypothesis (the text that is entailed).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W05-1203.txt | Citing Article:  W06-3806.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Experimental results lexical similarity siml (T, H) as defined in (Corley and Mihalcea, 2005).</S> | Reference Offset:  ['68','83'] | Reference Text:  <S sid = 68 ssid = >For comparison, we also evaluated the corpus-based similarity obtained through LSA; however, the results obtained were below the lexical matching baseline and are not reported here.</S><S sid = 83 ssid = >Both these figures are competitive with the best results achieved during the PASCAL entailment evaluation (Dagan et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W05-1203.txt | Citing Article:  W06-3806.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >First, as observed in (Corley and Mihalcea, 2005) the lexical-based distance kernel Kl shows an accuracy significantly higher than the random baseline ,i.e. 50%.</S> | Reference Offset:  ['78','82'] | Reference Text:  <S sid = 78 ssid = >For the task of paraphrase recognition, incorporating semantic information into the text similarity measure increases the likelihood of recognition significantly over the random baseline and over the lexical matching baseline.</S><S sid = 82 ssid = >Once again, the combination of similarity metrics gives the highest accuracy, measured at 58.3%, with a slight improvement observed in the supervised setting, where the highest accuracy was measured at 58.9%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W05-1203.txt | Citing Article:  W07-1406.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first backup strategy is a straightforward BoW method that we will not present in this paper (see more details in (Corley and Mihalcea, 2005)).</S> | Reference Offset:  ['1','14'] | Reference Text:  <S sid = 1 ssid = >This paper presents a knowledge-based method for measuring the semanticsimilarity of texts.</S><S sid = 14 ssid = >In this paper, we explore a knowledge-based method for measuring the semantic similarity of texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W05-1203.txt | Citing Article:  D11-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In practice, we implement WBOW by using the text similarity measure defined in (Corley and Mihalcea, 2005) as the single feature in the SVM classifier that, as in BOW, learns the threshold on this single feature.</S> | Reference Offset:  ['49','64'] | Reference Text:  <S sid = 49 ssid = >We illustrate the application of the text similarity measure with an example.</S><S sid = 64 ssid = >For each of the two data sets, we conduct two evaluations, under two different settings: (1) An unsupervised setting, where the decision on what constitutes a paraphrase (entailment) is made using a constant similarity threshold of 0.5 across all experiments; and (2) A supervised setting, where the optimal threshold and weights associated with various similarity metrics are determined through learning on training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W05-1203.txt | Citing Article:  W06-1603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The system performance reported in (CM05; (Corley and Mihalcea, 2005)), which is among the best we are aware of, is also included for comparison.</S> | Reference Offset:  ['68','79'] | Reference Text:  <S sid = 68 ssid = >For comparison, we also evaluated the corpus-based similarity obtained through LSA; however, the results obtained were below the lexical matching baseline and are not reported here.</S><S sid = 79 ssid = >In the unsupervised setting, the best performance is achieved using a method that combines several similarity metrics into one, for an overall accuracy of 68.8%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W05-1203.txt | Citing Article:  W11-1302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This simple feature is the lexical similarity between T and H computed using WordNet-based metrics as in (Corley and Mihalcea, 2005).</S> | Reference Offset:  ['24','43'] | Reference Text:  <S sid = 24 ssid = >We use the WordNet-based implementation of these metrics, as available in the WordNet::Similarity package (Patwardhan et al., 2003).</S><S sid = 43 ssid = >For nouns and verbs, we use a measure of semantic similarity based on WordNet, while for the other word classes we apply lexical matching1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W05-1203.txt | Citing Article:  W08-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Otherwise, WordNet (Miller, 1995) similarities (as in (Corley and Mihalcea, 2005)) and different relation between words such as verb entailment and derivational morphology are applied.</S> | Reference Offset:  ['70','81'] | Reference Text:  <S sid = 70 ssid = >For entailment identification, since this is a directional relation, we only measure the semantic similarity with respect to the hypothesis (the text that is entailed).</S><S sid = 81 ssid = >For the entailment data set, although we do not explicitly check for entailment, the directional similarity computed for textual entailment recognition does improve over the random and lexical matching baselines.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W05-1203.txt | Citing Article:  S12-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although, there are asymmetric measures such as the Monge-Elkan measure (1996) and the measure proposed by Corley and Mihalcea (Corley and Mihalcea, 2005), they are outnumbered by the symmetric measures.</S> | Reference Offset:  ['11','60'] | Reference Text:  <S sid = 11 ssid = >The only exception to this trend is perhaps the latent semantic analysis (LSA) method (Landauer et al., 1998), which represents an improvement over earlier attempts to use measures of semantic similarity for information retrieval (Voorhees, 1993), (Xu and Croft, 1996).</S><S sid = 60 ssid = >Unlike traditional similarity measures based on lexical matching, our metric takes into account the semantic similarity of these words, resulting in a more precise measure of text similarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W05-1203.txt | Citing Article:  P06-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Also, we will try different similarity score functions for both the clustering and the anchor approaches, as those surveyed in Corley and Mihalcea (2005).</S> | Reference Offset:  ['42','50'] | Reference Text:  <S sid = 42 ssid = >Next, we try to determine pairs of similar words across the sets corresponding to the same open-class in the two text segments.</S><S sid = 50 ssid = >Given two text segments, as shown in Figure 1, we want to determine a score that reflects their semantic similarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W05-1203.txt | Citing Article:  S12-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The semantic similarity formula from (Corley and Mihalcea, 2005) defines the similarity of a pair of documents differently depending on with respect to which text it is computed.</S> | Reference Offset:  ['19','38'] | Reference Text:  <S sid = 19 ssid = >We do this by combining metrics of word-to-word similarity and language models into a formula that is a potentially good indicator of the semantic similarity of the two input texts.</S><S sid = 38 ssid = >We define a directional measure of similarity, which indicates the semantic similarity of a text segment Ti with respect to a text segment Tj.</S> | Discourse Facet:  NA | Annotator: Automatic


