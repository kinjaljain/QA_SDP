Citance Number: 1 | Reference Article:  P10-1142.txt | Citing Article:  W11-1912.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As recently discussed in (Ng, 2010), the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: Generation of (transitively) redundant pairs, as the formation of co reference sets (co reference clustering) is done after pairwise classification.</S> | Reference Offset:  ['83','93'] | Reference Text:  <S sid = 83 ssid = >From a learning perspective, a two-step approach to coreference — classification and clustering — is undesirable.</S><S sid = 93 ssid = >The entity-mention model addresses the expressiveness problem with the mention-pair model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P10-1142.txt | Citing Article:  W11-1912.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Ng, 2010) discusses the entity-mention model which operates on emerging co reference sets to create features describing the relation of an anaphor candidate and established co reference sets.</S> | Reference Offset:  ['93','104'] | Reference Text:  <S sid = 93 ssid = >The entity-mention model addresses the expressiveness problem with the mention-pair model.</S><S sid = 104 ssid = >This model is commonly known as the entity-mention model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P10-1142.txt | Citing Article:  P14-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This shortcoming has been addressed by entity-mention models, which relate a candidate mention to the full cluster of mentions predicted to be co referent so far (for more discussion on the model types, see, e.g., (Ng, 2010)).</S> | Reference Offset:  ['92','93'] | Reference Text:  <S sid = 92 ssid = >Below we discuss how these weaknesses are addressed by the entity-mention model and ranking models.</S><S sid = 93 ssid = >The entity-mention model addresses the expressiveness problem with the mention-pair model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P10-1142.txt | Citing Article:  W11-1901.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A better idea of the progress in the field can be obtained by reading recent survey articles (Ng, 2010) and tutorials (Ponzetto and Poesio, 2009) dedicated to this subject.</S> | Reference Offset:  ['14','174'] | Reference Text:  <S sid = 14 ssid = >Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research.</S><S sid = 174 ssid = >It would be interesting to incorporate this idea into a learning-based resolver.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P10-1142.txt | Citing Article:  W12-2501.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In computational linguistics, the increasing availability of annotated coreference corpora has led to developments in machine learning approaches to automatic co reference resolution (see Ng, 2010).</S> | Reference Offset:  ['1','18'] | Reference Text:  <S sid = 1 ssid = >The research focus of computational coreference resolution has exhibited a shift from heuristic approaches to machine learning approaches in the past decade.</S><S sid = 18 ssid = >The widespread popularity of machine learning approaches to coreference resolution can be attributed in part to the public availability of annotated coreference corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P10-1142.txt | Citing Article:  W12-2501.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The task of automatic NP coreference resolution is to determine "which NPs in a text [...] refer to the same real-world entity" (Ng, 2010, p. 1396).</S> | Reference Offset:  ['3','153'] | Reference Text:  <S sid = 3 ssid = >Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue refer to the same real-world entity, has been at the core of natural language processing (NLP) since the 1960s.</S><S sid = 153 ssid = >Some features determine NP type (e.g., are both NPs definite or pronouns?).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P10-1142.txt | Citing Article:  W11-1911.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In principle, this algorithm is too greedy and sometimes results in unreasonable partition (Ng, 2010).</S> | Reference Offset:  ['55','199'] | Reference Text:  <S sid = 55 ssid = >One criticism of the closest-first and best-first clustering algorithms is that they are too greedy.</S><S sid = 199 ssid = >Note that both scorers have only been defined for the case where the key partition has the same set of NPs as the response partition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P10-1142.txt | Citing Article:  W12-3205.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a historical account and assessent of work in automated anaphora resolution in this period and afterwards, we direct the reader to Strube (2007), Ng (2010) and Stede (2012).</S> | Reference Offset:  ['159','209'] | Reference Text:  <S sid = 159 ssid = >There has been an increasing amount of work on investigating semantic features for coreference resolution.</S><S sid = 209 ssid = >In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P10-1142.txt | Citing Article:  W11-1913.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ng (2010) provides an excellent overview of the history and recent developments within the field.</S> | Reference Offset:  ['67','140'] | Reference Text:  <S sid = 67 ssid = >A Bell tree provides an elegant way of organizing the space of NP partitions.</S><S sid = 140 ssid = >Below we give an overview of these features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P10-1142.txt | Citing Article:  W12-4503.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow the standard architecture where mentions are extracted in the first step, then they are clustered using a pair-wise classifier (see e.g., (Ng, 2010)).</S> | Reference Offset:  ['29','187'] | Reference Text:  <S sid = 29 ssid = >The mention-pair model is a classifier that determines whether two NPs are coreferent.</S><S sid = 187 ssid = >In the third method, a mention detector is first trained on the gold-standard NPs in the training texts, and is then applied to automatically extract system mentions in a test text.7 Note that these three extraction methods typically produce different numbers of NPs: the NPs extracted from a parser tend to significantly outnumber the system mentions, which in turn outnumber the gold NPs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P10-1142.txt | Citing Article:  W12-4503.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The two most common decoding algorithms often found in literature are the so-called BestFirst (henceforth BF) and ClosestFirst (CF) algorithms (Ng, 2010).</S> | Reference Offset:  ['51','59'] | Reference Text:  <S sid = 51 ssid = >Below we describe some commonly used coreference clustering algorithms.</S><S sid = 59 ssid = >Several algorithms that address one or both of these problems have been used for coreference clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P10-1142.txt | Citing Article:  D12-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Interested readers can refer to the literature review by Ng (2010).</S> | Reference Offset:  ['3','208'] | Reference Text:  <S sid = 3 ssid = >Noun phrase (NP) coreference resolution, the task of determining which NPs in a text or dialogue refer to the same real-world entity, has been at the core of natural language processing (NLP) since the 1960s.</S><S sid = 208 ssid = >While many of the techniques discussed in this paper were originally developed for English, they have been applied to learn coreference models for other languages, such as Chinese (e.g., Converse (2006)), Japanese (e.g., Iida (2007)), Arabic (e.g., Luo and Zitouni (2005)), Dutch (e.g., Hoste (2005)), German (e.g., Wunsch (2010)), Swedish (e.g., Nilsson (2010)), and Czech (e.g., Ngu.y et al. (2009)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P10-1142.txt | Citing Article:  E12-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Excellent surveys are provided by Strube (2007) and Ng (2010). Unresolved anaphora can add significant translation ambiguity, and their incorrect translation can significantly decrease a reader's ability to understand a text.</S> | Reference Offset:  ['98','209'] | Reference Text:  <S sid = 98 ssid = >Clinton” and “she” will end up in the same cluster, which is incorrect due to gender mismatch.</S><S sid = 209 ssid = >In addition, researchers have developed approaches that are targeted at handling certain kinds of anaphora present in non-English languages, such as zero anaphora (e.g., Iida et al. (2007a), Zhao and Ng (2007)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P10-1142.txt | Citing Article:  W12-4501.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a detailed survey of the progress in this field, we refer the reader to a recent article (Ng, 2010) and a tutorial (Ponzetto and Poesio, 2009) dedicated to this subject.</S> | Reference Offset:  ['14','200'] | Reference Text:  <S sid = 14 ssid = >Note that several leading coreference researchers have published books (e.g., Mitkov (2002)), written survey articles (e.g., Mitkov (1999), Strube (2009)), and delivered tutorials (e.g., Strube (2002), Ponzetto and Poesio (2009)) that provide a broad overview of coreference research.</S><S sid = 200 ssid = >To apply these scorers to automatically extracted NPs, different methods have been proposed (see Rahman and Ng (2009) and Stoyanov et al. (2009)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P10-1142.txt | Citing Article:  W12-4501.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['56','226'] | Reference Text:  <S sid = 56 ssid = >In particular, clusters are formed based on a small subset of the pairwise decisions made by the model.</S><S sid = 226 ssid = >Any opinions, findings, and conclusions or recommendations expressed are those of the author and do not necessarily reflect the views or official policies, either expressed or implied, of the NSF.</S> | Discourse Facet:  NA | Annotator: Automatic


