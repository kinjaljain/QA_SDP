Citance Number: 1 | Reference Article:  P09-1058.txt | Citing Article:  D10-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow Kruengkrai et al (2009) and split the CTB 5 into training, development testing and testing sets, as shown in Table 3.</S> | Reference Offset:  ['37','126'] | Reference Text:  <S sid = 37 ssid = >In the testing phase, we can use a dynamic programming algorithm to search for the most likely path out of all candidate paths.</S><S sid = 126 ssid = >In this paper, we used CTB 5.0 (LDC2005T01) as our main corpus, defined the training, development and test sets according to (Jiang et al., 2008a; Jiang et al., 2008b), and designed our experiments to explore the impact of the training corpus size on our approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1058.txt | Citing Article:  D10-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kruengkrai et al (2009) made use of character type knowledge for spaces, numerals, symbols, alphabets, Chinese and other characters.</S> | Reference Offset:  ['124','170'] | Reference Text:  <S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S><S sid = 170 ssid = >For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1058.txt | Citing Article:  D10-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kruengkrai et al (2009) and Zhang and Clark (2008) are the most similar to our system among related work.</S> | Reference Offset:  ['147','170'] | Reference Text:  <S sid = 147 ssid = >Zhang and Clark (2008) (Z&C08) generated CTB 3.0 from CTB 4.0.</S><S sid = 170 ssid = >For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1058.txt | Citing Article:  D10-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The work of Kruengkrai et al (2009) is based on Nakagawa and Uchimoto (2007), which separates the processing of known words and unknown words, and uses a set of segmentation tags to represent the segmentation of characters.</S> | Reference Offset:  ['25','166'] | Reference Text:  <S sid = 25 ssid = >We represent the search space with a lattice based on the word-character hybrid model (Nakagawa and Uchimoto, 2007).</S><S sid = 166 ssid = >Maximum entropy models are widely used for word segmentation and POS tagging tasks (Uchimoto et al., 2001; Ng and Low, 2004; Nakagawa, 2004; Nakagawa and Uchimoto, 2007) since they only need moderate training times while they provide reasonable performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1058.txt | Citing Article:  D10-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our learning and decoding algorithms are also different from Kruengkrai et al (2009).</S> | Reference Offset:  ['139','155'] | Reference Text:  <S sid = 139 ssid = >The total number of words is the same, but the different policies yield different balances between the known and artificial unknown words for learning the hybrid model.</S><S sid = 155 ssid = >Our experiment on the large training corpus is identical to that of Jiang et al. (Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1058.txt | Citing Article:  D12-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.</S><S sid = 187 ssid = >We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1058.txt | Citing Article:  D12-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >K2009 is the result of Kruengkrai et al (2009).</S> | Reference Offset:  ['89','155'] | Reference Text:  <S sid = 89 ssid = >As a result, we cannot directly use the 0/1 loss.</S><S sid = 155 ssid = >Our experiment on the large training corpus is identical to that of Jiang et al. (Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1058.txt | Citing Article:  D12-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.</S><S sid = 187 ssid = >We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1058.txt | Citing Article:  D12-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, it's natural that we evaluate the accuracy of joint Chinese word segmentation and part of speech tagging, as reported in previous literature (Kruengkrai et al 2009).</S> | Reference Offset:  ['0','124'] | Reference Text:  <S sid = 0 ssid = >An Error-Driven Word-Character Hybrid Model for Joint Chinese Word Segmentation and POS Tagging</S><S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1058.txt | Citing Article:  P11-1141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For ordinary word segmentation, the best result is reported to be around 97% F1 on CTB 5.0 (Kruengkrai et al, 2009), while our parser performs at 97.3%, though we should remember that the result concerns flat words only.</S> | Reference Offset:  ['89','157'] | Reference Text:  <S sid = 89 ssid = >As a result, we cannot directly use the 0/1 loss.</S><S sid = 157 ssid = >The result of our error-driven model is superior to previous reported results for both Seg and Seg & Tag, and the result of our baseline model compares favorably to the others.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1058.txt | Citing Article:  P12-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because the tasks of word segmentation and POS tagging have strong interactions, many studies have been devoted to the task of joint word segmentation and POS tagging for languages such as Chinese (e.g. Kruengkrai et al (2009)).</S> | Reference Offset:  ['0','124'] | Reference Text:  <S sid = 0 ssid = >An Error-Driven Word-Character Hybrid Model for Joint Chinese Word Segmentation and POS Tagging</S><S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1058.txt | Citing Article:  P12-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >"Kruengkrai+ '09" is a lattice-based model by Kruengkrai et al (2009).</S> | Reference Offset:  ['12','25'] | Reference Text:  <S sid = 12 ssid = >Nakagawa (2004) described a training method based on a word-based Markov model and a character-based maximum entropy model that can be completed in a reasonable time.</S><S sid = 25 ssid = >We represent the search space with a lattice based on the word-character hybrid model (Nakagawa and Uchimoto, 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1058.txt | Citing Article:  W10-3205.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We applied morphological analysis and part-of-speech tagging by using TreeTagger (Schmid, 1994) for English, JUMAN for Japanese, and mma (Kruengkrai et al, 2009) for Chinese, respectively.</S> | Reference Offset:  ['5','124'] | Reference Text:  <S sid = 5 ssid = >In Chinese, word segmentation and part-of-speech (POS) tagging are indispensable steps for higherlevel NLP tasks.</S><S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1058.txt | Citing Article:  P12-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse all the sentences in the data.</S> | Reference Offset:  ['103','170'] | Reference Text:  <S sid = 103 ssid = >Using just the surface forms can overfit the training data and lead to poor predictions on the test data.</S><S sid = 170 ssid = >For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1058.txt | Citing Article:  P10-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Firstly, the Chinese sentences are segmented, POS tagged and parsed by the tools described in Kruengkrai et al (2009) and Cao et al (2007), both of which are trained on the Penn Chinese Treebank 6.0.</S> | Reference Offset:  ['20','124'] | Reference Text:  <S sid = 20 ssid = >We conducted our experiments on Penn Chinese Treebank (Xia et al., 2000) and compared our approach with the best previous approaches reported in the literature.</S><S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1058.txt | Citing Article:  D11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On the Chinese side, we used the morphological analyzer described in (Kruengkrai et al, 2009) trained on the training data of CTBtp to perform word segmentation and POS tagging and used the first-order Parsers to parse all the sentences in the data.</S> | Reference Offset:  ['124','170'] | Reference Text:  <S sid = 124 ssid = >Previous studies on joint Chinese word segmentation and POS tagging have used Penn Chinese Treebank (CTB) (Xia et al., 2000) in experiments.</S><S sid = 170 ssid = >For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1058.txt | Citing Article:  P13-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.</S><S sid = 187 ssid = >We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1058.txt | Citing Article:  D12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.</S><S sid = 187 ssid = >We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1058.txt | Citing Article:  D12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >Here, we define unidentified unknown words as OOV words in each validation set that cannot be recovered by the system.</S><S sid = 187 ssid = >We would like to thank Tetsuji Nakagawa for his helpful suggestions about the word-character hybrid model, Chen Wenliang for his technical assistance with the Chinese processing, and the anonymous reviewers for their insightful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1058.txt | Citing Article:  P10-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the MMA system (Kruengkrai et al, 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline Parser to parse all the sentences in the data.</S> | Reference Offset:  ['103','170'] | Reference Text:  <S sid = 103 ssid = >Using just the surface forms can overfit the training data and lead to poor predictions on the test data.</S><S sid = 170 ssid = >For example, a perceptron algorithm is used for joint Chinese word segmentation and POS tagging (Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b).</S> | Discourse Facet:  NA | Annotator: Automatic


