Citance Number: 1 | Reference Article:  P06-1095.txt | Citing Article:  W06-0904.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1095.txt | Citing Article:  P14-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1095.txt | Citing Article:  S10-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our approach for labelling temporal relations (or TLINKs) is based on NLTK's maximum entropy classifier, using the feature sets initially proposed in Mani et al (2006).</S> | Reference Offset:  ['2','146'] | Reference Text:  <S sid = 2 ssid = >To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.</S><S sid = 146 ssid = >We showed that temporal reasoning can be used as an oversampling method to dramatically expand the amount of training data for TLINK labeling, resulting in labeling predictive accuracy as high as 93% using an off-the-shelf Maximum Entropy classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1095.txt | Citing Article:  S10-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thus, the features in Mani et al (2006) are augmented with those used to describe signals detailed in Derczynski and Gaizauskas (2010), with some slight changes.</S> | Reference Offset:  ['57','135'] | Reference Text:  <S sid = 57 ssid = >For event-time links, we used the above event and signal features along with TIMEX3 time features.</S><S sid = 135 ssid = >(Berglund et al. 2006) use a document-level evaluation approach pioneered by (Setzer and Gaizauskas 2000), which uses a distinct evaluation metric.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1095.txt | Citing Article:  S10-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The performance of classifier based approaches to temporal link labelling seems to be levelling off - the 60% - 70% relation labelling accuracy of work such as Mani et al (2006) has not been greatly exceeded.</S> | Reference Offset:  ['2','132'] | Reference Text:  <S sid = 2 ssid = >To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.</S><S sid = 132 ssid = >Other work in machine-learning and hand-coded approaches, while interesting, is harder to compare in terms of accuracy since they do not use common task definitions, annotation standards, and evaluation measures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1095.txt | Citing Article:  C08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1095.txt | Citing Article:  C08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While machine learning approaches attempt to improve classification accuracy through feature engineering, Mani et al (2006) introduced a temporal reasoning component to greatly expand the training data.</S> | Reference Offset:  ['15','62'] | Reference Text:  <S sid = 15 ssid = >To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data.</S><S sid = 62 ssid = >It’s possible that feature engineering could improve performance, but since this is “perfect” data, the result is not encouraging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1095.txt | Citing Article:  C08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, extensions of Mani et al (2006)'s research is briefly described in (Mani et al, 2007).</S> | Reference Offset:  ['134','141'] | Reference Text:  <S sid = 134 ssid = >(Mani et al. 2003) obtained 80.2 F-measure training a decision tree on 2069 clauses in anchoring events to reference times that were inferred for each clause.</S><S sid = 141 ssid = >Recently, researchers have developed other tools for automatically tagging aspects of TimeML, including EVENT (Sauri et al. 2005) at 0.80 F-measure and TIMEX36 tags at 0.82-0.85 F-measure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1095.txt | Citing Article:  C08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This technical report addresses two problems found in (Mani et al, 2006): (1) feature vector duplication caused by the data normalization process (once fixed, the accuracy drops to 76.56% and 83.23%) and (2) a somewhat unrealistic evaluation scheme (we describe Mani et al (2007)'s results in Section 4.1).</S> | Reference Offset:  ['135','139'] | Reference Text:  <S sid = 135 ssid = >(Berglund et al. 2006) use a document-level evaluation approach pioneered by (Setzer and Gaizauskas 2000), which uses a distinct evaluation metric.</S><S sid = 139 ssid = >(Schilder and Habel 2001) report 84% accuracy inferring temporal relations in German data, and (Li et al. 2001) report 93% accuracy on extracting temporal relations in Chinese.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1095.txt | Citing Article:  C08-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1095.txt | Citing Article:  I08-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although Mani et al (2006) use the links introduced by closure to boost the amount of training data for a tlink classifier, this technique is not suitable for our learning task since the closure might easily propagate errors in the automatic annotations.</S> | Reference Offset:  ['123','124'] | Reference Text:  <S sid = 123 ssid = >We can see that even after closure, the baseline of learning from unclosed human annotations is much poorer than ME-C, and is in fact substantially worse than the majority class on event ordering.</S><S sid = 124 ssid = >This means that for preprocessing new data sets to produce noisily annotated data for this classification task, it is far better to use machinelearning from closed human annotations rather than machine-learning from closed annotations produced by an intuitive baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1095.txt | Citing Article:  C10-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following (Mani et al, 2006), prior approaches exploit temporal inferences to enrich the set of training in stances used for learning.</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >Machine Learning Of Temporal Relations</S><S sid = 15 ssid = >To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1095.txt | Citing Article:  C10-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1095.txt | Citing Article:  C10-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P06-1095.txt | Citing Article:  C10-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These differences are likely to come from the fact that: (i) (Mani et al, 2006) perform a 6-way classification, and not a 13-way classification, and (ii) (Chambers and Jurafsky, 2008) use a relation set that is even more restrictive than TempEval's.</S> | Reference Offset:  ['79','130'] | Reference Text:  <S sid = 79 ssid = >The improvement provided by temporal closure can be explained by three factors: (1) closure effectively creates a new classification problem with many more instances, providing more data to train on; (2) the class distribution is further skewed which results in a higher majority class baseline (3) closure produces additional data in such a way as to increase the frequencies and statistical power of existing features in the unclosed data, as opposed to adding new features.</S><S sid = 130 ssid = >Future research will investigate methods for tighter integration of temporal reasoning and statistical classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P06-1095.txt | Citing Article:  I08-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As such, it emphasizes robustness at Web scale, without taking advantage of existing specification languages for representing events and temporal expressions occurring in text (Pustejovsky et al, 2003), and forgoing the potential benefits of more complex methods that extract temporal relations from relatively clean text collections (Mani et al, 2006).</S> | Reference Offset:  ['19','35'] | Reference Text:  <S sid = 19 ssid = >TimeML (Pustejovsky et al. 2005) (www.timeml.org) is an annotation scheme for markup of events, times, and their temporal relations in news articles.</S><S sid = 35 ssid = >Two corpora have been released based on TimeML: the TimeBank (Pustejovsky et al. 2003) (we use version 1.2.a) with 186 documents and 64,077 words of text, and the Opinion Corpus (www.timeml.org), with 73 documents and 38,709 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P06-1095.txt | Citing Article:  P08-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Taking a cue from Mani et al (2006), we also increased Timebank's size by applying transitivity rules to the hand labeled data.</S> | Reference Offset:  ['66','96'] | Reference Text:  <S sid = 66 ssid = >SputLink’s transitivity table is represented by 745 axioms.</S><S sid = 96 ssid = >The bottom-line here is that even when heuristic preferences are intuited, those preferences need to be guided by empirical data, whereas hand-coded rules are relatively ignorant of the distributions that are found in data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P06-1095.txt | Citing Article:  S10-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','155'] | Reference Text:  <S sid = 48 ssid = >In addition, a program, as a baseline, can trivially link all tagged events and times, getting 100% recall on Task A.</S><S sid = 155 ssid = >To further facilitate further research, our tools as well as labeled vectors (unclosed as well as closed) are available for others to experiment with.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P06-1095.txt | Citing Article:  S10-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Mani et al (2006) introduced a temporal reasoning component that greatly expands the available training data.</S> | Reference Offset:  ['2','15'] | Reference Text:  <S sid = 2 ssid = >To address data sparseness, we used temporal reasoning as an oversampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data.</S><S sid = 15 ssid = >To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P06-1095.txt | Citing Article:  D08-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In order to connect the event graph, we draw on work from (Mani et al, 2006) and apply transitive closure to our documents.</S> | Reference Offset:  ['26','75'] | Reference Text:  <S sid = 26 ssid = >The anchor relation is an Event-Time TLINK, and the order relation is an Event-Event TLINK.</S><S sid = 75 ssid = >There are only an average of 0.84 TLINKs per event before closure, but after closure it shoots up to 9.49 TLINKs per event.</S> | Discourse Facet:  NA | Annotator: Automatic


