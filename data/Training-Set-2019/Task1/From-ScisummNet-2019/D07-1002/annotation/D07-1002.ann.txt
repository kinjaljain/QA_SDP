Citance Number: 1 | Reference Article:  D07-1002.txt | Citing Article:  P08-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Shen and Lapata, 2007) has shown that shallow semantic information in the form of predicate argument structures (PASs) improves the automatic detection of correct answers to a target question.</S> | Reference Offset:  ['45','48'] | Reference Text:  <S sid = 45 ssid = >Their system identifies predicate argument structures by merging semanticrole information from PropBank and FrameNet.</S><S sid = 48 ssid = >They use ASSERT (Pradhan et al, 2004), a publicly available shallow semantic parser trained on PropBank, to generate predicate-argument structures which subsequently form the basis of comparison between question and answer sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D07-1002.txt | Citing Article:  D08-1048.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Shen and Lapata (2007) show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system.</S> | Reference Offset:  ['0','38'] | Reference Text:  <S sid = 0 ssid = >Using Semantic Roles to Improve Question Answering</S><S sid = 38 ssid = >Question answering systems have traditionally de pended on a variety of lexical resources to bridge surface differences between questions and potential answers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D07-1002.txt | Citing Article:  E09-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The alignment of answers to question types as a semantic role labelling task using similar methods was explored by Shen and Lapata (2007).</S> | Reference Offset:  ['0','146'] | Reference Text:  <S sid = 0 ssid = >Using Semantic Roles to Improve Question Answering</S><S sid = 146 ssid = >Answer types are determined using classi fication rules similar to Li and Roth (2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D07-1002.txt | Citing Article:  W09-2417.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The state-of-the-art in semantic role labelling has now advanced so much that a number of studies have shown that automatically inferred semantic argument structures can lead to tangible performance gains in NLP applications such as information extraction (Surdeanu et al, 2003), question answering (Shen and Lapata, 2007) or recognising textual entailment (Burchardt and Frank, 2006).</S> | Reference Offset:  ['45','61'] | Reference Text:  <S sid = 45 ssid = >Their system identifies predicate argument structures by merging semanticrole information from PropBank and FrameNet.</S><S sid = 61 ssid = >Semantic structures for questions and sentences are automatically derived using the model described in Section 4 (Model I).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D07-1002.txt | Citing Article:  W11-0124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >FrameNet has a shorter history in NLP applications than WordNet, but lately more and more researchers have been demonstrating its potential to improve the quality of question answering (Shen and Lapata, 2007) and recognizing textual entailment (Burchardt et al, 2009).</S> | Reference Offset:  ['0','39'] | Reference Text:  <S sid = 0 ssid = >Using Semantic Roles to Improve Question Answering</S><S sid = 39 ssid = >WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D07-1002.txt | Citing Article:  D08-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al, 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005).</S> | Reference Offset:  ['19','113'] | Reference Text:  <S sid = 19 ssid = >Question answering (QA) is often cited as an obvious beneficiary of semantic 12 role labeling (Gildea and Jurafsky, 2002; Palmer et al., 2005; Narayanan and Harabagiu, 2004).</S><S sid = 113 ssid = >Edge covers have been success fully applied in several natural language processing tasks, including machine translation (Taskar et al, 2005) and annotation projection (Pado?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D07-1002.txt | Citing Article:  W08-1810.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Shen and Lapata (2007) developed an answer extraction module that incorporates FrameNet style semantic role information.</S> | Reference Offset:  ['27','242'] | Reference Text:  <S sid = 27 ssid = >In this paper we propose an answer extractionmodel which effectively incorporates FrameNetstyle semantic role information.</S><S sid = 242 ssid = >We present a graph-based answer extrac tion model which effectively incorporates FrameNet style role semantic information and show that it achieves promising results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D07-1002.txt | Citing Article:  P11-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Indeed, the analysis produced by existing semantic role labelers has been shown to benefit a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005).</S> | Reference Offset:  ['39','41'] | Reference Text:  <S sid = 39 ssid = >WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).</S><S sid = 41 ssid = >Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D07-1002.txt | Citing Article:  W08-2208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recent studies (e.g. Shen and Lapata (2007)) show that the use of FrameNet can potentially improve the performance of Question Answering systems.</S> | Reference Offset:  ['0','34'] | Reference Text:  <S sid = 0 ssid = >Using Semantic Roles to Improve Question Answering</S><S sid = 34 ssid = >In the following section we provide an overview of existing work on question answering systems that exploit semantic role-based lexical resources.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D07-1002.txt | Citing Article:  W08-2208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yet, Shen and Lapata (2007) also point out that the low coverage of the current version of FrameNet significantly limits the expected boost in performance.</S> | Reference Offset:  ['49','228'] | Reference Text:  <S sid = 49 ssid = >They find that semantic analysis does not boost performance due to the low recall of the semantic parser.</S><S sid = 228 ssid = >Table 3: System Performance on TREC datasets (see Total column in Table 1); ?: significantly better than +SemParse; ?: significantly better than SynMatch (p < 0.01, using a ?2 test).tem to yield better performance over a purely syn tactic answer extraction module.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D07-1002.txt | Citing Article:  P10-2022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other work incorporating syntactic and linguistic information into IR includes early research by (Smeaton, O Donnell and Kelledy, 1995), who employed tree structured analytics (TSAs) resembling dependency trees, the use of syntax to detect paraphrases for question answering (QA) (Lin and Pantel, 2001), and semantic role labelling in QA (Shen and Lapata, 2007).</S> | Reference Offset:  ['41','161'] | Reference Text:  <S sid = 41 ssid = >Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.</S><S sid = 161 ssid = >Baseline We compared our answer extractionmethod to a QA system that exploits solely syntac tic information without making use of FrameNet or any other type of role semantic annotations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D07-1002.txt | Citing Article:  D11-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Semantic role analysis has the potential of benefiting a wide spectrum of applications ranging from information extraction (Surdeanu et al, 2003) and question answering (Shen and Lapata, 2007), to machine translation (Wu and Fung, 2009) and summarization (Melli et al, 2005).</S> | Reference Offset:  ['39','41'] | Reference Text:  <S sid = 39 ssid = >WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).</S><S sid = 41 ssid = >Most syntax-based QA systems (Wu et al, 2005) incorporate some means of comparison between the tree representing the question with the subtree surrounding the answer candidate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D07-1002.txt | Citing Article:  W09-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, resources annotated with the surface realization of semantic roles, like FrameNet (Baker et al, 1998) or PropBank (Palmeret al, 2005) have shown to convey an improvement in several NLP tasks, from question answering (Shen and Lapata, 2007) to textual entailment (Burchardt et al, 2007) and shallow semantic parsing (Giuglea and Moschitti, 2006).</S> | Reference Offset:  ['6','39'] | Reference Text:  <S sid = 6 ssid = >Recent years have witnessed significant progress in developing methods for the automatic identificationand labeling of semantic roles conveyed by sentential constituents.1 The success of these methods, often referred to collectively as shallow semantic pars ing (Gildea and Jurafsky, 2002), is largely due to the availability of resources like FrameNet (Fillmore et al., 2003) and PropBank (Palmer et al, 2005), which document the surface realization of semantic roles in real world corpora.</S><S sid = 39 ssid = >WordNet (Fellbaum, 1998) is perhaps the most popular resource and has been employed in a variety of QA-related tasks ranging from query expansion, to axiom-based reasoning (Moldovan et al., 2003), passage scoring (Paranjpe et al, 2003), and answer filtering (Leidner et al, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


