Citance Number: 1 | Reference Article:  N03-2021.txt | Citing Article:  N04-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Another example of a loss function in this class is the MTeval metric introduced in Melamed et al (2003).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N03-2021.txt | Citing Article:  S12-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the following n-gram-based metrics: BLEU (Papineni et al, 2002), NIST (Dod ding ton, 2002), ROUGE (Lin and Och, 2004), GTM (Melamed et al, 2003), METEOR (Banerjee and Lavie, 2005).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N03-2021.txt | Citing Article:  P09-2025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >GTM General Text Matching (Melamed et al, 2003) calculates word overlap between a reference and a solution, without double counting duplicate words.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N03-2021.txt | Citing Article:  W11-2157.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 2 reports the translation performance as measured by BLEU (Papineni et al,2002), GTM (Melamed et al, 2003) and ME TEOR2 (Banerjee and Lavie, 2005) for Apertium and the three systems presented in the previous section, as well as the size of the phrase table and the amount of unknown words in the test set.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N03-2021.txt | Citing Article:  P04-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed et al (2003) used unigram F-measure to estimate machine translation quality and showed that unigram F-measure was as good as BLEU.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N03-2021.txt | Citing Article:  P06-2003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have selected a representative set of 22 metric variants corresponding to six different families: BLEU (Papineni et al, 2001), NIST (Dodding ton, 2002), GTM (Melamed et al, 2003), Per (Leusch et al, 2003) , WER (NieBen et al, 2000) and ROUGE (Lin and Och, 2004a).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N03-2021.txt | Citing Article:  H05-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Third, we computed the correspondence between each hypothesis sentence and each of its corresponding reference sentences using an approximation to maximum matching (Melamed et al, 2003).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N03-2021.txt | Citing Article:  I08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other well-known metrics are WER (NieBen et al, 2000), NIST (Doddington, 2002), GTM (Melamed et al, 2003), ROUGE (Lin and Och, 2004a), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al, 2006), just to name a few.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N03-2021.txt | Citing Article:  P06-2037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have computed the BLEU score (accumulated up to 4-grams) (Papineni et al, 2001), the NIST score (accumulated up to 5-grams) (Doddington, 2002), the General Text Matching (GTM) F-measure (e= 1, 2) (Melamed et al, 2003), and the METEOR measure (Banerjee and Lavie, 2005).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N03-2021.txt | Citing Article:  W07-0734.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Meteor, as well as several other proposed metrics such as GTM (Melamed et al, 2003), TER (Snover et al, 2006) and CDER (Leusch et al, 2006) aim to address some of these weaknesses.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N03-2021.txt | Citing Article:  P09-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed et al (2003) argued, at the time of introducing the GTM metric, that Pearson correlation coefficients can be affected by scale properties, and suggested, in order to avoid this effect, to use the non-parametric Spearman correlation coefficients instead.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N03-2021.txt | Citing Article:  E06-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed et al (2003) formulate a metric which measures translation accuracy in terms of precision and recall directly rather than precision and a brevity penalty.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N03-2021.txt | Citing Article:  E06-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Meteor (Banerjee and Lavie, 2005), Precision and Recall (Melamed et al, 2003), and other such automatic metrics may also be affected to a greater or lesser degree because they are all quite rough measures of translation similarity, and have inexact models of allowable variation in translation.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N03-2021.txt | Citing Article:  W06-3126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For evaluation we have selected a set of 8 metric variants corresponding to seven different families: BLEU (n= 4) (Papineni et al, 2001), NIST (n= 5) (Lin and Hovy, 2002), GTM F1-measure (e= 1, 2) (Melamed et al, 2003), 1-WER (NieBen et al, 2000), 1-PER (Leusch et al, 2003), ROUGE (ROUGE-S*) (Lin and Och, 2004) and METEOR3 (Banerjee and Lavie, 2005).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N03-2021.txt | Citing Article:  D11-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed et al (2003) argued, at the time of introducing the GTM metric, that Pearson correlation coefficients can be affected by scale properties.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N03-2021.txt | Citing Article:  H05-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >each of its corresponding reference sentences using an approximation to maximum matching (Melamed et al, 2003).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N03-2021.txt | Citing Article:  W10-4216.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At this time, the realizations are also scored using the General Text Matcher method (GTM) (Melamed et al, 2003), by comparing them to the original sentence.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N03-2021.txt | Citing Article:  W04-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Melamed et al (2003) used unigram F-measure to estimate machine translation quality and showed that unigram F measure was as good as BLEU.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N03-2021.txt | Citing Article:  W08-0312.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Meteor, as well as several other proposed metrics such as GTM (Melamed et al, 2003), TER (Snover et al, 2006) and CDER (Leusch et al, 2006) aim to address some of these weaknesses.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N03-2021.txt | Citing Article:  P07-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Metrics in the Rouge family allow for skip n-grams (Lin and Och,2004a); Kauchak and Barzilay (2006) take paraphrasing into account; metrics such as METEOR (Banerjee and Lavie, 2005) and GTM (Melamed et al., 2003) calculate both recall and precision; METEOR is also similar to SIA (Liu and Gildea, 2006) in that word class information is used.</S> | Reference Offset:  ['0'] | Reference Text:  <S sid = 0 ssid = >Precision And Recall Of Machine Translation</S> | Discourse Facet:  NA | Annotator: Automatic


