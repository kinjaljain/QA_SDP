Citance Number: 1 | Reference Article:  N10-1115.txt | Citing Article:  D11-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar methods to Shen et al (2007) have also been used in Shen and Joshi (2008) and Goldberg and Elhadad (2010).</S> | Reference Offset:  ['56','167'] | Reference Text:  <S sid = 56 ssid = >The model is trained using a variant of the structured perceptron (Collins, 2002), similar to the algorithm of (Shen et al., 2007; Shen and Joshi, 2008).</S><S sid = 167 ssid = >Indeed, one major influence on our work is Shen et.al.’s bi-directional POS-tagging algorithm (Shen et al., 2007), which combines a perceptron learning procedure similar to our own with beam search to produce a state-of-the-art POStagger, which does not rely on left-to-right processing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N10-1115.txt | Citing Article:  P14-2120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To identify explicit predicate-argument relationships we utilized dependency parsing by the Easy-First parser (Goldberg and Elhadad, 2010).</S> | Reference Offset:  ['0','20'] | Reference Text:  <S sid = 0 ssid = >An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing</S><S sid = 20 ssid = >We propose a new category of dependency parsing algorithms, inspired by (Shen et al., 2007): nondirectional easy-first parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N10-1115.txt | Citing Article:  P12-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Goldberg and Elhadad (2010) observed that parsing time is dominated by feature extraction and score calculation.</S> | Reference Offset:  ['99','105'] | Reference Text:  <S sid = 99 ssid = >Thus, we observe that the feature extraction and score calculation can be performed once for each action/location pair in a given sentence, and reused throughout all the iterations.</S><S sid = 105 ssid = >In terms of feature extraction and score calculation operations, our algorithm has the same cost as traditional shift-reduce (MALT) parsers, and is an order of magnitude more efficient than graph-based (MST) parsers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N10-1115.txt | Citing Article:  P12-3013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >BIUTEE provides state-of-the-art pre-processing utilities: Easy-First parser (Goldberg and Elhadad, 2010), Stanford named-entity-recognizer (Finkel et al, 2005) and ArkRef coreference resolver (Haghighi and Klein, 2009), as well as utilities for sentence splitting and numerical-normalizations.</S> | Reference Offset:  ['84','167'] | Reference Text:  <S sid = 84 ssid = >The unigram and bigram features are adapted from the feature set for left-to-right Arc-Standard dependency parsing described in (Huang et al., 2009).</S><S sid = 167 ssid = >Indeed, one major influence on our work is Shen et.al.’s bi-directional POS-tagging algorithm (Shen et al., 2007), which combines a perceptron learning procedure similar to our own with beam search to produce a state-of-the-art POStagger, which does not rely on left-to-right processing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N10-1115.txt | Citing Article:  E12-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','184'] | Reference Text:  <S sid = 57 ssid = >As usual, we use parameter averaging to prevent the perceptron from overfitting.</S><S sid = 184 ssid = >We hope that further work on this non-directional parsing framework will pave the way to better understanding of an interesting cognitive question: which kinds of parsing decisions are hard to make, and which linguistic constructs are hard to analyze?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N10-1115.txt | Citing Article:  E12-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This has some similarity to Goldberg and Elhadad (2010).</S> | Reference Offset:  ['57','184'] | Reference Text:  <S sid = 57 ssid = >As usual, we use parameter averaging to prevent the perceptron from overfitting.</S><S sid = 184 ssid = >We hope that further work on this non-directional parsing framework will pave the way to better understanding of an interesting cognitive question: which kinds of parsing decisions are hard to make, and which linguistic constructs are hard to analyze?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N10-1115.txt | Citing Article:  D12-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We are using a multi-sieve approach (Raghunathan et al., 2010), which splits pairwise "co-reference" vs. "non-coreference" decisions to different types and attempts to make the easy decisions first (Goldberg and Elhadad, 2010).</S> | Reference Offset:  ['52','160'] | Reference Text:  <S sid = 52 ssid = >We must, therefore, learn how to order the decisions.</S><S sid = 160 ssid = >This model is similar to ours, in that it attempts to defer harder decisions to later passes over the sentence, and allows late decisions to make use of rich syntactic information (built in earlier passes) on both sides of the decision point.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N10-1115.txt | Citing Article:  D12-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','184'] | Reference Text:  <S sid = 57 ssid = >As usual, we use parameter averaging to prevent the perceptron from overfitting.</S><S sid = 184 ssid = >We hope that further work on this non-directional parsing framework will pave the way to better understanding of an interesting cognitive question: which kinds of parsing decisions are hard to make, and which linguistic constructs are hard to analyze?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N10-1115.txt | Citing Article:  W12-1512.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Hebrew tagger and parsing models are described in Goldberg and Elhadad (2010).</S> | Reference Offset:  ['19','112'] | Reference Text:  <S sid = 19 ssid = >As a result, these models, while accurate, are slow (O(n3) for projective, first-order models, higher polynomials for higher-order models, and worse for richer tree-feature models).</S><S sid = 112 ssid = >Each section is tagged after training the tagger on all other sections.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N10-1115.txt | Citing Article:  D11-1137.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We plan to examine to model such a complex structure (granduncle) (Goldberg and Elhadad, 2010) or higher-order structure than third-order for reranking which is computationally expensive for a baseline parser.</S> | Reference Offset:  ['16','52'] | Reference Text:  <S sid = 16 ssid = >In order to make the search tractable, the feature set needs to be restricted to features over single edges (first-order models) or edges pairs (higher-order models, e.g.</S><S sid = 52 ssid = >We must, therefore, learn how to order the decisions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N10-1115.txt | Citing Article:  P13-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The easy-first dependency parsing algorithm (Goldberg and Elhadad, 2010) is attractive due to its good accuracy, fast speed and simplicity.</S> | Reference Offset:  ['0','168'] | Reference Text:  <S sid = 0 ssid = >An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing</S><S sid = 168 ssid = >Shen and Joshi (2008) extends the bidirectional tagging algorithm to LTAG parsing, with good results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N10-1115.txt | Citing Article:  P13-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As an alternative, greedy search which only explores a tiny fraction of the search space is adopted (Goldberg and Elhadad, 2010).</S> | Reference Offset:  ['162','164'] | Reference Text:  <S sid = 162 ssid = >Beam Search Several researchers dealt with the early-commitment and error propagation of deterministic parsers by extending the greedy decisions with various flavors of beam-search (Sagae and Lavie, 2006a; Zhang and Clark, 2008; Titov and Henderson, 2007).</S><S sid = 164 ssid = >Beam search can be incorporated into our parser as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N10-1115.txt | Citing Article:  P13-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The easy-first dependency parsing algorithm (Goldberg and Elhadad, 2010) builds a dependency tree by performing two types of actions.</S> | Reference Offset:  ['0','33'] | Reference Text:  <S sid = 0 ssid = >An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing</S><S sid = 33 ssid = >Our (projective) parsing algorithm builds the parse tree bottom up, using two kinds of actions: ATTACHLEFT(i) and ATTACHRIGHT(i) .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N10-1115.txt | Citing Article:  P13-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','184'] | Reference Text:  <S sid = 57 ssid = >As usual, we use parameter averaging to prevent the perceptron from overfitting.</S><S sid = 184 ssid = >We hope that further work on this non-directional parsing framework will pave the way to better understanding of an interesting cognitive question: which kinds of parsing decisions are hard to make, and which linguistic constructs are hard to analyze?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N10-1115.txt | Citing Article:  P13-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Besides the features in (Goldberg and Elhadad, 2010), we also include some trigram features and valency features which are useful for transition-based dependency parsing (Zhang and Nivre, 2011).</S> | Reference Offset:  ['89','90'] | Reference Text:  <S sid = 89 ssid = >The pp-attachment features are similar to the bigram features, but fire only when one of the structures is headed by a preposition (IN).</S><S sid = 90 ssid = >These features are more lexicalized than the regular bigram features, and include also the word-form of the rightmost child of the PP (rcwp).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N10-1115.txt | Citing Article:  P14-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our system not only outperforms the best single system (Bjorkelund et al., 2013) by 1.4%, but it also tops the ensemble system that combines three powerful parsers: the Mate parser (Bohnet, 2010), the Easy-First parser (Goldberg and Elhadad, 2010) and the Turbo parser (Martins et al., 2013).</S> | Reference Offset:  ['115','167'] | Reference Text:  <S sid = 115 ssid = >Parsers We evaluate our parser against the transition-based MALT parser and the graph-based MST parser.</S><S sid = 167 ssid = >Indeed, one major influence on our work is Shen et.al.’s bi-directional POS-tagging algorithm (Shen et al., 2007), which combines a perceptron learning procedure similar to our own with beam search to produce a state-of-the-art POStagger, which does not rely on left-to-right processing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N10-1115.txt | Citing Article:  P13-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the context of dependency parsing, the strategy of delaying arc construction when the current configuration is not informative is called the easy-first strategy, and has been first explored by Goldberg and Elhadad (2010).</S> | Reference Offset:  ['0','177'] | Reference Text:  <S sid = 0 ssid = >An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing</S><S sid = 177 ssid = >This strategy allows using more context at each decision.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N10-1115.txt | Citing Article:  D11-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The parsing approach is based upon the non directional easy-first algorithm recently presented by Goldberg and Elhadad (2010).</S> | Reference Offset:  ['0','175'] | Reference Text:  <S sid = 0 ssid = >An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing</S><S sid = 175 ssid = >We presented a non-directional deterministic dependency parsing algorithm, which is not restricted by the left-to-right parsing order of other deterministic parsers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N10-1115.txt | Citing Article:  D11-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While theoretically slower, this has a limited impact upon actual parsing times. See Goldberg and Elhadad (2010) for more explanation.</S> | Reference Offset:  ['94','98'] | Reference Text:  <S sid = 94 ssid = >Each iteration of the main loop connects two structures and removes one of them, and so the loop repeats for exactly n times.</S><S sid = 98 ssid = >However, these changes are limited to a fixed local context around the attachment point of the action.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N10-1115.txt | Citing Article:  D11-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The feature set is based off the features used by Goldberg and Elhadad (2010) but has a significant number of extensions.</S> | Reference Offset:  ['84','100'] | Reference Text:  <S sid = 84 ssid = >The unigram and bigram features are adapted from the feature set for left-to-right Arc-Standard dependency parsing described in (Huang et al., 2009).</S><S sid = 100 ssid = >After each iteration we need to update the extracted features and calculated scores for only k locations, where k is a fixed number depending on the window size used in the feature extraction, and usually k « n. Using this technique, we perform only (k + 1)n feature extractions and score calculations for each sentence, that is O(n) feature-extraction operations per sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


