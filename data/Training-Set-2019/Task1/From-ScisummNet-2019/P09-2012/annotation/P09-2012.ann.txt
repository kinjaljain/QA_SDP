Citance Number: 1 | Reference Article:  P09-2012.txt | Citing Article:  P10-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['18','73'] | Reference Text:  <S sid = 18 ssid = >In contrast, multiple derivations in a TSG can produce the same parse; obtaining the parse probability requires a summation over all derivations that could have produced it.</S><S sid = 73 ssid = >Acknowledgments This work was supported by NSF grants IIS-0546554 and ITR-0428020.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-2012.txt | Citing Article:  D11-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['18','73'] | Reference Text:  <S sid = 18 ssid = >In contrast, multiple derivations in a TSG can produce the same parse; obtaining the parse probability requires a summation over all derivations that could have produced it.</S><S sid = 73 ssid = >Acknowledgments This work was supported by NSF grants IIS-0546554 and ITR-0428020.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-2012.txt | Citing Article:  D11-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar models were developed independently by O'Donnell et al. (2009) and Post and Gildea (2009).</S> | Reference Offset:  ['10','37'] | Reference Text:  <S sid = 10 ssid = >Recently, many groups have had success using Gibbs sampling to address the complexity issue and nonparametric priors to address the overfitting problem (DeNero et al., 2008; Goldwater et al., 2009).</S><S sid = 37 ssid = >prior2 For an excellent introduction to collapsed Gibbs sampling with a DP prior, we refer the reader to Appendix A of Goldwater et al. (2009), which we follow closely here.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-2012.txt | Citing Article:  P12-2038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A more principled technique is to use a sparse nonparametric prior, as was recently presented by Cohn et al (2009) and Post and Gildea (2009).</S> | Reference Offset:  ['10','37'] | Reference Text:  <S sid = 10 ssid = >Recently, many groups have had success using Gibbs sampling to address the complexity issue and nonparametric priors to address the overfitting problem (DeNero et al., 2008; Goldwater et al., 2009).</S><S sid = 37 ssid = >prior2 For an excellent introduction to collapsed Gibbs sampling with a DP prior, we refer the reader to Appendix A of Goldwater et al. (2009), which we follow closely here.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-2012.txt | Citing Article:  P12-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['18','73'] | Reference Text:  <S sid = 18 ssid = >In contrast, multiple derivations in a TSG can produce the same parse; obtaining the parse probability requires a summation over all derivations that could have produced it.</S><S sid = 73 ssid = >Acknowledgments This work was supported by NSF grants IIS-0546554 and ITR-0428020.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-2012.txt | Citing Article:  P11-2036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['18','73'] | Reference Text:  <S sid = 18 ssid = >In contrast, multiple derivations in a TSG can produce the same parse; obtaining the parse probability requires a summation over all derivations that could have produced it.</S><S sid = 73 ssid = >Acknowledgments This work was supported by NSF grants IIS-0546554 and ITR-0428020.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-2012.txt | Citing Article:  P11-2038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Of these approaches, work in Bayesian learning of TSGs produces intuitive grammars in a principled way, and has demonstrated potential in language modeling tasks (Post and Gildea, 2009b; Post, 2010).</S> | Reference Offset:  ['0','5'] | Reference Text:  <S sid = 0 ssid = >Bayesian Learning of a Tree Substitution Grammar</S><S sid = 5 ssid = >Tree substition grammars (TSGs) have potential advantages over regular context-free grammars (CFGs), but there is no obvious way to learn these grammars.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-2012.txt | Citing Article:  P11-2038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A Bayesian-learned tree substitution grammar (Post and Gildea, 2009a).</S> | Reference Offset:  ['0','11'] | Reference Text:  <S sid = 0 ssid = >Bayesian Learning of a Tree Substitution Grammar</S><S sid = 11 ssid = >In this paper we apply these techniques to learn a tree substitution grammar, evaluate it on the Wall Street Journal parsing task, and compare it to previous work.</S> | Discourse Facet:  NA | Annotator: Automatic


