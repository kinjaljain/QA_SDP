Citance Number: 1 | Reference Article:  W95-0105.txt | Citing Article:  W96-0303.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, work on word sense disambiguation i corpora (e.g. Resnik 1995), could lead to an estimate of frequencies for word senses in general, with rule-derived senses simply being a special case.</S> | Reference Offset:  ['98','119'] | Reference Text:  <S sid = 98 ssid = >In each case, I give the source of the noun grouping, the grouping itself, and for each word a description of word senses together with their values of y).</S><S sid = 119 ssid = >For each case, they were given the full set of nouns in the numbered category (as shown above) together with descriptions of the WordNet senses for the word to be disambiguated (as, for example, the list of 25 senses for line given in the previous section, though thankfully few words have that many senses!).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W95-0105.txt | Citing Article:  W07-2088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An adaptation of Lesk dictionary-based WSD algorithm has been used to disambiguate adjectives and ad verbs (Banerjee and Pedersen, 2002), an adaptation of the Resnik algorithm has been used to disambiguate nouns (Resnik, 1995), while the algorithm we developed for disambiguating verbs exploits the nouns in the context of the verb as well as the nouns both in the glosses and in the phrases that WordNet utilizes to describe the usage of a verb.</S> | Reference Offset:  ['64','84'] | Reference Text:  <S sid = 64 ssid = >Algorithm.</S><S sid = 84 ssid = >First, unlike Sussna's proposal, this algorithm aims to disambiguate groupings of nouns already established (e.g. by clustering, or by manual effort) to be related, as opposed to groupings of nouns that happen to appear near each other in running text (which may or may not reflect relatedness based on meaning).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W95-0105.txt | Citing Article:  W07-2088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The procedure is obtained by making some variations to the algorithm designed by Resnik (1995) for disambiguating noun groups.</S> | Reference Offset:  ['0','138'] | Reference Text:  <S sid = 0 ssid = >Disambiguating Noun Groupings With Respect To Wordnet Senses</S><S sid = 138 ssid = >Immediate plans include a larger scale version of the experiment presented here, involving thesaurus classes, as well as a similarly designed evaluation of how the algorithm fares when presented with noun groups produced by distributional clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W95-0105.txt | Citing Article:  W07-2088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >JIGSAW nouns differs from the original algorithm by Resnik (1995) in the similarity measure used to compute relatedness of two senses.</S> | Reference Offset:  ['64','87'] | Reference Text:  <S sid = 64 ssid = >Algorithm.</S><S sid = 87 ssid = >Third, unlike Sussna's algorithm, the semantic similarity/distance computation here is not based on path length, but on information content, a choice that I have argued for elsewhere (Resnik, 1993; Resnik, 1995).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W95-0105.txt | Citing Article:  W97-0812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although the assessment of semantic similarity using a dictionary database as knowledge source has been recognized as providing significant cues for word clustering (Resnik 1995b) and the determination of lexical cohesion (Morris& amp; Hirst, 1991), its relevance for word disambiguation in running text remains relatively unexplored.</S> | Reference Offset:  ['27','98'] | Reference Text:  <S sid = 27 ssid = >If successful, such an approach has obvious benefits: one can use whatever sources of good word groupings are available — primarily unsupervised word clustering methods, but also on-line thesauri and the like — without folding in the complexity of dealing with word senses at the same time.3 The resulting sense groupings should be useful for a variety of purposes, although ultimately this work is motivated by the goal of sense disambiguation for unrestricted text using unsupervised methods.</S><S sid = 98 ssid = >In each case, I give the source of the noun grouping, the grouping itself, and for each word a description of word senses together with their values of y).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W95-0105.txt | Citing Article:  W97-0812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Resnik (1995a) defines the semantic similarity between two words as the entropy value of the most informative concept subsuming the two words in a hierarchically structured thesaurus.</S> | Reference Offset:  ['38','95'] | Reference Text:  <S sid = 38 ssid = >The intuition behind the approach is simple: the more similar two words are, the more informative will be the most specific concept that subsumes them both.</S><S sid = 95 ssid = >If one were to include all subsuming concepts for each word, rather than just the synsets of which they are directly members, the concepts with non-zero values of co would be as follows: Given assignments of co at all levels of abstraction, one obvious method of semantic annotation is to assign the highest-level concept for which co is at least as large as the sense-specific value of cp.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W95-0105.txt | Citing Article:  W01-0716.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At present, we are trying to integrate the word sense disambiguation method proposed in (Resnik, 1995) into our system.</S> | Reference Offset:  ['97','103'] | Reference Text:  <S sid = 97 ssid = >In this section I present a number of examples for evaluation by inspection.</S><S sid = 103 ssid = >The group comes from from the thesaurus entry for the word method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W95-0105.txt | Citing Article:  A97-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Semantic tags are assigned from on-line thesaura like WordNet (Basili et al 1996) (Resnik, 1995), Roget's categories (Yarowsky 1992) (Chen and Chen, 1996), the Japanese BGH (Utsuro et al 1993), or assigned manually (Basili et al 1992).</S> | Reference Offset:  ['7','16'] | Reference Text:  <S sid = 7 ssid = >(Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).</S><S sid = 16 ssid = >lActually, this depends on the fine-grainedness of sense distinctions; clearly one could annotate corpora with very high level semantic distinctions For example, Basili et al. (1994) take such a coarse-grained approach, utilizing on the order of 10 to 15 semantic tags for a given domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W95-0105.txt | Citing Article:  W97-0202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The verbs are tagged with respect to senses in WordNet (Miller 1990), which has become widely used, for example in corpus-annotation projects (Miller et al 1994, Ng& amp; Hian 1996, and Grishman et al 1994) and for performing disambiguation (Resnik 1995 and Leacock et ai.</S> | Reference Offset:  ['7','18'] | Reference Text:  <S sid = 7 ssid = >(Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).</S><S sid = 18 ssid = >It is quite small, by current corpus standards (on the order of hundreds of thousands of words, rather than millions or tens of millions); the direct annotation methodology used to create it is labor intensive (Marcus et al. (1993) found that direct annotation takes twice as long as automatic tagging plus correction, for partof-speech annotation); and the output quality reflects the difficulty of the task (inter-annotator disagreement is on the order of 10%, as contrasted with the approximately 3% error rate reported for part-of-speech annotation by Marcus et al.).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W95-0105.txt | Citing Article:  W98-0702.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, disambiguating the direct object according to WordNet categories, e.g., Resnik (1995), would improve the accuracy of using these categories to disambiguate verbs.</S> | Reference Offset:  ['0','22'] | Reference Text:  <S sid = 0 ssid = >Disambiguating Noun Groupings With Respect To Wordnet Senses</S><S sid = 22 ssid = >And my own treatment of selectional constraints (Resnik, 1993) provides a way to describe the plausibility of co-occurrence in terms of WordNet's semantic categories, using co-occurrence relationships mediated by syntactic structure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W95-0105.txt | Citing Article:  P98-2180.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >There have been a number of attempts to combine paradigmatic and syntagmatic similarity strategies (e.g., Hearst and Grefenstette 1992, Resnik 1995).</S> | Reference Offset:  ['7','87'] | Reference Text:  <S sid = 7 ssid = >(Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).</S><S sid = 87 ssid = >Third, unlike Sussna's algorithm, the semantic similarity/distance computation here is not based on path length, but on information content, a choice that I have argued for elsewhere (Resnik, 1993; Resnik, 1995).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W95-0105.txt | Citing Article:  W97-0813.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Eventually, the sense supported by those patterns which are semantically closer to the context in question is selected as the most likely one (see, among others, [Dolan, 1994], [Resnik, 1995a, 1995b], [Agirre and Rigau, 1996], [Sanfilippo, 1997]).</S> | Reference Offset:  ['9','101'] | Reference Text:  <S sid = 9 ssid = >Consider, for example, the cluster containing attorney, counsel, trial, court, and judge, used by Brown et al. (1992) to illustrate a &quot;semantically sticky&quot; group of words.</S><S sid = 101 ssid = >The word stray probably should be excluded also, since it most likely appears on this list as an adjective (as in &quot;stray bullet&quot;).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W95-0105.txt | Citing Article:  P97-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al, 1994), (Resnik, 1995)).</S> | Reference Offset:  ['7','13'] | Reference Text:  <S sid = 7 ssid = >(Bensch and Savitch, 1992; Brill, 1991; Brown et al., 1992; Grefenstette, 1994; McKeown and Hatzivassiloglou, 1993; Pereira et al., 1993; Schtitze, 1993)).</S><S sid = 13 ssid = >One obvious solution to this problem would be to extend distributional grouping methods to word senses.</S> | Discourse Facet:  NA | Annotator: Automatic


