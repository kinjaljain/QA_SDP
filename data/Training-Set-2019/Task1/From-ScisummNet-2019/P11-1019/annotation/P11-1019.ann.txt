Citance Number: 1 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A number of techniques have been investigated, including cosine similarity of feature vectors (Attali and Burstein, 2006), often combined with dimensionality reduction techniques such as Latent Semantic Analysis (LSA) (Landauer et al, 2003), and generative machine learning models (Rudner and Liang, 2002) as well as discriminative ones (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['15','164'] | Reference Text:  <S sid = 15 ssid = >Different techniques have been used, including cosine similarity of vectors representing text in various ways (Attali and Burstein, 2006), often combined with dimensionality reduction techniques such as Latent Semantic Analysis (LSA) (Landauer et al., 2003), generative machine learning models (Rudner and Liang, 2002), domain-specific feature extraction (Attali and Burstein, 2006), and/or modified syntactic parsers (Lonsdale and Strong-Krause, 2003).</S><S sid = 164 ssid = >Intelligent Essay Assessor (IEA) (Landauer et al., 2003) uses Latent Semantic Analysis (LSA) (Landauer and Foltz, 1998) to compute the semantic similarity between texts, at a specific grade point, and a test text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we explore the utility of our best model for assessing the incoherent 'outlier' texts used in Yannakoudakis et al. (2011).</S> | Reference Offset:  ['6','94'] | Reference Text:  <S sid = 6 ssid = >Finally, using a set of ‘outlier’ texts, we test the validity of our model and identify cases where the model’s scores diverge from that of a human examiner.</S><S sid = 94 ssid = >Finally, features whose overall frequency is lower than four are discarded from the model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Also, in Yannakoudakis et al (2011), experiments are presented that test the validity of the system using a number of automatically-created 'outlier' texts.</S> | Reference Offset:  ['6','190'] | Reference Text:  <S sid = 6 ssid = >Finally, using a set of ‘outlier’ texts, we test the validity of our model and identify cases where the model’s scores diverge from that of a human examiner.</S><S sid = 190 ssid = >Preliminary experiments based on a set of ‘outlier’ texts have shown the types of texts for which the system’s scoring capability can be undermined.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the First Certificate in English (FCE) ESOL examinationscripts2 (upper-intermediate level assessment) described in detail in Yannakoudakis et al (2011), extracted from the Cambridge Learner Corpus3 (CLC).</S> | Reference Offset:  ['34','35'] | Reference Text:  <S sid = 34 ssid = >The Cambridge Learner Corpus2 (CLC), developed as a collaborative project between Cambridge University Press and Cambridge Assessment, is a large collection of texts produced by English language learners from around the world, sitting Cambridge Assessment’s English as a Second or Other Language (ESOL) examinations3.</S><S sid = 35 ssid = >For the purpose of this work, we extracted scripts produced by learners taking the First Certificate in English (FCE) exam, which assesses English at an upper-intermediate level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in Yannakoudakis et al (2011), we analyze all texts using the RASP toolkit (Briscoe et al, 2006).</S> | Reference Offset:  ['67','152'] | Reference Text:  <S sid = 67 ssid = >We parsed the training and test data (see Section 2) using the Robust Accurate Statistical Parsing (RASP) system with the standard tokenisation and sentence boundary detection modules (Briscoe et al., 2006) in order to broaden the space of candidate features suitable for the task.</S><S sid = 152 ssid = >P´erez-Marin et al. (2009), Williamson (2009), Dikli (2006) and Valenti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Among the features used in Yannakoudakis et al (2011), none explicitly captures coherence and none models inter sentential relationships.</S> | Reference Offset:  ['2','193'] | Reference Text:  <S sid = 2 ssid = >In particular, we use rank preference learning to explicitly model the grade relationships between scripts.</S><S sid = 193 ssid = >It is clear from the ‘outlier’ experiments reported here that our system would benefit from features assessing discourse coherence, and to a lesser extent from features assessing semantic (selectional) coherence over longer bounds than those captured by ngrams.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the following experiments, we evaluate the best model identified on year 2000 on a set of 97 texts from the exam year 2001, previously used in Yannakoudakis et al (2011) to report results of the final best system.</S> | Reference Offset:  ['43','48'] | Reference Text:  <S sid = 43 ssid = >Our data consists of 1141 scripts from the year 2000 for training written by 1141 distinct learners, and 97 scripts from the year 2001 for testing written by 97 distinct learners.</S><S sid = 48 ssid = >There is no overlap between the prompts used in 2000 and in 2001.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >RASP’s rule names are semiautomatically generated and encode detailed information about the grammatical constructions found (e.g.</S><S sid = 197 ssid = >Finally, we would like to thank Marek Rei, Øistein Andersen and the anonymous reviewers for their useful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P11-1019.txt | Citing Article:  W12-2004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >See Yannakoudakis et al (2011) for details.</S> | Reference Offset:  ['128','152'] | Reference Text:  <S sid = 128 ssid = >However, Powers et al. (2002) invited writing experts to trick the scoring capabilities of an earlier version of e-Rater (Burstein et al., 1998). e-Rater (see Section 6 for more details) assigns a score to a text based on linguistic feature types extracted using relatively domain-specific techniques.</S><S sid = 152 ssid = >P´erez-Marin et al. (2009), Williamson (2009), Dikli (2006) and Valenti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P11-1019.txt | Citing Article:  P14-2098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Their correction detection algorithm relies on a set of heuristics developed from one single data collection (the FCE corpus (Yannakoudakis et al, 2011)).</S> | Reference Offset:  ['177','192'] | Reference Text:  <S sid = 177 ssid = >Recently, Chen et al. (2010) has proposed an unsupervised approach to AA of texts addressing the same topic, based on a voting algorithm.</S><S sid = 192 ssid = >Briscoe et al. (2010) describe an approach to automatic offprompt detection which does not require retraining for each new question prompt and which we plan to integrate with our system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P11-1019.txt | Citing Article:  P14-2098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We considered four corpora with different ESL populations and annotation standards, including FCE corpus (Yannakoudakis et al, 2011), NUCLE corpus (Dahlmeier et al, 2013), UIUCcor pus 2 (Rozovskaya and Roth, 2010) and HOO2011 corpus (Dale and Kilgarriff, 2011).</S> | Reference Offset:  ['86','152'] | Reference Text:  <S sid = 86 ssid = >In order to estimate the error-rate, we build a trigram language model (LM) using ukWaC (ukWaC LM) (Ferraresi et al., 2008), a large corpus of English containing more than 2 billion tokens.</S><S sid = 152 ssid = >P´erez-Marin et al. (2009), Williamson (2009), Dikli (2006) and Valenti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P11-1019.txt | Citing Article:  W12-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The CLC-FCE sub corpus was extracted, anonymized, and made available as a set of XML files by Yannakoudakis et al (2011).</S> | Reference Offset:  ['87','133'] | Reference Text:  <S sid = 87 ssid = >Next, we extend our language model with trigrams extracted from a subset of the texts contained in the CLC (CLC LM).</S><S sid = 133 ssid = >We extracted 6 high-scoring FCE scripts from the CLC that do not overlap with our training and test data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P11-1019.txt | Citing Article:  W12-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Errors have been shown to have a significant impact on predicting learner level (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['79','152'] | Reference Text:  <S sid = 79 ssid = >In developing our AA system, a number of different grammatical complexity measures were extracted from parses, and their impact on the accuracy of the system was explored.</S><S sid = 152 ssid = >P´erez-Marin et al. (2009), Williamson (2009), Dikli (2006) and Valenti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P11-1019.txt | Citing Article:  W12-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >By running ablation studies - i.e., removing one or more sets of features (cf. e.g. (Yannakoudakis et al., 2011)) - we can determine their relative importance and usefulness.</S> | Reference Offset:  ['3','108'] | Reference Text:  <S sid = 3 ssid = >A number of different features are extracted and ablation tests are used to investigate their contribution to overall performance.</S><S sid = 108 ssid = >An ablation test consists of removing one feature of the system at a time and re-evaluating the model on the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P11-1019.txt | Citing Article:  W12-2024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We extend our n-gram-based data-driven prediction approach from the Helping Our Own (HOO) 2011 Shared Task (Boyd and Meurers, 2011) to identify determiner and preposition errors in non-native English essays from the Cambridge Learner Corpus FCE Dataset (Yannakoudakis et al, 2011) as part of the HOO 2012 Shared Task.</S> | Reference Offset:  ['21','34'] | Reference Text:  <S sid = 21 ssid = >We make such a dataset of ESOL examination scripts available1 (see Section 2 for more details), describe our novel approach to the task, and provide results for our system on this dataset.</S><S sid = 34 ssid = >The Cambridge Learner Corpus2 (CLC), developed as a collaborative project between Cambridge University Press and Cambridge Assessment, is a large collection of texts produced by English language learners from around the world, sitting Cambridge Assessment’s English as a Second or Other Language (ESOL) examinations3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P11-1019.txt | Citing Article:  W12-2025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The documents are a subset of the 1,244 document sin the Cambridge Learner Corpus FCE (First Certificate in English) data set (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['34','35'] | Reference Text:  <S sid = 34 ssid = >The Cambridge Learner Corpus2 (CLC), developed as a collaborative project between Cambridge University Press and Cambridge Assessment, is a large collection of texts produced by English language learners from around the world, sitting Cambridge Assessment’s English as a Second or Other Language (ESOL) examinations3.</S><S sid = 35 ssid = >For the purpose of this work, we extracted scripts produced by learners taking the First Certificate in English (FCE) exam, which assesses English at an upper-intermediate level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P11-1019.txt | Citing Article:  N12-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A suitable corpus for developing this program is the Cambridge Learner Corpus (CLC) (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['34','195'] | Reference Text:  <S sid = 34 ssid = >The Cambridge Learner Corpus2 (CLC), developed as a collaborative project between Cambridge University Press and Cambridge Assessment, is a large collection of texts produced by English language learners from around the world, sitting Cambridge Assessment’s English as a Second or Other Language (ESOL) examinations3.</S><S sid = 195 ssid = >We would like to thank Cambridge ESOL, a division of Cambridge Assessment, for permission to use and distribute the examination scripts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P11-1019.txt | Citing Article:  W12-2031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The HOO development dataset consists of 1000 exam scripts drawn from a subset of the CLC FCE Dataset (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['21','87'] | Reference Text:  <S sid = 21 ssid = >We make such a dataset of ESOL examination scripts available1 (see Section 2 for more details), describe our novel approach to the task, and provide results for our system on this dataset.</S><S sid = 87 ssid = >Next, we extend our language model with trigrams extracted from a subset of the texts contained in the CLC (CLC LM).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P11-1019.txt | Citing Article:  W12-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the shared task, we made use of data drawn from the CLC FCE Dataset, a set of 1,244 exam scripts written by candidates sitting the Cambridge ESOL First Certificate in English (FCE) examination in 2000 and 2001, and made available by Cambridge Universiy Press; see (Yannakoudakis et al, 2011).</S> | Reference Offset:  ['34','195'] | Reference Text:  <S sid = 34 ssid = >The Cambridge Learner Corpus2 (CLC), developed as a collaborative project between Cambridge University Press and Cambridge Assessment, is a large collection of texts produced by English language learners from around the world, sitting Cambridge Assessment’s English as a Second or Other Language (ESOL) examinations3.</S><S sid = 195 ssid = >We would like to thank Cambridge ESOL, a division of Cambridge Assessment, for permission to use and distribute the examination scripts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P11-1019.txt | Citing Article:  W12-0206.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also apply our visualiser to a set of 1,244 publically available FCE ESOL texts (Yannakoudakis et al, 2011) and make it available as a web service to other researchers.</S> | Reference Offset:  ['5','19'] | Reference Text:  <S sid = 5 ssid = >Experimental results on the first publically available dataset show that our system can achieve levels of performance close to the upper bound for the task, as defined by the agreement between human examiners on the same corpus.</S><S sid = 19 ssid = >Although there are many published analyses of the performance of individual systems, as yet there is no publically available shared dataset for training and testing such systems and comparing their performance.</S> | Discourse Facet:  NA | Annotator: Automatic


