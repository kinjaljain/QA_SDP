Citance Number: 1 | Reference Article:  P09-1104.txt | Citing Article:  P14-1139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This directional model has been shown produce state-of-the art results with this setup (Haghighi et al, 2009).</S> | Reference Offset:  ['35','150'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 150 ssid = >No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In order to reduce spurious derivations, Wu (1997), Haghighi et al (2009), Liu et al (2010) propose different variations of the grammar.</S> | Reference Offset:  ['35','44'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 44 ssid = >Wu (1997)â€™s inversion transduction grammar (ITG) is a synchronous grammar formalism in which derivations of sentence pairs correspond to alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi et al (2009) give some restrictions on null-aligned word attachment.</S> | Reference Offset:  ['36','100'] | Reference Text:  <S sid = 36 ssid = >(2006), we assume the score a of a potential alignment a) decomposes as where sij are word-to-word potentials and siE and sEj represent English null and foreign null potentials, respectively.</S><S sid = 100 ssid = >Null productions are also a source of double counting, as there are many possible orders in which to attach null alignments to a bitext cell; we address this by adapting the grammar to force a null attachment order.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Four grammars were used to parse these alignments, namely LG (Wu, 1997), HaG (Haghighi et al, 2009), LiuG (Liu et al, 2010) and LGFN (Section 3.3).</S> | Reference Offset:  ['35','48'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 48 ssid = >The set of such ITG alignments, AITG, are a strict subset of A1-1 (Wu, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To further study how spurious ambiguity affects the discriminative learning, we implemented a frame work following Haghighi et al (2009).</S> | Reference Offset:  ['9','10'] | Reference Text:  <S sid = 9 ssid = >In this work, we investigate large-scale, discriminative ITG word alignment.</S><S sid = 10 ssid = >Past work on discriminative word alignment has focused on the family of at-most-one-to-one matchings (Melamed, 2000; Taskar et al., 2005; Moore et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  ['35','159'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 159 ssid = >For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  ['35','159'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 159 ssid = >For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  ['35','159'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 159 ssid = >For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in hand annotated parallel corpora (Haghighi et al, 2009).</S> | Reference Offset:  ['28','37'] | Reference Text:  <S sid = 28 ssid = >Indeed, blocks are the primary reason for gold alignments being outside the space of one-to-one ITG alignments.</S><S sid = 37 ssid = >We evaluate our proposed alignments (a) against hand-annotated alignments, which are marked with sure (s) and possible (p) alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al, 2009) and translation models (Chiang et al, 2008).</S> | Reference Offset:  ['35','79'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 79 ssid = >We instead use a variant of MIRA similar to Chiang et al. (2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al (2009).</S> | Reference Offset:  ['35','155'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 155 ssid = >For features on one-by-one cells, we consider Dice, the distance features from (Taskar et al., 2005), dictionary features, and features for the 50 most frequent lexical pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['59','190'] | Reference Text:  <S sid = 59 ssid = >We will use BITG to refer to this block ITG variant and ABITG to refer to the alignment family, which is neither contained in nor contains A1-1.</S><S sid = 190 ssid = >Our models yielded the lowest published error for Chinese-English alignment and an increase in downstream translation performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This supervised base line is a reimplementation of the MIRA-trained model of Haghighi et al (2009).</S> | Reference Offset:  ['35','186'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 186 ssid = >Our supervised ITG model gave a 1.1 BLEU increase over GIZA++.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1104.txt | Citing Article:  P11-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This training regimen on this data set has provided state-of-the-art unsupervised results that outperform IBM Model 4 (Haghighi et al., 2009).</S> | Reference Offset:  ['145','150'] | Reference Text:  <S sid = 145 ssid = >Table 1 illustrates results for the Hansards data set.</S><S sid = 150 ssid = >No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1104.txt | Citing Article:  N10-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The best published results for this dataset are supervised, and trained on 17 times more data (Haghighi et al, 2009).</S> | Reference Offset:  ['31','169'] | Reference Text:  <S sid = 31 ssid = >All in all, our discriminatively trained, block ITG models produce alignments which exhibit the best AER on the NIST 2002 Chinese-English alignment data set.</S><S sid = 169 ssid = >The right-hand three columns in Table 2 present supervised results on our Chinese English data set using block features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >When evaluated on parsing and word alignment, this model significantly improves over independently trained baselines: the monolingual parser of Petrov and Klein (2007) and the discriminative word aligner of Haghighi et al (2009).</S> | Reference Offset:  ['150','156'] | Reference Text:  <S sid = 150 ssid = >No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S><S sid = 156 ssid = >We also trained an HMM aligner as described in DeNero and Klein (2007) and used the posteriors of this model as features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although this assumption does limit the space of possible word-level alignments, for the domain we consider (Chinese-English word alignment), the reduced space still contains almost all empirically observed alignments (Haghighi et al, 2009).</S> | Reference Offset:  ['28','115'] | Reference Text:  <S sid = 28 ssid = >Indeed, blocks are the primary reason for gold alignments being outside the space of one-to-one ITG alignments.</S><S sid = 115 ssid = >Then, When a* is an ITG alignment (i.e., m* is 0), M(a*) consists only of alignments which have all the sure alignments in a*, but may have some subset of the possible alignments in a*.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We begin with the same set of alignment features as Haghighi et al (2009), which are defined only for terminal bi spans.</S> | Reference Offset:  ['35','155'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 155 ssid = >For features on one-by-one cells, we consider Dice, the distance features from (Taskar et al., 2005), dictionary features, and features for the 50 most frequent lexical pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because of this, given a particular word alignment w, we maximize the marginal probability of the set of derivations A (w) that are consistent with w (Haghighi et al., 2009).</S> | Reference Offset:  ['113','150'] | Reference Text:  <S sid = 113 ssid = >We opt instead to maximize the probability of the set of alignments M(a*) which achieve the same optimal in-class loss.</S><S sid = 150 ssid = >No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We prune our ITG forests using the same basic idea as Haghighi et al (2009), but we employ a technique that allows us to be more aggressive.</S> | Reference Offset:  ['35','126'] | Reference Text:  <S sid = 35 ssid = >Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = 126 ssid = >Our second pruning technique is to prune all one-by-one (word-to-word) bitext cells that have a posterior below 10âˆ’4 in both HMM models.</S> | Discourse Facet:  NA | Annotator: Automatic


