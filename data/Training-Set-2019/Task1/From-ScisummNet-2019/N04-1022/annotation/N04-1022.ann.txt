Citance Number: 1 | Reference Article:  N04-1022.txt | Citing Article:  P13-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Minimum Bayes Risk (MBR) techniques have been successfully applied to a wide range of natural language processing tasks, such as statistical machine translation (Kumar and Byrne, 2004), automatic speech recognition (Goel and Byrne, 2000), parsing (Titov and Henderson, 2006), etc.</S> | Reference Offset:  ['0','12'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 12 ssid = >We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N04-1022.txt | Citing Article:  W10-1756.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This solution is often referred to as the Minimum Bayes Risk (MBR) solution (Kumar and Byrne,2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N04-1022.txt | Citing Article:  D07-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This list is then rescored using Minimum Bayes-Risk (MBR) decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N04-1022.txt | Citing Article:  P09-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The corresponding minimum Bayes risk (MBR) procedure maximizes the expected similarity score of a system 's translations relative to the model 's distribution over possible translations (Kumar and Byrne, 2004).</S> | Reference Offset:  ['1','84'] | Reference Text:  <S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S><S sid = 84 ssid = >This is measured through Bayes-Risk : The expectation is taken under the true distribution that describes translations of human quality.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Consensus decoding procedures select translations for a single system with a minimum Bayes risk (MBR) (Kumar and Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In SMT, MBR decoding allows to minimize the loss of the output for a single translation system. MBR is generally implemented by re-ranking an N best list of translations produced by a first pass decoder (Kumar and Byrne, 2004).</S> | Reference Offset:  ['83','91'] | Reference Text:  <S sid = 83 ssid = >Our goal is to find the decoder that has the best performance over all translations.</S><S sid = 91 ssid = >We therefore use statistical translation models (Och, 2002) to approximate the distribution . tion 3) on the -best List is implemented as and .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N04-1022.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For each system, we report the performance of max-derivation decoding (MAX) and 1000-best3 MBR decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  ['4','23'] | Reference Text:  <S sid = 4 ssid = >We report the performance of the MBR decoders on a Chinese-to-English translation task.</S><S sid = 23 ssid = >We finally report the performance of MBR decoders optimized for each loss function.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N04-1022.txt | Citing Article:  W10-1710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we used Minimum Bayes Risk decoding (Kumar and Byrne, 2004) based on the BLEU score (Papineni et al, 2002).</S> | Reference Offset:  ['0','7'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 7 ssid = >This rapid progress has been greatly facilitated by the development of automatic translation evaluation metrics such as BLEU score (Papineni et al., 2001), NIST score (Doddington, 2002) and Position Independent Word Error Rate (PER) (Och, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N04-1022.txt | Citing Article:  W12-3136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We experimented with two decoding settings: (1) monotone at punctuation reordering (Tillmannand Ney, 2003), and (2) minimum Bayes risk decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N04-1022.txt | Citing Article:  W09-0426.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although during minimum error training we assume a decoder that uses the maximum derivation decision rule, we find benefits to translating using a minimum risk decision rule on a test set (Kumar and Byrne, 2004).</S> | Reference Offset:  ['11','85'] | Reference Text:  <S sid = 11 ssid = >In contrast, the maximum likelihood techniques that underlie the decision processes of most current MT systems do not take into account these application specific goals.</S><S sid = 85 ssid = >Given a loss function and a distribution, it is well known that the decision rule that minimizes the BayesRisk is given by (Bickel and Doksum, 1977; Goel and Byrne, 2000): We shall refer to the decoder given by this equation as the Minimum Bayes-Risk (MBR) decoder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N04-1022.txt | Citing Article:  W11-2160.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We decoded the test set to produce a 300-best list of unique translations, then chose the best candidate for each sentence using Minimum Bayes Risk reranking (Kumar and Byrne, 2004).</S> | Reference Offset:  ['83','100'] | Reference Text:  <S sid = 83 ssid = >Our goal is to find the decoder that has the best performance over all translations.</S><S sid = 100 ssid = >Each Chinese sentence in this set has four reference translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N04-1022.txt | Citing Article:  W10-1757.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Modifying the multitask objective to incorporate application-specific loss/decoding, such as Minimum Bayes Risk (Kumar and Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N04-1022.txt | Citing Article:  W11-2139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This reliably results in a small but consistent improvement in translation quality, but is much more time consuming to compute (Kumar and Byrne, 2004).</S> | Reference Offset:  ['106','138'] | Reference Text:  <S sid = 106 ssid = >For each sentence, we compute the error rate of the hypothesis translation with respect to the most similar reference translation under the corresponding loss function.</S><S sid = 138 ssid = >We present results under the Bitree loss function as an example of incorporating linguistic information into a loss function; we have not yet measured its correlation with human assessments of translation quality.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N04-1022.txt | Citing Article:  W09-0416.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the Confusion Network (CN) (Mangu et al, 2000).</S> | Reference Offset:  ['1','12'] | Reference Text:  <S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S><S sid = 12 ssid = >We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N04-1022.txt | Citing Article:  W10-1727.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N04-1022.txt | Citing Article:  P13-2071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Moses Baseline: We trained a Moses system (Koehn et al, 2007) with the following settings: maximum sentence length 80, grow-diag-final and symmetrization of GIZA++ alignments, an interpolated KneserNey smoothed 5-gram language model with KenLM (Heafield, 2011) used at runtime, msd-bidirectional-felexicalized reordering, sparse lexical and domain features (Hasler et al, 2012), distortion limit of 6, 100-best translation options, minimum bayes-risk decoding (Kumar and Byrne, 2004), cube-pruning (Huangand Chiang, 2007) and the no-reordering-over punctuation heuristic.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N04-1022.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our baseline translation system uses Viterbi decoding while our final system uses segment-level Minimum Bayes-Risk decoding (Kumar and Byrne, 2004) over 500-best lists using 1 BLEU as the loss function.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N04-1022.txt | Citing Article:  W12-3131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >With large training data, moving to a 5-gram language model, increasing the cube pruning pop limit to 1000, and using Minimum Bayes-Risk decoding (Kumar and Byrne, 2004) over 500-best lists collectively show a slight improvement.</S> | Reference Offset:  ['0','108'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 108 ssid = >The 1000-best lists were then rescored using the different translation loss functions described in Section 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N04-1022.txt | Citing Article:  C10-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kumar and Byrne (2004) first introduced MBR decoding to SMT field and developed it on the N-best list translations.</S> | Reference Offset:  ['12','89'] | Reference Text:  <S sid = 12 ssid = >We apply the Minimum Bayes-Risk (MBR) techniques developed for automatic speech recognition (Goel and Byrne, 2000) and bitext word alignment for statistical MT (Kumar and Byrne, 2002), to the problem of building automatic MT systems tuned for specific metrics.</S><S sid = 89 ssid = >In practice, we will consider the space of translations to be an -best list of translation alternatives generated under a baseline translation model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N04-1022.txt | Citing Article:  W09-0424.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Minimum Bayes Risk Rescoring: In this system, we re-ranked the n-best output of our baseline system using Minimum Bayes Risk (Kumarand Byrne, 2004).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Minimum Bayes-Risk Decoding For Statistical Machine Translation</S><S sid = 1 ssid = >We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


