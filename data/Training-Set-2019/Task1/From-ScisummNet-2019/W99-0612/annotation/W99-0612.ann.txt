Citance Number: 1 | Reference Article:  W99-0612.txt | Citing Article:  W02-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some have assumed only partially tagged training corpora (Merialdo, 1994), while others have begin with small tagged seed word lists (such as Collins and Singer (1999) and Cucerzan and Yarowsky (1999) for named-entity tagging).</S> | Reference Offset:  ['7','13'] | Reference Text:  <S sid = 7 ssid = >Indeed, most named entity recognizers that have been published either use tagged text, perform syntactical and morphological analysis or use semantic information for contextual clues.</S><S sid = 13 ssid = >For each entity class to be recognized and tagged, it is assumed that the user can provide a short list (order of one hundred) of unambiguous examples (seeds).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W99-0612.txt | Citing Article:  W12-1908.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The bootstrapping methods for language independent NER of Cucerzan and Yarowsky (1999) have a similar effect.</S> | Reference Offset:  ['39','133'] | Reference Text:  <S sid = 39 ssid = >Some other advantages and disadvantages of the two methods will be discussed below.</S><S sid = 133 ssid = >It would be inappropriate to compare the results of a language independent system with the ones designed for only one language.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W99-0612.txt | Citing Article:  E09-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cucerzan and Yarowsky (1999) exploit morphological and contextual patterns to propose a language-independent solution to NER.</S> | Reference Offset:  ['0','22'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 22 ssid = >Contextual patterns (e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W99-0612.txt | Citing Article:  P02-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cucerzan and Yarowsky (1999) built a cross language NER, and the performance on English was low compared to supervised single-language NER such as Identi Finder.</S> | Reference Offset:  ['133','173'] | Reference Text:  <S sid = 133 ssid = >It would be inappropriate to compare the results of a language independent system with the ones designed for only one language.</S><S sid = 173 ssid = >Cross-language analysis yields further insight.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W99-0612.txt | Citing Article:  I08-5005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It has been previously attempted by Cucerzan and Yarowsky in their language independent NER work which used morphological and contextual evidences (Cucerzan and Yarowsky, 1999).</S> | Reference Offset:  ['0','40'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 40 ssid = >Before describing the algorithm, we will present a brief overview of some of its goals: Three important concepts are used in our model: 2.1 Trie structures are used for both morphological and contextual information Tries provide an effective, efficient and flexible data structure for storing both contextual and morphological patterns and statistics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W99-0612.txt | Citing Article:  W04-3234.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We can also exploit what Cucerzan and Yarowsky (1999) call the one sense per discourse phenomenon, the tendency of terms to have a fixed meaning within a single document.</S> | Reference Offset:  ['26','27'] | Reference Text:  <S sid = 26 ssid = >Moreover, he claims that the number of instances of the new entity is not associated with the document length but with the importance of the entity with regard to the subject/discourse.</S><S sid = 27 ssid = >We will use this property in conjunction with the one sense per discourse tendency noted by Gale, Church and Yarowsky (1992b), who showed that words strongly tend to exhibit only one sense in a document/discourse.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W99-0612.txt | Citing Article:  W04-3234.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['62','200'] | Reference Text:  <S sid = 62 ssid = >Beginning with some seed names for each class, the algorithm learns contextual patterns that are indicative for those classes and then iteratively learns new class members and word-internal morphological clues.</S><S sid = 200 ssid = >The authors would like to thank Eric Brill, Radu Florian, Shanka,r Kumar, Murat Saraclar, Dimitra Vergyri and Jun Wu for both their feedback on this work and their help in annotating the named-entity data for the languages studied.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W99-0612.txt | Citing Article:  N06-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora.</S> | Reference Offset:  ['10','16'] | Reference Text:  <S sid = 10 ssid = >The applicability of AI-style algorithms and supervised methods is limited in the multilingual case because of the cost of knowledge databases and manually annotated corpora.</S><S sid = 16 ssid = >Although such information can be utilised if present, it is not required, and no other assumptions are made in the general model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W99-0612.txt | Citing Article:  I08-5004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The NER task for Hindi has been explored by Cucerzan and Yarowsky in their language independent NER work which used morphological and contextual evidences (Cucerzan and Yarowsky, 1999).</S> | Reference Offset:  ['0','40'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 40 ssid = >Before describing the algorithm, we will present a brief overview of some of its goals: Three important concepts are used in our model: 2.1 Trie structures are used for both morphological and contextual information Tries provide an effective, efficient and flexible data structure for storing both contextual and morphological patterns and statistics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W99-0612.txt | Citing Article:  W03-0432.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tries have previously been used in both supervised (Patrick et al, 2002) and unsupervised (Cucerzan and Yarowsky, 1999) named entity recognition.</S> | Reference Offset:  ['0','195'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 195 ssid = >This paper has presented an algorithm for the minimally supervised learning of named entity recognizers given short name lists as seed data (typically 40100 example words per entity class).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W99-0612.txt | Citing Article:  W03-0428.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Earlier papers have taken a character-level approach to named entity recognition (NER), notably Cucerzan and Yarowsky (1999), which used prefix and suffix tries, though to our knowledge incorporating all character grams is new.</S> | Reference Offset:  ['0','168'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 168 ssid = >The reason for this is that the morphology models are full hierarchically smoothed character tries rather than word token tries, and hence have much denser initial statistics for small training data sets, proving greater partial matching potential for previously unseen words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W99-0612.txt | Citing Article:  P06-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both (Cucerzan and Yarowsky, 1999) and (Collins and Singer, 1999) present algorithms to obtain NEs from untagged corpora.</S> | Reference Offset:  ['10','16'] | Reference Text:  <S sid = 10 ssid = >The applicability of AI-style algorithms and supervised methods is limited in the multilingual case because of the cost of knowledge databases and manually annotated corpora.</S><S sid = 16 ssid = >Although such information can be utilised if present, it is not required, and no other assumptions are made in the general model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W99-0612.txt | Citing Article:  W09-1116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Collins and Singer (1999) and Cucerzan and Yarowsky (1999) apply bootstrapping to the related task of named-entity recognition.</S> | Reference Offset:  ['0','5'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 5 ssid = >For the 1995 Message Understanding Conference (MUC-6), a separate named entity recognition task was developed and the best systems achieved impressive accuracy (with an F-measure approaching 95%).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W99-0612.txt | Citing Article:  I08-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The NER task for Hindi has been explored by Cucerzan and Yarowsky in their language independent NER work which used morphological and contextual evidences (Cucerzan and Yarowsky, 1999).</S> | Reference Offset:  ['0','40'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 40 ssid = >Before describing the algorithm, we will present a brief overview of some of its goals: Three important concepts are used in our model: 2.1 Trie structures are used for both morphological and contextual information Tries provide an effective, efficient and flexible data structure for storing both contextual and morphological patterns and statistics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W99-0612.txt | Citing Article:  I08-5010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous work (Cucerzan and Yarowsky, 1999) was done using the complete words as features which suffers from a low recall problem.</S> | Reference Offset:  ['129','175'] | Reference Text:  <S sid = 129 ssid = >The basic measures for evaluation of this work are precision and recall.</S><S sid = 175 ssid = >A language such as German would be roughly in the middle, where lower-case words have low probability as named entities, but capitalized words are highly ambiguous between common and proper nouns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W99-0612.txt | Citing Article:  I08-5010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Prefix and suffix tries were also used previously (Cucerzan and Yarowsky, 1999).</S> | Reference Offset:  ['119','161'] | Reference Text:  <S sid = 119 ssid = >Here the bipartite structure of the two pairs of tries has a central role: during stage 2, the left context and prefix tries interact with each other and so do the right context and suffix tries, but there's no interference between the two pairs during the bootstrapping stage.</S><S sid = 161 ssid = >The context-only case restricts system training to the two (left and right) contextual tries, ignoring the prefix/suffix morphological information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W99-0612.txt | Citing Article:  W02-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The core model utilized, extended and evaluated here is based on Cucerzan and Yarowsky (1999).</S> | Reference Offset:  ['93','103'] | Reference Text:  <S sid = 93 ssid = >This stage is the core bootstrapping phase of the algorithm.</S><S sid = 103 ssid = >The core of stage 2 is the bootstrapping procedure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W99-0612.txt | Citing Article:  W02-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because the core model has been presented in detail in Cucerzan and Yarowsky (1999), this paper focuses primarily on the modifications of the algorithm and its adaptation to the current task.</S> | Reference Offset:  ['93','195'] | Reference Text:  <S sid = 93 ssid = >This stage is the core bootstrapping phase of the algorithm.</S><S sid = 195 ssid = >This paper has presented an algorithm for the minimally supervised learning of named entity recognizers given short name lists as seed data (typically 40100 example words per entity class).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W99-0612.txt | Citing Article:  W02-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The bootstrapping stage (5) uses the initial or current entity assignments to estimate the class conditional distributions for both entities and contexts along their trie paths, and then re-estimates the distributions of the contexts/entity-candidates to which they are linked, recursively, until all accessible nodes are reached, as presented in Cucerzan and Yarowsky (1999).</S> | Reference Offset:  ['52','72'] | Reference Text:  <S sid = 52 ssid = >Similarly, nodes of the context tries contain links to the tokens that occurred in the particular contexts defined by the paths.</S><S sid = 72 ssid = >Stage 0: build the initial training list of class representatives Stage 1: read the text and build the left and right morphological and context tries Stage 2: introduce the training information in the tries and re-estimate the distributions by bootstrapping Stage 3: identify and classify the named entities in the text using competing classifiers Stage 4: update the entity and context training space, using the new extracted information Stage 0: This stage is performed once for each language/task and consists of defining the classes and filling in the initial class seed data with examples provided by the user.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W99-0612.txt | Citing Article:  W02-2007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This paper has presented and evaluated an extended bootstrapping model based on Cucerzan and Yarowsky (1999) that uses a unified framework of both entity internal and contextual evidence.</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >Language Independent Named Entity Recognition Combining Morphological And Contextual Evidence</S><S sid = 17 ssid = >The algorithm relies on both word internal and contextual clues as relatively independent evidence sources that drive the bootstrapping algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


