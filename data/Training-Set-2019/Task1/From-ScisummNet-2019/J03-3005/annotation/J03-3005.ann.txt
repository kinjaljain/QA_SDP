Citance Number: 1 | Reference Article:  J03-3005.txt | Citing Article:  W04-3214.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following the methodology in Keller and Lapata (2003), we divide the verbs into four frequency bands, frequency being absolute number of annotated sentences: low (5), medium-low (12), medium-high (22), and high (38).</S> | Reference Offset:  ['67','389'] | Reference Text:  <S sid = 67 ssid = >Again, proper nouns and low-frequency nouns were discarded from this list.</S><S sid = 389 ssid = >Here, the conditional probability model reached a performance of 83.9% correct on the low-frequency data set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J03-3005.txt | Citing Article:  P07-3014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Keller and Lapata (2003) showed that web frequencies correlate reliably with standard corpus frequencies.</S> | Reference Offset:  ['418','420'] | Reference Text:  <S sid = 418 ssid = >For the seen bigrams, we showed that the Web frequencies correlate better with judged plausibility than corpus frequencies.</S><S sid = 420 ssid = >We found that Web frequencies and re-created frequencies are reliably correlated, and that Web frequencies are better at predicting plausibility judgments than smoothed frequencies.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J03-3005.txt | Citing Article:  P07-3014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the log of the web counts returned, as recommended in previous work (Keller and Lapata, 2003).</S> | Reference Offset:  ['209','215'] | Reference Text:  <S sid = 209 ssid = >Previous work has demonstrated that corpus counts correlate with human plausibility judgments for adjective-noun bigrams.</S><S sid = 215 ssid = >For seen and unseen adjective-noun bigrams, we used the two sets of plausibility judgments collected by Lapata, McDonald, and Keller (1999) and Lapata, Keller, and McDonald (2001), respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J03-3005.txt | Citing Article:  P05-2023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Web has already been used successfully for a series of NLP tasks such as Mt (Grefenstette, 1999), word sense disambiguation (Agirre and Martinez, 2000), synonym recognition (Turney, 2001), anaphora resolution (Modjeska et al, 2003) and determining frequencies for unseen bi-grams (Keller and Lapata, 2003).</S> | Reference Offset:  ['13','435'] | Reference Text:  <S sid = 13 ssid = >Mihalcea and Moldovan (1999) and Agirre and Martinez (2000) use the Web for word sense disambiguation, Volk (2001) proposes a method for resolving PP attachment ambiguities based on Web data, Markert, Nissim, and Modjeska (2003) use the Web for the resolution of nominal anaphora, and Zhu and Rosenfeld (2001) use Web-based n-gram counts to improve language modeling.</S><S sid = 435 ssid = >Preliminary results are reported by Lapata and Keller (2003), who use Web counts successfully for a range of NLP tasks, including candidate selection for machine translation, context-sensitive spelling correction, bracketing and interpretation of compounds, adjective ordering, and PP attachment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J03-3005.txt | Citing Article:  N12-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thus, the frequency of appearance of n-grams on the Web (via the Google search engine) appears as a good indicator of the n-gram popularity/soundness (Keller and Lapata, 2003).</S> | Reference Offset:  ['174','199'] | Reference Text:  <S sid = 174 ssid = >Keller and Lapata Web Frequencies for Unseen Bigrams Another source of noise is the fact that Google (but not AltaVista) will sometimes return pages that do not include the search term at all.</S><S sid = 199 ssid = >The difference in correlation coefficients was not significant for noun-noun and verb-object bigrams, for either search engine.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J03-3005.txt | Citing Article:  W05-0603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recently, Keller and Lapata (2003) evaluate the utility of using Web search engines for obtaining frequencies for unseen bigrams.</S> | Reference Offset:  ['0','302'] | Reference Text:  <S sid = 0 ssid = >Using The Web To Obtain Frequencies For Unseen Bigrams</S><S sid = 302 ssid = >For both seen and unseen bigrams, there was only a very small difference between the correlation coefficients obtained with the two search engines.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J03-3005.txt | Citing Article:  W05-0603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >See Keller and Lapata (2003) for more issues.</S> | Reference Offset:  ['210','215'] | Reference Text:  <S sid = 210 ssid = >This result holds both for seen bigrams (Lapata, McDonald, and Keller 1999) and for unseen bigrams whose counts have been re-created using smoothing techniques (Lapata, Keller, and McDonald 2001).</S><S sid = 215 ssid = >For seen and unseen adjective-noun bigrams, we used the two sets of plausibility judgments collected by Lapata, McDonald, and Keller (1999) and Lapata, Keller, and McDonald (2001), respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J03-3005.txt | Citing Article:  W05-1207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The findings described in (Keller and Lapata, 2003) seem to suggest that count estimations we need in the present study over Subject-Verb bigrams are highly correlated to corpus counts.</S> | Reference Offset:  ['412','414'] | Reference Text:  <S sid = 412 ssid = >We found that the counts obtained from the Web are highly correlated with the counts obtained from the BNC.</S><S sid = 414 ssid = >Again, we found that Web counts are highly correlated with corpus counts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J03-3005.txt | Citing Article:  P06-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The performance is similar to other published results like those by Keller and Lapata (2003), who adopted a similar feature set and reported around 75% success rates on the ACE data set.</S> | Reference Offset:  ['262','381'] | Reference Text:  <S sid = 262 ssid = >A similar picture was observed for the NANTC counts.</S><S sid = 381 ssid = >The performance on the whole data set is 77.7%, which is below the performance of 80.0% reported by Rooth et al. (1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J03-3005.txt | Citing Article:  W10-3504.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It has been shown that web documents (as Wikipedia) are reliable samples of language (Keller and Lapata, 2003).</S> | Reference Offset:  ['44','192'] | Reference Text:  <S sid = 44 ssid = >Other samples of spoken language are also included, ranging from business or government meetings to radio shows and phoneins.</S><S sid = 192 ssid = >The results are shown in Table 9.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J03-3005.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also use Keller and Lapata (2003)'s approach to obtaining web-counts.</S> | Reference Offset:  ['13','210'] | Reference Text:  <S sid = 13 ssid = >Mihalcea and Moldovan (1999) and Agirre and Martinez (2000) use the Web for word sense disambiguation, Volk (2001) proposes a method for resolving PP attachment ambiguities based on Web data, Markert, Nissim, and Modjeska (2003) use the Web for the resolution of nominal anaphora, and Zhu and Rosenfeld (2001) use Web-based n-gram counts to improve language modeling.</S><S sid = 210 ssid = >This result holds both for seen bigrams (Lapata, McDonald, and Keller 1999) and for unseen bigrams whose counts have been re-created using smoothing techniques (Lapata, Keller, and McDonald 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J03-3005.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Also, the Keller and Lapata (2003) approach will be undefined if the pair is unobserved on the web.</S> | Reference Offset:  ['210','348'] | Reference Text:  <S sid = 210 ssid = >This result holds both for seen bigrams (Lapata, McDonald, and Keller 1999) and for unseen bigrams whose counts have been re-created using smoothing techniques (Lapata, Keller, and McDonald 2001).</S><S sid = 348 ssid = >For each pair (v, n) a fairly frequent verb v' was randomly chosen such that the pair (v', n) did not occur in the data set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J03-3005.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['151','441'] | Reference Text:  <S sid = 151 ssid = >From these data, we computed the average factor by which the Web counts are larger than the BNC counts.</S><S sid = 441 ssid = >Special thanks are due to Stephen Clark and Detlef Prescher for making their pseudodisambiguation data sets available.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J03-3005.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recall that even the Keller and Lapata (2003) system, built on the world's largest corpus, achieves only 34% recall (Table 1) (with only 48% of positives and 27% of all pairs previously observed, but see Footnote 5).</S> | Reference Offset:  ['147','262'] | Reference Text:  <S sid = 147 ssid = >Recall that the NANTC is 3.5 times larger than the BNC, which does not seem to be enough to substantially mitigate data sparseness.</S><S sid = 262 ssid = >A similar picture was observed for the NANTC counts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J03-3005.txt | Citing Article:  W06-1704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['151','441'] | Reference Text:  <S sid = 151 ssid = >From these data, we computed the average factor by which the Web counts are larger than the BNC counts.</S><S sid = 441 ssid = >Special thanks are due to Stephen Clark and Detlef Prescher for making their pseudodisambiguation data sets available.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J03-3005.txt | Citing Article:  C08-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The web as a corpus has been successfully used for many areas in NLP (Kilgarriff and Grefenstette 2003) such as WSD (Mihalcea and Moldovan 1999), obtaining frequencies for bigrams (Keller and Lapata 2003) and noun compound bracketing (Nakov and Hearst 2005).</S> | Reference Offset:  ['215','435'] | Reference Text:  <S sid = 215 ssid = >For seen and unseen adjective-noun bigrams, we used the two sets of plausibility judgments collected by Lapata, McDonald, and Keller (1999) and Lapata, Keller, and McDonald (2001), respectively.</S><S sid = 435 ssid = >Preliminary results are reported by Lapata and Keller (2003), who use Web counts successfully for a range of NLP tasks, including candidate selection for machine translation, context-sensitive spelling correction, bracketing and interpretation of compounds, adjective ordering, and PP attachment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J03-3005.txt | Citing Article:  P05-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is believed that the size of the web is thousands of times larger than normal large corpora, and the counts obtained from the web are highly correlated with the counts from large balanced corpora for predicate-argument bi-grams (Keller and Lapata, 2003).</S> | Reference Offset:  ['205','412'] | Reference Text:  <S sid = 205 ssid = >We found that Web counts were highly correlated with frequencies from two different corpora.</S><S sid = 412 ssid = >We found that the counts obtained from the Web are highly correlated with the counts obtained from the BNC.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J03-3005.txt | Citing Article:  P05-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, previous study (Keller and Lapata, 2003) reveals that the large amount of data available for the web counts could outweigh the noisy problems.</S> | Reference Offset:  ['204','428'] | Reference Text:  <S sid = 204 ssid = >We conclude that simple heuristics (see Section 2.3) are sufficient to obtain useful frequencies from the Web; it seems that the large amount of data available for Web counts outweighs the associated problems (noisy, unbalanced, etc.).</S><S sid = 428 ssid = >It seems that the large amount of data available outweighs the problems associated with using the Web as a corpus (such as the fact that it is noisy and unbalanced).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J03-3005.txt | Citing Article:  W06-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['151','441'] | Reference Text:  <S sid = 151 ssid = >From these data, we computed the average factor by which the Web counts are larger than the BNC counts.</S><S sid = 441 ssid = >Special thanks are due to Stephen Clark and Detlef Prescher for making their pseudodisambiguation data sets available.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J03-3005.txt | Citing Article:  D07-1086.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >NC analysis has benefited from the recent trend of using web-derived features rather than corpus based counts (Keller and Lapata, 2003).</S> | Reference Offset:  ['210','252'] | Reference Text:  <S sid = 210 ssid = >This result holds both for seen bigrams (Lapata, McDonald, and Keller 1999) and for unseen bigrams whose counts have been re-created using smoothing techniques (Lapata, Keller, and McDonald 2001).</S><S sid = 252 ssid = >We used correlation analysis to compare corpus counts and Web counts with plausibility judgments.</S> | Discourse Facet:  NA | Annotator: Automatic


