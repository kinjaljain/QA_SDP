Citance Number: 1 | Reference Article:  C02-1144.txt | Citing Article:  C04-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Different measures have been proposed, which are not easy to evaluate (see (Lin and Pantel, 2002) for proposals).</S> | Reference Offset:  ['15','105'] | Reference Text:  <S sid = 15 ssid = >One way to deal with these problems is to use a clustering algorithm to automatically induce semantic classes (Lin and Pantel 2001).</S><S sid = 105 ssid = >Many cluster evaluation schemes have been proposed.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C02-1144.txt | Citing Article:  P06-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >NLP researchers have developed many algorithms for mining knowledge from text and the Web, including facts (Etzioni et al 2005), semantic lexicons (Riloff and Shepherd 1997), concept lists (Lin and Pantel 2002), and word similarity lists (Hindle 1990).</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >Concept Discovery From Text</S><S sid = 15 ssid = >One way to deal with these problems is to use a clustering algorithm to automatically induce semantic classes (Lin and Pantel 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C02-1144.txt | Citing Article:  E09-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The labeled classes are acquired in three stages: 1) extraction of a noisy pool of pairs of a class label and a potential class instance, by applying a few Is-A extraction patterns, selected from (Hearst, 1992), to Web documents: (fruits, apple), (fruits, corn), (fruits, mango), (fruits, orange), (foods, broccoli), (crops, lettuce), (flowers, rose); 2) extraction of unlabeled clusters of distributionally similar phrases, by clustering vectors of contextual features collected around the occurrences of the phrases within Web documents (Lin and Pantel, 2002).</S> | Reference Offset:  ['126','131'] | Reference Text:  <S sid = 126 ssid = >We start with a list of m empty sets, each of which is labeled with a class in the answer key.</S><S sid = 131 ssid = >If an element is in a set whose class is not.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C02-1144.txt | Citing Article:  C08-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >Phase II: Find committees.</S><S sid = 213 ssid = >This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C02-1144.txt | Citing Article:  C08-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For CBC we simply used the same parameter values as reported in (Lin and Pantel, 2002).</S> | Reference Offset:  ['71','148'] | Reference Text:  <S sid = 71 ssid = >If the condition is violated, the committee is simply discarded.</S><S sid = 148 ssid = >We collected the frequency counts of the grammatical relationships (contexts) output by Minipar and used them to compute the pointwise mutual information values from Section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C02-1144.txt | Citing Article:  P06-2071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Schutze, 1998) and (Lin and Pantel, 2002a, b) show that clustering methods are helpful in this area.</S> | Reference Offset:  ['15','53'] | Reference Text:  <S sid = 15 ssid = >One way to deal with these problems is to use a clustering algorithm to automatically induce semantic classes (Lin and Pantel 2001).</S><S sid = 53 ssid = >Following (Lin 1998), we represent each word by a feature vector.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C02-1144.txt | Citing Article:  D10-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Options for identifying interesting classes include manually created methods (WordNet (Miller et al, 1990)), textual patterns (Hearst, 1992), automated clustering (Lin and Pantel, 2002), and combinations (Snow et al, 2006).</S> | Reference Offset:  ['139','181'] | Reference Text:  <S sid = 139 ssid = >We generated clusters from a news corpus using CBC and compared them with classes extracted from WordNet (Miller 1990).</S><S sid = 181 ssid = >For each cluster c, we also include wn(c).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C02-1144.txt | Citing Article:  W08-1910.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Mutual information (MI) is an information theoric measure and has been used in many NLP tasks, including clustering words (e.g. Lin and Pantel, 2002).</S> | Reference Offset:  ['62','78'] | Reference Text:  <S sid = 62 ssid = >A well known problem with mutual information is that it is biased towards infrequent words/features.</S><S sid = 78 ssid = >To compute the top similar words of a word w, we first sort w?s features according to their mutual information with w. We only compute pairwise similarities between w and the words that share a high mutual information feature with w. 4.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C02-1144.txt | Citing Article:  W10-2302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >Phase II: Find committees.</S><S sid = 213 ssid = >This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C02-1144.txt | Citing Article:  W10-2302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['79','213'] | Reference Text:  <S sid = 79 ssid = >Phase II: Find committees.</S><S sid = 213 ssid = >This research was partly supported by Natural Sciences and Engineering Research Council of Canada grant OGP121338 and scholarship PGSB207797.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C02-1144.txt | Citing Article:  P06-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To date, researchers have harvested, with varying success, several resources, including concept lists (Lin and Pantel 2002), topic signatures (Lin and Hovy 2000), facts (Etzioni et al 2005), and word similarity lists (Hindle 1990).</S> | Reference Offset:  ['0','53'] | Reference Text:  <S sid = 0 ssid = >Concept Discovery From Text</S><S sid = 53 ssid = >Following (Lin 1998), we represent each word by a feature vector.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C02-1144.txt | Citing Article:  P11-1162.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To extract this information, (Lin and Pantel, 2002) showed the effect of using different sizes and genres of corpora such as news and Web documents.</S> | Reference Offset:  ['139','153'] | Reference Text:  <S sid = 139 ssid = >We generated clusters from a news corpus using CBC and compared them with classes extracted from WordNet (Miller 1990).</S><S sid = 153 ssid = >The sizes of the WordNet classes vary a lot.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C02-1144.txt | Citing Article:  C08-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Clustering by committee has also been used to discover concepts from a text by grouping terms into conceptually related clusters (Lin and Pantel, 2002).</S> | Reference Offset:  ['3','204'] | Reference Text:  <S sid = 3 ssid = >We present a clustering algorithm called CBC (Cluster ing By Committee) that automatically discovers concepts from text.</S><S sid = 204 ssid = >We presented a clustering algorithm, CBC, for automatically discovering concepts from text.</S> | Discourse Facet:  NA | Annotator: Automatic


