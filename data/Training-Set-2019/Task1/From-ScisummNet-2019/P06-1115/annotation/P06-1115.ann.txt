Citance Number: 1 | Reference Article:  P06-1115.txt | Citing Article:  D08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >KRISP (Kate and Mooney, 2006) is a semantic parser learning system which uses word subsequence kernel based SVM (Cristianini and Shawe-Taylor, 2000) classifiers and was shown to be robust to noise compared to other semantic parser learners.</S> | Reference Offset:  ['9','151'] | Reference Text:  <S sid = 9 ssid = >Kernel methods (Cristianini and Shawe-Taylor, 2000) are particularly suitable for semantic parsing because it involves mappingphrases of natural language (NL) sentences to semantic concepts in a meaning representation lan guage (MRL).</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1115.txt | Citing Article:  D08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For details please refer to (Kate and Mooney, 2006).</S> | Reference Offset:  ['7','151'] | Reference Text:  <S sid = 7 ssid = >Previous work on learning semantic parsers either employ rule-based algorithms (Tang andMooney, 2001; Kate et al, 2005), or use sta tistical feature-based methods (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006).</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1115.txt | Citing Article:  D08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Word subsequence kernel was employed in (Kate and Mooney, 2006) to compute the similarity between two substrings.</S> | Reference Offset:  ['94','180'] | Reference Text:  <S sid = 94 ssid = >The more the two strings share, the greater the similarity score will be.</S><S sid = 180 ssid = >ulate this type of noise by substituting a word in the corpus by another word, w, with probability ped(w)?P (w), where p is a parameter, ed(w) isw?s edit distance (Levenshtein, 1966) from the original word and P (w) is w?s probability proportional toits word frequency.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1115.txt | Citing Article:  W10-2924.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We note that this use of multiple classifiers to determine the most probable parse is similar to the method used in the KRISP semantic parser (Kate and Mooney, 2006).</S> | Reference Offset:  ['63','188'] | Reference Text:  <S sid = 63 ssid = >2.2 Most Probable Semantic Derivation.</S><S sid = 188 ssid = >The results are also similar on the GEOQUERY corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1115.txt | Citing Article:  W08-2105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We describe how these are applied in an error driven manner using the base semantic parsing learning algorithm presented in (Kate and Mooney, 2006) resulting in a better learned semantic parser.</S> | Reference Offset:  ['0','38'] | Reference Text:  <S sid = 0 ssid = >Using String-Kernels For Learning Semantic Parsers</S><S sid = 38 ssid = >KRISP does semantic parsing using the notion of a semantic derivation of an NL sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1115.txt | Citing Article:  W08-2105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We very briefly describe the semantic parser learning system, KRISP (Kate and Mooney, 2006), which we will use as a base system for transforming MRGs, we however note that the MRG transformation methods presented in this paper are general enough to work with any system which learns semantic parser using MRGs.</S> | Reference Offset:  ['7','151'] | Reference Text:  <S sid = 7 ssid = >Previous work on learning semantic parsers either employ rule-based algorithms (Tang andMooney, 2001; Kate et al, 2005), or use sta tistical feature-based methods (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006).</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1115.txt | Citing Article:  D08-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >KRISP (Kate and Mooney, 2006) is a discriminative approach where meaning representation structures are constructed from the natural language strings hierarchically.</S> | Reference Offset:  ['1','93'] | Reference Text:  <S sid = 1 ssid = >We present a new approach for mappingnatural language sentences to their formal meaning representations using string kernel-based classifiers.</S><S sid = 93 ssid = >One difference, however, is that their strings are over characters while our strings are over words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1115.txt | Citing Article:  P12-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >KRISP (Kate and Mooney, 2006) uses string classifiers to label substrings of the NL with entities from the MR.</S> | Reference Offset:  ['65','151'] | Reference Text:  <S sid = 65 ssid = >In the next subsection we will de scribe how KRISP obtains these probabilities using string-kernel based SVM classifiers.</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1115.txt | Citing Article:  P12-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The remaining refined landmarks plans are then treated as supervised training data for a semantic-parser learner, KRISP (Kate and Mooney, 2006).</S> | Reference Offset:  ['13','151'] | Reference Text:  <S sid = 13 ssid = >The productions of the formal MRL grammar are treated like semantic concepts.</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1115.txt | Citing Article:  P12-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To train a semantic parser using KRISP (Kate and Mooney, 2006), they had to supply a MRG, a context-free grammar, for their formal navigation plan language.</S> | Reference Offset:  ['13','151'] | Reference Text:  <S sid = 13 ssid = >The productions of the formal MRL grammar are treated like semantic concepts.</S><S sid = 151 ssid = >We compared our system?s performance with the following existing systems: the string and tree versions of SILT (Kate et al, 2005), a system that learns transformation rules relating NL phrases to MRL expressions; WASP (Wong and Mooney, 2006), a system that learns transformation rules using statistical machine translation techniques; SCISSOR (Ge and Mooney, 2005), a system that learns an integrated syntactic-semantic parser; and CHILL (Tang and Mooney, 2001) an ILP-based semantic parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1115.txt | Citing Article:  N07-2021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We modify KRISP, a supervised learning system for semantic parsing presented in (Kate and Mooney, 2006), to make a semi-supervised system we call SEMISUP-KRISP.</S> | Reference Offset:  ['7','38'] | Reference Text:  <S sid = 7 ssid = >Previous work on learning semantic parsers either employ rule-based algorithms (Tang andMooney, 2001; Kate et al, 2005), or use sta tistical feature-based methods (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006).</S><S sid = 38 ssid = >KRISP does semantic parsing using the notion of a semantic derivation of an NL sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1115.txt | Citing Article:  N07-2021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >KRISP (Kernel-based Robust Interpretation for Semantic Parsing) (Kate and Mooney, 2006) is a supervised learning system for semantic parsing which takes NL sentences paired with their MRs as training data.</S> | Reference Offset:  ['12','24'] | Reference Text:  <S sid = 12 ssid = >In contrast, kernel methods allow a convenient mechanism to implicitly work with a potentially infinite number of features which can robustly capture these range of contexts even when the data is noisy.Our system, KRISP (Kernel-based Robust Interpretation for Semantic Parsing), takes NL sentences paired with their formal meaning representations as training data.</S><S sid = 24 ssid = >A learn ing system for semantic parsing is given a trainingcorpus of NL sentences paired with their respec tive MRs from which it has to induce a semantic parser which can map novel NL sentences to their correct MRs. Figure 1 shows an example of an NL sentence and its MR from the CLANG domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1115.txt | Citing Article:  N07-2021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Experimentally, KRISP compares favorably to other existing semantic parsing systems and is particularly robust to noisy training data (Kate and Mooney, 2006).</S> | Reference Offset:  ['4','193'] | Reference Text:  <S sid = 4 ssid = >Our experiments on two real world data sets show that this approachcompares favorably to other existing sys tems and is particularly robust to noise.</S><S sid = 193 ssid = >The re sults showed that our system compares favorably to other existing systems and is particularly robust to noise.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1115.txt | Citing Article:  C10-2062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['48','194'] | Reference Text:  <S sid = 48 ssid = >Instead of non-terminals, productions are shown in the nodes to emphasize the role of productions in semantic derivations.</S><S sid = 194 ssid = >AcknowledgmentsThis research was supported by Defense Ad vanced Research Projects Agency under grant HR0011-04-1-0007.</S> | Discourse Facet:  NA | Annotator: Automatic


