Citance Number: 1 | Reference Article:  P08-1085.txt | Citing Article:  C08-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thus, an orthogonal line of research can involve inducing classes for words which are more general than single categories, i.e., something akin to ambiguity classes (see, e.g., the discussion of ambiguity class guessers in Goldberg et al, 2008).</S> | Reference Offset:  ['143','160'] | Reference Text:  <S sid = 143 ssid = >For these missing elements, we assign an ambiguity class by a simple ambiguity-class guesser, and set p(t|w) to be uniform over all the tags in the ambiguity class.</S><S sid = 160 ssid = >This seem to indicate that in English the linear context is better at refining the estimations when the ambiguity classes are known, while the morphological context is in charge of adding possible tags when the ambiguity classes are not known.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P08-1085.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This efficient and data-driven approach gives the best reported tagging accuracy for type-supervised sequence models, outperforming the minimized model of Ravi and Knight (2009), the Bayesian LDA-based model of Toutanova and Johnson (2008), and an HMM trained with language-specific initialization described by Goldberg et al (2008).</S> | Reference Offset:  ['17','182'] | Reference Text:  <S sid = 17 ssid = >The result is a series of creative algorithms, that have steadily improved results on the same dataset: unsupervised CRF training using contrastive estimation (SE), a fully-bayesian HMM model that jointly performs clustering and sequence learning (GG), and a Bayesian LDA-based model using only observed context features to predict tag words (TJ).</S><S sid = 182 ssid = >As we outperform this model in the complete dictionary case, it seems that the advantage of this model is due to its much stronger ambiguity class model, and not its Bayesian components.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P08-1085.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','202'] | Reference Text:  <S sid = 63 ssid = >The method is based on language-specific rules for constructing a similar words (SW) set for each analysis of a word.</S><S sid = 202 ssid = >Experimenting with combining similar models (as well as TJ’s ambiguity class model) with our p(t|w) distribution estimation method is an interesting research direction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P08-1085.txt | Citing Article:  P14-2132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >All of the methods to which we compare except Goldberg et al (2008) focus on learning and modeling techniques, while our method only addresses initialization.</S> | Reference Offset:  ['4','94'] | Reference Text:  <S sid = 4 ssid = >We also test the same method on the standard WSJ unsupervised POS tagging task and obtain results competitive with recent state-ofthe-art methods, while using simple and efficient learning methods.</S><S sid = 94 ssid = >For each of these, we first compare the computed p(tjw) against a gold standard distribution, taken from the test corpus (90K tokens), according to the measure used by (Levinger et al., 1995) (Dist).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P08-1085.txt | Citing Article:  E09-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >See Goldberg et al (2008) for details.</S> | Reference Offset:  ['50','68'] | Reference Text:  <S sid = 50 ssid = >In Hebrew, Levinger et al. (1995) introduced the similar-words algorithm for estimating p(t|w) from unlabeled data, which we describe below.</S><S sid = 68 ssid = >For the complete details, refer to the original paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P08-1085.txt | Citing Article:  P10-2039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Goldberg et al (2008) provide a linguistically-informed starting point for EM to achieve 91.4% accuracy.</S> | Reference Offset:  ['187','201'] | Reference Text:  <S sid = 187 ssid = >We achieve accuracy of 92.85% for the 19tags set, and 91.3% for the complete 46-tags tagset.</S><S sid = 201 ssid = >In particular, (Haghighi and Klein, 2006) presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P08-1085.txt | Citing Article:  P10-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Goldberg et al (2008) use linguistic considerations for choosing a good starting point for the EM algorithm.</S> | Reference Offset:  ['0','199'] | Reference Text:  <S sid = 0 ssid = >EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)</S><S sid = 199 ssid = >As such, they are not very good at assigning ambiguity-classes to OOV tokens when starting with a very small dictionary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P08-1085.txt | Citing Article:  D10-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Goldberg et al, 2008) extend the work of (Adler and Elhadad, 2006) by using an EM algorithm, and achieve an accuracy of 88% for full morphological analysis, but again, this does not include lemma IDs.</S> | Reference Offset:  ['99','201'] | Reference Text:  <S sid = 99 ssid = >We reach 88% accuracy on full morphological and 92% accuracy for POS tagging and word segmentation, for the Morph+Linear initial conditions.</S><S sid = 201 ssid = >In particular, (Haghighi and Klein, 2006) presents very strong results using a distributional-similarity module and achieve impressive tagging accuracy while starting with a mere 116 prototypical words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P08-1085.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','202'] | Reference Text:  <S sid = 63 ssid = >The method is based on language-specific rules for constructing a similar words (SW) set for each analysis of a word.</S><S sid = 202 ssid = >Experimenting with combining similar models (as well as TJ’s ambiguity class model) with our p(t|w) distribution estimation method is an interesting research direction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P08-1085.txt | Citing Article:  C10-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Despite the fact that HMM-EM has a poor reputation in POS literature (Goldberg et al, 2008) has shown that with good initialization together with some language specific features and language dependent constraints HMM-EM achieves 91.4% accuracy.</S> | Reference Offset:  ['0','147'] | Reference Text:  <S sid = 0 ssid = >EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)</S><S sid = 147 ssid = >EM-HMM, a second-order EM-HMM initialized with the estimated p(t|w).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P08-1085.txt | Citing Article:  E09-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Traditionally, such unsupervised EM-trained HMM taggers are thought to be inaccurate, but (Goldberg et al, 2008) showed that by feeding thee M process with sufficiently good initial probabilities, accurate taggers (> 91% accuracy) can be learned for both English and Hebrew, based on a (possibly incomplete) lexicon and large amount of raw text.</S> | Reference Offset:  ['0','148'] | Reference Text:  <S sid = 0 ssid = >EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)</S><S sid = 148 ssid = >Baselines As baseline, we use two EM-trained HMM taggers, initialized with a uniform p(t|w) for every word, based on the allowed tags in the dictionary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P08-1085.txt | Citing Article:  P11-2124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As another baseline, we experimented with a pipeline system in which the input text is automatically segmented and tagged using a state-of-the-art HMMpos-tagger (Goldberg et al, 2008).</S> | Reference Offset:  ['33','196'] | Reference Text:  <S sid = 33 ssid = >We also report state-of-the-art results for Hebrew full morphological disambiguation.</S><S sid = 196 ssid = >In English, our model is competitive with recent state-of-the-art results, while using simple and efficient learning methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P08-1085.txt | Citing Article:  D12-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Goldberg et al 2008 note that fixing noisy dictionaries by hand is actually quite feasible, and suggest that effort should focus on exploiting human knowledge rather than just algorithmic improvements.</S> | Reference Offset:  ['130','164'] | Reference Text:  <S sid = 130 ssid = >L+suff=W,S The word appears just after word W, with suffix 5 (L+suff=have,ed).</S><S sid = 164 ssid = >Note that the context-free tagger based on our p(tjw) estimates is quite accurate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P08-1085.txt | Citing Article:  S12-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The probability of a lemma was defined as the sum of probabilities for all morphological analyses containing the lemma, using a morpho-lexical context-independent probabilities approximation (Goldberg et al, 2008).</S> | Reference Offset:  ['62','138'] | Reference Text:  <S sid = 62 ssid = >Morphology-based p(t|w) approximation Levinger et al. (1995) developed a context-free method for acquiring morpho-lexical probabilities (p(t|w)) from an untagged corpus.</S><S sid = 138 ssid = >Combined p(t|w) approximation This approximation combines the morphological and linear context approximations by using all the abovementioned context templates together in the iterative process.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P08-1085.txt | Citing Article:  S12-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The latter had two important characteristics: The first is flexibility This tagger allows adapting the estimates of the prior (context-independent) probability of each morphological analysis in an unsupervised manner, from an unlabeled corpus of the target domain (Goldberg et al, 2008).</S> | Reference Offset:  ['67','164'] | Reference Text:  <S sid = 67 ssid = >The approximated probability of each analysis is based on the corpus frequency of its SW set.</S><S sid = 164 ssid = >Note that the context-free tagger based on our p(tjw) estimates is quite accurate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P08-1085.txt | Citing Article:  W12-1905.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The importance is underscored succinctly by Goldberg et al (2008).</S> | Reference Offset:  ['50','86'] | Reference Text:  <S sid = 50 ssid = >In Hebrew, Levinger et al. (1995) introduced the similar-words algorithm for estimating p(t|w) from unlabeled data, which we describe below.</S><S sid = 86 ssid = >Linear-Context-based p(t|w) approximation For the initial p(t|w) we use either a uniform distribution based on the tags allowed in the dictionary, or the estimate obtained by using the modified Levinger et al. algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P08-1085.txt | Citing Article:  P09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >EM-HMM tagger provided with good initial conditions (Goldberg et al, 2008).</S> | Reference Offset:  ['2','188'] | Reference Text:  <S sid = 2 ssid = >We demonstrate that good results can be obtained using the robust EM-HMM learner when provided with good initial conditions, even with incomplete dictionaries.</S><S sid = 188 ssid = >We have demonstrated that unsupervised POS tagging can reach good results using the robust EMHMM learner when provided with good initial conditions, even with incomplete dictionaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P08-1085.txt | Citing Article:  P09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Goldberg et al (2008) depart from the Bayesian framework and show how EM can be used to learn good POS taggers for Hebrew and English, when provided with good initial conditions.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >EM Can Find Pretty Good HMM POS-Taggers (When Given a Good Start)</S><S sid = 2 ssid = >We demonstrate that good results can be obtained using the robust EM-HMM learner when provided with good initial conditions, even with incomplete dictionaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P08-1085.txt | Citing Article:  P09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The system achieves a better accuracy than the 88.6% from Smith and Eisner (2005), and even surpasses the 91.4% achieved by Goldberg et al (2008) without using any additional linguistic constraints or manual cleaning of the dictionary.</S> | Reference Offset:  ['12','51'] | Reference Text:  <S sid = 12 ssid = >In recent work, researchers try to address these deficiencies by using dictionaries with unfiltered POS-tags, and testing the methods on “diluted dictionaries” – in which many of the lexical entries are missing (Smith and Eisner, 2005) (SE), (Goldwater and Griffiths, 2007) (GG), (Toutanova and Johnson, 2008) (TJ).</S><S sid = 51 ssid = >Our method uses this algorithm as a first step, and refines the approximation by introducing additional linguistic constraints and an iterative refinement step.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P08-1085.txt | Citing Article:  P09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Their models are trained on the entire Penn Treebank data (instead of using only the 24,115-token test data), and so are the tagging models used by Goldberg et al (2008).</S> | Reference Offset:  ['153','171'] | Reference Text:  <S sid = 153 ssid = >All the p(tjw) estimates and HMM models are trained on the entire WSJ corpus.</S><S sid = 171 ssid = >While our models are trained on the unannotated text of the entire WSJ Treebank, CE and BHMM use much less training data (only the 24k words of the test-set).</S> | Discourse Facet:  NA | Annotator: Automatic


