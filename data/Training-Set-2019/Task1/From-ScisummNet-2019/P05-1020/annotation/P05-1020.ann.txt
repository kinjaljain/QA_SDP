Citance Number: 1 | Reference Article:  P05-1020.txt | Citing Article:  W06-1633.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Ng, 2005) treats coreference resolution as a problem of ranking candidate partitions generated by a set of coreference systems.</S> | Reference Offset:  ['1','31'] | Reference Text:  <S sid = 1 ssid = >In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.</S><S sid = 31 ssid = >Ranking candidate partitions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P05-1020.txt | Citing Article:  W06-1633.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The main difference between this approach and ours is that (Ng, 2005)'s approach takes coreference resolution one step further, by comparing the results of multiple systems, while our system is a single resolver; furthermore, he emphasizes the global optimization of ranking clusters obtained locally, whereas our focus is on globally optimizing the clusterization method inside the resolver.</S> | Reference Offset:  ['111','139'] | Reference Text:  <S sid = 111 ssid = >Our approach.</S><S sid = 139 ssid = >Our approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P05-1020.txt | Citing Article:  W12-4508.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >There are many different training example generation algorithms, e.g., McCarthy and Lehnert's method, Soon et als method, Ng and Cardies method (Ng, 2005).</S> | Reference Offset:  ['52','57'] | Reference Text:  <S sid = 52 ssid = >In an attempt to reduce the training time, Soon et al.’s method creates a smaller number of training instances than McCarthy and Lehnert’s.</S><S sid = 57 ssid = >Negative instances are generated as in Soon et al.’s method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P05-1020.txt | Citing Article:  P07-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar to many previous works on co-reference (Ng, 2005), we cast the problem as a classification task and solve it in two steps: (1) train a classifier to determine whether two mentions are co-referent or not, and (2) use a clustering algorithm to partition the mentions into clusters, based on the pairwise predictions.</S> | Reference Offset:  ['8','41'] | Reference Text:  <S sid = 8 ssid = >Specifically, a classifier is first trained to determine whether two NPs in a document are co-referring or not.</S><S sid = 41 ssid = >A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To our knowledge, the best results on this dataset were obtained by the meta-classification scheme of Ng (2005).</S> | Reference Offset:  ['37','144'] | Reference Text:  <S sid = 37 ssid = >To our knowledge, our work is the first attempt to optimize a ranker for clustering-level accuracy.</S><S sid = 144 ssid = >In particular, the best result for BNEWS is achieved using only method-based features, whereas the best result for NPAPER is obtained using only partitionbased features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although our train-test splits may differ slightly, the best B-Cubed F1 score reported in Ng (2005) is 69.3%, which is considerably lower than the 79.3% obtained with our method.</S> | Reference Offset:  ['108','144'] | Reference Text:  <S sid = 108 ssid = >Ng and Cardie’s system, on the other hand, employs RIPPER to train a coreference classifier on instances created by N&C’s method and represented by N&C’s feature set, inducing a partition on the given NPs via best-first clustering.</S><S sid = 144 ssid = >In particular, the best result for BNEWS is achieved using only method-based features, whereas the best result for NPAPER is obtained using only partitionbased features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ng (2005) learns a meta-classifier to choose the best prediction from the output of several coreference systems.</S> | Reference Offset:  ['108','134'] | Reference Text:  <S sid = 108 ssid = >Ng and Cardie’s system, on the other hand, employs RIPPER to train a coreference classifier on instances created by N&C’s method and represented by N&C’s feature set, inducing a partition on the given NPs via best-first clustering.</S><S sid = 134 ssid = >So, we apply a perfect ranking model, which uses an oracle to choose the best candidate partition for each test text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P05-1020.txt | Citing Article:  N07-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This could be incorporated in a ranking scheme, as in Ng (2005).</S> | Reference Offset:  ['31','126'] | Reference Text:  <S sid = 31 ssid = >Ranking candidate partitions.</S><S sid = 126 ssid = >Random ranking.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P05-1020.txt | Citing Article:  P07-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure of about 62% for the same data set.</S> | Reference Offset:  ['109','112'] | Reference Text:  <S sid = 109 ssid = >The baseline results are shown in rows 1 and 2 of Table 3, where performance is reported in terms of recall, precision, and F-measure.</S><S sid = 112 ssid = >Recall that our approach uses labeled data to train both the coreference classifiers and the ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['67','182'] | Reference Text:  <S sid = 67 ssid = >We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S><S sid = 182 ssid = >We thank the three anonymous reviewers for their valuable comments on an earlier draft of the paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['67','182'] | Reference Text:  <S sid = 67 ssid = >We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S><S sid = 182 ssid = >We thank the three anonymous reviewers for their valuable comments on an earlier draft of the paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P05-1020.txt | Citing Article:  D08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >MUC and B3 metrics (Ng, 2005a).</S> | Reference Offset:  ['27','28'] | Reference Text:  <S sid = 27 ssid = >We evaluate our approach on three standard coreference data sets using two different scoring metrics.</S><S sid = 28 ssid = >In our experiments, our approach compares favorably to two state-of-the-art coreference systems adopting the standard machine learning approach, outperforming them by as much as 4–7% on the three data sets for one of the performance metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P05-1020.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Wellner (2004) using conditional random fields, and Ng (2005) using rerankers.</S> | Reference Offset:  ['6','179'] | Reference Text:  <S sid = 6 ssid = >(2004)).</S><S sid = 179 ssid = >McCallum and Wellner (2003) and Zelenko et al. (2004) have employed graph-based partitioning algorithms such as correlation clustering (Bansal et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P05-1020.txt | Citing Article:  N07-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A third global approach is offered by Ng (2005), who proposes a global reranking over partitions generated by different coreference systems.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Machine Learning For Coreference Resolution: From Local Classification To Global Ranking</S><S sid = 1 ssid = >In this paper, we view coreference resolution as a problem of ranking candidate partitions generated by different coreference systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P05-1020.txt | Citing Article:  P08-2012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other work on global models of coreference (as opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a reranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model.</S> | Reference Offset:  ['6','179'] | Reference Text:  <S sid = 6 ssid = >(2004)).</S><S sid = 179 ssid = >McCallum and Wellner (2003) and Zelenko et al. (2004) have employed graph-based partitioning algorithms such as correlation clustering (Bansal et al., 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P05-1020.txt | Citing Article:  D12-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, the method of (Ng, 2005) ranks base models according to their performance on separate tuning set, and then uses the highest-ranked base model for predicting on test documents.</S> | Reference Offset:  ['40','134'] | Reference Text:  <S sid = 40 ssid = >Given a test text, we use our coreference systems to create candidate partitions as in training, and select the highest-ranked partition according to the ranking model to be the final partition.3 The rest of this section describes how we select these learning-based coreference systems and acquire the ranking model.</S><S sid = 134 ssid = >So, we apply a perfect ranking model, which uses an oracle to choose the best candidate partition for each test text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P05-1020.txt | Citing Article:  P08-1096.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results are comparable to those reported in (Ng, 2005) which uses similar features and gets an F-measure ranging in 50-60% for the same data set.</S> | Reference Offset:  ['109','112'] | Reference Text:  <S sid = 109 ssid = >The baseline results are shown in rows 1 and 2 of Table 3, where performance is reported in terms of recall, precision, and F-measure.</S><S sid = 112 ssid = >Recall that our approach uses labeled data to train both the coreference classifiers and the ranking model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P05-1020.txt | Citing Article:  S10-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >According to Ng (2005), most learning based coreference systems can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S> | Reference Offset:  ['41','107'] | Reference Text:  <S sid = 41 ssid = >A learning-based coreference system can be defined by four elements: the learning algorithm used to train the coreference classifier, the method of creating training instances for the learner, the feature set used to represent a training or test instance, and the clustering algorithm used to coordinate the coreference classification decisions.</S><S sid = 107 ssid = >Specifically, Soon et al.’s system employs a decision tree learner to train a coreference classifier on instances created by Soon’s method and represented by Soon’s feature set, coordinating the classification decisions via closest-first clustering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P05-1020.txt | Citing Article:  S10-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This strategy has been described as best-first clustering by Ng (2005).</S> | Reference Offset:  ['59','71'] | Reference Text:  <S sid = 59 ssid = >We employ two feature sets for representing an instance, as described below.</S><S sid = 71 ssid = >We employ three clustering algorithms, as described below.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P05-1020.txt | Citing Article:  C10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In contrast to Ng (2005), Ng and Cardie (2002a) proposed a rule-induction system with rule pruning.</S> | Reference Offset:  ['65','67'] | Reference Text:  <S sid = 65 ssid = >See Ng and Cardie (2002b) for details.</S><S sid = 67 ssid = >We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al., 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


