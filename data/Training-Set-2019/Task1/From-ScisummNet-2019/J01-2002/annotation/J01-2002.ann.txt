Citance Number: 1 | Reference Article:  J01-2002.txt | Citing Article:  P06-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This simple idea has been applied to a variety of classification problems ranging from optical character recognition to medical diagnosis, part-of-speech tagging (see Dietterich 1997 and van Halteren et al 2001 for overviews), and notably supervised WSD (Florian et al, 2002).</S> | Reference Offset:  ['207','483'] | Reference Text:  <S sid = 207 ssid = >It is based on the classification used in the most popular descriptive grammar of Dutch, the Algemene Nederlandse Spraakkunst (ANS [Geerts et al. 1984]).</S><S sid = 483 ssid = >In another recent study, Marquez et al. (1999) investigate several types of ensemble construction in a decision tree learning framework for tagging specific classes of ambiguous words (as opposed to tagging all words).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J01-2002.txt | Citing Article:  W03-0806.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, the state of the art POS tagger is an ensemble of individual taggers (van Halterenet al, 2001), each of which must process the text separately.</S> | Reference Offset:  ['52','491'] | Reference Text:  <S sid = 52 ssid = >There are several ways in which an ensemble can be created, both in the selection of the individual classifiers and in the way they are combined.</S><S sid = 491 ssid = >Their approach is also demonstrated for prepositional phrase attachment, again with results comparable to but not better than state-of-the-art single classifier systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J01-2002.txt | Citing Article:  P05-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Illustrating the negative impact of annotation errors on computational uses of annotated corpora, van Halteren et al (2001) compare taggers trained and tested on the Wall Street Journal (WSJ, Marcus et al, 1993) and the Lancaster-Oslo-Bergen (LOB, Johansson, 1986) corpora and find that the results for the WSJ perform significantly worse.</S> | Reference Offset:  ['161','170'] | Reference Text:  <S sid = 161 ssid = >We then switch to Wall Street Journal material (WSJ), tagged with the Penn Treebank II tagset (Marcus, Santorini, and Marcinkiewicz 1993).</S><S sid = 170 ssid = >The first data set we use for our experiments consists of the tagged Lancaster-Oslo/Bergen corpus (LOB [Johansson 1986]).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J01-2002.txt | Citing Article:  W03-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Classifier combination has been shown to be effective in improving the performance of NLP applications, and have been investigated by Brill and Wu (1998) and van Halteren et al (2001) for part-of-speech tagging, Tjong Kim Sang et al (2000) for base noun phrase chunking, and Florian et al (2003a) for word sense disambiguation.</S> | Reference Offset:  ['468','470'] | Reference Text:  <S sid = 468 ssid = >For example, Rigau, Atserias, and Agirre (1997) combine different heuristics for word sense disambiguation by voting, and Agirre et al. (1998) do the same for spelling correction evaluation heuristics.</S><S sid = 470 ssid = >For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J01-2002.txt | Citing Article:  W05-0404.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Given that the latest literature on POS tagging using Penn Treebank reports an accuracy of around 97% with in-domain training data (van Halteren et al, 2001), we achieve a very reasonable performance, considering these errors.</S> | Reference Offset:  ['182','314'] | Reference Text:  <S sid = 182 ssid = >The material is tagged with the Penn Treebank tagset (Marcus, Santorini, and Marcirtkiewicz 1993), which is much smaller than the LOB one.</S><S sid = 314 ssid = >For example, on LOB, TagPair produces 2,321 errors (corresponding to an accuracy of 97.98%), which is 17.8% less than HMM's 2,824 errors.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J01-2002.txt | Citing Article:  P04-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This data set was also used in (van Halteren et al, 2001), therefore the second experiment will allow for a comparison of the results with previous work on tagging Dutch.</S> | Reference Offset:  ['207','473'] | Reference Text:  <S sid = 207 ssid = >It is based on the classification used in the most popular descriptive grammar of Dutch, the Algemene Nederlandse Spraakkunst (ANS [Geerts et al. 1984]).</S><S sid = 473 ssid = >As we now apply the methods of van Halteren, Zavrel, and Daelemans (1998) to WSJ as well, it is easier to make a comparison.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J01-2002.txt | Citing Article:  P04-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These sentences received no contextual labels and thus not all of the training data used in (van Halteren et al, 2001) could be used in the Wotan experiment.</S> | Reference Offset:  ['255','311'] | Reference Text:  <S sid = 255 ssid = >A tagger using this learning method, MBT, was proposed by Daelemans et al. (1996).18 During the training phase, the training corpus is transformed into two case bases, one which is to be used for known words and one for unknown words.</S><S sid = 311 ssid = >*c5.0 was not able to cope with the large amount of data involved in all Tags+Word experiments and the Tags+Context experiment with Wotan.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J01-2002.txt | Citing Article:  P04-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the Wotan experiment, 36K sentences (628K words) are used for training (compared to 640K words in (van Halteren et al, 2001)), and 4176 sentences (72K words) are used for testing.</S> | Reference Offset:  ['219','255'] | Reference Text:  <S sid = 219 ssid = >The training set consists of 640K tokens and the test set of 72K tokens.</S><S sid = 255 ssid = >A tagger using this learning method, MBT, was proposed by Daelemans et al. (1996).18 During the training phase, the training corpus is transformed into two case bases, one which is to be used for known words and one for unknown words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J01-2002.txt | Citing Article:  P04-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Wotan data is annotated with a tag set consisting of 345 tags (although a number of 341 is reported in (van Halteren et al, 2001)).</S> | Reference Offset:  ['209','311'] | Reference Text:  <S sid = 209 ssid = >The Wotan tagset is not only very large (233 base tags, leading to 341 tags when counting each ditto tag separately), but furthermore contains distinctions that are very difficult for automatic taggers, such as verb transitivity, syntactic use of adjectives, and the recognition of multitoken units.</S><S sid = 311 ssid = >*c5.0 was not able to cope with the large amount of data involved in all Tags+Word experiments and the Tags+Context experiment with Wotan.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J01-2002.txt | Citing Article:  P04-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This result is very similar to the 92.06% reported by Van Halteren, Zavrel and Daelemans in (van Halteren et al, 2001) who used the TnT trigram tagger (Brants, 2000) on the same training and testing data.</S> | Reference Offset:  ['98','160'] | Reference Text:  <S sid = 98 ssid = >One of the best methods for tagger combination in (van Halteren, Zavrel, and Daelemans 1998) is the TagPair method.</S><S sid = 160 ssid = >The first is the LOB corpus (Johansson 1986), which we used in the earlier experiments as well (van Halteren, Zavrel, and Daelemans 1998) and which has proved to be a good testing ground.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J01-2002.txt | Citing Article:  E09-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have experimented with various classifier combination methods, such as those described in (Brill and Wu, 1998) or (van Halteren et al., 2001), and got improved results, as expected.</S> | Reference Offset:  ['312','470'] | Reference Text:  <S sid = 312 ssid = >In Table 6 the results of our experiments with the various combination methods are shown.</S><S sid = 470 ssid = >For part-of-speech tagging, a significant increase in accuracy through combining the output of different taggers was first demonstrated in van Halteren, Zavrel, and Daelemans (1998) and Brill and Wu (1998).</S> | Discourse Facet:  NA | Annotator: Automatic


