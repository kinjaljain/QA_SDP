Citance Number: 1 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Another research line is to exploit various linguistically informed features under the framework of supervised models, (Pitler et al, 2009a) and (Lin et al, 2009), e.g., polarity features, semantic classes, tense, production rules of parse trees of arguments, etc. Our study on PDTB test data shows that the average f-score for the most general 4 senses can reach 91.8% when we simply mapped the ground truth implicit connective of each test instance to its most frequent sense.</S> | Reference Offset:  ['3','16'] | Reference Text:  <S sid = 3 ssid = >We use several linguistically informed features, including polarity tags, Levin verb classes, length of verb phrases, modality, context, and lexical features.</S><S sid = 16 ssid = >The most general senses (comparison, contingency, temporal and expansion) can be disambiguated in explicit relations with 93% accuracy based solely on the discourse connective used to signal the relation (Pitler et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this paper, we include 9 types of features in our system due to their superior performance in previous studies, e.g., polarity features, semantic classes of verbs, contextual sense, modality, inquirer tags of words, first-last words of arguments, cross-argument word pairs, ever used in (Pitler et al, 2009a), production rules of parse trees of arguments used in (Lin et al, 2009), and intra-argument word pairs inspired by the work of (Saito et al, 2006).</S> | Reference Offset:  ['122','226'] | Reference Text:  <S sid = 122 ssid = >Development testing showed that including features for all wordsâ€™ tags was not useful, so we include the Inquirer tags of only the verbs in the two arguments and their cross-product.</S><S sid = 226 ssid = >Only word pairs were used as features for both.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Here we provide the details of the 9 features, shown as follows: Verbs: Similar to the work in (Pitler et al, 2009a), the verb features consist of the number of pairs of verbs in Arg1 and Arg2 if they are from the same class based on their highest Levin verb class level (Dorr, 2001).</S> | Reference Offset:  ['138','139'] | Reference Text:  <S sid = 138 ssid = >Verbs: These features include the number of pairs of verbs in Arg1 and Arg2 from the same verb class.</S><S sid = 139 ssid = >Two verbs are from the same verb class if each of their highest Levin verb class (Levin, 1993) levels (in the LCS Database (Dorr, 2001)) are the same.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following the work of (Pitler et al, 2009a), we used sections 2-20 as training set, sections 21-22 as test set, and sections 0-1 as development set for parameter optimization.</S> | Reference Offset:  ['167','168'] | Reference Text:  <S sid = 167 ssid = >For all experiments, we used sections 2-20 of the PDTB for training and sections 21-22 for testing.</S><S sid = 168 ssid = >Sections 0-1 were used as a development set for feature design.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Here the numbers of training and test instances for Expansion relation are different from those in (Pitler et al, 2009a).</S> | Reference Offset:  ['16','170'] | Reference Text:  <S sid = 16 ssid = >The most general senses (comparison, contingency, temporal and expansion) can be disambiguated in explicit relations with 93% accuracy based solely on the discourse connective used to signal the relation (Pitler et al., 2008).</S><S sid = 170 ssid = >As each of the relations besides Expansion are infrequent, we train using equal numbers of positive and negative examples of the target relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 2 summarizes the best performance achieved by the baseline system in comparison with previous state-of-the-art performance achieved in (Pitler et al, 2009a).</S> | Reference Offset:  ['176','218'] | Reference Text:  <S sid = 176 ssid = >The performance using only our semantically informed features is shown in Table 7.</S><S sid = 218 ssid = >Adding other features to word pairs leads to improved performance for Contingency, Expansion and Temporal relations, but not for Comparison.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 2: Performance comparison of the baseline system with the system of (Pitler et al, 2009a) on test set.</S> | Reference Offset:  ['176','180'] | Reference Text:  <S sid = 176 ssid = >The performance using only our semantically informed features is shown in Table 7.</S><S sid = 180 ssid = >Our random baseline is the f-score one would achieve by randomly assigning classes in proportion to its true distribution in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['238','239'] | Reference Text:  <S sid = 238 ssid = >This work was partially supported by NSF grants IIS-0803159, IIS-0705671 and IGERT 0504487.</S><S sid = 239 ssid = >We would like to thank Sasha Blair-Goldensohn for providing us with the TextRels data and for the insightful discussion in the early stages of our work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although on Comparison relation there is only as light improvement (+1.07%), our two best systems both got around 10% improvements of f score over a state-of-the-art system in (Pitler et al, 2009a).</S> | Reference Offset:  ['182','220'] | Reference Text:  <S sid = 182 ssid = >Our features provide 6% to 18% absolute improvements in f-score over the baseline for each of the four tasks.</S><S sid = 220 ssid = >This combination led to a definite improvement, reaching an f-score of 47.13 (16% absolute improvement in f-score over Wordpairs-TextRels).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This also encourages our future work on finding the most suitable connectives for implicit relation recognition. From this table, we found that, using only predicted implicit connectives achieved an comparable performance to (Pitler et al, 2009a), although it was still a bit lower than our best baseline.</S> | Reference Offset:  ['147','176'] | Reference Text:  <S sid = 147 ssid = >In our experiments on implicits, the first and last words are not connectives.</S><S sid = 176 ssid = >The performance using only our semantically informed features is shown in Table 7.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since (Pitler et al, 2009a) used different selection of instances for Expansion sense, we cannot make a direct comparison.</S> | Reference Offset:  ['16','49'] | Reference Text:  <S sid = 16 ssid = >The most general senses (comparison, contingency, temporal and expansion) can be disambiguated in explicit relations with 93% accuracy based solely on the discourse connective used to signal the relation (Pitler et al., 2008).</S><S sid = 49 ssid = >In our experiments, we use only the top level of the sense annotations: Comparison, Contingency, Expansion, and Temporal.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Specifically, the model for the Comparison relation achieves an f-score of 26.02% (5% over the previous work in (Pitler et al, 2009a)).</S> | Reference Offset:  ['74','223'] | Reference Text:  <S sid = 74 ssid = >Blair-Goldensohn et al. (2007) proposed several refinements of the word pair model.</S><S sid = 223 ssid = >We trained a CRF classifier (Lafferty et al., 2001) over the sequence of implicit examples from all documents in sections 02 to 20.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Furthermore, the models for Contingency and Temporal relation achieve 35.72% and 13.76% f-score respectively, which are comparable to the previous work in (Pitler et al, 2009a).</S> | Reference Offset:  ['217','221'] | Reference Text:  <S sid = 217 ssid = >The absolute difference in f-score between the two models is close to 2% for Comparison, and 6% for Contingency.</S><S sid = 221 ssid = >For detecting expansions, the best combination of our features (polarity+Inquirer tags+context) outperformed Wordpairs-PDTBImpl by a wide margin, close to 13% absolute improvement (fscores of 76.42 and 63.84 respectively).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1077.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Pitler et al, 2009a) performed implicit relation classification on the second version of the PDTB.</S> | Reference Offset:  ['51','196'] | Reference Text:  <S sid = 51 ssid = >Each relation in the PDTB takes two arguments.</S><S sid = 196 ssid = >This makes sense, as Pitler et al. (2008) found that implicit contingencies are often found immediately following explicit comparisons.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Each relation has two arguments, Arg1 and Arg2, and the annotators decide whether it is explicit or implicit. The first to evaluate directly on PDTB in a realistic setting were Pitler et al (2009).</S> | Reference Offset:  ['33','51'] | Reference Text:  <S sid = 33 ssid = >They delete the connective and use [Arg1, Arg2] as an example of an implicit relation.</S><S sid = 51 ssid = >Each relation in the PDTB takes two arguments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, the approach taken by Pitler et al (2009) and repeated in more recent work (training directly on PDTB) is problematic as well: when training a model with so many sparse features on a dataset the size of PDTB (there are 22, 141 non-explicit relations overall), it is likely that many important word pairs will not be seen in training.</S> | Reference Offset:  ['166','167'] | Reference Text:  <S sid = 166 ssid = >Wordpairs-PDTBExpl In this case, the model was formed by using the word pairs from the explicit relations in the sections of the PDTB used for training.</S><S sid = 167 ssid = >For all experiments, we used sections 2-20 of the PDTB for training and sections 21-22 for testing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An analysis in (Pitler et al, 2009) also shows that the top word pairs (ranked by information gain) all contain common functional words, and are not at all the semantically-related content words that were imagined.</S> | Reference Offset:  ['20','85'] | Reference Text:  <S sid = 20 ssid = >We examine the most informative word pair features and find that they are not the semantically-related pairs that researchers had hoped.</S><S sid = 85 ssid = >After removing word pairs that appear less than 5 times, the remaining features were ranked by information gain using the MALLET toolkit1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our word pair features outperform the previous formulation (represented by the results reported by (Pitler et al, 2009), but used by virtually all previous work on this task).</S> | Reference Offset:  ['19','226'] | Reference Text:  <S sid = 19 ssid = >Given two text spans, previous work has used the cross-product of the words in the spans as features.</S><S sid = 226 ssid = >Only word pairs were used as features for both.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['238','239'] | Reference Text:  <S sid = 238 ssid = >This work was partially supported by NSF grants IIS-0803159, IIS-0705671 and IGERT 0504487.</S><S sid = 239 ssid = >We would like to thank Sasha Blair-Goldensohn for providing us with the TextRels data and for the insightful discussion in the early stages of our work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1077.txt | Citing Article:  P13-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['238','239'] | Reference Text:  <S sid = 238 ssid = >This work was partially supported by NSF grants IIS-0803159, IIS-0705671 and IGERT 0504487.</S><S sid = 239 ssid = >We would like to thank Sasha Blair-Goldensohn for providing us with the TextRels data and for the insightful discussion in the early stages of our work.</S> | Discourse Facet:  NA | Annotator: Automatic


