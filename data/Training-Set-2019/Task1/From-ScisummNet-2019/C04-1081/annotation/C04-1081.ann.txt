Citance Number: 1 | Reference Article:  C04-1081.txt | Citing Article:  W04-3230.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A simple approach would be to let a character be a token (i.e., character-based Begin/Inside tagging) so that boundary ambiguity never occur (Peng et al, 2004).</S> | Reference Offset:  ['96','113'] | Reference Text:  <S sid = 96 ssid = >The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.</S><S sid = 113 ssid = >unit character (e.g.,G,?)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C04-1081.txt | Citing Article:  W10-4103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Peng et al (2004) uses the CRFs to address this issue.</S> | Reference Offset:  ['16','21'] | Reference Text:  <S sid = 16 ssid = >Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.</S><S sid = 21 ssid = >Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C04-1081.txt | Citing Article:  W10-4103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In last part of the experiments, the generality of the datasets and the toughness of our system are tested (Peng et al, 2004).</S> | Reference Offset:  ['69','100'] | Reference Text:  <S sid = 69 ssid = >See Peng and McCallum (2004) for more details and further experiments.</S><S sid = 100 ssid = >The list of lexicons used in our experiments is shown in Figure 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C04-1081.txt | Citing Article:  W06-0130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The superiority of CRFs on Chinese information processing was also demonstrated in word segmentation (Peng et al 2004).</S> | Reference Offset:  ['16','27'] | Reference Text:  <S sid = 16 ssid = >Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.</S><S sid = 27 ssid = >These beneficialproperties suggests that CRFs are a promising ap proach for Chinese word segmentation.New word detection is one of the most impor tant problems in Chinese information processing.Many machine learning approaches have been pro posed (Chen and Bai, 1998; Wu and Jiang, 2000; Nie et al, 1995).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C04-1081.txt | Citing Article:  W06-0140.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word.</S> | Reference Offset:  ['96','138'] | Reference Text:  <S sid = 96 ssid = >The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.</S><S sid = 138 ssid = >These datasets represent four different segmentation standards.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C04-1081.txt | Citing Article:  W06-1655.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >CRFs using this technique have been shown to be very successful at the task of Chinese word segmentation (CWS), starting with the model of Peng et al (2004).</S> | Reference Offset:  ['0','40'] | Reference Text:  <S sid = 0 ssid = >Chinese Segmentation And New Word Detection Using Conditional Random Fields</S><S sid = 40 ssid = >This indicates that CRFs are a viable model for robust Chinese word segmentation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C04-1081.txt | Citing Article:  N09-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A popular discriminative model that have been used for this task is the conditional random fields (CRFs) (Lafferty et al, 2001), starting with the model of Peng et al (2004).</S> | Reference Offset:  ['21','41'] | Reference Text:  <S sid = 21 ssid = >Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.</S><S sid = 41 ssid = >Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C04-1081.txt | Citing Article:  I08-4015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al, 2004), (Tseng et al, 2005), (Low et al., 2005), (Zhao et al, 2006).</S> | Reference Offset:  ['16','165'] | Reference Text:  <S sid = 16 ssid = >Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.</S><S sid = 165 ssid = >S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C04-1081.txt | Citing Article:  W08-0336.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al (2001), and was first used for the Chinese word segmentation task by Peng et al (2004), who treated word segmentation as a binary decision task.</S> | Reference Offset:  ['21','41'] | Reference Text:  <S sid = 21 ssid = >Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.</S><S sid = 41 ssid = >Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C04-1081.txt | Citing Article:  P07-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow the format from Peng et al (2004).</S> | Reference Offset:  ['69','165'] | Reference Text:  <S sid = 69 ssid = >See Peng and McCallum (2004) for more details and further experiments.</S><S sid = 165 ssid = >S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C04-1081.txt | Citing Article:  P07-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >represents the CRF model from Peng et al (2004), and the last row represents our model.</S> | Reference Offset:  ['17','159'] | Reference Text:  <S sid = 17 ssid = >Zhang et al (2003) use a hierarchical hidden Markov Model to incorporate lexical knowledge.</S><S sid = 159 ssid = >Our results are in the last row.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C04-1081.txt | Citing Article:  D07-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >RMNs are the special case of Conditional Markov Networks (or Conditional Random Fields) in which graph structure and parameter tying are determined by SQL-like form. As for the marginal probability to use as a confidence measure shown in Figure 4, Peng et al (2004) has applied linear-chain CRFs to Chinese word segmentation.</S> | Reference Offset:  ['21','41'] | Reference Text:  <S sid = 21 ssid = >Linear-chain conditional random fields (CRFs) (Lafferty et al, 2001) are models that address both issues above.</S><S sid = 41 ssid = >Conditional random fields (CRFs) are undirected graphical models trained to maximize a conditional probability (Lafferty et al, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C04-1081.txt | Citing Article:  P13-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Aiming to improve both tasks, work by Peng et al (2004) and Sun et al (2012) conduct segmentation and detection sequentially, but in an iterative manner rather than joint.</S> | Reference Offset:  ['123','165'] | Reference Text:  <S sid = 123 ssid = >We consider here new word detection as an integral part of segmentation, aimingto improve both segmentation and new word detec tion: detected new words are added to the word list lexicon in order to improve segmentation; improved segmentation can potentially further improve new word detection.</S><S sid = 165 ssid = >S01 is one of the best segmentation systems in mainland China (Zhang et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C04-1081.txt | Citing Article:  I05-3027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Work by Peng et al (2004) first used this framework for Chinese word segmentation by treating it as a binary decision task, such that each character is labeled either as the beginning of a word or the continuation of one.</S> | Reference Offset:  ['9','16'] | Reference Text:  <S sid = 9 ssid = >Un fortunately, building a Chinese word segmentation system is complicated by the fact that there is no standard definition of word boundaries in Chinese.</S><S sid = 16 ssid = >Gao et al(2003) uses class-based language for word segmentation where some word cat egory information can be incorporated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C04-1081.txt | Citing Article:  I05-3027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >3.2.1 Results on Sighanbakeoff 2003 Experiments done while developing this system showed that its performance was significantly better than that of Peng et al (2004).</S> | Reference Offset:  ['69','197'] | Reference Text:  <S sid = 69 ssid = >See Peng and McCallum (2004) for more details and further experiments.</S><S sid = 197 ssid = >The quality of lexicons can affect the performance of CRFs significantly.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C04-1081.txt | Citing Article:  I05-3027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','203'] | Reference Text:  <S sid = 63 ssid = >L? = ? i logP?(yi|xi)?</S><S sid = 203 ssid = >AcknowledgmentsThis work was supported in part by the Center for Intelligent Information Retrieval, in part by The Cen tral Intelligence Agency, the National Security Agencyand National Science Foundation under NSF grant #IIS 0326249, and in part by SPAWARSYSCEN-SD grant number N66001-02-1-8903.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C04-1081.txt | Citing Article:  C08-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Peng et al (2004) defined the word segmentation problem as labeling each character as whether or not the previous character boundary of the current character is a word boundary.</S> | Reference Offset:  ['113','119'] | Reference Text:  <S sid = 113 ssid = >unit character (e.g.,G,?)</S><S sid = 119 ssid = >Figure 1: Lexicons used in our experiments C?2: second previous character in lexicon C?1: previous character in lexicon C1: next character in lexicon C2: second next character in lexicon C0C1: current and next character in lexicon C?1C0: current and previous character in lexicon C?2C?1: previous two characters in lexicon C?1C0C1: previous, current, and next character in the lexicon Figure 2: Feature conjunctions used in experiments use feature conjunctions in both the open and closed tests, as listed Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C04-1081.txt | Citing Article:  C08-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also used lexical features consulting a dictionary: one is to check if any of the above defined character n-grams appear in a dictionary (Peng et al, 2004), and the other is to check if there are any words in the dictionary that start or end at the current character boundary.</S> | Reference Offset:  ['10','119'] | Reference Text:  <S sid = 10 ssid = >Approaches to Chinese segmentation fall roughly into two categories: heuristic dictionary-based methods and statistical machine learning methods.In dictionary-based methods, a predefined dictio nary is used along with hand-generated rules for segmenting input sequence (Wu, 1999).</S><S sid = 119 ssid = >Figure 1: Lexicons used in our experiments C?2: second previous character in lexicon C?1: previous character in lexicon C1: next character in lexicon C2: second next character in lexicon C0C1: current and next character in lexicon C?1C0: current and previous character in lexicon C?2C?1: previous two characters in lexicon C?1C0C1: previous, current, and next character in the lexicon Figure 2: Feature conjunctions used in experiments use feature conjunctions in both the open and closed tests, as listed Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C04-1081.txt | Citing Article:  P12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al, 2004).</S> | Reference Offset:  ['27','40'] | Reference Text:  <S sid = 27 ssid = >These beneficialproperties suggests that CRFs are a promising ap proach for Chinese word segmentation.New word detection is one of the most impor tant problems in Chinese information processing.Many machine learning approaches have been pro posed (Chen and Bai, 1998; Wu and Jiang, 2000; Nie et al, 1995).</S><S sid = 40 ssid = >This indicates that CRFs are a viable model for robust Chinese word segmentation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C04-1081.txt | Citing Article:  I05-3035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Different from (Peng et al, 2004), we represent the positions of a hanzi (Chinese character) with four different tags: B for a hanzi 196 that starts a word, I for a hanzi that continues the word, F for a hanzi that ends the word, S for a hanzi that occurs as a single-character word.</S> | Reference Offset:  ['96','138'] | Reference Text:  <S sid = 96 ssid = >The open features include a large word list (containing single and multiple-character words), a character list, and additional topic or part-of-speech character lexicons obtained from various sources.</S><S sid = 138 ssid = >These datasets represent four different segmentation standards.</S> | Discourse Facet:  NA | Annotator: Automatic


