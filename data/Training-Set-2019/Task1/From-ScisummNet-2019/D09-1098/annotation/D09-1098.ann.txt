Citance Number: 1 | Reference Article:  D09-1098.txt | Citing Article:  D09-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Full algorithmic details are presented in (Pantel et al, 2009).</S> | Reference Offset:  ['8','41'] | Reference Text:  <S sid = 8 ssid = >2008) and textual advertising (Chang et al. 2009).</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D09-1098.txt | Citing Article:  D09-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','183'] | Reference Text:  <S sid = 57 ssid = >Let PMI(w) denote a pointwise mutual information vector, constructed for each term as follows: PMI(w) = (pmiw1, pmiw2, ..., pmiwm), where pmiwf is the pointwise mutual information between term w and feature f: where cwf is the frequency of feature f occurring for term w, n is the number of unique terms and N is the total number of features for all terms.</S><S sid = 183 ssid = >Finally, we release to the community a testbed for experimentally analyzing automatic set expansion, which includes a large collection of nearly random entity sets extracted from Wikipedia and over 22,000 randomly sampled seed expansion trials.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D09-1098.txt | Citing Article:  D09-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >KE dis alone, a state-of-the-art distributional system implementing (Pantel et al, 2009), where the Ranker assigns scores to instances using the similarity score returned by KE dis alone.</S> | Reference Offset:  ['41','182'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 182 ssid = >We evaluated the impact of the large similarity matrix on a set expansion task and found that the Web similarity matrix gave a large performance boost over a state-of-the-art expansion algorithm using Wikipedia.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D09-1098.txt | Citing Article:  P14-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Distributional representations of words have been successfully used in many language processing tasks such as entity set expansion (Pantel et al,2009), part-of-speech (POS) tagging and chunking (Huang and Yates, 2009), ontology learning (Curran, 2005), computing semantic textual similarity (Besanc? on et al, 1999), and lexical inference (Kotlerman et al, 2012).</S> | Reference Offset:  ['8','41'] | Reference Text:  <S sid = 8 ssid = >2008) and textual advertising (Chang et al. 2009).</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D09-1098.txt | Citing Article:  P13-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To score relevant words not appearing in the database (due to incompleteness of the database or lexical variations), GUSP uses DASH (Pantel et al, 2009) to provide additional word-pair scoring based on lexical distributional similarity computed over general text corpora (Wikipedia in this case).</S> | Reference Offset:  ['12','41'] | Reference Text:  <S sid = 12 ssid = >In this paper, we propose a large-scale term similarity algorithm, based on distributional similarity, implemented in the MapReduce framework and deployed over a 200 billion word crawl of the Web.</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D09-1098.txt | Citing Article:  P13-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since case information is important for parsers and taggers, we first true cased the sentences using DASH (Pantel et al, 2009), which stores the case for each phrase in Wikipedia.</S> | Reference Offset:  ['41','137'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 137 ssid = >We then computed the similarity between all noun phrase chunks using the model of Section 3.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D09-1098.txt | Citing Article:  P10-2068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pantel et al (2009) discusses the issue of seed set size in detail, concluding that 5-20 seed words are often required for good performance.</S> | Reference Offset:  ['161','169'] | Reference Text:  <S sid = 161 ssid = >We study the impact of seed selection effect by inspecting the system performance for several randomly selected seed sets of fixed size and we find that seed set composition greatly affects performance.</S><S sid = 169 ssid = >We found that a) very small seed sets of size 1 or 2 are not sufficient for representing the intended entity set; b) 520 seeds yield on average best performance; and c) surprisingly, increasing the seed set size beyond 20 or 30 on average does not find any new correct instances.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D09-1098.txt | Citing Article:  N10-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, (Vyaset al, 2009) proposed an automatic system for improving the seeds generated by editors (Pantel et al, 2009).</S> | Reference Offset:  ['8','41'] | Reference Text:  <S sid = 8 ssid = >2008) and textual advertising (Chang et al. 2009).</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D09-1098.txt | Citing Article:  N10-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned above, (Etzioni et al, 2005) report that seed set composition affects the correctness of the harvested instances, and (Pantel et al, 2009) observe an increment of 42% precision and 39% recall between the best and worst performing seed sets for the task of entity set expansion.</S> | Reference Offset:  ['41','165'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 165 ssid = >On average, the best performing seed sets had 42% higher precision and 39% higher recall than the worst performing seed set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D09-1098.txt | Citing Article:  N10-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >According to (Pantel et al, 2009) 10 to 20 seeds are a sufficient starting set in a distributional similarity model to discover as many new correct instances as may ever be found.</S> | Reference Offset:  ['169','173'] | Reference Text:  <S sid = 169 ssid = >We found that a) very small seed sets of size 1 or 2 are not sufficient for representing the intended entity set; b) 520 seeds yield on average best performance; and c) surprisingly, increasing the seed set size beyond 20 or 30 on average does not find any new correct instances.</S><S sid = 173 ssid = >Error analysis on the Web100 corpus shows that once our model has seen 10-20 seeds, the distributional similarity model seems to have enough statistics to discover as many new correct instances as it could ever find.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D09-1098.txt | Citing Article:  C10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We computed the distributional similarity between arguments using (Pantel et al, 2009) over a large crawl of the Web (described in Section 4.1).</S> | Reference Offset:  ['41','137'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 137 ssid = >We then computed the similarity between all noun phrase chunks using the model of Section 3.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D09-1098.txt | Citing Article:  C10-2069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our last feature is the distributional similarity scores of Pantel et al (2009), as trained over Wikipedia.</S> | Reference Offset:  ['0','41'] | Reference Text:  <S sid = 0 ssid = >Web-Scale Distributional Similarity and Entity Set Expansion</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D09-1098.txt | Citing Article:  P10-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because human evaluation of word similarities is very difficult and costly, we conducted automatic evaluation in the set expansion setting, following previous studies such as Pantel et al (2009).</S> | Reference Offset:  ['41','156'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 156 ssid = >We omitted statistics from Wikipedia “List of” pages in order to not bias our evaluation to the test set described in Section 5.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D09-1098.txt | Citing Article:  W11-0315.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To obtain examples of multiple semantic categories, we utilized selected Wikipedia listOf pages from (Pantel et al, 2009) and augmented these with our own manually defined categories, such that each list contained at least ten distinct examples occurring in our corpus.</S> | Reference Offset:  ['41','142'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 142 ssid = >On average they only find 73% 5 To avoid biasing our Wikipedia corpus with the test sets, Wikipedia “List of” pages were omitted from our statistics as were any page linked to gold standard list members from “List of” pages. of the top-1000 similar terms of a random term whereas we find all of them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D09-1098.txt | Citing Article:  P11-2128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The task of this paper is entity set expansion in which the lexicons are expanded from just a few seed entities (Pantel et al, 2009).</S> | Reference Offset:  ['0','41'] | Reference Text:  <S sid = 0 ssid = >Web-Scale Distributional Similarity and Entity Set Expansion</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D09-1098.txt | Citing Article:  P11-2128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some prior studies use every word in a document/sentence as the features, such as the distributional approaches (Pantel et al, 2009).</S> | Reference Offset:  ['31','41'] | Reference Text:  <S sid = 31 ssid = >Supervised approaches (McCallum and Li 2003, Bunescu and Mooney 2004) rely on large sets of labeled examples, perform targeted extraction and employ a variety of sentence- and corpus-level features.</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D09-1098.txt | Citing Article:  C10-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >CL-Web: A state-of-the-art open domain method based on features extracted from the Web documents data set (Pantel et al, 2009).</S> | Reference Offset:  ['30','41'] | Reference Text:  <S sid = 30 ssid = >Apart from the choice of a data source, state-of-the-art entity extraction methods differ in their use of numerous, few or no labeled examples, the open or targeted nature of the extraction as well as the types of features employed.</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D09-1098.txt | Citing Article:  P10-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As (Pantel et al, 2009) show, picking seeds that yield high numbers of different terms is difficult.</S> | Reference Offset:  ['41','179'] | Reference Text:  <S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S><S sid = 179 ssid = >This study shows that only few seeds (10-20) yield best performance and that adding more seeds beyond this does not on average affect performance in a positive or negative way.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D09-1098.txt | Citing Article:  P10-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Given the seeds set S, a seeds centroid vector is produced using the surrounding word contexts (see below) of all occurrences of all the seeds in the corpus (Pantel et al 2009).</S> | Reference Offset:  ['160','176'] | Reference Text:  <S sid = 160 ssid = >Intuitively, some seeds are better than others.</S><S sid = 176 ssid = >We see that most gold standard instances are discovered with the first 5-10 seeds.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D09-1098.txt | Citing Article:  P10-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This combination was also used in (Pantel et al, 2009).</S> | Reference Offset:  ['8','41'] | Reference Text:  <S sid = 8 ssid = >2008) and textual advertising (Chang et al. 2009).</S><S sid = 41 ssid = >Etzioni et al. (2005) and Pantel et al.</S> | Discourse Facet:  NA | Annotator: Automatic


