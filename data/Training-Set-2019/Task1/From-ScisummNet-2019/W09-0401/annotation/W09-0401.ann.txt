Citance Number: 1 | Reference Article:  W09-0401.txt | Citing Article:  D09-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These systems were selected from WMT09 (Callison-Burch et al, 2009).</S> | Reference Offset:  ['5','147'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 147 ssid = >The ULC metric had the strongest correlation with human judgments in WMT08 (CallisonBurch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W09-0401.txt | Citing Article:  E12-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To identify the most suitable system for our requirements, we run a set of experiments training the three models with Europarl V4 German-English (Koehn, 2005) and optimizing and testing on the News corpus (Callison-Burch et al 2009).</S> | Reference Offset:  ['5','131'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 131 ssid = >The edited output of the best performing systems under this evaluation model were deemed acceptable around 50% of the time for French-English, English-French, EnglishSpanish, German-English, and English-German.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W09-0401.txt | Citing Article:  E12-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To train our models we use the freely available corpora (when possible): Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al 2006), DGTTM3, Opus (Tiedemann, 2009), SE-Times (Tyers and Alperen, 2010), Tehran English-Persian Parallel Corpus (Pilevar et al 2011), NewsCorpus (Callison-Burch et al 2009), UN Corpus (Rafalovitch and Dale, 2009), CzEng0.9 (Bojar and Z ?abokrtsky?, 2009), English-Persian parallel corpus distributed by ELRA4 and two ArabicEnglish datasets distributed by LDC5.</S> | Reference Offset:  ['5','41'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 41 ssid = >In addition to cleaning the sentence-aligned parallel corpus we also de-duplicated the corpus, removing all sentence pairs that occured more than once in the parallel corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W09-0401.txt | Citing Article:  E12-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We trained two SMT systems, SMT content and SMTtitle, using the Europarl V4 German-English data as training corpus, and two different development sets: one made of content sentences, News Commentaries (Callison-Burch et al 2009), and the other made of news titles in the source language which were translated into English using a commercial translation system.</S> | Reference Offset:  ['58','131'] | Reference Text:  <S sid = 58 ssid = >On the other hand, the training data used by Google is unconstrained, which means that it may have an advantage compared to the research systems evaluated in this workshop, since they were trained using only the provided materials.</S><S sid = 131 ssid = >The edited output of the best performing systems under this evaluation model were deemed acceptable around 50% of the time for French-English, English-French, EnglishSpanish, German-English, and English-German.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W09-0401.txt | Citing Article:  W10-1726.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The recent Fr-En 109 (Callison-Burch et al, 2009) corpus aggregates huge numbers of parallel French English sentences from the web.</S> | Reference Offset:  ['28','41'] | Reference Text:  <S sid = 28 ssid = >109 word parallel corpus To create the large French-English parallel corpus, we conducted a targeted web crawl of bilingual web sites.</S><S sid = 41 ssid = >In addition to cleaning the sentence-aligned parallel corpus we also de-duplicated the corpus, removing all sentence pairs that occured more than once in the parallel corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W09-0401.txt | Citing Article:  W10-1757.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Evaluation campaigns like WMT (Callison-Burch et al, 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks.</S> | Reference Offset:  ['0','5'] | Reference Text:  <S sid = 0 ssid = >Findings of the 2009 Workshop on Statistical Machine Translation</S><S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W09-0401.txt | Citing Article:  W10-1754.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We test our metrics in the setting of the WMT 2009 evaluation task (Callison-Burch et al, 2009).</S> | Reference Offset:  ['5','6'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 6 ssid = >There were three shared tasks this year: a translation task between English and five other European languages, a task to combine the output of multiple machine translation systems, and a task to predict human judgments of translation quality using automatic evaluation metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W09-0401.txt | Citing Article:  W10-1750.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we plan to repeat this experiment over other test beds with document structure, such as those from the 2009 Work shop on Statistical Machine Translation shared task (Callison-Burch et al, 2009) and the 2009 NIST MT Evaluation Campaign (Przybocki et al,2009).</S> | Reference Offset:  ['0','5'] | Reference Text:  <S sid = 0 ssid = >Findings of the 2009 Workshop on Statistical Machine Translation</S><S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W09-0401.txt | Citing Article:  W11-2108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the data collected during three Workshops on Statistical Machine Translation: WMT08 (Callison Burch et al, 2008), WMT09 (Callison-Burch et al, 2009) and WMT10 (Callison-Burch et al, 2010).</S> | Reference Offset:  ['5','147'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 147 ssid = >The ULC metric had the strongest correlation with human judgments in WMT08 (CallisonBurch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W09-0401.txt | Citing Article:  W10-1713.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results shown in the remainder of this paper are reported in terms of case insensitive BLEU which showed last year a better correlation with human judgments than case sensitive BLEU for the two languages we con sider (Callison-Burch et al, 2009).</S> | Reference Offset:  ['5','80'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 80 ssid = >The results of this are reported in Section 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W09-0401.txt | Citing Article:  W12-3709.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To train our models based on Moses we used the freely available corpora: Europarl (Koehn, 2005), JRC-Acquis (Steinberger et al, 2006), Opus (Tiedemann, 2009), News Corpus (Callison-Burch et al, 2009).</S> | Reference Offset:  ['5','26'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 26 ssid = >As in past years we provided parallel corpora to train translation models, monolingual corpora to train language models, and development sets to tune parameters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W09-0401.txt | Citing Article:  D10-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We train a baseline phrase-based French-English system using WMT-09 corpora (Callison-Burchetal., 2009) for training and evaluation.</S> | Reference Offset:  ['14','26'] | Reference Text:  <S sid = 14 ssid = >We additionally provided training data and a baseline system.</S><S sid = 26 ssid = >As in past years we provided parallel corpora to train translation models, monolingual corpora to train language models, and development sets to tune parameters.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W09-0401.txt | Citing Article:  W10-1738.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The main part of the corpus in this task consists of the Europarl corpus as used in the WMT evaluation (Callison-Burch et al, 2009), with some additional data collected in the scope of the project.</S> | Reference Offset:  ['23','41'] | Reference Text:  <S sid = 23 ssid = >Previous evaluations additionally used test sets drawn from the Europarl corpus.</S><S sid = 41 ssid = >In addition to cleaning the sentence-aligned parallel corpus we also de-duplicated the corpus, removing all sentence pairs that occured more than once in the parallel corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W09-0401.txt | Citing Article:  W10-3222.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, most evaluations of machine translation systems (Callison-Burch et al, 2009) indicate that the performance of corpus-based statistical machine translation (SMT) has come up to the traditional rule-based method.</S> | Reference Offset:  ['55','188'] | Reference Text:  <S sid = 55 ssid = >We also evaluated 7 commercial rule-based MT systems, and Google’s online statistical machine translation system.</S><S sid = 188 ssid = >This year’s evaluation also included 7 commercial rule-based MT systems and Google’s online statistical machine translation system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W09-0401.txt | Citing Article:  C10-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >There have been various evaluation metrics developed and validated for reliability in fields such as MT and summarization (Callison-Burch et al,2009).</S> | Reference Offset:  ['5','82'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 82 ssid = >We experimented with a new type of evaluation this year where we asked judges to edit the output of MT systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W09-0401.txt | Citing Article:  W11-2120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Rule-based systems could fulfill this role; they are also an attractive choice given their high quality (as judged by human evaluators) in earlier evaluations (e.g. WMT2009 (Callison-Burch et al, 2009)).</S> | Reference Offset:  ['5','55'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 55 ssid = >We also evaluated 7 commercial rule-based MT systems, and Google’s online statistical machine translation system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W09-0401.txt | Citing Article:  P11-3003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While this type of evaluation has its advantages, mainly that it is fast and cheap, its correlation with human judgments is often low, especially for translation out of English (Callison-Burch et al, 2009).</S> | Reference Offset:  ['5','147'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 147 ssid = >The ULC metric had the strongest correlation with human judgments in WMT08 (CallisonBurch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W09-0401.txt | Citing Article:  P11-3003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >I mainly take advantage of this type of evaluation as part of participating with my research group in MT 13 shared tasks with large evaluation campaigns such as WMT (e.g. Callison-Burch et al (2009)).</S> | Reference Offset:  ['5','82'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 82 ssid = >We experimented with a new type of evaluation this year where we asked judges to edit the output of MT systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W09-0401.txt | Citing Article:  W11-2110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Spearman's rank correlation coefficients on the document (system) level between all the metric sand the human ranking are computed on the English, French, Spanish, German and Czech texts generated by various translation systems in the framework of the third (Callison-Burch et al, 2008), fourth (Callison-Burch et al, 2009) and fifth (Callison-Burch et al, 2010) shared translation tasks.</S> | Reference Offset:  ['5','147'] | Reference Text:  <S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S><S sid = 147 ssid = >The ULC metric had the strongest correlation with human judgments in WMT08 (CallisonBurch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W09-0401.txt | Citing Article:  P11-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Human judgement of rank has been chosen as the official determinant of translation quality for the 2009 Workshop on Machine Translation (Callison-Burch et al, 2009).</S> | Reference Offset:  ['0','5'] | Reference Text:  <S sid = 0 ssid = >Findings of the 2009 Workshop on Statistical Machine Translation</S><S sid = 5 ssid = >This paper presents the results of the shared tasks of the 2009 EACL Workshop on Statistical Machine Translation, which builds on three previous workshops (Koehn and Monz, 2006; CallisonBurch et al., 2007; Callison-Burch et al., 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


