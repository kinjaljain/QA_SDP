Citance Number: 1 | Reference Article:  N07-1071.txt | Citing Article:  W07-1425.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Though, at least, roles of participants in the event have to be preserved by some means, such as the way presented in (Pantel et al, 2007).</S> | Reference Offset:  ['36','162'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 162 ssid = >We presented algorithms for learning what we call inferential selectional preferences, and presented evidence that learning selectional preferences can be useful in filtering out incorrect inferences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N07-1071.txt | Citing Article:  W11-2408.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This work was refined by Pantel et al (2007) by assigning the x and y terms semantic types (inferential selectional preferences - ISP) based on lexical abstraction from empirically observed argument types.</S> | Reference Offset:  ['0','161'] | Reference Text:  <S sid = 0 ssid = >ISP: Learning Inferential Selectional Preferences</S><S sid = 161 ssid = >For these cases, ISP algorithms learn many selectional preferences that accept the same types of entities as those that made DIRT learn the inference rule in the first place, hence ISP will not filter out many incorrect inferences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N07-1071.txt | Citing Article:  C10-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most distributional methods so far extract representations from large texts, and only as a follow-on step they either 1) alter these in order to reflect a disambiguated word (such as (Erk and Pado, 2008)) or 2) directly asses the appropriateness of a similarity judgment, given a specific context (such as (Pantel et al, 2007)).</S> | Reference Offset:  ['36','87'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 87 ssid = >Our first set of semantic classes was directly extracted from the output of the CBC clustering algorithm (Pantel and Lin 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N07-1071.txt | Citing Article:  C10-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Context-sensitive extensions of DIRT (Pantelet al, 2007) and (Basili et al, 2007) focus on making DIRT rules context-sensitive by attaching appropriate semantic classes to the X and Y slots of an inference rule.</S> | Reference Offset:  ['36','80'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 80 ssid = >In this paper, we focus on the inference rules contained in the DIRT resource (Lin and Pantel 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N07-1071.txt | Citing Article:  C10-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For this (Pantel et al, 2007) build a set of semantic classes using WordNet in one case and CBC clustering algorithm in the other; for each rule, they use the overlap of the fillers found in the input corpus as an indicator of the correct semantic classes.</S> | Reference Offset:  ['54','87'] | Reference Text:  <S sid = 54 ssid = >The semantic classes C(x) and C(y) can be obtained from a conceptual taxonomy as proposed in (Resnik 1996), such as WordNet, or from the classes extracted from a word clustering algorithm such as CBC (Pantel and Lin 2002).</S><S sid = 87 ssid = >Our first set of semantic classes was directly extracted from the output of the CBC clustering algorithm (Pantel and Lin 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N07-1071.txt | Citing Article:  C10-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On a common data set (Pantel et al, 2007) and (Basili et al, 2007) achieve significant improvements over DIRT at 95% confidence level when employing the clustering methods.</S> | Reference Offset:  ['6','36'] | Reference Text:  <S sid = 6 ssid = >Several important applications are already relying heavily on inference, including question answering (Moldovan et al. 2003; Harabagiu and Hickl 2006), information extraction (Romano et al.</S><S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N07-1071.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A couple of earlier works utilized a cluster-based model (Pantel et al, 2007) and an LSA-based model (Szpektor et al, 2008), in a selectional-preferences style approach.</S> | Reference Offset:  ['36','71'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 71 ssid = >Model 2: Independent Inferential Model (IIM) Our independent model is the same as the joint model above except that it computes candidate inferential SPs using the Independent Relational Model (IRM) instead of the JRM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N07-1071.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While most works on context-insensitive predicate inference rules, such as DIRT (Lin and Pantel, 2001), are based on word-level similarity measures, almost all prior models addressing context sensitive predicate inference rules are based on topic models (except for (Pantel et al, 2007), which was outperformed by later models).</S> | Reference Offset:  ['36','80'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 80 ssid = >In this paper, we focus on the inference rules contained in the DIRT resource (Lin and Pantel 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N07-1071.txt | Citing Article:  E09-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In their work on determining selectional preferences, both Resnik (1997) and Li and Abe (1998) relied on uniformly distributing observed frequencies for a given word across all its senses, an approach later followed by Pantel et al (2007).</S> | Reference Offset:  ['29','50'] | Reference Text:  <S sid = 29 ssid = >Learning SPs often relies on an underlying set of semantic classes, as in both Resnik’s and our approach.</S><S sid = 50 ssid = >In Section 3.1, we describe methods for automatically determining the semantic contexts of each single relation’s selectional preferences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N07-1071.txt | Citing Article:  E09-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Terminal nodes of the resultant structure were used as the basis for inferring semantic type restrictions, reminiscent of the use of CBC clusters (Pantel and Lin, 2002) by Pantel et al (2007), for typing the arguments of paraphrase rules.</S> | Reference Offset:  ['33','87'] | Reference Text:  <S sid = 33 ssid = >CBC (Pantel and Lin 2002).</S><S sid = 87 ssid = >Our first set of semantic classes was directly extracted from the output of the CBC clustering algorithm (Pantel and Lin 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N07-1071.txt | Citing Article:  W11-2403.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pantel et al (2007) and Szpektor et al (2008) represented the context of such rules as the intersection of preferences of the rule's LHS and RHS, namely the observed argument instantiations or their semantic classes.</S> | Reference Offset:  ['7','36'] | Reference Text:  <S sid = 7 ssid = >2006), and textual entailment (Szpektor et al. 2004).</S><S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N07-1071.txt | Citing Article:  D10-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To add the necessary context, ISP (Pantel et al, 2007) learned selectional preferences (Resnik, 1997) for DIRT's rules.</S> | Reference Offset:  ['0','66'] | Reference Text:  <S sid = 0 ssid = >ISP: Learning Inferential Selectional Preferences</S><S sid = 66 ssid = >Whereas in Section 3.1 we learned selectional preferences for the arguments of a relation p, in this section we learn selectional preferences for the arguments of an inference rule pi => pj.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N07-1071.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow Pantel et al (2007) in using automatically-extracted semantic classes to help characterize plausible arguments.</S> | Reference Offset:  ['87','143'] | Reference Text:  <S sid = 87 ssid = >Our first set of semantic classes was directly extracted from the output of the CBC clustering algorithm (Pantel and Lin 2002).</S><S sid = 143 ssid = >First, systems using the semantic classes from WordNet tend to perform less well than systems using CBC classes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N07-1071.txt | Citing Article:  D08-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >MI was also recently used for inference-rule SPs by Pantel et al (2007).</S> | Reference Offset:  ['36','38'] | Reference Text:  <S sid = 36 ssid = >TEASE1 (Szpektor et al. 2004) and DIRT (Lin and Pantel 2001).</S><S sid = 38 ssid = >Zanzotto et al. (2006) recently explored a different interplay between SPs and inferences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N07-1071.txt | Citing Article:  C08-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As a way of enriching such a template-like knowledge, Pantel et al (2007) proposed the notion of inferential selectional preference and collected expressions that would fill those slots.</S> | Reference Offset:  ['17','51'] | Reference Text:  <S sid = 17 ssid = >What is missing is knowledge about the admissible argument values for which an inference rule holds, which we call Inferential Selectional Preferences.</S><S sid = 51 ssid = >Section 3.2 uses these for developing our inferential selectional preference models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N07-1071.txt | Citing Article:  P13-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['60','164'] | Reference Text:  <S sid = 60 ssid = >Intuitively, we have more confidence in a particular candidate if its semantic classes are closely associated given the relation p. Pointwise mutual information (Cover and Thomas 1991) is a commonly used metric for measuring this association strength between two events e1 and e2: 2 In this paper, the semantic classes C(x) and C(y) are extracted from WordNet and CBC (described in Section 4.2).</S><S sid = 164 ssid = >This work constitutes a step towards better understanding of the interaction of selectional preferences and inferences, bridging these two aspects of semantics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N07-1071.txt | Citing Article:  P13-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pantel et al (2007) apply a collection of rules to filter out incorrect inferences for SP.</S> | Reference Offset:  ['20','21'] | Reference Text:  <S sid = 20 ssid = >In this paper, we propose ISP, a collection of methods for learning inferential selectional preferences and filtering out incorrect inferences.</S><S sid = 21 ssid = >The presented algorithms apply to any collection of inference rules between binary semantic relations, such as example (1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N07-1071.txt | Citing Article:  I08-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The notion of Inferential Selectional Preference (ISP) has been introduced by Pantel et al (2007).</S> | Reference Offset:  ['0','51'] | Reference Text:  <S sid = 0 ssid = >ISP: Learning Inferential Selectional Preferences</S><S sid = 51 ssid = >Section 3.2 uses these for developing our inferential selectional preference models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N07-1071.txt | Citing Article:  P12-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Pantel et al, 2007), they augment each relation with its selectional preferences, i.e. fine-grained entity types of two arguments, to handle polysemy.</S> | Reference Offset:  ['66','84'] | Reference Text:  <S sid = 66 ssid = >Whereas in Section 3.1 we learned selectional preferences for the arguments of a relation p, in this section we learn selectional preferences for the arguments of an inference rule pi => pj.</S><S sid = 84 ssid = >Too general a class will provide no discriminatory power while too fine-grained a class will offer little generalization and apply in only extremely few cases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N07-1071.txt | Citing Article:  P12-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This approach can be seen as a proxy to ISP (Pantel et al, 2007), since selectional preferences are one way of distinguishing multiple senses of a path.</S> | Reference Offset:  ['0','49'] | Reference Text:  <S sid = 0 ssid = >ISP: Learning Inferential Selectional Preferences</S><S sid = 49 ssid = >The remainder of this section describes the ISP approach.</S> | Discourse Facet:  NA | Annotator: Automatic


