Citance Number: 1 | Reference Article:  N03-1030.txt | Citing Article:  W04-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SEE allowed the judges to step through predefined units of the model summary (elementary discourse units/EDUs) (Soricut and Marcu, 2003) and for each unit of that summary, mark the sentences in the peer summary that expressed [all (4), most (3), some (2), hardly any (1) or none (0)] of the content in the current model summary unit.</S> | Reference Offset:  ['45','46'] | Reference Text:  <S sid = 45 ssid = >In this section, we present a discourse segmentation algorithm that deals with segmenting sentences into elementary discourse units.</S><S sid = 46 ssid = >The discourse segmenter proposed here takes as input a sentence and outputs its elementary discourse unit boundaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N03-1030.txt | Citing Article:  P14-2085.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Texts were segmented into clauses using SPADE (Soricut and Marcu, 2003) with some heuristic post-processing.</S> | Reference Offset:  ['42','94'] | Reference Text:  <S sid = 42 ssid = >In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).</S><S sid = 94 ssid = >This mapping leads to the notion of a dominance set over a discourse segmented lexicalized syntactic tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N03-1030.txt | Citing Article:  N07-3006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our model was trained and tested on RST-DT (2002) and achieves a performance of up to 86.12% F-Score, which is comparable to Soricut and Marcu (2003).</S> | Reference Offset:  ['36','184'] | Reference Text:  <S sid = 36 ssid = >The (RST-DT, 2002) corpus uses 110 different rhetorical relations.</S><S sid = 184 ssid = >This is even more remarkable given that the discourse corpus (RST-DT, 2002) was built with no syntactic theory in mind.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N03-1030.txt | Citing Article:  W10-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003).</S> | Reference Offset:  ['0','190'] | Reference Text:  <S sid = 0 ssid = >Sentence Level Discourse Parsing Using Syntactic And Lexical Information</S><S sid = 190 ssid = >Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N03-1030.txt | Citing Article:  P09-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since segmentation is the first stage of discourse parsing, quality discourse segments are critical to building quality discourse representations (Soricut and Marcu, 2003).</S> | Reference Offset:  ['39','157'] | Reference Text:  <S sid = 39 ssid = >We break down the problem of building sentence-level discourse trees into two sub-problems: discourse segmentation and discourse parsing.</S><S sid = 157 ssid = >The discourse parsing model uses syntactic trees produced by Charniak’s parser (2000) and discourse segments produced by the algorithm described in Section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N03-1030.txt | Citing Article:  P09-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Soricut and Marcu (2003) construct a statistical discourse segmenter as part of their sentence-level discourse parser (SPADE), the only implementation available for our comparison.</S> | Reference Offset:  ['47','136'] | Reference Text:  <S sid = 47 ssid = >Our statistical approach to sentence segmentation uses two components: a statistical model which assigns a probability to the insertion of a discourse boundary after each word in a sentence, and a segmenter, which uses the probabilities computed by the model for inserting discourse boundaries.</S><S sid = 136 ssid = >The metric we use to evaluate the discourse segmenter records the accuracy of the discourse segmenter with respect to its ability to insert inside-sentence discourse boundaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N03-1030.txt | Citing Article:  N07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Soricut and Marcu (2003) use syntactic features to identify sentence-internal RST structure.</S> | Reference Offset:  ['2','60'] | Reference Text:  <S sid = 2 ssid = >The models use syntactic and lexical features.</S><S sid = 60 ssid = >We denote such node , and the features we use are node , its parent , and the siblings of .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N03-1030.txt | Citing Article:  D09-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The test set includes only sentences for which our English parser (Soricut and Marcu, 2003) could produce a parse tree, which effectively excluded a few very long sentences.</S> | Reference Offset:  ['33','133'] | Reference Text:  <S sid = 33 ssid = >The remaining 5% of the sentences cannot be used in our approach, as no well-formed discourse tree can be associated with these sentences.</S><S sid = 133 ssid = >For this evaluation, we re-trained Charniak’s parser (2000) such that the test sentences from the discourse corpus were not seen by the syntactic parser during training.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N03-1030.txt | Citing Article:  W05-0613.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One exception is Marcu's work (Marcu, 1997, 1999) (see also Soricut and Marcu (2003) for constructing discourse structures for individual sentences).</S> | Reference Offset:  ['29','186'] | Reference Text:  <S sid = 29 ssid = >In our experiments we used as discourse structures only the discourse sub-trees spanning over individual sentences.</S><S sid = 186 ssid = >Yet, they built discourse structures at sentence level that are not only consistent with the syntactic structures of sentences, but also derivable from them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N03-1030.txt | Citing Article:  W06-1317.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Within Rhetorical Structure Theory (RST), Soricut and Marcu (2003) have developed two probabilistic models for identifying clausal elementary discourse units and generating discourse trees at the sentence level.</S> | Reference Offset:  ['1','20'] | Reference Text:  <S sid = 1 ssid = >We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S><S sid = 20 ssid = >In this paper, we introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N03-1030.txt | Citing Article:  N06-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003).</S> | Reference Offset:  ['0','190'] | Reference Text:  <S sid = 0 ssid = >Sentence Level Discourse Parsing Using Syntactic And Lexical Information</S><S sid = 190 ssid = >Another interesting finding is that the performance of current state-of-the-art syntactic parsers (Charniak, 2000) is not a bottleneck for coming up with a good solution to the sentence-level discourse parsing problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N03-1030.txt | Citing Article:  P07-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >their relation edges are obtained from the Spade system described in Soricut and Marcu (2003).</S> | Reference Offset:  ['128','143'] | Reference Text:  <S sid = 128 ssid = >Tuple ENABLEMENT-NS[2,2,3] has a score of 0.40, obtained ATTRIBUTION-SN[1,1,3] has a score of 0.37 for the structure, and a score of 0.009 for the relation.</S><S sid = 143 ssid = >We also compute the agreement between human annotators on the discourse segmentation task ( ), using the doubly-annotated discourse corpus mentioned in Section 2. described in this paper ( ) using syntactic trees produced by Charniak’s parser (2000), in comparison with the results obtained by the algorithm described in (Marcu, 2000) ( ), and baseline algorithms and , on the same test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N03-1030.txt | Citing Article:  W04-2322.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Soricut and Marcu (2003) also build up RST sentential trees to use in discourse parsing.</S> | Reference Offset:  ['1','185'] | Reference Text:  <S sid = 1 ssid = >We introduce two probabilistic models that can be used to identify elementary discourse units and build sentence-level discourse parse trees.</S><S sid = 185 ssid = >The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N03-1030.txt | Citing Article:  D07-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Though statistical methods have been used to induce such trees (Soricut and Marcu, 2003), they are not used for ordering and other text-structuring tasks.</S> | Reference Offset:  ['68','185'] | Reference Text:  <S sid = 68 ssid = >Once we have the segmenting probabilities given by the statistical model, a straightforward algorithm is used to implement the segmenter.</S><S sid = 185 ssid = >The annotators used by Carlson et al. (2003) were not instructed to build discourse trees that were consistent with the syntax of the sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N03-1030.txt | Citing Article:  P12-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Soricut and Marcu, 2003) and (Polanyi et al., 2004) implement models to perform discourse parsing.</S> | Reference Offset:  ['10','26'] | Reference Text:  <S sid = 10 ssid = >In this paper, we describe probabilistic models and algorithms that exploit the discourseannotated corpus produced by Carlson et al. (2003).</S><S sid = 26 ssid = >(See (Carlson et al., 2003) for details concerning the corpus and the annotation process.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A discourse tree (Soricut and Marcu, 2003).</S> | Reference Offset:  ['12','90'] | Reference Text:  <S sid = 12 ssid = >An example of a discourse structure is the tree given in Figure 1.</S><S sid = 90 ssid = >The overall probability of a discourse tree is obtained multiplying the structural probabilities and the relational probabilities for all the tuples in the discourse tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Soricut and Marcu (2003) introduce a statistical discourse segmenter, which is trained on RST DT to label words with boundary or no-boundary labels.</S> | Reference Offset:  ['55','56'] | Reference Text:  <S sid = 55 ssid = >Our statistical model assigns a segmenting probability for each word , where boundary, no-boundary .</S><S sid = 56 ssid = >Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Like Soricut and Marcu (2003), they formulate the discourse segmentation task as a binary classification problem of deciding whether a word is the boundary or no-boundary of EDUs.</S> | Reference Offset:  ['56','69'] | Reference Text:  <S sid = 56 ssid = >Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S><S sid = 69 ssid = >Given a syntactic tree , the algorithm inserts a boundary after each word for which boundary .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Soricut and Marcu (2003) and Subba and Di Eugenio (2007) use boundary labels, which are assigned to words at the end of EDUs.</S> | Reference Offset:  ['56','155'] | Reference Text:  <S sid = 56 ssid = >Because our model is concerned with discourse segmentation at sentence level, we define boundary , i.e., the sentence boundary is always a discourse boundary as well.</S><S sid = 155 ssid = >As mentioned in Section 2, we use both 18 labels and 110 labels for the discourse relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N03-1030.txt | Citing Article:  W12-1623.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SPADE is the work of Soricut and Marcu (2003).</S> | Reference Offset:  ['42','187'] | Reference Text:  <S sid = 42 ssid = >In the present work, elementary discourse units are taken to be clauses or clauselike units that are unequivocally the NUCLEUS or SATELLITE of a rhetorical relation that holds between two adjacent spans of text (see (Carlson et al., 2003) for details).</S><S sid = 187 ssid = >Recent work on Tree Adjoining Grammar-based lexicalized models of discourse (Forbes et al., 2001) has already shown how to exploit within a single framework lexical, syntactic, and discourse cues.</S> | Discourse Facet:  NA | Annotator: Automatic


