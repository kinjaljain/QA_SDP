Citance Number: 1 | Reference Article:  C08-1107.txt | Citing Article:  D09-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since we acquire verb entailment pairs based on unary templates (Szpektor and Dagan, 2008) we used the Lin formula to acquire unary templates directly rather than using the DIRT formula, which is the arithmetic-geometric mean of Lin's similarities for two slots in a binary template.</S> | Reference Offset:  ['0','44'] | Reference Text:  <S sid = 0 ssid = >Learning Entailment Rules for Unary Templates</S><S sid = 44 ssid = >The DIRT algorithm(Lin and Pantel, 2001) learns non-directional binary rules for templates that are paths in a depen dency parse-tree between two noun variables X and Y . The similarity between two templates t and t ? is the geometric average: DIRT (t, t ? ) = ? Lin x (t, t ? ) ? Lin y (t, t ? ) where Lin xis the Lin similarity between X?s in stantiations of t and X?s instantiations of t ? in a corpus (equivalently for Lin y ).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C08-1107.txt | Citing Article:  D09-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Szpektor and Dagan (2008) proposed a directional similarity measure called BInc (Balanced Inclusion) that consists of Lin and Precision, as BInc (l, r)=? Lin (l, r)? Precision (l, r) 1173where l and r are the target templates.</S> | Reference Offset:  ['44','109'] | Reference Text:  <S sid = 44 ssid = >The DIRT algorithm(Lin and Pantel, 2001) learns non-directional binary rules for templates that are paths in a depen dency parse-tree between two noun variables X and Y . The similarity between two templates t and t ? is the geometric average: DIRT (t, t ? ) = ? Lin x (t, t ? ) ? Lin y (t, t ? ) where Lin xis the Lin similarity between X?s in stantiations of t and X?s instantiations of t ? in a corpus (equivalently for Lin y ).</S><S sid = 109 ssid = >BInc identifies entail ing templates based on a directional measure but penalizes infrequent templates using a symmetric measure: BInc(l, r) = ? Lin(l, r) ? Precision(l, r) 3.4 Deriving Unary Rules From Binary Rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C08-1107.txt | Citing Article:  D09-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Szpektor and Dagan (2008) also proposed a unary template, which is defined as a template consisting of one argument slot and one predicate phrase.</S> | Reference Offset:  ['70','106'] | Reference Text:  <S sid = 70 ssid = >3.2 Unary Template Structure.</S><S sid = 106 ssid = >If an in frequent template has common instantiations with another template, the coverage of its features istypically high, whether or not an entailment relation exists between the two templates.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C08-1107.txt | Citing Article:  D09-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We define a unary template as a template consisting of one argument slot and one predicate, following Szpektor and Dagan (2008).</S> | Reference Offset:  ['70','112'] | Reference Text:  <S sid = 70 ssid = >3.2 Unary Template Structure.</S><S sid = 112 ssid = >First, for each binary rule, we generate all possible unary rules that are part of that rule (each unary template is extracted following the same procedure describedin Section 3.2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C08-1107.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >DC follows the double conditioned contextualized similarity measure according to Equation 4, as implemented by (Ritter et al, 2010), while SC follows the single conditioned one at Equation 5, as implemented by (Dinu and Lapata, 2010b; Dinu and Lapata, 2010a). Since our model can contextualize various distributional similarity measures, we evaluated the performance of all the above methods on several base similarity measures and their learned rule sets, namely Lin (Lin, 1998), BInc (Szpektor and Dagan, 2008) and vector Cosine similarity.</S> | Reference Offset:  ['44','101'] | Reference Text:  <S sid = 44 ssid = >The DIRT algorithm(Lin and Pantel, 2001) learns non-directional binary rules for templates that are paths in a depen dency parse-tree between two noun variables X and Y . The similarity between two templates t and t ? is the geometric average: DIRT (t, t ? ) = ? Lin x (t, t ? ) ? Lin y (t, t ? ) where Lin xis the Lin similarity between X?s in stantiations of t and X?s instantiations of t ? in a corpus (equivalently for Lin y ).</S><S sid = 101 ssid = >We first adaptedDIRT for unary templates (unary-DIRT, apply ing Lin-similarity to the single feature vector), as well as its output filtering by LEDIR.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C08-1107.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Binc (Szpektor and Dagan, 2008) is a directional similarity measure between word vectors, which outperformed Lin for predicate inference (Szpek tor and Dagan, 2008).</S> | Reference Offset:  ['34','109'] | Reference Text:  <S sid = 34 ssid = >Various measures wereproposed in the literature for assessing such simi larity between two words, u and v. Given a word q, its set of features F q and feature weights w q (f) for f ? F q , a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u, v) = ? f?F u ?F v [w u (f) + w v (f)] ? f?F u w u (f) + ? f?F v w v (f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: w q (f) = log[ Pr(f |q) Pr(f) ].</S><S sid = 109 ssid = >BInc identifies entail ing templates based on a directional measure but penalizes infrequent templates using a symmetric measure: BInc(l, r) = ? Lin(l, r) ? Precision(l, r) 3.4 Deriving Unary Rules From Binary Rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C08-1107.txt | Citing Article:  P10-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >argument mapping by decomposing templates with several arguments into unary ones (Szpektor and Dagan, 2008).</S> | Reference Offset:  ['0','190'] | Reference Text:  <S sid = 0 ssid = >Learning Entailment Rules for Unary Templates</S><S sid = 190 ssid = >Such rules are leaned because many binary templates have a more complex structure than paths between arguments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C08-1107.txt | Citing Article:  D09-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ArgumentMappedWordNet (AmWN): A resource for entailment rules between verbal and nominal predicates (Szpektor and Dagan, 2009), including their argument mapping, based on WordNet and NomLex plus (Meyers et al, 2004), verified statistically through intersection with the unary-DIRT algorithm (Szpektor and Dagan, 2008).</S> | Reference Offset:  ['20','147'] | Reference Text:  <S sid = 20 ssid = >(Lin and Pantel, 2001; Szpektor et al, 2004; Sekine, 2005).</S><S sid = 147 ssid = >All rules were learned in canonical form (Szpektor and Dagan, 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C08-1107.txt | Citing Article:  W11-0202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Szpektor and Dagan (2008) use the distributional similarity of arguments to detect unary template entailment, whilst Berant et al (2010) apply it to binary relations in focused entailment graphs.</S> | Reference Offset:  ['0','59'] | Reference Text:  <S sid = 0 ssid = >Learning Entailment Rules for Unary Templates</S><S sid = 59 ssid = >Most unsupervised rule learning algorithms focused on learning binary entailment rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C08-1107.txt | Citing Article:  W09-2504.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['69','222'] | Reference Text:  <S sid = 69 ssid = >The second approach,which was also mentioned in (Iftene and Balahur Dobrescu, 2007), derives unary rules from learned binary rules.</S><S sid = 222 ssid = >Acknowledgements This work was partially supported by ISF grant 1095/05, the IST Programme of the EuropeanCommunity under the PASCAL Network of Ex cellence IST-2002-506778 and the NEGEV project (www.negev-initiative.org).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C08-1107.txt | Citing Article:  W09-2504.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow here the experimental setup presented in (Szpektor and Dagan, 2008), testing the generated rules on the ACE 2005 event dataset 6. This.</S> | Reference Offset:  ['122','171'] | Reference Text:  <S sid = 122 ssid = >Following (Szpektor et al, 2008), we found the ACE 2005 event training set 2useful for this pur pose.</S><S sid = 171 ssid = >is also generated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C08-1107.txt | Citing Article:  W09-2504.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Adjuncts (time and 6http: //projects.ldc.upenn.edu/ace/ 7 Only 26 frequent event types that correspond to a unique predicate were tested, following (Szpektor and Dagan, 2008).</S> | Reference Offset:  ['122','124'] | Reference Text:  <S sid = 122 ssid = >Following (Szpektor et al, 2008), we found the ACE 2005 event training set 2useful for this pur pose.</S><S sid = 124 ssid = >2 http://projects.ldc.upenn.edu/ace/ 852All event mentions are annotated in the corpus, in cluding the instantiated arguments of the predicate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C08-1107.txt | Citing Article:  S12-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Algorithms for computing semantic textual similarity (STS) are relevant for a variety of applications, including in formation extraction (Szpektor and Dagan, 2008), question answering (Harabagiu and Hickl, 2006) and machine translation (Mirkin et al, 2009).</S> | Reference Offset:  ['5','16'] | Reference Text:  <S sid = 5 ssid = >In many NLP applications, such as Question An swering (QA) and Information Extraction (IE), it is crucial to recognize whether a specific target meaning is inferred from a text.</S><S sid = 16 ssid = >(Romano et al, 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C08-1107.txt | Citing Article:  D12-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >apply BInc (Szpektor and Dagan, 2008), to compute for every verb pair a similarity score between each of the five count vectors.</S> | Reference Offset:  ['46','116'] | Reference Text:  <S sid = 46 ssid = >(Ravichandran and Hovy, 2002; Szpektor et al, 2004; Sekine, 2005).Directional Measures Most rule learning meth ods apply a symmetric similarity measure between two templates, viewing them as paraphrasing eachother.</S><S sid = 116 ssid = >The score of each generated rule is set to be the score of the original binary rule.The same unary rule can be derived from different binary rules.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C08-1107.txt | Citing Article:  P10-1124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We consider two similarity functions: The Lin (2001) similarity measure, and the Balanced Inclusion (BInc) similarity measure (Szpektor and Dagan, 2008).</S> | Reference Offset:  ['4','220'] | Reference Text:  <S sid = 4 ssid = >In addition, a novel directional similarity measure for learning entailment, termed Balanced-Inclusion, is the best performing measure.</S><S sid = 220 ssid = >In addition, the Balanced-Inclusion measure outperformed all other tested methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C08-1107.txt | Citing Article:  P10-1124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, we obtained similarity lists learned by Linand Pantel (2001), and replicated 3 similarity measures learned by Szpektor and Dagan (2008), over the RCV1corpus7.</S> | Reference Offset:  ['20','147'] | Reference Text:  <S sid = 20 ssid = >(Lin and Pantel, 2001; Szpektor et al, 2004; Sekine, 2005).</S><S sid = 147 ssid = >All rules were learned in canonical form (Szpektor and Dagan, 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C08-1107.txt | Citing Article:  W12-4006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Szpektor and Dagan, 2008), two approaches for unsupervised learning of unary rules (i.e. between templates with a single variable) are investigated. In (Zhao et al, 2009), a pivot approach for extracting paraphrase patterns from bilingual parallel corpora is presented, while in (Callison-Burch,2008) the quality of paraphrase extraction from parallel corpora is improved by requiring that phrases and their paraphrases have the same syntactic type. Our approach is different from theirs in many respects: their goal is paraphrase extraction, while we are extracting directional entailment rules; as textual resources for pattern extraction they use parallel corpora (using patterns in another language as pivots), while we rely on monolingual Wikipedia revisions (taking benefit from its increasing size); the para phrases they extract are more similar to DIRT, while our approach allows to focus on the acquisition of rules for specific phenomena frequent in entailment pairs, and not covered by other resources.</S> | Reference Offset:  ['1','214'] | Reference Text:  <S sid = 1 ssid = >Most work on unsupervised entailment rule acquisition focused on rules between templates with two variables, ignoring unary rules - entailment rules betweentemplates with a single variable.</S><S sid = 214 ssid = >We presented two approaches for unsupervised ac quisition of unary entailment rules from regular (non-comparable) corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C08-1107.txt | Citing Article:  P09-2018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, (Szpektor and Dagan, 2008) tried identifying the entailment relation between lexical-syntactic templates using WeedsPrec, but observed that it tends to promote unreliable relations involving infrequent templates.</S> | Reference Offset:  ['0','131'] | Reference Text:  <S sid = 0 ssid = >Learning Entailment Rules for Unary Templates</S><S sid = 131 ssid = >Templatesare matched using a syntactic matcher that han dles simple morpho-syntactic phenomena, as in (Szpektor and Dagan, 2007).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C08-1107.txt | Citing Article:  P09-2018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we adopt the balancing approach in (Szpektor and Dagan, 2008), which, as explained in Section 2, penalizes similarity for infrequent words having fewer features (4 th property) (in our version, we truncated LIN similarity lists after top 1000 words).</S> | Reference Offset:  ['34','35'] | Reference Text:  <S sid = 34 ssid = >Various measures wereproposed in the literature for assessing such simi larity between two words, u and v. Given a word q, its set of features F q and feature weights w q (f) for f ? F q , a common symmetric similarity measure is Lin similarity (Lin, 1998a): Lin(u, v) = ? f?F u ?F v [w u (f) + w v (f)] ? f?F u w u (f) + ? f?F v w v (f) where the weight of each feature is the pointwise mutual information (pmi) between the word and the feature: w q (f) = log[ Pr(f |q) Pr(f) ].</S><S sid = 35 ssid = >Weeds and Weir (2003) proposed to measure thesymmetric similarity between two words by av eraging two directional (asymmetric) scores: the coverage of each word?s features by the other.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C08-1107.txt | Citing Article:  P11-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008).</S> | Reference Offset:  ['147','152'] | Reference Text:  <S sid = 147 ssid = >All rules were learned in canonical form (Szpektor and Dagan, 2007).</S><S sid = 152 ssid = >No threshold setting mechanism is suggested inthe literature for the scores of the different algo rithms, especially since rules for different right hand side templates have different score ranges.</S> | Discourse Facet:  NA | Annotator: Automatic


