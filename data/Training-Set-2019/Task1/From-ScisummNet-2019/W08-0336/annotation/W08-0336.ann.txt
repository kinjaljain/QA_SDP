Citance Number: 1 | Reference Article:  W08-0336.txt | Citing Article:  W09-0436.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chinese word segmentation is done by the Stanford Chinese segmenter (Chang et al, 2008).</S> | Reference Offset:  ['66','105'] | Reference Text:  <S sid = 66 ssid = >The MaxMatch segmenter is a simple and common baseline for the Chinese word segmentation task.</S><S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W08-0336.txt | Citing Article:  P12-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The most obvious example of this lies in languages that do not separate words with white space such as Chinese, Japanese, or Thai, in which the choice of a segmentation standard has a large effect on translation accuracy (Chang et al., 2008).</S> | Reference Offset:  ['9','11'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 11 ssid = >Chinese information retrieval (IR) systems benefit from a segmentation that breaks compound words into shorter “words” (Peng et al., 2002), paralleling the IR gains from compound splitting in languages like German (Hollink et al., 2004), whereas automatic speech recognition (ASR) systems prefer having longer words in the speech lexicon (Gao et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W08-0336.txt | Citing Article:  P11-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It has been recognized that varying segmentation granularities are needed for SMT (Chang et al, 2008).</S> | Reference Offset:  ['10','105'] | Reference Text:  <S sid = 10 ssid = >It has been recognized that different NLP applications have different needs for segmentation.</S><S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W08-0336.txt | Citing Article:  D10-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >All Chinese data was re-segmented with the CRF-based Stanford Chinese segmenter (Chang et al, 2008) that is trained on the segmentation of the Chinese Treebank for consistency.</S> | Reference Offset:  ['9','105'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W08-0336.txt | Citing Article:  P09-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Chinese text was segmented with a CRF-based Chinesesegmenter optimized for MT (Chang et al, 2008).</S> | Reference Offset:  ['105','149'] | Reference Text:  <S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S><S sid = 149 ssid = >Since the word segmentation standard under consideration (Chinese Treebank (Xue et al., 2005)) was neither specifically designed nor optimized for MT, it seems reasonable to investigate whether any segmentation granularity in continuum between character-level and CTB-style segmentation is more effective for MT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W08-0336.txt | Citing Article:  P09-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chinese words were automatically segmented with a conditional random field (CRF) classifier (Chang et al, 2008) that conforms to the Chinese Treebank (CTB) standard.</S> | Reference Offset:  ['9','149'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 149 ssid = >Since the word segmentation standard under consideration (Chinese Treebank (Xue et al., 2005)) was neither specifically designed nor optimized for MT, it seems reasonable to investigate whether any segmentation granularity in continuum between character-level and CTB-style segmentation is more effective for MT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W08-0336.txt | Citing Article:  P14-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These models are conducive to MT to some extent, since they commonly have relatively good aggregate performance and segmentation consistency (Chang et al, 2008). But one outstanding problem is that these models may leave out some crucial segmentation features for SMT, since the output words conform to the tree bank segmentation standard designed for monolingually linguistic intuition, rather than specific to the SMT task.</S> | Reference Offset:  ['8','144'] | Reference Text:  <S sid = 8 ssid = >Without a standardized notion of a word, traditionally, the task of Chinese word segmentation starts from designing a segmentation standard based on linguistic and task intuitions, and then aiming to building segmenters that output words that conform to the standard.</S><S sid = 144 ssid = >Note that consistency is only one of the competing factors of how good a segmentation is for MT performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W08-0336.txt | Citing Article:  P14-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chang et al (2008) enhanced a CRF s segmentation model in MT tasks by tuning the word granularity and improving the segmentation consistence.</S> | Reference Offset:  ['105','149'] | Reference Text:  <S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S><S sid = 149 ssid = >Since the word segmentation standard under consideration (Chinese Treebank (Xue et al., 2005)) was neither specifically designed nor optimized for MT, it seems reasonable to investigate whether any segmentation granularity in continuum between character-level and CTB-style segmentation is more effective for MT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W08-0336.txt | Citing Article:  P14-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chang et al (2008) described constraint driven learning (CODL) that augments model learning on unlabeled data by adding a cost for violating expectations of constraint features designed by domain knowledge.</S> | Reference Offset:  ['23','170'] | Reference Text:  <S sid = 23 ssid = >Unless these issues are attended to, simple baseline segmenters can be more effective inside an MT system than more complex machine learning based models, with much lower word segmentation error rate.</S><S sid = 170 ssid = >The linguistic features help capturing words that were unseen to the segmenter; while the lexicon-based features constrain the segmenter with external knowledge of what sequences are likely to be words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W08-0336.txt | Citing Article:  P14-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The optimal set of the model parameter values was found on dev MT to be k= 3, t AC= 0.0 and t COOC= 15. The comparison candidates also involve two popular off-the-shelf segmentation models: Stanford Segmenter: this model, trained by Chang et al (2008), treats CWS as a binary word boundary decision task.</S> | Reference Offset:  ['106','158'] | Reference Text:  <S sid = 106 ssid = >(2004), who treated word segmentation as a binary decision task.</S><S sid = 158 ssid = >We chose the λ0 = 2 on another dev set (MT02).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W08-0336.txt | Citing Article:  D09-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Zhang et al (2008b) and Chang et al (2008) show that get ting the tokenization of one of the languages in the corpus close to a gold standard does not necessarily help with building better machine translation systems.</S> | Reference Offset:  ['9','11'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 11 ssid = >Chinese information retrieval (IR) systems benefit from a segmentation that breaks compound words into shorter “words” (Peng et al., 2002), paralleling the IR gains from compound splitting in languages like German (Hollink et al., 2004), whereas automatic speech recognition (ASR) systems prefer having longer words in the speech lexicon (Gao et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W08-0336.txt | Citing Article:  D09-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The third and fourth tokenizations come from the CRF-based Stanford Chinese segmenter described by Chang et al (2008).</S> | Reference Offset:  ['105','121'] | Reference Text:  <S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S><S sid = 121 ssid = >More details of CRF-Lex will be described in Section 5.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W08-0336.txt | Citing Article:  D09-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This affirms our be lief that consistency in tokenization is important for machine translation, which was also mentioned by Chang et al (2008).</S> | Reference Offset:  ['0','3'] | Reference Text:  <S sid = 0 ssid = >Optimizing Chinese Word Segmentation for Machine Translation Performance</S><S sid = 3 ssid = >We find that other factors such as segmentation consistency and granularity of Chinese “words” can be more important for machine translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W08-0336.txt | Citing Article:  W10-1760.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The use of monolingual probabilistic models does not necessarily yield a better MT performance (Chang et al, 2008).</S> | Reference Offset:  ['2','119'] | Reference Text:  <S sid = 2 ssid = >In this paper, we demonstrate that optimizing segmentation for an existing segmentation standard does not always yield better MT performance.</S><S sid = 119 ssid = >(ii) a higher F measure segmenter does not necessarily outperforms on the MT task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W08-0336.txt | Citing Article:  W12-4207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['59','189'] | Reference Text:  <S sid = 59 ssid = >The training data for the segmenter is two orders of magnitude smaller than for the MT system, it is not terribly well matched to it in terms of genre and variety, and the information an MT system learns about alignment of Chinese to English might be the basis for a task appropriate segmentation style for Chinese-English MT.</S><S sid = 189 ssid = >This paper is based on work funded in part by the Defense Advanced Research Projects Agency through IBM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W08-0336.txt | Citing Article:  P12-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >we first segmented the sentences using the Stanford Chinese Word Segmenter (Chang et al, 2008).</S> | Reference Offset:  ['105','133'] | Reference Text:  <S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S><S sid = 133 ssid = >For example, for a word “ABC” in the gold segmentation, we look at how it is segmented with a segmenter.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W08-0336.txt | Citing Article:  P13-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We tokenized the English with packages from the Stan ford Parser (Klein and Manning, 2003) according to the Penn Treebank standard (Marcus et al, 1993), the Arabic with the Stanford Arabic segmenter (Green and DeNero, 2012) according to the Penn Arabic Treebank standard (Maamouri et al, 2008), and the Chinese with the Stanford Chinese segmenter (Chang et al, 2008) according to the Penn Chinese Treebank standard (Xue et al, 2005).</S> | Reference Offset:  ['9','149'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 149 ssid = >Since the word segmentation standard under consideration (Chinese Treebank (Xue et al., 2005)) was neither specifically designed nor optimized for MT, it seems reasonable to investigate whether any segmentation granularity in continuum between character-level and CTB-style segmentation is more effective for MT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W08-0336.txt | Citing Article:  P14-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For English corpora, the pre-processing are the same as that in (Qiu et al, 2009), and for Chinese corpora, the Stanford Word Segmenter (Changet al, 2008) is used to perform word segmentation.</S> | Reference Offset:  ['9','105'] | Reference Text:  <S sid = 9 ssid = >One widely used standard is the Penn Chinese Treebank (CTB) Segmentation Standard (Xue et al., 2005).</S><S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W08-0336.txt | Citing Article:  D09-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Chinese text was segmented with a CRF-based Chinese segmenter optimized for MT (Chang et al, 2008), and the English text was parsed using the Stanford parser (Klein and Manning, 2003).</S> | Reference Offset:  ['47','59'] | Reference Text:  <S sid = 47 ssid = >The MT system used in this paper is Moses, a stateof-the-art phrase-based system (Koehn et al., 2003).</S><S sid = 59 ssid = >The training data for the segmenter is two orders of magnitude smaller than for the MT system, it is not terribly well matched to it in terms of genre and variety, and the information an MT system learns about alignment of Chinese to English might be the basis for a task appropriate segmentation style for Chinese-English MT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W08-0336.txt | Citing Article:  P13-1167.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A variety of segmentation granularities, or atomic units, exist, including segmentations at the morpheme (e.g., Sirts and Alumae 2012), word (e.g., Chang et al 2008), sentence (e.g., Reynar and Ratnaparkhi 1997), and paragraph (e.g., Hearst 1997) levels.</S> | Reference Offset:  ['82','105'] | Reference Text:  <S sid = 82 ssid = >Having words as the basic units helps the reordering model.</S><S sid = 105 ssid = >CRF is a statistical sequence modeling framework introduced by Lafferty et al. (2001), and was first used for the Chinese word segmentation task by Peng et al.</S> | Discourse Facet:  NA | Annotator: Automatic


