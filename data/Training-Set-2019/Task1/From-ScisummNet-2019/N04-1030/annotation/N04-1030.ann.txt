Citance Number: 1 | Reference Article:  N04-1030.txt | Citing Article:  C04-1197.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Note that the result here is not comparable with the best in this domain (Pradhan et al., 2004) where the full parse tree is assumed given.</S> | Reference Offset:  ['38','194'] | Reference Text:  <S sid = 38 ssid = >Path ? The syntactic path through the parse tree from the parse constituent to the predicate being classified.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N04-1030.txt | Citing Article:  P14-2124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N04-1030.txt | Citing Article:  P07-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Using this intuition, state-of-the-art systems first build a parse tree, and syntactic constituents are then labeled by feeding hand-built features extracted from the parse tree to a machine learning system, e.g. the ASSERT system (Pradhan et al, 2004).</S> | Reference Offset:  ['38','195'] | Reference Text:  <S sid = 38 ssid = >Path ? The syntactic path through the parse tree from the parse constituent to the predicate being classified.</S><S sid = 195 ssid = >Surdeanu et al (2003) report results on two systems using a decision tree classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N04-1030.txt | Citing Article:  P07-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N04-1030.txt | Citing Article:  P07-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compared our system to the freely available Assert system (Pradhan et al, 2004).</S> | Reference Offset:  ['18','194'] | Reference Text:  <S sid = 18 ssid = >A larger, cleaner, completely adjudicated version of PropBank was made available in Feb 2004.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N04-1030.txt | Citing Article:  P07-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Because ASSERT uses a parser, and because PropBank was built by labeling the nodes of a hand-annotated parse tree, per node accuracy is usually reported in papers such as (Pradhan et al, 2004).</S> | Reference Offset:  ['29','74'] | Reference Text:  <S sid = 29 ssid = >Each node in the parse tree can be classified as eitherone that represents a semantic argument (i.e., a NONNULL node) or one that does not represent any seman tic argument (i.e., a NULL node).</S><S sid = 74 ssid = >Table 2shows the performance of the parser on the task of identifying and labeling semantic arguments using the hand corrected parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N04-1030.txt | Citing Article:  P07-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We measured the argument classification accuracy of our network, assuming the correct segmentation is given to our system, as in (Pradhan et al, 2004), by post-processing our per-word tags to form a majority vote over each segment.</S> | Reference Offset:  ['160','194'] | Reference Text:  <S sid = 160 ssid = >However, we found that there was an improve ment in the CORE ARGUMENT accuracy on the combined task of identifying and assigning semantic arguments, given hand-corrected parses, whereas the accuracy of the ADJUNCTIVE ARGUMENTS slightly deteriorated.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N04-1030.txt | Citing Article:  I08-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For these reasons, we use a semantic role labeler (Pradhan et al, 2004) to provide and delimit the text spans that contain the semantic arguments of a predicate.</S> | Reference Offset:  ['27','194'] | Reference Text:  <S sid = 27 ssid = >The problem of shallow semantic parsing can be viewed as three different tasks.Argument Identification ? This is the process of identi fying parsed constituents in the sentence that represent semantic arguments of a given predicate.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N04-1030.txt | Citing Article:  C10-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To compute the semantic roles for the source trees, we use an in-house max-ent classifier with features following Xue and Palmer (2004) and Pradhan et al (2004).</S> | Reference Offset:  ['50','194'] | Reference Text:  <S sid = 50 ssid = >We formulate the parsing problem as a multi-class clas sification problem and use a Support Vector Machine (SVM) classifier (Hacioglu et al, 2003; Pradhan et al2003).</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N04-1030.txt | Citing Article:  P05-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Examples are linearly interpolated relative frequency models (Gildea and Jurafsky, 2002), SVMs (Pradhan et al, 2004), decision trees (Surdeanu et al, 2003), and log-linear models (Xue and Palmer, 2004).</S> | Reference Offset:  ['8','194'] | Reference Text:  <S sid = 8 ssid = >In recent work, a number of researchers have cast thisproblem as a tagging problem and have applied vari ous supervised machine learning techniques to it (Gildea and Jurafsky (2000, 2002); Blaheta and Charniak (2000); Gildea and Palmer (2002); Surdeanu et al (2003); Gildea and Hockenmaier (2003); Chen and Rambow (2003); Fleischman and Hovy (2003); Hacioglu and Ward (2003); Thompson et al (2003); Pradhan et al (2003)).</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N04-1030.txt | Citing Article:  P05-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N04-1030.txt | Citing Article:  W11-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N04-1030.txt | Citing Article:  P07-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N04-1030.txt | Citing Article:  P11-2051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We adopted the ASSERT English SRL labeler (Pradhan et al, 2004), which was trained on PropBank data using SVM classifier.</S> | Reference Offset:  ['194','195'] | Reference Text:  <S sid = 194 ssid = >The Surdeanu et al System.</S><S sid = 195 ssid = >Surdeanu et al (2003) report results on two systems using a decision tree classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N04-1030.txt | Citing Article:  D07-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They use ASSERT (Pradhan et al, 2004), a publicly available shallow semantic parser trained on PropBank, to generate predicate-argument structures which subsequently form the basis of comparison between question and answer sentences.</S> | Reference Offset:  ['171','194'] | Reference Text:  <S sid = 171 ssid = >To evaluate this scenario, we used the Charniak parser (Chaniak, 2001) to generate parses for PropBank training and test data.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N04-1030.txt | Citing Article:  I08-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For semantic analysis, we used the ASSERT toolkit (Pradhan et al, 2004) that produces shallow semantic parses using the PropBank conventions.</S> | Reference Offset:  ['0','20'] | Reference Text:  <S sid = 0 ssid = >Shallow Semantic Parsing Using Support Vector Machines</S><S sid = 20 ssid = >PropBank was constructed by assigning semantic arguments to constituents of the hand-corrected TreeBank parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N04-1030.txt | Citing Article:  D09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned by (Pradhan et al, 2004), argument identification plays a bottleneck role in improving the performance of a SRL system.</S> | Reference Offset:  ['96','194'] | Reference Text:  <S sid = 96 ssid = >Partial Path ? For the argument identification task,.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N04-1030.txt | Citing Article:  W07-2018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A crucial difference from similar approaches, such as SRL with PropBank roles (Pradhan et al, 2004) is that by identifying relations as part of a frame, you have identified a gestalt of relations that enables far more inference, and sentences from the same passage that use other words from the same frame will be easier to link together.</S> | Reference Offset:  ['13','194'] | Reference Text:  <S sid = 13 ssid = >We will be reporting on results using PropBank1 (Kingsbury et al, 2002), a 300k-word corpus in which predi cate argument relations are marked for part of the verbsin the Wall Street Journal (WSJ) part of the Penn Tree Bank (Marcus et al, 1994).</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N04-1030.txt | Citing Article:  W06-1603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A pair of sentences is first fed to a syntactic parser (Charniak, 2000) and then passed to a semantic role labeler (ASSERT; (Pradhan et al, 2004)), to label predicate argument tuples.</S> | Reference Offset:  ['12','194'] | Reference Text:  <S sid = 12 ssid = >We evaluate results using both hand corrected TreeBank syntactic parses, and actual parses from the Charniak parser.</S><S sid = 194 ssid = >The Surdeanu et al System.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N04-1030.txt | Citing Article:  D08-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['78','252'] | Reference Text:  <S sid = 78 ssid = >7.2 New Features.</S><S sid = 252 ssid = >We would like to thank Ralph Weischedel and Scott Miller ofBBN Inc. for letting us use their named entity tagger ? Iden tiFinder; Martha Palmer for providing us with the PropBank data, Valerie Krugler for tagging the AQUAINT test set with PropBank arguments, and all the anonymous reviewers for their helpful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


