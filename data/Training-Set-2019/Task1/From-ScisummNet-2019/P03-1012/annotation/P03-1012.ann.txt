Citance Number: 1 | Reference Article:  P03-1012.txt | Citing Article:  N03-2017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The details of this algorithm are described in (Cherry and Lin, 2003).</S> | Reference Offset:  ['155','190'] | Reference Text:  <S sid = 155 ssid = >The initial (02) row is the score for the algorithm (described in Section 4.1) that generates our initial alignment.</S><S sid = 190 ssid = >The alignment algorithm described here is incapable of creating alignments that are not one-to-one.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P03-1012.txt | Citing Article:  W06-2904.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Cherry and Lin, 2003) exploited such cohesion between the dependency structures to improve the quality of word alignment of parallel sentences.</S> | Reference Offset:  ['0','38'] | Reference Text:  <S sid = 0 ssid = >A Probability Model To Improve Word Alignment</S><S sid = 38 ssid = >Instead it takes both sentences as given, and uses the sentences to determine an alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P03-1012.txt | Citing Article:  H05-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Cherry and Lin, 2003) recently proposed a direct alignment formulation and state that it would be straightforward to estimate the parameters given a supervised alignment corpus.</S> | Reference Offset:  ['9','111'] | Reference Text:  <S sid = 9 ssid = >In addition to the IBM models, researchers have proposed a number of alternative alignment methods.</S><S sid = 111 ssid = >A state in this space is a partial alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P03-1012.txt | Citing Article:  H05-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in (Cherryand Lin, 2003), the above functions simplify the conditioning portion, h by utilizing only the words and context involved in the link li.</S> | Reference Offset:  ['40','52'] | Reference Text:  <S sid = 40 ssid = >We will refer to consecutive subsets of A as lji = {li, li+1, ... , lj}.</S><S sid = 52 ssid = >Note that both the context Ck and the link lk imply the occurrence of eik and fjk.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P03-1012.txt | Citing Article:  H05-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The basic intuition behind this feature is that words inside prepositional phrases tend to align, which is similar to the dependency structure feature of (Cherry and Lin, 2003).</S> | Reference Offset:  ['58','107'] | Reference Text:  <S sid = 58 ssid = >For any co-occurring pair of words (eik, fjk), we check whether it has the feature ft.</S><S sid = 107 ssid = >The word pair (thea, l') will have an active adjacency feature fta(+1, +1, host) as well as a dependency feature ftd(−1, det).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P03-1012.txt | Citing Article:  W05-0812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This parser has been used in a much different alignment model (Cherry and Lin, 2003).</S> | Reference Offset:  ['35','75'] | Reference Text:  <S sid = 35 ssid = >We propose here a system which models P(A|E, F) directly, using a different decomposition of terms.</S><S sid = 75 ssid = >We will describe the features used in our implementation of this model in Section 3.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P03-1012.txt | Citing Article:  P06-2092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, researchers like Cherry and Lin (2003) have begun to use syntactic analyses to guide and restrict the word alignment process.</S> | Reference Offset:  ['7','187'] | Reference Text:  <S sid = 7 ssid = >Since their introduction, many researchers have become interested in word alignments as a knowledge source.</S><S sid = 187 ssid = >There have been many recent proposals to leverage syntactic data in word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P03-1012.txt | Citing Article:  W05-0801.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, our work is similar to that of Cherry and Lin (2003) in our use of the conditional probability of a link given the co-occurrence of the linked words.</S> | Reference Offset:  ['41','173'] | Reference Text:  <S sid = 41 ssid = >Given this notation, P(A|E, F) can be decomposed as follows: Here P(lk|eik, fjk) is link probability given a cooccurrence of the two words, which is similar in spirit to Melamed’s explicit noise model (Melamed, 2000).</S><S sid = 173 ssid = >In our work, we use the probabilities directly.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P03-1012.txt | Citing Article:  C04-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','203'] | Reference Text:  <S sid = 63 ssid = >This ordering can be arbitrary as long as the same ordering is used in training1 and probability evaluation.</S><S sid = 203 ssid = >Our experiments show that this model can be an effective tool for improving an existing word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P03-1012.txt | Citing Article:  C04-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Cherry and Lin, 2003) a probability model Pr (aJ1 | fJ1, eI1) is used, which is symmetric per definition.</S> | Reference Offset:  ['22','75'] | Reference Text:  <S sid = 22 ssid = >In this section we describe our probability model.</S><S sid = 75 ssid = >We will describe the features used in our implementation of this model in Section 3.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P03-1012.txt | Citing Article:  H05-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These approaches include an enhanced HMM alignment model that uses part-of speech tags (Toutanova et al, 2002), a log-linear combination of IBM translation models and HMM models (Och and Ney, 2003), techniques that rely on dependency relations (Cherry and Lin, 2003), and a log-linear combination of IBM Model 3 alignment probabilities, POS tags, and bilingual dictionary coverage (Liu et al, 2005).</S> | Reference Offset:  ['145','188'] | Reference Text:  <S sid = 145 ssid = >Table 2 compares the results of our algorithm with the results in (Och and Ney, 2000), where an HMM model is used to bootstrap IBM Model 4.</S><S sid = 188 ssid = >Methods such as (Wu, 1997), (Alshawi et al., 2000) and (Lopez et al., 2002) employ a synchronous parsing procedure to constrain a statistical alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P03-1012.txt | Citing Article:  W07-0715.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our model extends to phrase alignment the concept of a sentence pair generating a word alignment developed by Cherry and Lin (2003).</S> | Reference Offset:  ['3','15'] | Reference Text:  <S sid = 3 ssid = >We present a statistical model for computing the probability of an alignment given a sentence pair.</S><S sid = 15 ssid = >This model allows us to compute the probability of an alignment for a given sentence pair.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P03-1012.txt | Citing Article:  W04-3207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, inspired by these intuitive notions of translational correspondence, Cherry and Lin (2003) include dependency features in a word alignment model to improve non-syntactic baseline systems.</S> | Reference Offset:  ['0','12'] | Reference Text:  <S sid = 0 ssid = >A Probability Model To Improve Word Alignment</S><S sid = 12 ssid = >It has been shown that once a baseline alignment has been created, one can improve results by using a refined scoring metric that is based on the alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P03-1012.txt | Citing Article:  H05-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','203'] | Reference Text:  <S sid = 63 ssid = >This ordering can be arbitrary as long as the same ordering is used in training1 and probability evaluation.</S><S sid = 203 ssid = >Our experiments show that this model can be an effective tool for improving an existing word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P03-1012.txt | Citing Article:  P05-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cherry and Lin (2003) developed a statistical model to find word alignments, which allow easy integration of context-specific features.</S> | Reference Offset:  ['4','202'] | Reference Text:  <S sid = 4 ssid = >This model allows easy integration of context-specific features.</S><S sid = 202 ssid = >This model allows easy integration of context-specific features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P03-1012.txt | Citing Article:  P06-2014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cherry and Lin (2003) use the phrasal cohesion of a dependency tree as a constraint on a beam search aligner.</S> | Reference Offset:  ['91','126'] | Reference Text:  <S sid = 91 ssid = >The cohesion constraint requires that this induced dependency tree does not have any crossing dependencies.</S><S sid = 126 ssid = >Our use of the one-to-one constraint and the cohesion constraint precludes sampling directly from all possible alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P03-1012.txt | Citing Article:  W03-0302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More details on the probability model used by ProAlign are available in (Cherry and Lin, 2003).</S> | Reference Offset:  ['22','75'] | Reference Text:  <S sid = 22 ssid = >In this section we describe our probability model.</S><S sid = 75 ssid = >We will describe the features used in our implementation of this model in Section 3.2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P03-1012.txt | Citing Article:  D10-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most other researchers take either the HMM alignments (Liang et al, 2006) or IBM Model 4 alignments (Cherry and Lin, 2003) as input and perform post-processing, whereas our model is a potential replacement for the HMM and IBM Model 4.</S> | Reference Offset:  ['145','147'] | Reference Text:  <S sid = 145 ssid = >Table 2 compares the results of our algorithm with the results in (Och and Ney, 2000), where an HMM model is used to bootstrap IBM Model 4.</S><S sid = 147 ssid = >The row IBM-4 Intersect shows the results obtained by taking the intersection of the alignments produced by IBM-4 E→F and IBM-4 F→E.</S> | Discourse Facet:  NA | Annotator: Automatic


