Citance Number: 1 | Reference Article:  W06-1639.txt | Citing Article:  D07-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In (Thomas et al, 2006), the authors use the transcripts of debates from the US Congress to automatically classify speeches as supporting or opposing a given topic by taking advantage of the voting records of the speakers.</S> | Reference Offset:  ['1','43'] | Reference Text:  <S sid = 1 ssid = >We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation.</S><S sid = 43 ssid = >We extracted from GovTrack all available transcripts of U.S. floor debates in the House of Representatives for the year 2005 (3268 pages of transcripts in total), together with voting records for all roll-call votes during that year.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-1639.txt | Citing Article:  P14-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >votes on the bill under discussion (Thomas et al, 2006).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-1639.txt | Citing Article:  P12-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Thomas et al, 2006), or personal preferences for topics (Grimmer, 2009) would enrich the model and better illuminate the interaction of influence and topic.</S> | Reference Offset:  ['122','141'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 141 ssid = >Or, we could even attempt to model relationships between topics or concepts, in a kind of extension of collaborative filtering.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-1639.txt | Citing Article:  N12-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thomas et al (2006) achieved accuracies of 71.3% by using speaker agreement information in the graph-based MinCut/Maxflow algorithm, as compared to accuracies around 70% via an an SVM classifier operating on content alone.</S> | Reference Offset:  ['37','121'] | Reference Text:  <S sid = 37 ssid = >The enhanced accuracies are obtained via a fairly primitive automatically-acquired “agreement detector” and a conceptually simple method for integrating isolated-document and agreement-based information.</S><S sid = 121 ssid = >Moreover, and crucially, it is very clear that using agreement information, encoded as preferences within our graph-based approach rather than as hard constraints, yields substantial improvements on both the development and test set; this, we believe, is our most important finding.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-1639.txt | Citing Article:  P14-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The same applies to the task of subgroup detection (as done by (AbuJbara et al., 2012), (Anand et al, 2011) or (Thomas et al, 2006)) . In order to produce a finer-grained model of positions, we want to develop a model that places positions stated in text along a one-dimensional scale, as done by (Slapin and Proksch, 2008) with their system called Wordfish, (Gabel and Huber, 2000), (Laver and Garry, 2000), (Laver et al, 2003) or (Sim et al, 2013).</S> | Reference Offset:  ['25','134'] | Reference Text:  <S sid = 25 ssid = >Agrawal et al. (2003)).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-1639.txt | Citing Article:  P14-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Instead of selecting sentences from the manifesto that cover a topic, the position could be extracted from the manifesto using topic models, as shown in (Thomas et al, 2006) and (Gerrish and Blei, 2011).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-1639.txt | Citing Article:  D12-1119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our second dataset is taken from segments of speech from United States Congress floor debates, first introduced by Thomas et al (2006).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-1639.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, like other cascaded approaches (e.g., Thomas et al (2006), Mao and Lebanon (2006)), it can be difficult to control how errors propagate from the sentence-level subtask to the main document classification task.</S> | Reference Offset:  ['18','134'] | Reference Text:  <S sid = 18 ssid = >In particular, since we treat each individual speech within a debate as a single “document”, we are considering a version of document-level sentiment-polarity classification, namely, automatically distinguishing between positive and negative documents (Das and Chen, 2001; Pang et al., 2002; Turney, 2002; Dave et al., 2003).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-1639.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also use the U.S. Congressional floor debates transcripts from Thomas et al (2006).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Get Out The Vote: Determining Support Or Opposition From Congressional Floor-Debate Transcripts</S><S sid = 1 ssid = >We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-1639.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For our experiments, we evaluate our methods using the speaker based speech-segment classification setting as described in Thomas et al (2006). Datasets in the required format for SVMsle are available at http: //www.cs.cornell.edu/ ?ainur/data.html.</S> | Reference Offset:  ['39','110'] | Reference Text:  <S sid = 39 ssid = >This section outlines the main steps of the process by which we created our corpus (download site: www.cs.cornell.edu/home/llee/data/convote.html).</S><S sid = 110 ssid = >In particular, as an alternative to using same-speaker links, we tried a speaker-based approach wherein the way we determine the initial individual-document classification score for each speech segment uttered by a person p in a given debate is to run an SVM on the concatenation of all of p’s speech segments within that debate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-1639.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the other setting described in Thomas et al (2006) (segment-based speech-segment classification), around 39% of 1051 Table 1: Summary of the experimental results for the Movie Reviews (top) and U.S. Congressional Floor Debates (bottom) datasets using SVMsle, SVMslew/ Prior and SVMslefs with and without proximity features.</S> | Reference Offset:  ['47','101'] | Reference Text:  <S sid = 47 ssid = >Each speech segment was labeled by the vote (“yea” or “nay”) cast for the proposed bill by the person who uttered the speech segment.</S><S sid = 101 ssid = >Using relationship information Applying an SVM to classify each speech segment in isolation leads to clear improvements over the two baseline methods, as demonstrated in Table 4.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-1639.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['55','149'] | Reference Text:  <S sid = 55 ssid = >In this section, we discuss the specific classification framework that we adopt and the set of mechanisms that we propose for modeling specific types of relationships.</S><S sid = 149 ssid = >Any opinions, findings, and conclusions or recommendations expressed are those of the authors and do not necessarily reflect the views or official policies, either expressed or implied, of any sponsoring institutions, the U.S. government, or any other entity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-1639.txt | Citing Article:  W12-3710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thomas et al (2006) presented a method based on support vector machines to determine whether the speeches made by participants represent support or opposition to proposed legislation, using transcripts of U.S. congressional floor debates.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Get Out The Vote: Determining Support Or Opposition From Congressional Floor-Debate Transcripts</S><S sid = 1 ssid = >We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-1639.txt | Citing Article:  W12-3710.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our aggregation technique does, however, presuppose consistency of opinions, in a similar way to Thomas et al (2006).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-1639.txt | Citing Article:  D12-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thomas et al 2006 address the same problem of determining support and opposition as applied to congressional floor-debates.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Get Out The Vote: Determining Support Or Opposition From Congressional Floor-Debate Transcripts</S><S sid = 1 ssid = >We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-1639.txt | Citing Article:  D12-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first baseline is based on the work of (Thomas et al 2006).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-1639.txt | Citing Article:  D12-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the speaker agreement component presented in (Thomas et al 2006) as a baseline.</S> | Reference Offset:  ['80','126'] | Reference Text:  <S sid = 80 ssid = >These labels are then used to train an SVM classifier, the output of which is subsequently used to create weights on agreement links in the test set as follows.</S><S sid = 126 ssid = >Detecting agreement We used a simple method to learn to identify cross-speaker references indicating agreement.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-1639.txt | Citing Article:  W12-3712.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other work that has considered different discourse functions in sentiment analysis, have experimented on detecting arguments (Somasundaran et al, 2007) and the stance of political debates (Thomas et al, 2006).</S> | Reference Offset:  ['122','131'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 131 ssid = >Previous sentiment-analysis work in different domains has considered inter-document similarity (Agarwal and Bhattacharyya, 2005; Pang and Lee, 2005; Goldberg and Zhu, 2006) or explicit inter-document references in the form of hyperlinks (Agrawal et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-1639.txt | Citing Article:  P13-1066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Stances in online debates: Somasundaran and Wiebe (2009), Thomas et al (2006), Bansal et al (2008), Burfoot et al (2011), and Anand et al (2011) proposed methods to recognize stances in on line debates.</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-1639.txt | Citing Article:  P13-1066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Burfoot et al, (2011) builds on the work of (Thomas et al, 2006) and proposes collective classification using speaker contextual features (e.g., speaker intentions based on vote labels).</S> | Reference Offset:  ['122','134'] | Reference Text:  <S sid = 122 ssid = >Politically-oriented text Sentiment analysis has specifically been proposed as a key enabling technology in eRulemaking, allowing the automatic analysis of the opinions that people submit (Shulman et al., 2005; Cardie et al., 2006; Kwon et al., 2006).</S><S sid = 134 ssid = >Recently, several alternative, often quite sophisticated approaches to collective classification have been proposed (Neville and Jensen, 2000; Lafferty et al., 2001; Getoor et al., 2002; Taskar et al., 2002; Taskar et al., 2003; Taskar et al., 2004; McCallum and Wellner, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


