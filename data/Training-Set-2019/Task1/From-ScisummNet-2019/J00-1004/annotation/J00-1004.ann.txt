Citance Number: 1 | Reference Article:  J00-1004.txt | Citing Article:  P01-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wu (1997) and Alshawi et al (2000) showed statistical models based on syntactic structure.</S> | Reference Offset:  ['54','121'] | Reference Text:  <S sid = 54 ssid = >In the transducers produced by the training method described in this paper, the source and target positions are in the set {-1, 0,1}, though we have also used handcoded transducers (Alshawi and Xia 1997) and automatically trained transducers (Alshawi and Douglas 2000) with a larger range of positions.</S><S sid = 121 ssid = >Brown et al. 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J00-1004.txt | Citing Article:  W05-0904.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Dependency trees were found to correspond better across translation pairs than constituent trees by Fox (2002), and form the basis of the machine translation systems of Alshawi et al (2000).</S> | Reference Offset:  ['66','87'] | Reference Text:  <S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S><S sid = 87 ssid = >These model parameters can be used to generate pairs of synchronized dependency trees starting with the topmost nodes of the two trees and proceeding recursively to the leaves.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J00-1004.txt | Citing Article:  N03-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a different approach that is based on dependency tree transformations, see Alshawi et al (2000).</S> | Reference Offset:  ['66','209'] | Reference Text:  <S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S><S sid = 209 ssid = >At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J00-1004.txt | Citing Article:  W03-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yamada and Knight (2000, 2001) and Alshawi et al (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finite state head transducers respectively.</S> | Reference Offset:  ['0','54'] | Reference Text:  <S sid = 0 ssid = >Learning Dependency Translation Models As Collections Of Finite-State Head Transducers</S><S sid = 54 ssid = >In the transducers produced by the training method described in this paper, the source and target positions are in the set {-1, 0,1}, though we have also used handcoded transducers (Alshawi and Xia 1997) and automatically trained transducers (Alshawi and Douglas 2000) with a larger range of positions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J00-1004.txt | Citing Article:  P03-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Methods such as (Wu, 1997), (Alshawi et al, 2000) and (Lopez et al, 2002) employ a synchronous parsing procedure to constrain a statistical alignment.</S> | Reference Offset:  ['121','209'] | Reference Text:  <S sid = 121 ssid = >Brown et al. 1993).</S><S sid = 209 ssid = >At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J00-1004.txt | Citing Article:  P09-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Alshawi et al (2000) and Hwa et al (2005) explore transfer of deeper syntactic structure: dependency grammars.</S> | Reference Offset:  ['121','209'] | Reference Text:  <S sid = 121 ssid = >Brown et al. 1993).</S><S sid = 209 ssid = >At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J00-1004.txt | Citing Article:  P02-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other statistical machine translation systems such as (Wu, 1997) and (Alshawi et al, 2000) also produce a tree given a sentence.</S> | Reference Offset:  ['66','210'] | Reference Text:  <S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S><S sid = 210 ssid = >1993) for training translation systems automatically.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J00-1004.txt | Citing Article:  P03-2041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The latter are small and simple (Alshawi et al, 2000): tree nodes are words, and there need be no other structure to recover or align.</S> | Reference Offset:  ['67','121'] | Reference Text:  <S sid = 67 ssid = >A dependency tree for a sentence, in the sense of dependency grammar (for example Hays [1964] and Hudson [1984]), is a tree in which the words of the sentence appear as nodes (we do not have terminal symbols of the kind used in phrase structure grammar).</S><S sid = 121 ssid = >Brown et al. 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J00-1004.txt | Citing Article:  P03-2041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, the binary-branching SCFGs used by Wu (1997) and Alshawi et al (2000) are strictly less powerful than STSG.</S> | Reference Offset:  ['54','121'] | Reference Text:  <S sid = 54 ssid = >In the transducers produced by the training method described in this paper, the source and target positions are in the set {-1, 0,1}, though we have also used handcoded transducers (Alshawi and Xia 1997) and automatically trained transducers (Alshawi and Douglas 2000) with a larger range of positions.</S><S sid = 121 ssid = >Brown et al. 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J00-1004.txt | Citing Article:  N03-2017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Methods such as (Wu, 1997), (Alshawi et al, 2000) and (Lopez et al, 2002) employ a synchronous parsing procedure to constrain a statistical alignment.</S> | Reference Offset:  ['121','209'] | Reference Text:  <S sid = 121 ssid = >Brown et al. 1993).</S><S sid = 209 ssid = >At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J00-1004.txt | Citing Article:  P05-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Alshawi et al, 2000) represents each production in parallel dependency trees as a finite-state transducer.</S> | Reference Offset:  ['0','23'] | Reference Text:  <S sid = 0 ssid = >Learning Dependency Translation Models As Collections Of Finite-State Head Transducers</S><S sid = 23 ssid = >The dependency transduction model produces synchronized dependency trees in which each local tree is produced by a head transducer.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J00-1004.txt | Citing Article:  P05-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Along similar lines, Alshawi et al (2000) treat translation as a process of simultaneous induction of source and target dependency trees using head transduction; again, no separate parser is used.</S> | Reference Offset:  ['62','66'] | Reference Text:  <S sid = 62 ssid = >In this section we describe dependency transduction models, which can be used for machine translation and other transduction tasks.</S><S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J00-1004.txt | Citing Article:  W06-3601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Although hybrid approaches, such as dependency grammars augmented with phrase-structure information (Alshawi et al., 2000), can do re-ordering easily.</S> | Reference Offset:  ['69','121'] | Reference Text:  <S sid = 69 ssid = >The source and target dependency trees derived by a dependency transduction model are ordered, i.e., there is an ordering on the nodes of each local tree.</S><S sid = 121 ssid = >Brown et al. 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J00-1004.txt | Citing Article:  P03-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Alshawi et al (2000) also presented a two-level arranged word ordering and chunk ordering by a hierarchically organized collection of finite state transducers.</S> | Reference Offset:  ['63','69'] | Reference Text:  <S sid = 63 ssid = >These models consist of a collection of head transducers that are applied hierarchically.</S><S sid = 69 ssid = >The source and target dependency trees derived by a dependency transduction model are ordered, i.e., there is an ordering on the nodes of each local tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J00-1004.txt | Citing Article:  P03-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wu (1997) showed that restricting word-level alignments between sentence pairs to observe syntactic bracketing constraints significantly reduces the complexity of the alignment problem and allows a polynomial-time solution. Alshawi et al (2000) also induce parallel tree structures from unbracketed parallel text, modeling the generation of each node's children with a finite-state transducer.</S> | Reference Offset:  ['68','148'] | Reference Text:  <S sid = 68 ssid = >In such a tree, the parent of a node is its head and the child of a node is the node's dependent.</S><S sid = 148 ssid = >This procedure has 0(n6) complexity in the number of words in the source (or target) sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J00-1004.txt | Citing Article:  W04-1503.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In a somewhat related manner, Alshawi et al (2000) use cascaded head automata to derive dependency trees, but leave the nature of the cascading under-formalized.</S> | Reference Offset:  ['66','73'] | Reference Text:  <S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S><S sid = 73 ssid = >Head transducers and dependency transduction models are thus related as follows: Each pair of local trees produced by a dependency transduction derivation is the result of a head transducer derivation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J00-1004.txt | Citing Article:  W02-0705.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is described in Alshawi et al (2000b).</S> | Reference Offset:  ['121','209'] | Reference Text:  <S sid = 121 ssid = >Brown et al. 1993).</S><S sid = 209 ssid = >At the same time, we believe our method has advantages over the approach developed initially at IBM (Brown et al. 1990; Brown et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J00-1004.txt | Citing Article:  W04-3207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wu (1997) and Alshawi et al (2000) used unsupervised learning on parallel text to induce syntactic analysis that was useful for their respective applications in phrasal translation extraction and speech translation, though not necessarily similar to what a human annotator would select.</S> | Reference Offset:  ['0','177'] | Reference Text:  <S sid = 0 ssid = >Learning Dependency Translation Models As Collections Of Finite-State Head Transducers</S><S sid = 177 ssid = >These metrics, simple accuracy and translation accuracy, are used to compare the target string produced by the system against a reference human translation from held-out data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J00-1004.txt | Citing Article:  W04-1513.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Alshawi et al, 2000) extended the tree-based approach by representing each production in parallel dependency trees as a finite-state transducer.</S> | Reference Offset:  ['23','66'] | Reference Text:  <S sid = 23 ssid = >The dependency transduction model produces synchronized dependency trees in which each local tree is produced by a head transducer.</S><S sid = 66 ssid = >In the case of machine translation, the transducers derive pairs of dependency trees, a source language dependency tree and a target dependency tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J00-1004.txt | Citing Article:  W01-1404.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The input to our algorithm is a corpus consisting of pairs of sentences related by an hierarchical alignment (Alshawi et al, 2000).</S> | Reference Offset:  ['135','149'] | Reference Text:  <S sid = 135 ssid = >Of course, translations of phrases are not always transparently related by a hierarchical alignment.</S><S sid = 149 ssid = >In Alshawi and Douglas (2000) we describe a version of the alignment algorithm in which heads may have an arbitrary number of dependents, and in which the hierarchical alignments for the training corpus are refined by iterative reestimation.</S> | Discourse Facet:  NA | Annotator: Automatic


