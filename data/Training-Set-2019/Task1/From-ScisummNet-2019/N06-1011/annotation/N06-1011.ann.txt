Citance Number: 1 | Reference Article:  N06-1011.txt | Citing Article:  W06-1672.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow the recent work of (Klementiev and Roth 2006) who addressed the problem of discovery of transliterated named entities from comparable corpora and suggested that alignment may not be necessary for transliteration.</S> | Reference Offset:  ['0','145'] | Reference Text:  <S sid = 0 ssid = >Named Entity Transliteration And Discovery From Multilingual Comparable Corpora</S><S sid = 145 ssid = >In this work, we only consider single word Named Entities.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','157'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 157 ssid = >This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','157'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 157 ssid = >This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','157'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 157 ssid = >This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','157'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 157 ssid = >This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','157'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 157 ssid = >This research is supported by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program and a DOI grant under the Reflex program.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compared our algorithm to two models described in (Klementiev and Roth, 2006b) one uses only phonetic similarity and the second also considers temporal cooccurrence similarity when ranking the transliteration candidates.</S> | Reference Offset:  ['28','61'] | Reference Text:  <S sid = 28 ssid = >We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.</S><S sid = 61 ssid = >It then uses temporal alignment (with thresholding) to select the best transliteration candidate for the next round of training (lines 8, and 9).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N06-1011.txt | Citing Article:  N09-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This configuration is equivalent to the model used in (Klementiev and Roth, 2006b).</S> | Reference Offset:  ['32','87'] | Reference Text:  <S sid = 32 ssid = >Finally, pairs of NEs and the best candidates are used to iteratively train the transliteration model.</S><S sid = 87 ssid = >This model is called the infinite attribute model (Blum, 1992) and it follows the perceptron version in SNoW (Roth, 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We adopt a methodology parallel to that of [Klementiev and Roth, 2006], but we focus instead on mining parallel named entity transliteration pairs, using a well-trained linear classifier to identify transliteration pairs.</S> | Reference Offset:  ['0','24'] | Reference Text:  <S sid = 0 ssid = >Named Entity Transliteration And Discovery From Multilingual Comparable Corpora</S><S sid = 24 ssid = >Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, [Klementiev and Roth, 2006] outlined an approach by leveraging the availability of article aligned news corpora between English and Russian, and tools in English, for discovering transliteration pairs between the two languages, and progressively refining the discovery process.</S> | Reference Offset:  ['7','90'] | Reference Text:  <S sid = 7 ssid = >We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.</S><S sid = 90 ssid = >We ran experiments using a bilingual comparable English-Russian news corpus we built by crawling a Russian news web site (www.lenta.ru).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in [Klementiev and Roth, 2006] no language specific knowledge was used to refine our mining process, making the approach broadly applicable.</S> | Reference Offset:  ['138','140'] | Reference Text:  <S sid = 138 ssid = >This approach is specific to Russian morphology, and would have to be altered for other languages.</S><S sid = 140 ssid = >We expect that language specific knowledge used to discover accurate equivalence classes would result in performance improvements.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this section, we outline briefly the methodology presented in [Klementiev and Roth, 2006], and refer interested readers to the source for details.</S> | Reference Offset:  ['44','134'] | Reference Text:  <S sid = 44 ssid = >In the rest of the paper, whenever we refer to a Named Entity, we imply an NE equivalence class.</S><S sid = 134 ssid = >We developed a linear discriminative transliteration model, and presented a method to automatically generate features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We start with comparable corpora in English and Tamil, similar in size to that used in [Klementiev and Roth, 2006], and using the English side of this corpora, first, we extract all the NEs that occur more than a given threshold parameter, FE, using a standard NER tool.</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >Named Entity Transliteration And Discovery From Multilingual Comparable Corpora</S><S sid = 15 ssid = >The first observation is that NEs in one language in such corpora tend to co-occur with their counterparts in the other.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N06-1011.txt | Citing Article:  I08-6004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While we adopted a methodology similar to that in [Klementiev and Roth, 2006], our focus was on mining parallel NE transliteration pairs, leveraging the availability of comparable corpora and a well-trained linear classifier to identify transliteration pairs.</S> | Reference Offset:  ['0','24'] | Reference Text:  <S sid = 0 ssid = >Named Entity Transliteration And Discovery From Multilingual Comparable Corpora</S><S sid = 24 ssid = >Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N06-1011.txt | Citing Article:  N10-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, several techniques for mining name transliterations from monolingual and comparable corpora have been studied (Pasternack and Roth, 2009), (Goldwasser and Roth, 2008), (Klementiev and Roth, 2006), (Sproat et al, 2006), (Udupa et al, 2009b).</S> | Reference Offset:  ['54','57'] | Reference Text:  <S sid = 54 ssid = >For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and English-Korean generative transliteration models, respectively.</S><S sid = 57 ssid = >The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N06-1011.txt | Citing Article:  N10-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Character unigrams and bigrams were used as features to learn a discriminative transliteration model and time series similarity was combined with the transliteration similarity model (Klementiev and Roth, 2006).</S> | Reference Offset:  ['28','58'] | Reference Text:  <S sid = 28 ssid = >We use a Discrete Fourier Transform (Arfken, 1985) based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.</S><S sid = 58 ssid = >We make use of it here too, to learn a discriminative transliteration model that requires little knowledge of the target language.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N06-1011.txt | Citing Article:  D08-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al, 2008).</S> | Reference Offset:  ['2','12'] | Reference Text:  <S sid = 2 ssid = >Most current approaches employ machine learning techniques and require supervised data.</S><S sid = 12 ssid = >On the other hand, comparable multilingual data (such as multilingual news streams) are increasingly available (see section 4).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N06-1011.txt | Citing Article:  D08-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al, 2006) and train a discriminative classifier.</S> | Reference Offset:  ['54','57'] | Reference Text:  <S sid = 54 ssid = >For example, (AbdulJaleel and Larkey, 2003; Jung et al., 2000) train English-Arabic and English-Korean generative transliteration models, respectively.</S><S sid = 57 ssid = >The discriminative learning framework argued for in (Roth, 1998; Roth, 1999) as an alternative to generative models is now used widely in NLP, even in the context of word alignment (Taskar et al., 2005; Moore, 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N06-1011.txt | Citing Article:  D08-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function.</S> | Reference Offset:  ['65','83'] | Reference Text:  <S sid = 65 ssid = >We use a method called the F-index (Hetland, 2004) to implement the similarity function on line 8 of the algorithm.</S><S sid = 83 ssid = >We use the perceptron (Rosenblatt, 1958) algorithm to train the model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N06-1011.txt | Citing Article:  D08-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages.</S> | Reference Offset:  ['49','134'] | Reference Text:  <S sid = 49 ssid = >The use of similarity of time distributions for information extraction, in general, and NE extraction, in particular, is not new.</S><S sid = 134 ssid = >We developed a linear discriminative transliteration model, and presented a method to automatically generate features.</S> | Discourse Facet:  NA | Annotator: Automatic


