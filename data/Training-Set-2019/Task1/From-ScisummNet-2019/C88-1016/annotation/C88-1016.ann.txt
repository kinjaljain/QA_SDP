Citance Number: 1 | Reference Article:  C88-1016.txt | Citing Article:  C90-3063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Consider, for example, the following sentence, taken from the Hansard corpus of the proceedings of the Canadian parliament [Brown et al 1988]: (1) They know full well that the companies held tax money aside for collection later on the b~sis that the government said it was going to collect it.</S> | Reference Offset:  ['15','198'] | Reference Text:  <S sid = 15 ssid = >I l l  particular, we have chosen to work with the English and French languages because we were able to obtain the biqingual l lansard corpus of proceedings of the Canadian parliament containing 30 million words of text [8].</S><S sid = 198 ssid = >this he did several hours later.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C88-1016.txt | Citing Article:  W12-0209.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Parallel corpora have received a lot of attention since the advent of statistical machine translation (Brown et al, 1988) where they serve as training material for the underlying alignment models.</S> | Reference Offset:  ['106','165'] | Reference Text:  <S sid = 106 ssid = >Carry out steps 1 and 2 for all sentence pairs of tile training text.</S><S sid = 165 ssid = >Fcrguson, Ed., ltldden Marker Models for Speech.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C88-1016.txt | Citing Article:  H05-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The most successful translation models that are found in the literature exploit finite-state machinery. The approach started with the so-called IBM models (Brown et al, 1988), implementing a set of elementary operations, such as movement, duplication and translation, that independently act on individual words in the source sentence.</S> | Reference Offset:  ['5','52'] | Reference Text:  <S sid = 5 ssid = >The steps of the proposed translation process are: (1) Partition the source text into a set of fixed locutioris.</S><S sid = 52 ssid = >Initially set C(e~,f) = 0 for words et.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C88-1016.txt | Citing Article:  P01-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Developing a better TM is a fundamental issue for those applica tions. Researchers at IBM first described such a statistical TM in (Brown et al, 1988).</S> | Reference Offset:  ['4','108'] | Reference Text:  <S sid = 4 ssid = >Fundamental to the technique is a complex glossary of correspondence of fixed locutions.</S><S sid = 108 ssid = >Forttmately, the difficulty can be alleviated by use of itcrative re-estimation, which is a technique that starts out by guessing the values of unknown quantities and gradually re-adjusts them so as to account better and better for given data [ 11 ].</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C88-1016.txt | Citing Article:  P98-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most algorithms for bilingual word alignment to date have been based on the probabilistic translation models first proposed by Brown et al (1988, 1990), especially Model I and Model 2.</S> | Reference Offset:  ['86','127'] | Reference Text:  <S sid = 86 ssid = >Our procedure will be based on a model (an admittedly crude one) of how Ertgtish words are generated from their French counterparts.</S><S sid = 127 ssid = >It should be noted that while English / French translation is quite k)cal (as illustrated by the alignment of Figure 1), the model leading to (4.1) did not take advantage of this affinity of the two languages: tile relative position of the word translate pairs ill their respective selltences was not taken into account.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C88-1016.txt | Citing Article:  P06-2037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brown et al (1988) suggested that MT can be statistically approximated to the transmission of information through a noisy channel.</S> | Reference Offset:  ['52','183'] | Reference Text:  <S sid = 52 ssid = >Initially set C(e~,f) = 0 for words et.</S><S sid = 183 ssid = >Dcmpstcr, N.M.l.aird, al/d It.B.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C88-1016.txt | Citing Article:  W04-3225.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned above, the MDI2B model is closely related to the IBM2 model (Brown et al, 1988).</S> | Reference Offset:  ['86','95'] | Reference Text:  <S sid = 86 ssid = >Our procedure will be based on a model (an admittedly crude one) of how Ertgtish words are generated from their French counterparts.</S><S sid = 95 ssid = >This model of generation ofEnglish words from French ones then requires the specification of the following quantities: 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C88-1016.txt | Citing Article:  C94-1084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the field of eomputationa.1 linguistics, mutual information [Brown et al, 1988],  2 [Church and Hanks, 1990], or a likelihood ratio test [Dunning, 199a] are suggested.</S> | Reference Offset:  ['72','76'] | Reference Text:  <S sid = 72 ssid = >The above normalization may seem arbitrary, but it has a sound underpinning from the field of Information Theory [ 10].</S><S sid = 76 ssid = >One might, for instance, find the pair e, f with the highest mutual information, criminate e~ and f from all corresponding sentences in which they occur (i.e.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C88-1016.txt | Citing Article:  W03-0309.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In general a statistical machine translation system is composed of three components: a language model, a translation model, and a decoder (Brown et al, 1988). The language model tells how probable a given sentence is in the source language, the translation model indicates how likely it is that a particular target sentence is a translation of a given source sentence, and the decoder is what actually takes a source sentence as input and produces its translation as output.</S> | Reference Offset:  ['36','47'] | Reference Text:  <S sid = 36 ssid = >While the only way to refute the many weighty objections to our ideas woukl be to construct a machine that actually carries out satisfactory translation, some mitigating comments are ill order, 7 l We do not hope to partition uniquely the source sentence into locutions.</S><S sid = 47 ssid = >Laying aside for the time being the desirability of (idiomatic) word cluster - to - word cluster translation, what we areafter at first is to find for each word f in the (French) source language the list of words {e~, e2 ..... e,} of the (English) target language into which f can translate, and the probability P(e, I f  ) that such a translation takes place.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C88-1016.txt | Citing Article:  W06-1654.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is the task of finding for a word in one language words of a similar meaning in a second language. The results of this can be used to aid manual construction of resources or directly aid translation. This task was first approached as a distributional similarity-like problem by Brown et al (1988).</S> | Reference Offset:  ['17','47'] | Reference Text:  <S sid = 17 ssid = >Our approach eschews the use of an internmdiate ,nechalfism (language) that would encode the "meaning" of tile source text.</S><S sid = 47 ssid = >Laying aside for the time being the desirability of (idiomatic) word cluster - to - word cluster translation, what we areafter at first is to find for each word f in the (French) source language the list of words {e~, e2 ..... e,} of the (English) target language into which f can translate, and the probability P(e, I f  ) that such a translation takes place.</S> | Discourse Facet:  NA | Annotator: Automatic


