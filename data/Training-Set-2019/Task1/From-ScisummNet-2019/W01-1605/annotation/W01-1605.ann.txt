Citance Number: 1 | Reference Article:  W01-1605.txt | Citing Article:  P02-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The additional two systems were: PD-EDU: Same as EDU except using the perfect discourse trees, available from the RST corpus (Carlson et al, 2001).</S> | Reference Offset:  ['23','138'] | Reference Text:  <S sid = 23 ssid = >We decided to use RST for three reasons: can play a crucial role in building natural language generation systems (Novy, 1993; Moore and Paris, 1993; Moore, 1995) and text summarization systems (Marcu, 2000); can be used to increase the naturalness of machine translation outputs (Marcu et al. 2000); and can be used to build essayscoring systems that provide students with discourse-based feedback (Burstein et al., 2001).</S><S sid = 138 ssid = >The average number of words per EDU is 8.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W01-1605.txt | Citing Article:  P14-2052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We experimentally evaluated the test collection for single document summarization contained in the RST Discourse Treebank (RSTDTB) (Carlsonetal., 2001) distributed by the Linguistic Data Consortium (LDC).</S> | Reference Offset:  ['14','140'] | Reference Text:  <S sid = 14 ssid = >Two essential considerations from the outset were that the corpus needed to be consistently annotated, and that it would be made publicly available through the Linguistic Data Consortium for a nominal fee to cover distribution costs.</S><S sid = 140 ssid = >In selecting these documents, we partnered with the Linguistic Data Consortium to select Penn Treebank texts for which the syntactic bracketing was known to be of high caliber.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W01-1605.txt | Citing Article:  D10-1039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Two of the main corpora with discourse annotations are the RST Discourse Treebank (RSTDT) (Carlson et al., 2001) and the Penn Discourse Treebank (PDTB) (Prasad et al, 2008a), which are both based on the Wall Street Journal (WSJ) corpus.</S> | Reference Offset:  ['16','134'] | Reference Text:  <S sid = 16 ssid = >The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.</S><S sid = 134 ssid = >The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W01-1605.txt | Citing Article:  P14-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Fortunately, RST Discourse Treebank (RSTDT) (Carlson et al, 2001) is an available resource to help with.</S> | Reference Offset:  ['12','16'] | Reference Text:  <S sid = 12 ssid = >In this paper, we recount our experience in developing a large resource with discourse-level annotation for NLP research.</S><S sid = 16 ssid = >The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W01-1605.txt | Citing Article:  N07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the Cause versus Contrast case, their reported performance exceeds ours significantly; however, in a subset of their experiments which test Cause versus Contrast on instances from the human annotated RSTBank corpus (Carlson et al., 2001) where no cue phrase is present, they report only 63% accuracy over a 56% baseline (the baseline is > 50% because the number of input examples is unbalanced).</S> | Reference Offset:  ['47','122'] | Reference Text:  <S sid = 47 ssid = >The 78 relations used in annotating the corpus can be partitioned into 16 classes that share some type of rhetorical meaning: Attribution, Background, Cause, Comparison, Condition, Contrast, Elaboration, Enablement, Evaluation, Explanation, Joint, Manner-Means, Topic-Comment, Summary, Temporal, TopicChange.</S><S sid = 122 ssid = >These scores reflect very strong agreement and represent a significant improvement over previously reported results on annotating multiple texts in the RST framework (Marcu et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W01-1605.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['49','158'] | Reference Text:  <S sid = 49 ssid = >In addition, three relations are used to impose structure on the tree: textualorganization, span, and same-unit (used to link parts of units separated by embedded units or spans).</S><S sid = 158 ssid = >The added value of multiple layers of overt linguistic phenomena enhancing the Penn Treebank information can be exploited to advance the study of discourse, to enhance language technologies such as text summarization, machine translation or information retrieval, or to be a testbed for new and creative natural language processing techniques.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W01-1605.txt | Citing Article:  W05-0613.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the first, the labelled/unlabelled relations f scores are 50.3% /73.0% and for the latter, they are 75.3% /84.0%: this is similar to the performance on other discourse annotation projects, e.g., Carlson et al (2001).</S> | Reference Offset:  ['11','46'] | Reference Text:  <S sid = 11 ssid = >So far, the annotation of discourse structure of documents has been applied primarily to identifying topical segments (Hearst, 1997), inter-sentential relations (Nomoto and Matsumoto, 1999; Tsâ€™ou et al., 2000), and hierarchical analyses of small corpora (Moser and Moore, 1995; Marcu et al., 1999).</S><S sid = 46 ssid = >More extensive analysis of the final tagged corpus will demonstrate the extent to which individual relations that are similar in semantic content were distinguished consistently during the tagging process.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W01-1605.txt | Citing Article:  P08-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The generator is informed by a corpus study of embedded discourse units on two discourse annotated corpora: the RST Discourse Treebank (Carlson et al., 2001) and the Penn Discourse Treebank.</S> | Reference Offset:  ['16','143'] | Reference Text:  <S sid = 16 ssid = >The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.</S><S sid = 143 ssid = >A growing number of groups have developed or are developing discourse-annotated corpora for text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W01-1605.txt | Citing Article:  P14-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We evaluate DPLP on the RST Discourse Tree bank (Carlson et al, 2001), comparing against state-of-the-art results.</S> | Reference Offset:  ['101','122'] | Reference Text:  <S sid = 101 ssid = >Syntactic checking involved ensuring that the tree had a single root node and comparing the tree to the document to check for missing sentences or fragments from the end of the text.</S><S sid = 122 ssid = >These scores reflect very strong agreement and represent a significant improvement over previously reported results on annotating multiple texts in the RST framework (Marcu et al., 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W01-1605.txt | Citing Article:  P14-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To compare with previous works on RSTDT, we use the 18 coarse-grained relations defined in (Carlson et al, 2001).</S> | Reference Offset:  ['106','152'] | Reference Text:  <S sid = 106 ssid = >The kappa coefficient (Siegel and Castellan, 1988) has been used extensively in previous empirical studies of discourse (Carletta et al., 1997; Flammia and Zue, 1995; Passonneau and Litman, 1997).</S><S sid = 152 ssid = >Because the RST theory does not differentiate between different levels of the tree structure, a fairly fine-grained set of relations operates between EDUs and EDU clusters at the macrolevel.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W01-1605.txt | Citing Article:  W04-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Carlson et al 2001) reported relatively high levels of inter-annotator agreement, this was based on an annotation procedure where the annotators were allowed to iteratively revise the instructions based on joint discussion.</S> | Reference Offset:  ['105','124'] | Reference Text:  <S sid = 105 ssid = >We tracked inter-annotator agreement during each phase of the project, using a method developed by Marcu et al. (1999) for computing kappa statistics over hierarchical structures.</S><S sid = 124 ssid = >Results are based on pre-segmented documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W01-1605.txt | Citing Article:  W11-2040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To demonstrate the functionality of our system without relying on still imperfect discourse parsing, we use the RST parsed Wall Street Journal corpus as input (Carlson et al, 2001).</S> | Reference Offset:  ['50','134'] | Reference Text:  <S sid = 50 ssid = >Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).</S><S sid = 134 ssid = >The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W01-1605.txt | Citing Article:  D11-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Discourse Tree Bank (Carlson et al, 2001) only 26% of Contrast relations were indicated by cue phrases while in NTC-7 about 70% of Contrast were indicated by cue phrases.</S> | Reference Offset:  ['38','89'] | Reference Text:  <S sid = 38 ssid = >We opted for consistency in segmenting, sacrificing some potentially discourse-relevant phrases in the process.</S><S sid = 89 ssid = >]26 wsj_1111 The discourse sub-tree for this text fragment is given in Figure 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W01-1605.txt | Citing Article:  P09-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They use the RST corpus (Carlson et al,2001), which contains 385 Wall Street Journal articles annotated following the Rhetorical Structure Theory (Mann and Thompson, 1988).</S> | Reference Offset:  ['22','134'] | Reference Text:  <S sid = 22 ssid = >Our annotation work is grounded in the Rhetorical Structure Theory (RST) framework (Mann and Thompson, 1988).</S><S sid = 134 ssid = >The RST Corpus consists of 385 Wall Street Journal articles from the Penn Treebank, representing over 176,000 words of text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W01-1605.txt | Citing Article:  P13-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Soricut and Marcu, 2003) parsed the discourse structures of sentences on RST Bank data set (Carlson et al, 2001) which is annotated based on Rhetorical Structure Theory (Mann and Thompson, 1988).</S> | Reference Offset:  ['22','50'] | Reference Text:  <S sid = 22 ssid = >Our annotation work is grounded in the Rhetorical Structure Theory (RST) framework (Mann and Thompson, 1988).</S><S sid = 50 ssid = >Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W01-1605.txt | Citing Article:  P12-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The RST Discourse Treebank (RST-DT) (Carlson et al, 2001), is a corpus annotated in the framework of RST.</S> | Reference Offset:  ['16','50'] | Reference Text:  <S sid = 16 ssid = >The resulting corpus contains 385 documents of American English selected from the Penn Treebank (Marcus et al., 1993), annotated in the framework of Rhetorical Structure Theory.</S><S sid = 50 ssid = >Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W01-1605.txt | Citing Article:  P02-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the corpus of Rhetorical Structure trees built by Carlson et al (2001), for example, we have observed that only 61 of 238 CONTRAST relation sand 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase.</S> | Reference Offset:  ['39','42'] | Reference Text:  <S sid = 39 ssid = >Once the elementary units of discourse have been determined, adjacent spans are linked together via rhetorical relations creating a hierarchical structure.</S><S sid = 42 ssid = >Multinuclear relations hold among two or more spans of equal weight in the discourse structure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W01-1605.txt | Citing Article:  P02-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, empirical work of Marcu (2000) and Carlson et al (2001) suggests that the majority of occurrences of but, for example, do signal CONTRAST relations.</S> | Reference Offset:  ['23','50'] | Reference Text:  <S sid = 23 ssid = >We decided to use RST for three reasons: can play a crucial role in building natural language generation systems (Novy, 1993; Moore and Paris, 1993; Moore, 1995) and text summarization systems (Marcu, 2000); can be used to increase the naturalness of machine translation outputs (Marcu et al. 2000); and can be used to build essayscoring systems that provide students with discourse-based feedback (Burstein et al., 2001).</S><S sid = 50 ssid = >Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W01-1605.txt | Citing Article:  P02-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To test this, we used the corpus of discourse trees built in the style of RST by Carlson et al (2001).</S> | Reference Offset:  ['23','50'] | Reference Text:  <S sid = 23 ssid = >We decided to use RST for three reasons: can play a crucial role in building natural language generation systems (Novy, 1993; Moore and Paris, 1993; Moore, 1995) and text summarization systems (Marcu, 2000); can be used to increase the naturalness of machine translation outputs (Marcu et al. 2000); and can be used to build essayscoring systems that provide students with discourse-based feedback (Burstein et al., 2001).</S><S sid = 50 ssid = >Our methodology for annotating the RST Corpus builds on prior corpus work in the Rhetorical Structure Theory framework by Marcu et al. (1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W01-1605.txt | Citing Article:  P02-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >If no cue phrases are used to signal the relation between two elementary discourse units, an automatic discourse labeler can at best guess that an ELABORATION relation holds between the units, because ELABORATION relations are the most frequently used relations (Carlson et al, 2001).</S> | Reference Offset:  ['39','49'] | Reference Text:  <S sid = 39 ssid = >Once the elementary units of discourse have been determined, adjacent spans are linked together via rhetorical relations creating a hierarchical structure.</S><S sid = 49 ssid = >In addition, three relations are used to impose structure on the tree: textualorganization, span, and same-unit (used to link parts of units separated by embedded units or spans).</S> | Discourse Facet:  NA | Annotator: Automatic


