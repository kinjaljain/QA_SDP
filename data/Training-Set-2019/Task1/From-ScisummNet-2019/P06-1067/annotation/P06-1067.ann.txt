Citance Number: 1 | Reference Article:  P06-1067.txt | Citing Article:  N07-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence.</S><S sid = 187 ssid = >It was also partially supported by DARPA TIDES program monitored by SPAWAR under contract number N66001-99-2-8916.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P06-1067.txt | Citing Article:  P12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Lexicalized distortion models predict the jump from the last translated word to the next one, with a class for each possible jump length (Al-Onaizan and Papineni, 2006), or bin of lengths (Green et al, 2010).</S> | Reference Offset:  ['85','110'] | Reference Text:  <S sid = 85 ssid = >Second, their models consider only the direction (i.e., orientation) and not the relative jump.</S><S sid = 110 ssid = >Any aligner such as (Al-Onaizan et al., 1999) or (Vogel et al., 1996) can be used to obtain word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P06-1067.txt | Citing Article:  D09-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Demonstrating the inadequacy of such approaches, Al-Onaizan and Papineni (2006) showed that even given the words in the reference translation, and their alignment to the source words, a decoder of this sort charged with merely rearranging them into the correct target-language order could achieve a BLEU score (Papineni et al., 2002) of at best 69% and that only when restricted to keep most words very close to their source positions.</S> | Reference Offset:  ['19','137'] | Reference Text:  <S sid = 19 ssid = >This new model leads to significant improvements in MT quality as measured by BLEU (Papineni et al., 2002).</S><S sid = 137 ssid = >The final translation is a hypothesis that covers all source words and has the minimum cost among all possible 9 hypotheses that cover all source words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P06-1067.txt | Citing Article:  D09-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is similar to the oracle ordering used by Al-Onaizan and Papineni (2006), but differs in the handling of unaligned words.</S> | Reference Offset:  ['110','127'] | Reference Text:  <S sid = 110 ssid = >Any aligner such as (Al-Onaizan et al., 1999) or (Vogel et al., 1996) can be used to obtain word alignments.</S><S sid = 127 ssid = >The above distortion costs are used in conjunction with other cost components used in our decoder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P06-1067.txt | Citing Article:  C10-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence.</S><S sid = 187 ssid = >It was also partially supported by DARPA TIDES program monitored by SPAWAR under contract number N66001-99-2-8916.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P06-1067.txt | Citing Article:  W08-0405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since we are using the distortion model in (Al-Onaizan and Papineni, 2006) the entire last source phrase interval needs to be stored.</S> | Reference Offset:  ['81','184'] | Reference Text:  <S sid = 81 ssid = >We will also show how to generalize this word distortion model to a phrase-based model.</S><S sid = 184 ssid = >So, when translating into English, one needs to move the verb after the subject, which is often a long compounded phrase.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P06-1067.txt | Citing Article:  C08-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned by (Al-Onaizan and Papineni, 2006), it can be problematic that these deterministic choices are beyond the scope of optimization and cannot be undone by the decoder.</S> | Reference Offset:  ['49','110'] | Reference Text:  <S sid = 49 ssid = >Hence, reordering is better handled during the search algorithm and as part of the optimization function.</S><S sid = 110 ssid = >Any aligner such as (Al-Onaizan et al., 1999) or (Vogel et al., 1996) can be used to obtain word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P06-1067.txt | Citing Article:  D08-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our baseline MT decoder is a phrase-based decoder as described in (Al-Onaizan and Papineni 2006).</S> | Reference Offset:  ['46','129'] | Reference Text:  <S sid = 46 ssid = >Their approach show a statistically-significant improvement over a phrase-based monotone decoder.</S><S sid = 129 ssid = >The phrase-based decoder we use is inspired by the decoder described in (Tillmann and Ney, 2003) and similar to that described in (Koehn, 2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P06-1067.txt | Citing Article:  P07-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As pointed out in (Al-Onaizan and Papineni, 2006), these strategies make hard decisions in reordering which cannot be undone during decoding.</S> | Reference Offset:  ['11','48'] | Reference Text:  <S sid = 11 ssid = >There is a fundamental difference between decoding for machine translation and decoding for speech recognition.</S><S sid = 48 ssid = >Rewriting the input sentence whether using syntactic rules or heuristics makes hard decisions that can not be undone by the decoder.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P06-1067.txt | Citing Article:  W08-0406.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As mentioned by (Al-Onaizan and Papineni,2006), it can be problematic that these deterministic choices are beyond the scope of optimization and cannot be undone by the decoder.</S> | Reference Offset:  ['49','110'] | Reference Text:  <S sid = 49 ssid = >Hence, reordering is better handled during the search algorithm and as part of the optimization function.</S><S sid = 110 ssid = >Any aligner such as (Al-Onaizan et al., 1999) or (Vogel et al., 1996) can be used to obtain word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P06-1067.txt | Citing Article:  C10-2095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then trained the lexicalized reordering model that produced distortion costs based on the number of words that are skipped on the target side, in a manner similar to (Al-Onaizan and Papineni, 2006).</S> | Reference Offset:  ['126','142'] | Reference Text:  <S sid = 126 ssid = >The inbound and pair distortion costs (i..e, Ci(p, n, m, a) and Cp(p, n, m, a)) can be defined in a similar fashion.</S><S sid = 142 ssid = >The first parameter s denotes the number of source words that are temporarily skipped (i.e., temporarily left uncovered) during the search to cover a source word to the right of the skipped words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P06-1067.txt | Citing Article:  P07-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other further generalizations of orientation include the global prediction model (Nagata et al, 2006) and distortion model (Al-Onaizan and Papineni, 2006).</S> | Reference Offset:  ['110','147'] | Reference Text:  <S sid = 110 ssid = >Any aligner such as (Al-Onaizan et al., 1999) or (Vogel et al., 1996) can be used to obtain word alignments.</S><S sid = 147 ssid = >The language model used is an interpolated trigram model described in (Bahl et al., 1983).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P06-1067.txt | Citing Article:  P09-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The MT system is a phrase based SMT system as described in (Al-Onaizanand Papineni, 2006).</S> | Reference Offset:  ['129','171'] | Reference Text:  <S sid = 129 ssid = >The phrase-based decoder we use is inspired by the decoder described in (Tillmann and Ney, 2003) and similar to that described in (Koehn, 2004).</S><S sid = 171 ssid = >We presented a new distortion model that can be integrated with existing phrase-based SMT decoders.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P06-1067.txt | Citing Article:  D08-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This assumption is realistic: while truly parallel data (humanly created) might be in short supply or harder to acquire, adapting statistical machine translation (SMT) systems from one language-pair to another is not as challenging as it used to be (Al-Onaizan and Papineni, 2006).</S> | Reference Offset:  ['0','26'] | Reference Text:  <S sid = 0 ssid = >Distortion Models For Statistical Machine Translation</S><S sid = 26 ssid = >In Section 5, we present some empirical results that show the utility of our distortion model for statistical machine translation systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P06-1067.txt | Citing Article:  D08-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Chinese to English SMT system has similar architecture to the one described in (Al-Onaizan and Papineni, 2006).</S> | Reference Offset:  ['95','180'] | Reference Text:  <S sid = 95 ssid = >Chinese-English.</S><S sid = 180 ssid = >Our metric shows that Chinese-English have a closer word order than Arabic-English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P06-1067.txt | Citing Article:  N10-1129.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To remedy these deficiencies, Al-Onaizan and Papineni (2006) proposed a lexicalized, generative distortion model.</S> | Reference Offset:  ['25','178'] | Reference Text:  <S sid = 25 ssid = >In Section 4, we present our proposed distortion model.</S><S sid = 178 ssid = >Our proposed distortion model addresses this weakness of the n-gram language model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P06-1067.txt | Citing Article:  C10-1126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence.</S><S sid = 187 ssid = >It was also partially supported by DARPA TIDES program monitored by SPAWAR under contract number N66001-99-2-8916.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P06-1067.txt | Citing Article:  C10-1126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The lexicalized distortion model was used as described in (Al-Onaizan and Papineni, 2006) with a window width of up to 5 and a maximum number of skipped (not covered) words during decoding of 2.</S> | Reference Offset:  ['143','161'] | Reference Text:  <S sid = 143 ssid = >The second parameter is the window width w, which is defined as the distance (in number of source words) between the left-most uncovered source word and the right-most covered source word.</S><S sid = 161 ssid = >Table 5 shows BLEU scores for our SMT decoder with different parameter settings for skip s, window width w, with and without our distortion model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P06-1067.txt | Citing Article:  D07-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >(Yamada and Knight, 2002) propose a syntax-based decoder that restrict word reordering based on reordering operations on syntactic parse-trees of the input sentence.</S><S sid = 187 ssid = >It was also partially supported by DARPA TIDES program monitored by SPAWAR under contract number N66001-99-2-8916.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P06-1067.txt | Citing Article:  D08-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In future work, we plan to extend the parameterization of our models to not only predict phrase orientation, but also the length of each displacement as in (Al-Onaizan and Papineni, 2006).</S> | Reference Offset:  ['82','85'] | Reference Text:  <S sid = 82 ssid = >(Och et al., 2004; Tillman, 2004) propose orientation-based distortion models lexicalized on the phrase level.</S><S sid = 85 ssid = >Second, their models consider only the direction (i.e., orientation) and not the relative jump.</S> | Discourse Facet:  NA | Annotator: Automatic


