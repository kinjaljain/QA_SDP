Citance Number: 1 | Reference Article:  W04-0811.txt | Citing Article:  D12-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004) English all-words datasets.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W04-0811.txt | Citing Article:  P10-1155.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The F-score obtained by training on SemCor (mixed-domain corpus) and testing on the two target domains without using any injections (srcb) F-score of 61.7% on Tourism and F score of 65.5% on Health is comparable to the best result reported on the SEMEVAL datasets (65.02%, where both training and testing hap pens on a mixed-domain corpus (Snyder and Palmer, 2004)).</S> | Reference Offset:  ['5','24'] | Reference Text:  <S sid = 5 ssid = >While this result is encouraging, it seems that the best systems have a hit a wall in the 65- 70% range.</S><S sid = 24 ssid = >Although we did not compute a baseline score, we received several baseline figures from our participants.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W04-0811.txt | Citing Article:  W07-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >State-of-the-art systems attained a disambiguation accuracy around 65% in the Senseval-3 all-words task (Snyder and Palmer, 2004), where WordNet (Fellbaum, 1998) was adopted as a reference sense inventory.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W04-0811.txt | Citing Article:  W07-2006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recent estimations of the inter-annotator agreement when using the WordNet inventory report figures of 72.5% agreement in the preparation of the English all-words test set at Senseval-3 (Snyder and Palmer,2004) and 67.3% on the Open Mind Word Expert an notation exercise (Chklovski and Mihalcea, 2002).</S> | Reference Offset:  ['6','31'] | Reference Text:  <S sid = 6 ssid = >This is not surprising given the typical inter-annotator agreement of 70-75% for this task.</S><S sid = 31 ssid = >This is not surprising given the typical inter-annotator agreement of 70-75% for this task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W04-0811.txt | Citing Article:  W06-2503.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While contextual evidence is required for accurate WSD, it is useful to look at this heuristic since it is so widely used as a back-off model by many systems and is hard to beat on an all words task (Snyder and Palmer, 2004).</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W04-0811.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, using WN as a sense repository, the organizers of the English all-words task at SensEval-3 reported an inter-annotation agreement of 72.5% (Snyder and Palmer, 2004).</S> | Reference Offset:  ['0','31'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 31 ssid = >This is not surprising given the typical inter-annotator agreement of 70-75% for this task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W04-0811.txt | Citing Article:  E09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SensEval-38 English all-words corpus (hereinafter SE3) (Snyder and Palmer, 2004), is made up of 5,000 words, extracted from twoWSJ articles and one excerpt from the Brown Corpus.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W04-0811.txt | Citing Article:  W06-0608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Snyder and Palmer (2004) report 62% of all word types on the English all-words task at SENSEVAL-3 were labelled unanimously.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W04-0811.txt | Citing Article:  W06-0608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Nouns and verbal nouns (vn) have the highest agreements, similar to the results for the English all-words task at SENSEVAL-3 (Snyder and Palmer, 2004).</S> | Reference Offset:  ['0','29'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 29 ssid = >The greatest difference between these results and those of the SENSEVAL-2 English all-words task is that a greater number of systems have now achieved scores at or above the baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W04-0811.txt | Citing Article:  D07-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Unsupervised learning is introduced primarily to deal with the problem, but with limited success (Snyder and Palmer, 2004).</S> | Reference Offset:  ['27','28'] | Reference Text:  <S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S><S sid = 28 ssid = >In fact, all of the seven systems reported as supervised scored higher than any of the nine systems reported as unsupervised in both precision and recall (using either of the two scoring criteria).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W04-0811.txt | Citing Article:  W09-1701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As a point of comparison, the Senseval 3 all-words task had a 75% agreement on nouns (Snyder and Palmer, 2004).</S> | Reference Offset:  ['6','31'] | Reference Text:  <S sid = 6 ssid = >This is not surprising given the typical inter-annotator agreement of 70-75% for this task.</S><S sid = 31 ssid = >This is not surprising given the typical inter-annotator agreement of 70-75% for this task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W04-0811.txt | Citing Article:  W07-2002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Existing hand-annotated corpora like SemCor (Miller et al, 1993), which is annotated with Word Netsenses (Fellbaum, 1998) allow for a small improvement over the simple most frequent sense heuristic, as attested in the all-words track of the last Senseval competition (Snyder and Palmer, 2004).</S> | Reference Offset:  ['10','27'] | Reference Text:  <S sid = 10 ssid = >In fact, we believe that most of the annotator disagreements were, like this example, between closely related WordNet senses with only subtle (and often inexplicit) distinctions and that more coarse-grained sense distinctions are needed (Palmer et al., 2004).</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W04-0811.txt | Citing Article:  W09-2410.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We experiment with all the standard data sets, namely, Senseval 2 (SV2) (M. Palmer and Dang, 2001), Senseval 3 (SV3) (Snyder and Palmer, 2004), and SEMEVAL (SM) (Pradhan et al, 2007) English All Words data sets.</S> | Reference Offset:  ['13','27'] | Reference Text:  <S sid = 13 ssid = >Two sets of scores were computed for each system.</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W04-0811.txt | Citing Article:  N07-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >First, we use the acquired dominant senses to disambiguate the meanings of words in the Senseval-2 (Palmer et al, 2001) and Senseval-3 (Snyder and Palmer, 2004) datasets.</S> | Reference Offset:  ['10','27'] | Reference Text:  <S sid = 10 ssid = >In fact, we believe that most of the annotator disagreements were, like this example, between closely related WordNet senses with only subtle (and often inexplicit) distinctions and that more coarse-grained sense distinctions are needed (Palmer et al., 2004).</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W04-0811.txt | Citing Article:  W06-1670.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Senseval 3 shared task data (Snyder and Palmer, 2004).</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W04-0811.txt | Citing Article:  D11-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We prefer SemCor to all-words datasets available in Senseval-3 (Snyder and Palmer, 2004) or SemEval-2007 (Pradhan et al, 2007), since it includes many more documents than either set (350 versus 3) and therefore allowing more reliable results.</S> | Reference Offset:  ['27','29'] | Reference Text:  <S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S><S sid = 29 ssid = >The greatest difference between these results and those of the SENSEVAL-2 English all-words task is that a greater number of systems have now achieved scores at or above the baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W04-0811.txt | Citing Article:  W06-1669.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Existing hand-annotated corpora like Sem Cor (Miller et al, 1993), which is annotated with WordNet senses (Fellbaum, 1998) allow for a small improvement over the simple most frequent sense heuristic, as attested in the all-words track of the last Senseval competition (Snyder and Palmer, 2004).</S> | Reference Offset:  ['10','27'] | Reference Text:  <S sid = 10 ssid = >In fact, we believe that most of the annotator disagreements were, like this example, between closely related WordNet senses with only subtle (and often inexplicit) distinctions and that more coarse-grained sense distinctions are needed (Palmer et al., 2004).</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W04-0811.txt | Citing Article:  W06-1669.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >S3AW task In the Senseval-3 all-words task (Snyder and Palmer, 2004) all words in three document excerpts need to be disambiguated.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W04-0811.txt | Citing Article:  W09-2403.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, two different MFS baseline performance results are reported in Snyder and Palmer (2004), with further implementations being different still.</S> | Reference Offset:  ['19','21'] | Reference Text:  <S sid = 19 ssid = >Table 1 shows the system performance under the first interpretation of the results (&quot;With U&quot;).</S><S sid = 21 ssid = >Table 2 shows the system performance under the second interpretation of the results (&quot;Without U&quot;).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W04-0811.txt | Citing Article:  H05-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Indeed, only 5 out of the 26 systems in the recent SENSEVAL-3 English all words task (Snyder and Palmer, 2004) outperformed the heuristic of choosing the most frequent sense as derived from SemCor (which would give 61.5% precision and recall).</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >The English All-Words Task</S><S sid = 27 ssid = >As with the SENSEVAL-2 English all-words task, the supervised systems fared much better than the unsupervised systems (Palmer et al., 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


