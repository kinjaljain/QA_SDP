Citance Number: 1 | Reference Article:  J97-4005.txt | Citing Article:  P99-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On the other hand, as Abney (1997) points out, the context-sensitive dependencies that unification-based constraints introduce render the relative frequency estimator suboptimal.</S> | Reference Offset:  ['374','375'] | Reference Text:  <S sid = 374 ssid = >Even if the language described by the grammar of interest—that is, the set of possible trees—is context-free, there may well be context-sensitive statistical dependencies.</S><S sid = 375 ssid = >Random fields can be readily applied to capture such statistical dependencies whether or not L(G) is context-sensitive.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J97-4005.txt | Citing Article:  P99-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Abney (1997) proposes a Markov Random Field or log linear model for SUBGs, and the models described here are instances of Abney's general framework.</S> | Reference Offset:  ['51','263'] | Reference Text:  <S sid = 51 ssid = >The models of interest are known as random fields.</S><S sid = 263 ssid = >In this framework, a model consists of: (1) An AV grammar G whose purpose is to define a set of dags L(G).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J97-4005.txt | Citing Article:  P99-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Abney (1997) proposes a gradient ascent, based upon a Monte Carlo procedure for estimating E0 (fj).</S> | Reference Offset:  ['388','395'] | Reference Text:  <S sid = 388 ssid = >The procedure for adjusting field weights has much the same structure as the procedure for choosing initial weights.</S><S sid = 395 ssid = >The resulting Newton iteration is: The estimation procedure is: procedure Adjust Weights (ai, , an) begin until the field converges do</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J97-4005.txt | Citing Article:  P11-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Later, AVG were enriched with a statistical component (Abney, 1997): stochastic AVG (SAVG).</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >Stochastic Attribute-Value Grammars</S><S sid = 17 ssid = >Before the advent of statistical methods, regular and context-free grammars were considered too inexpressive for serious consideration, and even now the reliance on stochastic versions of the less-expressive grammars is often seen as an expedient necessitated by the lack of an adequate stochastic version of attribute-value grammars.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J97-4005.txt | Citing Article:  P11-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As Abney (1997) shows, we can not use relatively simple techniques such as relative frequencies to obtain a model for estimating derivation probabilities in attribute-value grammars.</S> | Reference Offset:  ['0','70'] | Reference Text:  <S sid = 0 ssid = >Stochastic Attribute-Value Grammars</S><S sid = 70 ssid = >It is not immediately obvious how to use the ITS algorithm to equip attribute-value grammars with probabilities.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J97-4005.txt | Citing Article:  P06-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >PCFG-based models can only approximate LFG and similar constraint-based formalisms (Abney, 1997).</S> | Reference Offset:  ['51','153'] | Reference Text:  <S sid = 51 ssid = >The models of interest are known as random fields.</S><S sid = 153 ssid = >We can impose such a constraint by means of an attribute-value grammar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J97-4005.txt | Citing Article:  P06-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Simple PCFG based models, while effective and computationally efficient, can only provide approximations to LFG and similar constraint-based formalisms (Abney,1997).</S> | Reference Offset:  ['51','153'] | Reference Text:  <S sid = 51 ssid = >The models of interest are known as random fields.</S><S sid = 153 ssid = >We can impose such a constraint by means of an attribute-value grammar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J97-4005.txt | Citing Article:  C02-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['136','399'] | Reference Text:  <S sid = 136 ssid = >The answer is of course that qi and /5 are probability distributions over L(Gi), but not all of L(G1) appears in the corpus.</S><S sid = 399 ssid = >All responsibility for flaws and errors of course remains with me.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J97-4005.txt | Citing Article:  C02-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Unfortunately, most of the proposed probability models are not mathematically clean in that the probabilities of all possible UBG readings do not sum to the value 1, a problem which is discussed intensively by Eisele (1994), Abney (1997).</S> | Reference Offset:  ['31','49'] | Reference Text:  <S sid = 31 ssid = >Eisele (1994) takes a logic-programming approach to constraint grammars.</S><S sid = 49 ssid = >Eisele recognizes that this problem arises only where there are context dependencies.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J97-4005.txt | Citing Article:  W03-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We would like the parsing model to include long-range dependencies, but this introduces problems for generative parsing models similar to those described by Abney (1997) for attribute-value grammars.</S> | Reference Offset:  ['0','90'] | Reference Text:  <S sid = 0 ssid = >Stochastic Attribute-Value Grammars</S><S sid = 90 ssid = >The standard parsing techniques can be readily adapted to the random-field models to be discussed below, so I simply refer the reader to the literature.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J97-4005.txt | Citing Article:  W03-0401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, when we apply a unification-based grammar, LPCFG-like modeling results in an inconsistent probability model because the model assigns probabilities to parsing results not allowed by the grammar (Abney, 1997).</S> | Reference Offset:  ['81','88'] | Reference Text:  <S sid = 81 ssid = >A point of terminology: I will use the term grammar to refer to an unweighted grammar, be it a context-free grammar or attribute-value grammar.</S><S sid = 88 ssid = >Then: In parsing, we use the probability distribution qi (x) defined by model M1 to disambiguate: the grammar assigns some set of trees {xi, , x,,} to a sentence a, and we choose that tree xi that has greatest probability qi (x,).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J97-4005.txt | Citing Article:  W03-0401.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, when we apply Feature-Based LTAG (FBLTAG), the above probability is no longer consistent because of the non-local constraints caused by feature unification (Abney, 1997).</S> | Reference Offset:  ['227','246'] | Reference Text:  <S sid = 227 ssid = >For purpose of illustration, take feature 1 to have weight )(31 = v--2- and feature 2 to have weight 02 = 3/2.</S><S sid = 246 ssid = >The aim of feature selection is to choose a feature that reduces this divergence as much as possible.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J97-4005.txt | Citing Article:  P05-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Such constraints are known 83 to introduce inconsistencies in probabilistic models estimated using simple relative frequency (Abney, 1997).</S> | Reference Offset:  ['51','259'] | Reference Text:  <S sid = 51 ssid = >The models of interest are known as random fields.</S><S sid = 259 ssid = >We estimate weights using the ERF method: we estimate the weight of a rule as the relative frequency of the rule in the training corpus, among rules with the same left-hand side.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J97-4005.txt | Citing Article:  P02-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As is well known (Abney, 1997), DAG-like dependencies can not in general be modeled with a generative approach of the kind taken here.</S> | Reference Offset:  ['51','261'] | Reference Text:  <S sid = 51 ssid = >The models of interest are known as random fields.</S><S sid = 261 ssid = >But it can be taken as a useful first approximation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J97-4005.txt | Citing Article:  C02-2025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Abney (1997) notes important problems with the soundness of the approach when a unification-based grammar is actually determining the derivations.</S> | Reference Offset:  ['92','220'] | Reference Text:  <S sid = 92 ssid = >By parameter estimation we mean determining values for the weights 0.</S><S sid = 220 ssid = >There are two important differences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J97-4005.txt | Citing Article:  P02-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Abney (1997) pointed out that the non-context free dependencies of a unification grammar require stochastic models more general than Probabilistic Context-Free Grammars (PCFGs) and Markov Branching Processes, and proposed the use of log linear models for defining probability distributions over the parses of a unification grammar.</S> | Reference Offset:  ['53','84'] | Reference Text:  <S sid = 53 ssid = >Markov chains are stochastic processes corresponding to regular grammars and random branching processes are stochastic processes corresponding to context-free grammars.</S><S sid = 84 ssid = >Throughout we will use the following stochastic context-free grammar for illustrative purposes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J97-4005.txt | Citing Article:  P02-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The following section reviews stochastic unification grammars (Abney, 1997) and the statistical quantities required for efficiently estimating such grammars from parsed training data (Johnson et al, 1999).</S> | Reference Offset:  ['65','370'] | Reference Text:  <S sid = 65 ssid = >Statistical dependencies under the model of Mark et al. (1992).</S><S sid = 370 ssid = >The approach described here assumes complete data (a parsed training corpus).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J97-4005.txt | Citing Article:  W07-2219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Abney, 1997) and has the advantage of elegantly bypassing the issue of loosing probability mass to failed derivations due to unification failures.</S> | Reference Offset:  ['134','258'] | Reference Text:  <S sid = 134 ssid = >As probability distributions, qi and /3 should have the same total mass, namely, one.</S><S sid = 258 ssid = >(Renormalization is necessary because of the failed derivations.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J97-4005.txt | Citing Article:  P05-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['136','399'] | Reference Text:  <S sid = 136 ssid = >The answer is of course that qi and /5 are probability distributions over L(Gi), but not all of L(G1) appears in the corpus.</S><S sid = 399 ssid = >All responsibility for flaws and errors of course remains with me.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J97-4005.txt | Citing Article:  C02-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Abney gives fuller details (Abney, 1997).</S> | Reference Offset:  ['287','312'] | Reference Text:  <S sid = 287 ssid = >(See Appendix 1 for details.)</S><S sid = 312 ssid = >This is the real justification for equation (3), and the reader is referred to Della Pietra, Della Pietra, and Lafferty (1995) for details.</S> | Discourse Facet:  NA | Annotator: Automatic


