Citance Number: 1 | Reference Article:  H05-1044.txt | Citing Article:  W06-1642.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wilson et al (2005) proposed supervised learning, dividing the resources into prior polarity and context polarity, which are similar to polar atoms and syntactic patterns in this paper, respectively.</S> | Reference Offset:  ['29','109'] | Reference Text:  <S sid = 29 ssid = >has the same prior and contextual polarity.</S><S sid = 109 ssid = >For the first step, we concentrate on whether clue instances are neutral or polar in context (where polar in context refers to having a contextual polarity that is positive, negative or both).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  H05-1044.txt | Citing Article:  P14-2008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, AbuJbara et al (2013) and Jochim and Schutze (2012) find the list of polar words from Wilson et al (2005) to be useful, and neither study lists dependency relations as significant features.</S> | Reference Offset:  ['44','184'] | Reference Text:  <S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S><S sid = 184 ssid = >Much work on sentiment analysis classifies documents by their overall sentiment, for example deter mining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al, 2003; Pang and Lee,2004; Beineke et al, 2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  H05-1044.txt | Citing Article:  P11-2018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, we used subjectivity clues extracted from the lexicon by Wilson et al (2005).</S> | Reference Offset:  ['74','87'] | Reference Text:  <S sid = 74 ssid = >For the experiments in this paper, we use a lexicon of over 8,000 subjectivity clues.</S><S sid = 87 ssid = >6.9% of the clues in the lexicon are marked as neutral.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  H05-1044.txt | Citing Article:  S10-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wilson et al (2005) present a two-step process to recognize contextual polarity that employs machine learning and a variety of features.</S> | Reference Offset:  ['36','163'] | Reference Text:  <S sid = 36 ssid = >We use a two-step process that employs machine learning and a variety of features.</S><S sid = 163 ssid = >The polarity classification results for this second step in the contextual disambiguation process are given in Table 5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  H05-1044.txt | Citing Article:  P09-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some lexicons assign real number scores to indicate sentiment orientations and strengths (i.e. probabilities of having positive and negative sentiments) (Esuli and Sebastiani, 2006) while other lexicons assign discrete classes (weak/strong, positive/negative) (Wilson et al, 2005).</S> | Reference Offset:  ['13','86'] | Reference Text:  <S sid = 13 ssid = >In these lexicons, entries are tagged with their a priori prior polarity: out of context, doesthe word seem to evoke something positive or some thing negative.</S><S sid = 86 ssid = >Only a small number of clues (0.3%) are marked as having both positive and negative polarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  H05-1044.txt | Citing Article:  C08-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['64','206'] | Reference Text:  <S sid = 64 ssid = >Neutral Positive Negative Both Total Neutral 123 14 24 0 161 Positive 16 73 5 2 96 Negative 14 2 167 1 184 Both 0 3 0 3 6 Total 153 92 196 6 447 Table 1: Agreement for Subjective Expressions (Agreement: 82%, ?: 0.72) For 18% of the subjective expressions, at least oneannotator used an uncertain tag when marking po larity.</S><S sid = 206 ssid = >This work was supported in part by the NSF under grant IIS-0208798 and by the Advanced Research and Development Activity (ARDA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  H05-1044.txt | Citing Article:  C08-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Further, there are analyses (Wiebe et al, 2005) and experiments (Wilson et al, 2005) that indicate that lexicon-lookup approaches to subjectivity analysis will have limited success on general texts.</S> | Reference Offset:  ['44','184'] | Reference Text:  <S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S><S sid = 184 ssid = >Much work on sentiment analysis classifies documents by their overall sentiment, for example deter mining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al, 2003; Pang and Lee,2004; Beineke et al, 2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  H05-1044.txt | Citing Article:  P10-1141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The former were based on the General Inquirer lexicon (Wilson et al, 2005), the MontyLingua part-of-speech tagger (Liu, 2004) and co-occurrence statistics of words with a set of predefined reference words.</S> | Reference Offset:  ['184','189'] | Reference Text:  <S sid = 184 ssid = >Much work on sentiment analysis classifies documents by their overall sentiment, for example deter mining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al, 2003; Pang and Lee,2004; Beineke et al, 2004)).</S><S sid = 189 ssid = >Yu and Hatzivassiloglou (2003), Kim and Hovy (2004), Hu and Liu (2004), and Grefenstette et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  H05-1044.txt | Citing Article:  P12-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More specifically, we use the terms in the lexicon constructed from (Wilson et al, 2005) as the indicators to identify the substructures for the convolution kernels, and extract different sub-structures according to these indicators for various types of parse trees (Section 3).</S> | Reference Offset:  ['97','196'] | Reference Text:  <S sid = 97 ssid = >We define the gold standard used to train and test the system in terms of the manual annotations described in Section 2.</S><S sid = 196 ssid = >However, they do not use the other types of features in our experiments, and they restrict their tags to positiveand negative (excluding our both and neutral categories).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  H05-1044.txt | Citing Article:  P12-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To solve this problem, we define the indicators in this task as subjective words in a polarity lexicon (Wilson et al, 2005).</S> | Reference Offset:  ['44','79'] | Reference Text:  <S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S><S sid = 79 ssid = >Words that are subjective in most contexts were marked strongly subjective (strongsubj), and those that may only have certain subjective usages were marked weakly subjective (weaksubj).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  H05-1044.txt | Citing Article:  P12-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use a manually constructed polarity lexicon (Wilson et al, 2005), in which each entry is annotated with its degree of subjectivity (strong, weak), as well as its sentiment polarity (positive, negative and neutral).</S> | Reference Offset:  ['74','140'] | Reference Text:  <S sid = 74 ssid = >For the experiments in this paper, we use a lexicon of over 8,000 subjectivity clues.</S><S sid = 140 ssid = >Adding a feature for the prior 351 Word Features word token word prior polarity: positive, negative, both, neutral Polarity Features negated: binary negated subject: binary modifies polarity: positive, negative, neutral, both, notmod modified by polarity: positive, negative, neutral, both, notmod conj polarity: positive, negative, neutral, both, notmod general polarity shifter: binary negative polarity shifter: binary positive polarity shifter: binary Table 6: Features for polarity classification polarity improves recall so that it is only 4.4% lower, but this hurts precision, which drops to 4.2% lower than the 28-feature classifier?s precision.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  H05-1044.txt | Citing Article:  P10-2050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['64','206'] | Reference Text:  <S sid = 64 ssid = >Neutral Positive Negative Both Total Neutral 123 14 24 0 161 Positive 16 73 5 2 96 Negative 14 2 167 1 184 Both 0 3 0 3 6 Total 153 92 196 6 447 Table 1: Agreement for Subjective Expressions (Agreement: 82%, ?: 0.72) For 18% of the subjective expressions, at least oneannotator used an uncertain tag when marking po larity.</S><S sid = 206 ssid = >This work was supported in part by the NSF under grant IIS-0208798 and by the Advanced Research and Development Activity (ARDA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  H05-1044.txt | Citing Article:  P10-2050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >PRIOR-POLARITY & PRIOR-INTENSITY: We obtain these prior-attributes from the polarity lexicon populated by Wilson et al (2005).</S> | Reference Offset:  ['29','82'] | Reference Text:  <S sid = 29 ssid = >has the same prior and contextual polarity.</S><S sid = 82 ssid = >The next step was to tag the clues in the lexicon with their prior polarity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  H05-1044.txt | Citing Article:  P10-2050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['64','206'] | Reference Text:  <S sid = 64 ssid = >Neutral Positive Negative Both Total Neutral 123 14 24 0 161 Positive 16 73 5 2 96 Negative 14 2 167 1 184 Both 0 3 0 3 6 Total 153 92 196 6 447 Table 1: Agreement for Subjective Expressions (Agreement: 82%, ?: 0.72) For 18% of the subjective expressions, at least oneannotator used an uncertain tag when marking po larity.</S><S sid = 206 ssid = >This work was supported in part by the NSF under grant IIS-0208798 and by the Advanced Research and Development Activity (ARDA).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  H05-1044.txt | Citing Article:  W09-1903.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Polar word Count (PC) Number of words that are polar (strong subjective words from the lexicon (Wilson et al, 2005)).</S> | Reference Offset:  ['113','148'] | Reference Text:  <S sid = 113 ssid = >6.3.1 Neutral-Polar Classification The neutral-polar classifier uses 28 features, listed in Table 3.</S><S sid = 148 ssid = >Word token and word prior polarity are un changed from the neutral-polar classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  H05-1044.txt | Citing Article:  P13-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also used two datasets for the evaluation purpose: the MPQA (Wilson et al, 2005) and IQAPs (Marneffe et al, 2010) datasets.</S> | Reference Offset:  ['42','44'] | Reference Text:  <S sid = 42 ssid = >A subjective expression is any word or phrase used to express an opinion, emotion, evaluation, stance, speculation, 1The MPQA Corpus is described in (Wiebe et al, 2005) and available at nrrc.mitre.org/NRRC/publications.htm.</S><S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  H05-1044.txt | Citing Article:  C10-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this work we use MPQA (Wilson et al, 2005).</S> | Reference Offset:  ['44','184'] | Reference Text:  <S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S><S sid = 184 ssid = >Much work on sentiment analysis classifies documents by their overall sentiment, for example deter mining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al, 2003; Pang and Lee,2004; Beineke et al, 2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  H05-1044.txt | Citing Article:  C10-1103.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The MPQA lexicon contains separate lexicons for subjectivity clues, intensifiers and valence shifters (Wilson et al, 2005), which are used for identifying opinion roots, modifiers and negation words.</S> | Reference Offset:  ['42','74'] | Reference Text:  <S sid = 42 ssid = >A subjective expression is any word or phrase used to express an opinion, emotion, evaluation, stance, speculation, 1The MPQA Corpus is described in (Wiebe et al, 2005) and available at nrrc.mitre.org/NRRC/publications.htm.</S><S sid = 74 ssid = >For the experiments in this paper, we use a lexicon of over 8,000 subjectivity clues.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  H05-1044.txt | Citing Article:  W11-1704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They use the Opinion Finder lexicon (Wilson et al, 2005) and two bilingual English-Romanian dictionaries to translate the words in the lexicon.</S> | Reference Offset:  ['74','87'] | Reference Text:  <S sid = 74 ssid = >For the experiments in this paper, we use a lexicon of over 8,000 subjectivity clues.</S><S sid = 87 ssid = >6.9% of the clues in the lexicon are marked as neutral.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  H05-1044.txt | Citing Article:  D10-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To generate the initial explanations, one can use an off-the shelf sentiment classifier such as OpinionFinder2 (Wilson et al, 2005).</S> | Reference Offset:  ['44','184'] | Reference Text:  <S sid = 44 ssid = >Please see (Wiebe et al, 2005) for more details on the existing annotations in the MPQA Corpus.etc. A general covering term for such states is private state (Quirk et al, 1985).</S><S sid = 184 ssid = >Much work on sentiment analysis classifies documents by their overall sentiment, for example deter mining whether a review is positive or negative (e.g., (Turney, 2002; Dave et al, 2003; Pang and Lee,2004; Beineke et al, 2004)).</S> | Discourse Facet:  NA | Annotator: Automatic


