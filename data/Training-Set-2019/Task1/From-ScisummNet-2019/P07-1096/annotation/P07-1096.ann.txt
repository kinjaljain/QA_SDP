Citance Number: 1 | Reference Article:  P07-1096.txt | Citing Article:  P08-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For our POS tagging experiments, we used the Wall Street Journal in PTB III (Marcus et al, 1994) with the same data split as used in (Shen et al., 2007).</S> | Reference Offset:  ['154','200'] | Reference Text:  <S sid = 154 ssid = >We carry out experiments on the standard data set of the Penn Treebank (PTB) (Marcus et al., 1994).</S><S sid = 200 ssid = >It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result (Toutanova et al., 2003) on the same data set, while using fewer features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1096.txt | Citing Article:  P08-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In POS tagging, the previous best performance was reported by (Shen et al, 2007) as summarized in Table 7.</S> | Reference Offset:  ['132','193'] | Reference Text:  <S sid = 132 ssid = >Toutanova et al. (2003) reported a POS tagger based on cyclic dependency network.</S><S sid = 193 ssid = >Compared to previous best result on the same data set, 2.76% by (Toutanova et al., 2003), our best result shows a relative error reduction of 3.3%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1096.txt | Citing Article:  P14-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Feature templates are shown in Table 3, which are based on those of Ratnaparkhi (1996) and Shen et al (2007).</S> | Reference Offset:  ['155','168'] | Reference Text:  <S sid = 155 ssid = >Following (Ratnaparkhi,1996; Collins, 2002; Toutanova et al., 2003; Tsuruoka and Tsujii, 2005), we cut the PTB into the training, development and test sets as shown in Table 1.</S><S sid = 168 ssid = >With set B, we include a few feature templates which are symmetric to those in Ratnaparkhi’s set, but are only available with bidirectional search.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1096.txt | Citing Article:  P12-2072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the experimental evaluations we use the Bidirectional Tagger with Guided Learning presented in Shen et al (2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Guided Learning for Bidirectional Sequence Classification</S><S sid = 1 ssid = >In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1096.txt | Citing Article:  S10-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the implementation, we used bpos (Shen et al., 2007) for the POS tagging.</S> | Reference Offset:  ['153','199'] | Reference Text:  <S sid = 153 ssid = >We apply our guided learning algorithm to POS tagging.</S><S sid = 199 ssid = >We apply this novel algorithm to POS tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1096.txt | Citing Article:  W11-0315.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For comparison, our best model, the PLMRF, achieved a 96.8% in-domain accuracy on sections 22-24 of the Penn Treebank, about 0.5% shy of a state-of-the-art in-domain system (Shen et al, 2007) with more sophisticated supervised learning.</S> | Reference Offset:  ['154','188'] | Reference Text:  <S sid = 154 ssid = >We carry out experiments on the standard data set of the Penn Treebank (PTB) (Marcus et al., 1994).</S><S sid = 188 ssid = >Comparison: Table 4 shows the comparison with the previous works on the PTB test sections.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The idea of bidirectional parsing is related to the bidirectional sequential classification method described in (Shen et al, 2007).</S> | Reference Offset:  ['0','30'] | Reference Text:  <S sid = 0 ssid = >Guided Learning for Bidirectional Sequence Classification</S><S sid = 30 ssid = >We first present an example of POS tagging to show the idea of bidirectional labeling.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar to bidirectional labelling in (Shen et al, 2007), there are two learning tasking in this model.</S> | Reference Offset:  ['0','27'] | Reference Text:  <S sid = 0 ssid = >Guided Learning for Bidirectional Sequence Classification</S><S sid = 27 ssid = >The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1096.txt | Citing Article:  D08-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The learning algorithm for level-0 dependency is similar to the guided learning algorithm for labelling as described in (Shen et al, 2007).</S> | Reference Offset:  ['31','101'] | Reference Text:  <S sid = 31 ssid = >Then we present the inference algorithm and the learning algorithm.</S><S sid = 101 ssid = >2.3 Learning Algorithm In this section, we propose guided learning, a Perceptron like algorithm, to learn the weight vector w, as shown in Algorithm 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1096.txt | Citing Article:  C10-2052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The only preprocessing step needed is POS tagging of the data, for which we used the system of Shen et al (2007).</S> | Reference Offset:  ['153','199'] | Reference Text:  <S sid = 153 ssid = >We apply our guided learning algorithm to POS tagging.</S><S sid = 199 ssid = >We apply this novel algorithm to POS tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1096.txt | Citing Article:  D11-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is competitive to CRF in tagging accuracy but requires much less training time (Shen et al, 2007).</S> | Reference Offset:  ['12','182'] | Reference Text:  <S sid = 12 ssid = >Taskar et al. (2003) improved the CRF method by employing the large margin method to separate the gold standard sequence labeling from incorrect labellings.</S><S sid = 182 ssid = >This is due to the fact that the accuracy of POS tagging is very high.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1096.txt | Citing Article:  N10-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We propose a new category of dependency parsing algorithms, inspired by (Shen et al, 2007): non directional easy-first parsing.</S> | Reference Offset:  ['1','187'] | Reference Text:  <S sid = 1 ssid = >In this paper, we propose guided learning, a new learning framework for bidirectional sequence classification.</S><S sid = 187 ssid = >In our recent work (Shen and Joshi, 2007), we have applied a variant of this algorithm to dependency parsing, and showed significant improvement over left-to-right non-aggressive learning strategy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1096.txt | Citing Article:  N10-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Indeed, one major influence on our work is Shen et.al's bi-directional POS-tagging algorithm (Shen et al, 2007), which combines a perceptron learning procedure similar to our own with beam search to produce a state-of-the-art POStagger, which does not rely on left-to-right processing.</S> | Reference Offset:  ['133','187'] | Reference Text:  <S sid = 133 ssid = >In their work, the order of inference is fixed as from left to right.</S><S sid = 187 ssid = >In our recent work (Shen and Joshi, 2007), we have applied a variant of this algorithm to dependency parsing, and showed significant improvement over left-to-right non-aggressive learning strategy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1096.txt | Citing Article:  N12-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','202'] | Reference Text:  <S sid = 63 ssid = >Similarly, we denote the top state for p as Algorithm 1 Inference Algorithm Require: token sequence w1 · · · wn; Require: beam width B; Require: weight vector w; where U is the score of an action.</S><S sid = 202 ssid = >It should be noted that the error rate is close to the inter-annotator discrepancy on PTB, the standard test set for POS tagging, therefore it is very difficult to achieve improvement.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1096.txt | Citing Article:  N12-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Note that Shen et al (2007) employ contextual features up to 5-gram which go beyond our local trigram window.</S> | Reference Offset:  ['27','169'] | Reference Text:  <S sid = 27 ssid = >The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S><S sid = 169 ssid = >With set C, we add more bi-gram and tri-gram features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1096.txt | Citing Article:  W10-1603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Shen et al, 2007) developed new algorithms based on the easiest-first strategy (Tsuruoka and Tsujii, 2005) and the perceptron algorithm.</S> | Reference Offset:  ['27','129'] | Reference Text:  <S sid = 27 ssid = >The new POS tagger is similar to (Toutanova et al., 2003; Tsuruoka and Tsujii, 2005) in the way that we employ context features.</S><S sid = 129 ssid = >Tsuruoka and Tsujii (2005) proposed a bidirectional POS tagger, in which the order of inference is handled with the easiest-first heuristic.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1096.txt | Citing Article:  P09-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Shen et al, (2007) report an accuracy of 97.33% on the same data set using a perceptron-based bidirectional tagging model.</S> | Reference Offset:  ['182','200'] | Reference Text:  <S sid = 182 ssid = >This is due to the fact that the accuracy of POS tagging is very high.</S><S sid = 200 ssid = >It obtains an error rate of 2.67% on the standard PTB test set, which represents 3.3% relative error reduction over the previous best result (Toutanova et al., 2003) on the same data set, while using fewer features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Shen et al (2007) have further shown that better results (97.3 % accuracy) can be obtained using guided learning, a framework for bidirectional sequence classification, which integrates token classification and inference order selection into a single learning task and uses a perceptron-like (Collins and Roark, 2004) passive-aggressive classifier to make the easiest decisions first.</S> | Reference Offset:  ['0','22'] | Reference Text:  <S sid = 0 ssid = >Guided Learning for Bidirectional Sequence Classification</S><S sid = 22 ssid = >Here, we will propose a novel learning framework, namely guided learning, to integrate classification of individual tokens and inference order selection into a single learning task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the feature set defined in (Shen et al 2007), which includes the following: 1.</S> | Reference Offset:  ['165','175'] | Reference Text:  <S sid = 165 ssid = >We first use the same feature set used in (Ratnaparkhi, 1996), which includes a set of prefix, suffix and lexical features, as well as some bi-gram and tri-gram context features.</S><S sid = 175 ssid = >We use feature set E for this set of experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1096.txt | Citing Article:  E12-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['63','202'] | Reference Text:  <S sid = 63 ssid = >Similarly, we denote the top state for p as Algorithm 1 Inference Algorithm Require: token sequence w1 · · · wn; Require: beam width B; Require: weight vector w; where U is the score of an action.</S><S sid = 202 ssid = >It should be noted that the error rate is close to the inter-annotator discrepancy on PTB, the standard test set for POS tagging, therefore it is very difficult to achieve improvement.</S> | Discourse Facet:  NA | Annotator: Automatic


