Citance Number: 1 | Reference Article:  W96-0208.txt | Citing Article:  W97-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This includes basic linguistic problems such as morphological analysis (van den Bosch et al., 1996), parsing (Zelle and Mooney, 1996), word sense disambiguation (Mooney, 1996), and anaphora resolution (Aone and Bennett, 1996).</S> | Reference Offset:  ['20','147'] | Reference Text:  <S sid = 20 ssid = >In particular, the UCI Machine Learning Data Repository (Merz, Murphy, & Aha, 1996) was assembled to facilitate empirical comparisons.</S><S sid = 147 ssid = >Similar comparisons of a range of algorithms should also be performed on other natural language problems such as part-of-speech tagging (Church, 1988), prepositional phrase attachment (Hindle 8,/ Rooth, 1993), anaphora resolution (Anoe & Bennett, 1995), etc..</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W96-0208.txt | Citing Article:  W12-2507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Mooney (1996) argues that Naive Bayes classification and perceptron classifiers are particularly fit for lexical sample word sense disambiguation problems, because they combine weighted evidence from all features rather than select a subset of features for early discrimination.</S> | Reference Offset:  ['122','131'] | Reference Text:  <S sid = 122 ssid = >Naive Bayes and perceptron are similar in that they both employ a weighted combination of all features.</S><S sid = 131 ssid = >Therefore, our results indicate that lexical disambiguation is perhaps best performed using methods that combine weighted evidence from all of the features rather tures actually present in the examples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W96-0208.txt | Citing Article:  W02-0811.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While it is unquestionable that certain algorithms are better suited to the WSD problem than others (for a comparison, see Mooney (1996)), it seems that, given similar input features, various algorithms exhibit roughly similar accuracies.</S> | Reference Offset:  ['1','122'] | Reference Text:  <S sid = 1 ssid = >This paper describes an experimental comparison of seven different learning algorithms on the problem of learning to disambiguate the meaning of a word from context.</S><S sid = 122 ssid = >Naive Bayes and perceptron are similar in that they both employ a weighted combination of all features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W96-0208.txt | Citing Article:  N01-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Decision trees have been used in supervised learning approaches to word sense disambiguation, and have fared well in a number of comparative studies (e.g., (Mooney, 1996), (Pedersen and Bruce, 1997)).</S> | Reference Offset:  ['0','82'] | Reference Text:  <S sid = 0 ssid = >Comparative Experiments On Disambiguating Word Senses: An Illustration Of The Role Of Bias In Machine Learning</S><S sid = 82 ssid = >A number of effective concept-learning systems have employed decision lists (Clark & Niblett, 1989; Quinlan, 1993; Mooney Sc Califf, 1995) and they have already been successfully applied to lexical disambiguation (Yarowsky, 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W96-0208.txt | Citing Article:  N03-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bag of words feature sets made up of unigrams have had a long history of success in text classification and word sense disambiguation (Mooney, 1996), and we believe that despite creating quite a bit of noise can provide useful information for discrimination.</S> | Reference Offset:  ['98','143'] | Reference Text:  <S sid = 98 ssid = >This provides information on the computational resources required by each method, which may also be useful in deciding between them for particular applications.</S><S sid = 143 ssid = >The current results are for only one simple encoding of the lexical disambiguation problem into a feature vector representing an unordered set of word stems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W96-0208.txt | Citing Article:  W04-0833.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Mooney (Mooney, 1996) has discussed the effect of bias on inductive learning methods.</S> | Reference Offset:  ['13','31'] | Reference Text:  <S sid = 13 ssid = >Subsequent experiments on this problem have demonstrated that an inductive logic programming method produces even better results than decision trees (Mooney & Califf, 1995).</S><S sid = 31 ssid = >Decision-tree methods have a bias for simple decision trees, rule induction methods have a bias for simple DNF expressions, neural-network methods have a bias for linear threshold functions, 1 and naive Bayes has a bias for functions which respect conditional independence of features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W96-0208.txt | Citing Article:  C04-1190.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Naive Bayes models (e.g., Mooney (1996), Chodorow et al (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)) in particular have shown a large degree of success for WSD, and have established challenging state-of-the-art benchmarks.</S> | Reference Offset:  ['106','109'] | Reference Text:  <S sid = 106 ssid = >The resulting learning curves are shown in Figure 1 and results on training and testing time are shown in Figures 2 and 3.</S><S sid = 109 ssid = >Naive Bayes and perceptron are not significantly different, except at 1,200 training examples where naive Bayes has a slight advantage.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W96-0208.txt | Citing Article:  D10-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Naive Bayes is particularly useful when relatively small amounts of training CSF instances are available (Zhang, 2004), and achieves good results when compared to other classifiers for the WSD task (Mooney, 1996), which might explain our results.</S> | Reference Offset:  ['109','127'] | Reference Text:  <S sid = 109 ssid = >Naive Bayes and perceptron are not significantly different, except at 1,200 training examples where naive Bayes has a slight advantage.</S><S sid = 127 ssid = >Therefore, each discrimination is clearly only testing a relatively small fraction of the 2,859 available features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W96-0208.txt | Citing Article:  W04-0850.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They have a long history of use in word sense disambiguation, dating back to early work by (Black, 1988), and have fared well in comparative studies such as (Mooney,1996) and (Pedersen and Bruce, 1997).</S> | Reference Offset:  ['0','47'] | Reference Text:  <S sid = 0 ssid = >Comparative Experiments On Disambiguating Word Senses: An Illustration Of The Role Of Bias In Machine Learning</S><S sid = 47 ssid = >The goal is to learn to use surrounding context to determine the sense of an ambiguous word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W96-0208.txt | Citing Article:  P04-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorowetal.</S> | Reference Offset:  ['109','122'] | Reference Text:  <S sid = 109 ssid = >Naive Bayes and perceptron are not significantly different, except at 1,200 training examples where naive Bayes has a slight advantage.</S><S sid = 122 ssid = >Naive Bayes and perceptron are similar in that they both employ a weighted combination of all features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W96-0208.txt | Citing Article:  W97-0213.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some clusters of studies have used common test suites, most notably the 2094-word Hne data of Leacock et al (1993), shared by Lehman (1994) and Mooney (1996) and evaluated on the system of Gale, Church and Yarowsky (1992).</S> | Reference Offset:  ['46','55'] | Reference Text:  <S sid = 46 ssid = >Several recent research projects have taken a corpus-based approach to lexical disambiguation (Brown, Della-Pietra, Della-Pietra, St Mercer, 1991; Gale, Church, St Yarowsky, 1992b; Leacock et al., 1993b; Lehman, 1994).</S><S sid = 55 ssid = >Leacock et al. (1993b), Leacock, Towell, and Voorhees (1993a) and Voorhees, Leacock, and Towell (1995) present results on a Bayesian method (Gale, Church, & Yarowsky, 1992a), a content vector method from information retrieval (Salton, Wong, & Yang, 1975), and a neural network trained using backpropagation (Rumelhart, Hinton, & Williams, 1986).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W96-0208.txt | Citing Article:  W02-1606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some researchers use neural networks in their word sense disambiguation systems Because of its strong capability in classification (Waltz et al, 1985, Gallant, 1991, Leacock et al, 1993, and Mooney, 1996).</S> | Reference Offset:  ['48','69'] | Reference Text:  <S sid = 48 ssid = >Our tests are based on the corpus assembled by Leacock et al. (1993b).</S><S sid = 69 ssid = >Since the previous results of Leacock et al. (1993b) indicated that neural networks did not benefit from hidden units on the &quot;line&quot; disambiguation data, we employed a simple perceptron (Rosenblatt, 1962) as a representative connectionist method.</S> | Discourse Facet:  NA | Annotator: Automatic


