Citance Number: 1 | Reference Article:  W10-2903.txt | Citing Article:  D11-1140.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available.</S> | Reference Offset:  ['141','201'] | Reference Text:  <S sid = 141 ssid = >The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W10-2903.txt | Citing Article:  N12-1049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recent work by Clarke et al (2010) and Liang et al.</S> | Reference Offset:  ['201','206'] | Reference Text:  <S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S><S sid = 206 ssid = >The direct approach resembles learning a binary classifier over a latent structure (Chang et al., 2010a); while the aggressive approach has similarities with work that uses labeled structures and a binary signal indicating the existence of good structures to improve structured prediction (Chang et al., 2010b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W10-2903.txt | Citing Article:  P12-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers.</S> | Reference Offset:  ['159','201'] | Reference Text:  <S sid = 159 ssid = >We automatically generate a set of natural language queries and response pairs {(x, r)} by executing the annotated logical forms on the database.</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W10-2903.txt | Citing Article:  P13-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance.</S> | Reference Offset:  ['141','201'] | Reference Text:  <S sid = 141 ssid = >The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W10-2903.txt | Citing Article:  P13-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments.</S> | Reference Offset:  ['141','201'] | Reference Text:  <S sid = 141 ssid = >The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W10-2903.txt | Citing Article:  P13-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Due to space consideration, we provide a brief description (see (Clarke et al, 2010) for more details).</S> | Reference Offset:  ['119','141'] | Reference Text:  <S sid = 119 ssid = >Due to space limitations we refer the reader to (Zelle and Mooney, 1996) for a detailed description of the Geoquery domain.</S><S sid = 141 ssid = >The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W10-2903.txt | Citing Article:  P13-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al, 2010) for more details).</S> | Reference Offset:  ['128','129'] | Reference Text:  <S sid = 128 ssid = >We frame the inference problem as an Integer Linear Programming (ILP) problem (Equation (2)) in which the first-order decisions are governed by αcs, a binary decision variable indicating that constituent c is aligned with logical symbol s. And Qcs,dt capture the second-order decisions indicating the symbol t (associated with constituent d) is an argument to function s (associated with conIt is clear that there are dependencies between the α-variables and Q-variables.</S><S sid = 129 ssid = >For example, given that Qcs,dt is active, the corresponding αvariables αcs and αdt must also be active.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W10-2903.txt | Citing Article:  P13-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, when trained using the noisy supervision, our method achieves substantially more accurate translations than a state-of-the-art semantic parser (Clarke et al, 2010) (specifically, 80.0% in F-Score compared to an F-Score of 66.7%).</S> | Reference Offset:  ['126','201'] | Reference Text:  <S sid = 126 ssid = >For example, whether next to and state forms next to(state(·)) or state(next to(·)).</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W10-2903.txt | Citing Article:  P13-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It continues sampling a specification tree for each text specification until it finds one which successfully reads all of the input examples. The second baseline Aggressive is a state-of the-art semantic parsing framework (Clarke et al, 2010). The framework repeatedly predicts hidden structures (specification trees in our case) using a structure learner, and trains the structure learner based on the execution feedback of its predictions.</S> | Reference Offset:  ['86','203'] | Reference Text:  <S sid = 86 ssid = >When a structure is found with positive feedback it is added to the training pool for a structured learner.</S><S sid = 203 ssid = >Although our framework can also be applied in these settings we do not assume that the text can be grounded in a world state.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W10-2903.txt | Citing Article:  P11-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in Clarke et al (2010), we obviate the need for annotated logical forms by considering the end-to-end problem of mapping questions to answers.</S> | Reference Offset:  ['1','127'] | Reference Text:  <S sid = 1 ssid = >Current approaches to semantic parsing, the task of converting text to a formal meaning representation, rely on annotated training data mapping sentences to logical forms.</S><S sid = 127 ssid = >Note that for all possible logical forms and alignments there exists a one-to-one mapping to these decisions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W10-2903.txt | Citing Article:  P11-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At the same time, representations such as FunQL (Kate et al, 2005), which was used in Clarke et al (2010), are simpler but lack the full expressive power of lambda calculus.</S> | Reference Offset:  ['141','201'] | Reference Text:  <S sid = 141 ssid = >The WordNet metric measures similarity based on synonymy, hyponymy and meronymy (Do et al., 2010).</S><S sid = 201 ssid = >Several recent works (Chen and Mooney, 2008; Liang et al., 2009; Branavan et al., 2009) explore using an external world context as a supervision signal for semantic interpretation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W10-2903.txt | Citing Article:  P11-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We first compare our system with Clarke et al (2010) (henceforth, SEMRESP), which also learns a semantic parser from question-answer pairs.</S> | Reference Offset:  ['167','177'] | Reference Text:  <S sid = 167 ssid = >Our experiments are designed to answer three questions: We first compare how well our model performs under four different learning regimes.</S><S sid = 177 ssid = >To answer the second question, we compare a supervised version of our model to existing semantic parsers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W10-2903.txt | Citing Article:  D12-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010).</S> | Reference Offset:  ['26','185'] | Reference Text:  <S sid = 26 ssid = >We consider scenarios where the feedback is provided as a binary signal, correct +1 or incorrect −1.</S><S sid = 185 ssid = >Analysis over the training data shows that in 66.8% examples both approaches predict a logical form that gives the correct answer.</S> | Discourse Facet:  NA | Annotator: Automatic


