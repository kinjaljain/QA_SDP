Citance Number: 1 | Reference Article:  C04-1072.txt | Citing Article:  P04-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Lin and Och (2004), we proposed a framework that automatically evaluated automatic MT evaluation metrics using only manual translations without further human involvement.</S> | Reference Offset:  ['4','49'] | Reference Text:  <S sid = 4 ssid = >In this paper, we introduce a new evaluation method, ORANGE, for evaluating automatic machine translation evaluation metrics automatically without extra human involvement other than using a set of reference translations.</S><S sid = 49 ssid = >(Oracle1 Ranking for Gisting Evaluation) and the smaller the ratio is, the better the automatic metric is. There are several advantages of the proposed ORANGE evaluation method: ? No extra human involvement ? ORANGE uses the existing human references but not human evaluations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C04-1072.txt | Citing Article:  P14-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This locality assumption eases efficient implementation of our algorithm, and can be realized using a sentence-level evaluation measure such as BLEU+1 (Lin and Och, 2004).</S> | Reference Offset:  ['42','62'] | Reference Text:  <S sid = 42 ssid = >We adopt this assumption and add one more assumption that automatic translations are usually worst than their reference translations.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C04-1072.txt | Citing Article:  P11-2027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >156 at the sentence levels moothed-bleu (Lin and Och, 2004) was used in this case.</S> | Reference Offset:  ['23','62'] | Reference Text:  <S sid = 23 ssid = >From the BLEU group, we found that shorter BLEU has better adequacy correlation while longer BLEU has better fluency correlation.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C04-1072.txt | Citing Article:  P07-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ROUGE utilizes, skip n-grams, which allow for matches of sequences of words that are not necessarily adjacent (Lin and Och, 2004a).</S> | Reference Offset:  ['62','141'] | Reference Text:  <S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S><S sid = 141 ssid = >Therefore, for candidate translations with less than n words, they can still get a positive smoothed BLEU score from shorter n-gram matches; however if nothing matches then they will get zero scores.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C04-1072.txt | Citing Article:  P07-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >BLEU is smoothed (Lin and Och, 2004b), and it considers only matching up to bi grams because this has higher correlations with human judgments than when higher-ordered n-grams are included.</S> | Reference Offset:  ['106','142'] | Reference Text:  <S sid = 106 ssid = >Therefore, Y1 would be ranked higher than Y2 using WLCS.</S><S sid = 142 ssid = >We call the smoothed BLEU: BLEUS.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C04-1072.txt | Citing Article:  P13-2058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Smoothed per-sentence BLEU (Lin and Och, 2004) was used as a similarity metric.</S> | Reference Offset:  ['62','142'] | Reference Text:  <S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S><S sid = 142 ssid = >We call the smoothed BLEU: BLEUS.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C04-1072.txt | Citing Article:  W07-0738.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Stemming is enabled (Lin and Och, 2004a).</S> | Reference Offset:  ['45','62'] | Reference Text:  <S sid = 45 ssid = >For example, a statistical machine translation system such as ISI?s AlTemp SMT system (Och 2003) can generate a list of n-best alternative translations given a source sentence.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C04-1072.txt | Citing Article:  P07-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Metrics in the Rouge family allow for skip n-grams (Lin and Och,2004a); Kauchak and Barzilay (2006) take para phrasing into account; metrics such as METEOR (Banerjee and Lavie, 2005) and GTM (Melamedetal., 2003) calculate both recall and precision; ME TEOR is also similar to SIA (Liu and Gildea, 2006) in that word class information is used.</S> | Reference Offset:  ['13','97'] | Reference Text:  <S sid = 13 ssid = >Turian et al (2003) introduced General Text Matcher (GTM) based on accuracy measures such as recall, precision, and F-measure.</S><S sid = 97 ssid = >Another possible function family is the polynomial family of the form k?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C04-1072.txt | Citing Article:  P07-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >BLEU is smoothed to be more appropriate for sentence level evaluation (Lin and Och, 2004b), and the bi gram versions of BLEU and HWCM are reported because they have higher correlations than when longer n-grams are included.</S> | Reference Offset:  ['23','142'] | Reference Text:  <S sid = 23 ssid = >From the BLEU group, we found that shorter BLEU has better adequacy correlation while longer BLEU has better fluency correlation.</S><S sid = 142 ssid = >We call the smoothed BLEU: BLEUS.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C04-1072.txt | Citing Article:  D10-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We then used these coefficients to estimate the confidence interval, after excluding the top 25 and bottom 25 coefficients, following (Lin and Och, 2004).</S> | Reference Offset:  ['19','62'] | Reference Text:  <S sid = 19 ssid = >correlation coefficients are computed according to different automatic evaluation methods vs. human assigned adequacy and fluency.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C04-1072.txt | Citing Article:  N12-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Unless otherwise stated, we will assume the use of sentence BLEU with add1 smoothing (Lin and Och, 2004).</S> | Reference Offset:  ['62','140'] | Reference Text:  <S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S><S sid = 140 ssid = >In order to compute BLEU at sentence level, we apply the following smoothing technique: Add one count to the n-gram hit and total n gram count for n > 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C04-1072.txt | Citing Article:  D12-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As F1 score is not decomposable, we optimize sentence-level F1 score which serves as an approximation of the corpus-level F1 score. Similarly, Hopkins and May optimize a sentence level BLEU approximation (Lin and Och, 2004) in stead of the corpus-level BLEU score (Papinenietal., 2002).</S> | Reference Offset:  ['32','50'] | Reference Text:  <S sid = 32 ssid = >The other potential problem for correlation analysis of human vs. automatic framework is that high corpus-level correlation might not translate to high sentence-level correlation.</S><S sid = 50 ssid = >Applicable on sentence-level ? Diagnostic error analysis on sentence-level is naturally provided.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C04-1072.txt | Citing Article:  D12-1052.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The optimization objective is sentence level BLEU (Lin and Och, 2004).</S> | Reference Offset:  ['50','62'] | Reference Text:  <S sid = 50 ssid = >Applicable on sentence-level ? Diagnostic error analysis on sentence-level is naturally provided.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C04-1072.txt | Citing Article:  D07-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As we would like to avoid this problem, we use the smoothed sentence-level Bleuscoreas suggested in (Lin and Och, 2004).</S> | Reference Offset:  ['50','62'] | Reference Text:  <S sid = 50 ssid = >Applicable on sentence-level ? Diagnostic error analysis on sentence-level is naturally provided.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C04-1072.txt | Citing Article:  D11-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They obtained similar results in both cases (Lin and Och, 2004a).</S> | Reference Offset:  ['187','207'] | Reference Text:  <S sid = 187 ssid = >Table 7 shows the results.</S><S sid = 207 ssid = >We then check the portion of the cases where machine translations are as good as the human translations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C04-1072.txt | Citing Article:  D11-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While the F measure over Precision and Recall satisfies these constraints, precision and recall in isolation do not satisfy all of them: maximum recall can be achieved without resembling the gold standard text decomposition; and maximum precision can be achieved with only a few overlapped elements.BLEU (Papineni et al, 2001a) computes the n gram precision while the metric ROUGE (LinandOch, 2004a) computes the n-gram recall.</S> | Reference Offset:  ['13','20'] | Reference Text:  <S sid = 13 ssid = >Turian et al (2003) introduced General Text Matcher (GTM) based on accuracy measures such as recall, precision, and F-measure.</S><S sid = 20 ssid = >BLEU1, 4, and 12 are BLEU with maximum n-gram lengths of 1, 4, and 12 respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C04-1072.txt | Citing Article:  E06-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The introduction of smoothing (Lin and Och, 2004) solves this problem only partially.</S> | Reference Offset:  ['62','85'] | Reference Text:  <S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S><S sid = 85 ssid = >Unfortunately, the basic LCS also has a problem that it does not differentiate LCSes of different spatial relations within their embedding sequences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C04-1072.txt | Citing Article:  E06-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As the BLEU score is unsuitable for sentence level evaluation in its original definition, BLEU-S smoothing as described by (Lin and Och, 2004) is performed.</S> | Reference Offset:  ['23','62'] | Reference Text:  <S sid = 23 ssid = >From the BLEU group, we found that shorter BLEU has better adequacy correlation while longer BLEU has better fluency correlation.</S><S sid = 62 ssid = >ROUGE-L and ROUGE-S are described in details in Lin and Och (2004).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C04-1072.txt | Citing Article:  I08-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Skip-bigrams (Lin and Och, 2004) are pairs of words in sentence order allowing for gaps in between.</S> | Reference Offset:  ['112','118'] | Reference Text:  <S sid = 112 ssid = >Statistics Skip-bigram is any pair of words in their sentence order, allowing for arbitrary gaps.</S><S sid = 118 ssid = >the gunman police killed each sentence has C(4,2)2 = 6 skip-bigrams.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C04-1072.txt | Citing Article:  I08-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Using the notation by (Lin and Och, 2004), we denote the skip bigram overlap between two sentences X and Y as Skip2 (X, Y).</S> | Reference Offset:  ['113','138'] | Reference Text:  <S sid = 113 ssid = >Skip-bigram cooccurrence statistics measure the overlap of skip bigrams between a candidate translation and a set of reference translations.</S><S sid = 138 ssid = >sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


