Citance Number: 1 | Reference Article:  C08-1109.txt | Citing Article:  C10-2031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The accuracy of the choice classifier, the part of the system to which the work at hand is most similar, is 62.32% when tested on text from Encarta and Reuters news. Tetreault and Chodorow (2008a) present a system for detecting preposition errors in learner text.</S> | Reference Offset:  ['45','215'] | Reference Text:  <S sid = 45 ssid = >Classifier performance is poor in such cases because the classifier was trained on well-edited text, i.e., without misspelled words.</S><S sid = 215 ssid = >It is interesting to note that the most common usage errors by learners overwhelmingly involved the ten most frequently occurring prepositions in native text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C08-1109.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Tetreault and Chodorow, 2008b) challenged the view that using one rater is adequate by showing that preposition usage errors actually do not have high inter-annotator reliability.</S> | Reference Offset:  ['117','127'] | Reference Text:  <S sid = 117 ssid = >What these two evaluation methods have in common is that they side-step the issue of annotator reliability.</S><S sid = 127 ssid = >3.2 Reliability.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C08-1109.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is mostly due to the fact that learner corpora are difficult to acquire (and then annotate), but also to the fact that they are 1 (Tetreault and Chodorow, 2008b) report that it would take 80hrs for one of their trained raters to find and mark 1,000 preposition errors.</S> | Reference Offset:  ['196','197'] | Reference Text:  <S sid = 196 ssid = >and ?OK? sub corpora.</S><S sid = 197 ssid = >The original corpus totaled over 22,000 prepositions which would normally take several weeks for two raters to double annotate and thenadjudicate.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C08-1109.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Examples include the Cambridge Learners Corpus2 used in (Felice and Pullman, 2009), and TOEFL data, used in (Tetreault and Chodorow, 2008a).</S> | Reference Offset:  ['192','211'] | Reference Text:  <S sid = 192 ssid = >In addition, while our methodology is used for evaluating a system, active learning is commonly used for training a system.</S><S sid = 211 ssid = >From our annotated set of preposition errors, we found that the most common prepositions that learners used incorrectly were in (21.4%), to (20.8%) and of (16.6%).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C08-1109.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Tetreault and Chodorow, 2008b) showed that trained human raters can achieve very high agreement (78%) on this task.</S> | Reference Offset:  ['23','160'] | Reference Text:  <S sid = 23 ssid = >Our results showed only about75% agreement between the two raters, and be tween each of our raters and Encarta.The presence of so much variability in prepo sition function and usage makes the task of thelearner a daunting one.</S><S sid = 160 ssid = >human rater.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C08-1109.txt | Citing Article:  W10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, (Tetreault and Chodorow, 2008b) found kappa between two raters averaged 0.630. Because there is no gold standard for the error detection task, kappa was used to compare Turker responses to those of three trained annotators.</S> | Reference Offset:  ['129','132'] | Reference Text:  <S sid = 129 ssid = >Despite the rigorous training regimen, kappa ranged from 0.411 to 0.786, with an overall combined value of 0.630.</S><S sid = 132 ssid = >The kappa of 0.630 shows the difficulty of this task and also shows how two highly trained raters can produce very different judgments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C08-1109.txt | Citing Article:  W10-4236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >There is already existing work that addresses specific problems in this area (see, for ex ample, (Tetreault and Chodorow, 2008)), but to be genuinely useful, we require a solution to the writing problem as a whole, integrating existing solutions to sub-problems with new solutions for problems as yet unexplored.</S> | Reference Offset:  ['11','40'] | Reference Text:  <S sid = 11 ssid = >c ? 2008.</S><S sid = 40 ssid = >In analyzing the contexts, we used only tagging and heuris tic phrase-chunking, rather than parsing, so as to avoid problems that a parser might encounter with ill-formed non-native text 1 . In test mode, the clas-.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C08-1109.txt | Citing Article:  W10-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In example 1, the context requires a definite article, and the definite article, in turn, calls for the 4Our error classification was inspired by the classification developed for the annotation of preposition errors (Tetreault and Chodorow, 2008a).</S> | Reference Offset:  ['120','133'] | Reference Text:  <S sid = 120 ssid = >3.1 Annotation.</S><S sid = 133 ssid = >Details on our annotation and human judgment experiments can be found in (Tetreault and Chodorow, 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C08-1109.txt | Citing Article:  W10-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Tetreault and Chodorow (Tetreault and Chodorow, 2008a) show that agreement between two native speakers on a cloze test targeting prepositions is about 76%, which demonstrates that there are many contexts that license multiple prepositions.</S> | Reference Offset:  ['126','154'] | Reference Text:  <S sid = 126 ssid = >Finally, the raters suggested prepositions that would best fit the context, even if there were no error (some contexts can license multiple prepositions).</S><S sid = 154 ssid = >prepositions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C08-1109.txt | Citing Article:  W10-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The latter is complicated by the fact that native speakers differ widely with respect to what constitutes acceptable usage (Tetreault and Chodorow, 2008a). To date, a common approach to annotating non native text has been to use one rater (Gamon et al, Source Errors Errors Mistakes by error type language total per 100 Repl.</S> | Reference Offset:  ['7','10'] | Reference Text:  <S sid = 7 ssid = >Usage errors involving prepositions are among the most common types seen in thewriting of non-native English speakers.</S><S sid = 10 ssid = >What is responsiblefor making preposition usage so difficult for non native speakers?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C08-1109.txt | Citing Article:  W11-1422.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some recent work includes Chodorow et al (2007), De Felice and Pulman (2008), Gamon (2010), Han et al (2010), Izumi et al (2004), Tetreault and Chodorow (2008), Rozovskaya and Roth (2010a, 2010b).</S> | Reference Offset:  ['64','113'] | Reference Text:  <S sid = 64 ssid = >This is a tactic also used for determiner selection in (Nagata et al, 2006) and (Han et al, 2006).</S><S sid = 113 ssid = >To date, single human annotation has typically been the gold standard for grammatical error detection, such as in the work of (Izumi et al, 2004), (Han et al, 2006), (Nagata et al, 2006), (Eeg-Olofsson and Knuttson, 2003) 2 .Another method for evaluation is verification ((Ga mon et al, 2008), where a human rater checks over a system?s output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C08-1109.txt | Citing Article:  W11-2111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The usage feature detects errors related to articles (Han et al, 2006), prepositions (Tetreault and Chodorow, 2008) and collocations (Futagi et al, 2008).</S> | Reference Offset:  ['64','113'] | Reference Text:  <S sid = 64 ssid = >This is a tactic also used for determiner selection in (Nagata et al, 2006) and (Han et al, 2006).</S><S sid = 113 ssid = >To date, single human annotation has typically been the gold standard for grammatical error detection, such as in the work of (Izumi et al, 2004), (Han et al, 2006), (Nagata et al, 2006), (Eeg-Olofsson and Knuttson, 2003) 2 .Another method for evaluation is verification ((Ga mon et al, 2008), where a human rater checks over a system?s output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C08-1109.txt | Citing Article:  D10-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some researchers (Tetreault and Chodorow, 2008) exploited syntactic information and n-gram features to represent verb usage context.</S> | Reference Offset:  ['11','69'] | Reference Text:  <S sid = 11 ssid = >c ? 2008.</S><S sid = 69 ssid = >which represent richer contextual struc ture in the form of syntactic patterns.Table 1 (first column) illustrates the four com bination features used for the example context ?take our place in the line?.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C08-1109.txt | Citing Article:  W10-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Typically, data-driven approaches to learner errors use a classifier trained on contextual information such as tokens and part-of-speech tags within a window of the preposition/article (Gamon et al 2008, 2010, DeFelice and Pulman 2007, 2008, Han et al 2006, Chodorow et al 2007, Tetreault and Chodorow 2008).</S> | Reference Offset:  ['64','113'] | Reference Text:  <S sid = 64 ssid = >This is a tactic also used for determiner selection in (Nagata et al, 2006) and (Han et al, 2006).</S><S sid = 113 ssid = >To date, single human annotation has typically been the gold standard for grammatical error detection, such as in the work of (Izumi et al, 2004), (Han et al, 2006), (Nagata et al, 2006), (Eeg-Olofsson and Knuttson, 2003) 2 .Another method for evaluation is verification ((Ga mon et al, 2008), where a human rater checks over a system?s output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C08-1109.txt | Citing Article:  W10-1502.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['85','229'] | Reference Text:  <S sid = 85 ssid = >We compared 867 Class Components Combo:word Features Combo:tag Features p-N FH line NN N-p-N PN-FH place-line NN-NN V-p-N PV-PN take-line VB-NN V-N-p-N PV-PN-FH take-place-line VB-NN-NN Table 1: Feature Examples for take our place in the line different models: the baseline model of 25 features and baseline with combination features added.</S><S sid = 229 ssid = >We wouldalso like to acknowledge the three anonymous reviewers and Derrick Higgins for their helpful com ments and feedback.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C08-1109.txt | Citing Article:  W10-1502.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example Tetreault and Chodorow (2008) use a maximum entropy classifier to build a model of correct preposition usage, with 7 million instances in their training set, and Lee and Knutsson (2008) use memory-based learning ,with10 million sentences in their training set.</S> | Reference Offset:  ['11','37'] | Reference Text:  <S sid = 11 ssid = >c ? 2008.</S><S sid = 37 ssid = >We have used a Maximum Entropy (ME) classi fier (Ratnaparkhi, 1998) to build a model of correctpreposition usage for 34 common English prepo sitions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C08-1109.txt | Citing Article:  W10-2921.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For further perspective on these results, note Chodorow et al (2007) achieved 69% with 7M training examples, while Tetreault and Chodorow (2008) found the human performance was around 75%.</S> | Reference Offset:  ['92','133'] | Reference Text:  <S sid = 92 ssid = >Results The baseline system (described in(Chodorow et al, 2007)) performed at 79.8% precision and 11.7% recall.</S><S sid = 133 ssid = >Details on our annotation and human judgment experiments can be found in (Tetreault and Chodorow, 2008).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C08-1109.txt | Citing Article:  W12-2025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We adopt the features from previous work by Han et al (2006), Tetreault and Chodorow (2008), and Rozovskaya et al (2011) for our system.</S> | Reference Offset:  ['64','113'] | Reference Text:  <S sid = 64 ssid = >This is a tactic also used for determiner selection in (Nagata et al, 2006) and (Han et al, 2006).</S><S sid = 113 ssid = >To date, single human annotation has typically been the gold standard for grammatical error detection, such as in the work of (Izumi et al, 2004), (Han et al, 2006), (Nagata et al, 2006), (Eeg-Olofsson and Knuttson, 2003) 2 .Another method for evaluation is verification ((Ga mon et al, 2008), where a human rater checks over a system?s output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C08-1109.txt | Citing Article:  P10-2065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We recreate a state-of-the-art preposition usage system (Tetreault and Chodorow (2008), henceforth T& amp; C08) originally trained with lexical features and augment it with parser output features.</S> | Reference Offset:  ['11','66'] | Reference Text:  <S sid = 11 ssid = >c ? 2008.</S><S sid = 66 ssid = >2.3 Combination Features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C08-1109.txt | Citing Article:  P10-2065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The prepositions were judged by two trained annotators and checked by the authors using the preposition annotation scheme described in Tetreault and Chodorow (2008b).</S> | Reference Offset:  ['120','130'] | Reference Text:  <S sid = 120 ssid = >3.1 Annotation.</S><S sid = 130 ssid = >Of the prepositions that Rater 1 judged to be errors, Rater 2 judged 30.2% to be acceptable.</S> | Discourse Facet:  NA | Annotator: Automatic


