Citance Number: 1 | Reference Article:  N01-1026.txt | Citing Article:  W03-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Yarowsky and Ngai, 2001) aim at pos tagging a target language corpus using English pos tags as well as estimation of lexical priors.</S> | Reference Offset:  ['39','41'] | Reference Text:  <S sid = 39 ssid = >Section 4.2.2 will discuss the estimation of P(tilti-i)â€¢ The following section describes the estimation of P(tiiwi), which using Bayes rule and direct (relatively noise-free) measurement of P(w) from the French data, can be used to calculate P(wiiti) as: Inspection of the raw projected tag data shows the need for an improved estimation of P(t1w).</S><S sid = 41 ssid = >NNS(,), Table 1 shows the observed frequency distributions of English tags projected onto four French words from 1-to-1 alignments, for the core N/V/J/R/I POS tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N01-1026.txt | Citing Article:  W03-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Having said this, we follow in principle the algorithm proposed by (Yarowsky and Ngai, 2001) to estimate lexical priors.</S> | Reference Offset:  ['54','59'] | Reference Text:  <S sid = 54 ssid = >The major reason for estimating the lexical priors and tag sequence model separately is that a tag sequence bigram (or even trigram) model has far fewer parameters than the lexical prior model and thus can be estimated on a very conservatively chosen set of filtered, high confidence alignment data.</S><S sid = 59 ssid = >After the lexical prior models have been trained (as above), sentences are also tested to identify those where the directly projected tag sequence (from the automatic alignments) is closely compatible with the estimated lexical prior probabilities for each word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N01-1026.txt | Citing Article:  W03-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, as was noted by (Yarowsky and Ngai, 2001), most words tend to have at most two pos.</S> | Reference Offset:  ['41','52'] | Reference Text:  <S sid = 41 ssid = >NNS(,), Table 1 shows the observed frequency distributions of English tags projected onto four French words from 1-to-1 alignments, for the core N/V/J/R/I POS tags.</S><S sid = 52 ssid = >Given the lower frequency of most content words, the potential risks of using these 1-to-n alignments are greater, but so are the benefits given that the 1-to-1 alignments tend to be both sparse and somewhat biased.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N01-1026.txt | Citing Article:  W03-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Yarowsky and Ngai, 2001) propose the same algorithm as the one proposed here for their estimation of lexical priors, with the exception that they use automatic word alignments rather than our extraction algorithm for finding corresponding words.</S> | Reference Offset:  ['59','63'] | Reference Text:  <S sid = 59 ssid = >After the lexical prior models have been trained (as above), sentences are also tested to identify those where the directly projected tag sequence (from the automatic alignments) is closely compatible with the estimated lexical prior probabilities for each word.</S><S sid = 63 ssid = >2The exception is for function words (i.e. the majority lexical prior is not a Noun, Verb, Adjective or Adverb) located in a 1-to-n alignment sequence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N01-1026.txt | Citing Article:  W03-0414.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As for (Yarowsky and Ngai, 2001) estimating lexical priors is merely an intermediate step, they do not report evaluation results for this step.</S> | Reference Offset:  ['54','75'] | Reference Text:  <S sid = 54 ssid = >The major reason for estimating the lexical priors and tag sequence model separately is that a tag sequence bigram (or even trigram) model has far fewer parameters than the lexical prior model and thus can be estimated on a very conservatively chosen set of filtered, high confidence alignment data.</S><S sid = 75 ssid = >Overall, these translingual projection results are quite encouraging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N01-1026.txt | Citing Article:  P14-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Moreover, the success of joint bilingual learning may lend itself to many inherent multilingual NLP tasks such as POS tagging (Yarowsky and Ngai, 2001), name entity recognition (Yarowsky et al, 2001).</S> | Reference Offset:  ['0','29'] | Reference Text:  <S sid = 0 ssid = >Inducing Multilingual POS Taggers And NP Bracketers Via Robust Projection Across Aligned Corpora</S><S sid = 29 ssid = >Both corpora were word-aligned by the now publicly available EGYPT system (Al-Onaizan et al., 1999) and based on IBM's Model 3 statistical MT formalism (Brown et al., 1990).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N01-1026.txt | Citing Article:  P11-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways.</S> | Reference Offset:  ['23','62'] | Reference Text:  <S sid = 23 ssid = >This further motivates the noise-robust training and stand-alone application of our current work.</S><S sid = 62 ssid = >Future work will focus on differential confidence weighting of sentence fragments, and iterative (E-M) re-estimation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N01-1026.txt | Citing Article:  P11-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This can be seen as a rough approximation of Yarowsky and Ngai (2001).</S> | Reference Offset:  ['86','87'] | Reference Text:  <S sid = 86 ssid = >A stand-alone POS tagger applicable to new data can be used to improve statistical MT translation models, both by supporting finer translation model granularity (e.g. wind/NN modeled distinctly from wind/VB), and by serving as a source of backoff alignment probabilities for previously unseen words.</S><S sid = 87 ssid = >Thus tagging models induced from bilingual alignments can be used to improve these very alignments, and hence improve their own training source.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N01-1026.txt | Citing Article:  C10-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001).</S> | Reference Offset:  ['30','31'] | Reference Text:  <S sid = 30 ssid = >The data sets used for our projection studies both contained approximately 2 million words in each language.</S><S sid = 31 ssid = >Their alignment was based on strictly word-based model variants for English and character-based model variants for Chinese, with no use of morphological analysis or stemming, POS-tagging, bracketing, outside dictionaries or any other external data source or annotation tool.'</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N01-1026.txt | Citing Article:  D07-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first to explore the idea were Yarowsky and Ngai (2001), who induced a part-of-speech tagger for French and base noun phrase detectors for French and Chinese via transfer from English resources.</S> | Reference Offset:  ['5','20'] | Reference Text:  <S sid = 5 ssid = >French sides.</S><S sid = 20 ssid = >Evaluation on noun-phrase bracketing showed 78% precision for Chinese, and 80% precision for English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N01-1026.txt | Citing Article:  D07-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky and Ngai (2001) were the first to propose the use of parallel texts to bootstrap the creation of taggers.</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >Inducing Multilingual POS Taggers And NP Bracketers Via Robust Projection Across Aligned Corpora</S><S sid = 17 ssid = >The primary exception has been in the area of parallel bilingual parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N01-1026.txt | Citing Article:  D07-1041.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['86','87'] | Reference Text:  <S sid = 86 ssid = >A stand-alone POS tagger applicable to new data can be used to improve statistical MT translation models, both by supporting finer translation model granularity (e.g. wind/NN modeled distinctly from wind/VB), and by serving as a source of backoff alignment probabilities for previously unseen words.</S><S sid = 87 ssid = >Thus tagging models induced from bilingual alignments can be used to improve these very alignments, and hence improve their own training source.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N01-1026.txt | Citing Article:  P13-2112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this case alignments such as English laws (NNS) to Frenchles (DT )lois (NNS) would be expected (Yarowsky and Ngai, 2001).</S> | Reference Offset:  ['41','48'] | Reference Text:  <S sid = 41 ssid = >NNS(,), Table 1 shows the observed frequency distributions of English tags projected onto four French words from 1-to-1 alignments, for the core N/V/J/R/I POS tags.</S><S sid = 48 ssid = >Finally, the issue arises of what to do with the 1-to-n phrasal alignment cases shown in Figure 2 (e.g. potatoes/NNS pommesINNSâ€ž de/NNSb terre/NNS, and Laws/NNS Les/NNSâ€ž /ois/NNSb).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N01-1026.txt | Citing Article:  I08-1069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['86','87'] | Reference Text:  <S sid = 86 ssid = >A stand-alone POS tagger applicable to new data can be used to improve statistical MT translation models, both by supporting finer translation model granularity (e.g. wind/NN modeled distinctly from wind/VB), and by serving as a source of backoff alignment probabilities for previously unseen words.</S><S sid = 87 ssid = >Thus tagging models induced from bilingual alignments can be used to improve these very alignments, and hence improve their own training source.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N01-1026.txt | Citing Article:  P11-2082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Given that we have a parallel corpus where the German side overtly realizes T and V, this is a classical case of annotation projection (Yarowsky and Ngai, 2001).</S> | Reference Offset:  ['9','40'] | Reference Text:  <S sid = 9 ssid = >The second limitation is the potential mismatch in the annotation needs of two languages; not all distinctions that may be desirable for one language (such as grammatical gender in French) are compatible or even present in a parallel language such as English.</S><S sid = 40 ssid = >Temporarily excluding the case of compound alignments (e.g.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N01-1026.txt | Citing Article:  C10-2135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A technique known as annotation projection (Yarowsky and Ngai, 2001) provides a means to relax this resource bottleneck to some extent.</S> | Reference Offset:  ['9','75'] | Reference Text:  <S sid = 9 ssid = >The second limitation is the potential mismatch in the annotation needs of two languages; not all distinctions that may be desirable for one language (such as grammatical gender in French) are compatible or even present in a parallel language such as English.</S><S sid = 75 ssid = >Overall, these translingual projection results are quite encouraging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N01-1026.txt | Citing Article:  H05-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous research on resource projection attempts to address these problems by redistributing the parameter values (Yarowsky and Ngai, 2001) or by applying transformation rules (Hwa et al, 851 2002).</S> | Reference Offset:  ['13','29'] | Reference Text:  <S sid = 13 ssid = >Previously, tools for automatic wordalignment of bilingual corpora were not widely available outside IBM, the research group pioneering statistical machine translation with the Candide system (Brown et al, 1990).</S><S sid = 29 ssid = >Both corpora were word-aligned by the now publicly available EGYPT system (Al-Onaizan et al., 1999) and based on IBM's Model 3 statistical MT formalism (Brown et al., 1990).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N01-1026.txt | Citing Article:  H05-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following the work of Yarowsky and Ngai (2001) we focus on the task of training a Part-of-Speech (POS) tagger, but we conduct our experiments with the more dissimilar language pair of English Chinese instead of English-French.</S> | Reference Offset:  ['28','69'] | Reference Text:  <S sid = 28 ssid = >The data used in our experiments are the EnglishFrench Canadian Hansards and English-Chinese Hong Kong Hansards, parallel records of parliamentary proceedings and publications.</S><S sid = 69 ssid = >As previously noted, the goal of this work is not to induce potential French tagset features such as grammatical gender, mood or subtle tense distinctions that do not appear in English, but to focus on the algorithm's effectiveness at accurately transferring tagging capabilities at the granularity that is present in English (or whichever projection source language used).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N01-1026.txt | Citing Article:  H05-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One method of acquiring a large corpus of automatically POS tagged Chinese data is by projection (Yarowsky and Ngai, 2001).</S> | Reference Offset:  ['65','70'] | Reference Text:  <S sid = 65 ssid = >Doing so salvages very large quantities of otherwise accurate tag sequence data with very little introduced noise.</S><S sid = 70 ssid = >For independent evaluation data, a 120K-word hand-tagged French dataset generously provided by Universite de Montreal was used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N01-1026.txt | Citing Article:  H05-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following Yarowsky and Ngai (2001), we define 12 equivalence classes over the 47 Penn-English Treebank POS tags.</S> | Reference Offset:  ['41','68'] | Reference Text:  <S sid = 41 ssid = >NNS(,), Table 1 shows the observed frequency distributions of English tags projected onto four French words from 1-to-1 alignments, for the core N/V/J/R/I POS tags.</S><S sid = 68 ssid = >The second is at the level of granularity captured in the English Penn Treebank tagset, where for example singular and plural nouns (NN and NNS) are distinguished.</S> | Discourse Facet:  NA | Annotator: Automatic


