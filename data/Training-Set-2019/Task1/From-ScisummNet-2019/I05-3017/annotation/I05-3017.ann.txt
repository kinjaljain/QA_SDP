Citance Number: 1 | Reference Article:  I05-3017.txt | Citing Article:  P06-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using CRFs for the IOB tagging, yielded a very high R-oov in all of the four corpora used, but the R-iv rates were lower.</S> | Reference Offset:  ['31','130'] | Reference Text:  <S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S><S sid = 130 ssid = >Also interesting to compare are the OOV recall rates be tween the Open and Closed tracks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  I05-3017.txt | Citing Article:  C10-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The experiments of closed tests on the second SIGHAN Bakeoff (Emerson, 2005) show that the joint model significantly outperforms the baseline models of both generative and discriminative approaches.</S> | Reference Offset:  ['90','128'] | Reference Text:  <S sid = 90 ssid = >In closed tests, participants were only allowed to use information found in the training data.</S><S sid = 128 ssid = >As one would expect the best F score on the open tests was higher than the best on the closed tests, 0.972 vs. 0.964, both on the MSR corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  I05-3017.txt | Citing Article:  C10-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The corpora provided by the second SIGHAN Bakeoff (Emerson, 2005) were used in our experiments.</S> | Reference Offset:  ['0','31'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  I05-3017.txt | Citing Article:  P12-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For more detailed information on the corpora, refer to Emerson (2005).</S> | Reference Offset:  ['52','98'] | Reference Text:  <S sid = 52 ssid = >Corpus Information 124 2005 and allowed to continue through the time the training data was made available on July 11.When a site registered they selected which cor pus or corpora there were interested in using, and whether they would take part in the open or closed tracks (described below.)</S><S sid = 98 ssid = >After the scoring was done the script would mail the detailed results to the participant.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  I05-3017.txt | Citing Article:  P07-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Four training and testing corpora were used in the second bakeoff (Emerson, 2005), including the Academia Sinica corpus (AS), the Hong Kong City University Corpus (CU), the Peking University Corpus (PK) and the Microsoft Research Corpus (MR).</S> | Reference Offset:  ['14','21'] | Reference Text:  <S sid = 14 ssid = >The Traditional Chinese corpora were provided by Academia Sinica in Taiwan and the City University of Hong Kong.</S><S sid = 21 ssid = >The Academia Sinica corpus, provided.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  I05-3017.txt | Citing Article:  P07-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We chose the three models that achieved at least one best score in the closed tests from Emerson (2005), as well as the sub-word-based model of Zhang et al (2006) for comparison.</S> | Reference Offset:  ['127','128'] | Reference Text:  <S sid = 127 ssid = >Discussion Across all of the corpora the best performing system, in terms of F score, achieved a 0.972, with an average of 0.918 and median of 0.941.</S><S sid = 128 ssid = >As one would expect the best F score on the open tests was higher than the best on the closed tests, 0.972 vs. 0.964, both on the MSR corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  I05-3017.txt | Citing Article:  W10-4126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, successfully conducted four prior word segmentation bakeoffs, in 2003 (Sproat and Emerson, 2003), 2005 (Emerson, 2005), 2006 (Levow, 2006) and 2007 (Jin and Chen, 2007), and the bakeoff 2007 was jointly organized with the Chinese Information Processing Society of China (CIPS).</S> | Reference Offset:  ['0','8'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 8 ssid = >In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  I05-3017.txt | Citing Article:  N06-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the results of the closed test in Bakeoff 2005 (Emerson, 2005), the work of (Tseng et al, 2005), using conditional random fields (CRF) for the IOB tagging, yielded very high R-oovs in all of the four corpora used, but the R-iv rates were lower.</S> | Reference Offset:  ['31','52'] | Reference Text:  <S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S><S sid = 52 ssid = >Corpus Information 124 2005 and allowed to continue through the time the training data was made available on July 11.When a site registered they selected which cor pus or corpora there were interested in using, and whether they would take part in the open or closed tracks (described below.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  I05-3017.txt | Citing Article:  N06-2049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For detailed info. of the corpora and these scores, refer to (Emerson, 2005).</S> | Reference Offset:  ['24','98'] | Reference Text:  <S sid = 24 ssid = >A detailed description of these issues can be found on the Bakeoff 2005 1 A fifth (Simplified Chinese) corpus was provided by the University of Pennsylvania, but for numerous technical reasons it was not used in the evaluation.</S><S sid = 98 ssid = >After the scoring was done the script would mail the detailed results to the participant.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  I05-3017.txt | Citing Article:  W06-0115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics, conducted two prior word segmentation bakeoffs, in 2003 and 2005 (Emerson, 2005), which established benchmarks for word segmentation against which other systems are judged.</S> | Reference Offset:  ['0','8'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 8 ssid = >In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  I05-3017.txt | Citing Article:  W08-0335.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As an evidence, the CWS evaluation campaign, the Sighan Bakeoff (Emerson, 2005) has been held four times since 2004.</S> | Reference Offset:  ['10','31'] | Reference Text:  <S sid = 10 ssid = >During the winter of 2004 it was decided to hold a second evaluation to determine how the latest research has affected segmentation technology.</S><S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  I05-3017.txt | Citing Article:  W08-0335.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These specs were used in the second Sighan Bakeoff (Emerson, 2005).</S> | Reference Offset:  ['0','31'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  I05-3017.txt | Citing Article:  P06-2056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track.</S> | Reference Offset:  ['1','131'] | Reference Text:  <S sid = 1 ssid = >The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.</S><S sid = 131 ssid = >The best OOV recall in the open evaluation was 0.872 compared to just 0.813 on the closed track.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  I05-3017.txt | Citing Article:  C10-2139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the data provided by the second SIGHAN Bakeoff (Emerson, 2005) to test the two segmentation models.</S> | Reference Offset:  ['0','31'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 31 ssid = >Specific details can be found on the Bakeoff 2005 pages of the SIGHAN website.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  I05-3017.txt | Citing Article:  W06-1655.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), two of the highest scoring systems in the closed track competition were based on a CRF model.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 1 ssid = >The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  I05-3017.txt | Citing Article:  W06-1655.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The data used was the Microsoft Research Beijing corpus from the Second International Chinese Word Segmentation Bakeoff (Emerson, 2005), and we used the same train/test split used in the competition.</S> | Reference Offset:  ['0','13'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 13 ssid = >The Corpora Four corpora were used in the evaluation, two each using Simplified and Traditional Chinese characters.1 The Simplified Chinese corporawere provided by Beijing University and Micro soft Research Beijing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  I05-3017.txt | Citing Article:  W06-1655.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We did not explicitly test the utility of CRF-type features for improving recall on out-of-vocabulary items, but we note that in the Bakeoff, the model of Tseng et al (2005), which was very similar to our CRF-only system (only containing a few more feature templates), was consistently among the best performing systems in terms of test OOV recall (Emerson, 2005).</S> | Reference Offset:  ['117','127'] | Reference Text:  <S sid = 117 ssid = >All of the results comprise the following data: test recall (R), test precision (P), balancedF score (where F = 2PR/(P + R)), the out-of vocabulary (OOV) rate on the test corpus, the recall on OOV words (Roov), and the recall on in-vocabulary words (Riv).</S><S sid = 127 ssid = >Discussion Across all of the corpora the best performing system, in terms of F score, achieved a 0.972, with an average of 0.918 and median of 0.941.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  I05-3017.txt | Citing Article:  I08-4033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson, 2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as 'Achilles' that consists of four modules mainly: Regular expression extractor, dictionary-based N-gram segmentation, CRF-based subword tagging (Zhang et al, 2006), and confidence-based segmentation.</S> | Reference Offset:  ['0','8'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 8 ssid = >In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  I05-3017.txt | Citing Article:  P14-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm.</S> | Reference Offset:  ['8','47'] | Reference Text:  <S sid = 8 ssid = >In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003).</S><S sid = 47 ssid = >Rules and Procedures The bakeoff was run almost identically to the first described in Sproat and Emerson (2003):the detailed instructions provided to the partici pants are available on the bakeoff website at http://www.sighan.org/bakeoff2005/ .Groups (or ?sites?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  I05-3017.txt | Citing Article:  W12-2304.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The second benchmark that we adopted is the SIGHAN Bakeoff-2005 dataset (Emerson, 2005) for Chinese word segmentation.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >The Second International Chinese Word Segmentation Bakeoff</S><S sid = 1 ssid = >The second international Chinese word segmentation bakeoff was held in the summer of 2005 to evaluate the current state of the art in word segmentation.Twenty three groups submitted 130 result sets over two tracks and four different corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


