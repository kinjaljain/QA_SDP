Citance Number: 1 | Reference Article:  W07-2006.txt | Citing Article:  D08-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To address this issue, a coarse-grained English all-words task (Navigli et al, 2007) was conducted during SemEval-2007.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-2006.txt | Citing Article:  I08-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, in the English coarse grained all words task (Navigli et al,2007) at the recent SemEval Workshop the base line of choosing the most frequent sense using the first WordNet sense attained precision and recall of 78.9% which is only a few percent lower than the top scoring system which obtained 82.5%.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-2006.txt | Citing Article:  W11-1413.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The problem of how to cluster fine-grained senses into coarse senses is hard, especially if consensus is required (Navigli et al 2007).</S> | Reference Offset:  ['30','39'] | Reference Text:  <S sid = 30 ssid = >In most of the cases, weasked the lexicographer to map senses of the orig inal word to senses of lexically-related words (e.g. WordNet senses of procedural were mapped to ODE senses of procedure, etc.).</S><S sid = 39 ssid = >Only 8 of them were as signed more than one sense: specifically, two coarse senses were assigned to a single word instance4 and two distinct fine-grained senses were assigned to 7 word instances.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-2006.txt | Citing Article:  P09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, the performance of WSD systems clearly indicates that WSD is not easy unless one adopts a coarse-grained approach, and then systems tagging all words at best perform a few percentage points above the most frequent sense heuristic (Navigli et al, 2007).</S> | Reference Offset:  ['101','114'] | Reference Text:  <S sid = 101 ssid = >LCC-WSD ? ?</S><S sid = 114 ssid = >UPV-WSD ? ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-2006.txt | Citing Article:  W09-2405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, results are presented from the SemEval-2007 coarse grained all-words task (Navigli et al, 2007), and we explore the influence of various types of selectors on the algorithm in order to draw insight for future improvement of Web-based methods.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-2006.txt | Citing Article:  W09-2405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The sense inventory was created by mapping senses in WordNet 2.1 to the Oxford Dictionary of English (Navigli et al., 2007).</S> | Reference Offset:  ['24','31'] | Reference Text:  <S sid = 24 ssid = >The method consists of automatically map ping WordNet senses to top level, numbered entries in the Oxford Dictionary of English (ODE, (Soanesand Stevenson, 2003)).</S><S sid = 31 ssid = >When this mapping was not straightforward, we just adopted the WordNet sense inventory for that word.We released the entire sense groupings (those in duced from the manual mapping for words in the test set plus those automatically derived on the other words) and made them available to the participants.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-2006.txt | Citing Article:  W09-2405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For SemEval 2007, all systems performed better than the random base line of 53.43%, but only 4 of 13 systems achieved an F1 score higher than the MFS baseline of 78.89% (Navigli et al, 2007). Table 2 lists the results of applying the generalized Web selector algorithm described in this paper in a straight-forward manner, such that all scale (T) are set to 1.</S> | Reference Offset:  ['60','63'] | Reference Text:  <S sid = 60 ssid = >We calculated a MFS baseline of 78.89% and a random baseline of 52.43%.</S><S sid = 63 ssid = >results are much higher.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-2006.txt | Citing Article:  W10-2304.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This will allow to asses its applicability to realistic tasks, such as query processing or document indexing. Experimental Set-up In order to measure accuracy, the Senseval 2007 coarse WSD dataset (Navigli et al, 2007) has been employed.</S> | Reference Offset:  ['86','98'] | Reference Text:  <S sid = 86 ssid = >In order to allow for a critical and comparative inspection of the system results, we asked the partici pants to answer some questions about their systems.</S><S sid = 98 ssid = >As a result of the discus sion at the Senseval-3 workshop in 2004, one of the aims of SemEval-2007 was to tackle the problems at the roots of WSD.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-2006.txt | Citing Article:  P10-1154.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We report our results in terms of precision, recall and F1-measure on the Semeval-2007 coarse-grained all-words dataset (Navigli et al, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-2006.txt | Citing Article:  W08-2114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['46','125'] | Reference Text:  <S sid = 46 ssid = >To this end, besidethe expert lexicographer, a second author indepen dently performed part of the manual sense mapping (590 word senses) described in Section 2.2.</S><S sid = 125 ssid = >We would like to thank Martha Palmer for providing us the first three texts of the test corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-2006.txt | Citing Article:  W08-2114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For the SemEval workshop, only 6 of 15 systems performed better than this baseline on the nouns (Navigli et al, 2007), all of which used MFS as a back off strategy and an external sense tagged data set.</S> | Reference Offset:  ['89','96'] | Reference Text:  <S sid = 89 ssid = >the system used the MFS as a backoff strategy; 3.</S><S sid = 96 ssid = >As expected, several systems used lexico-semantic information from the WordNet semantic networkand/or were trained on the SemCor semantically annotated corpus.Finally, we point out that all the systems perform ing better than the MFS baseline adopted it as a backoff strategy when they were not able to output a sense assignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-2006.txt | Citing Article:  W08-2114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >All systems performing better than the MFS used the heuristic as a back off strategy when unable to output a sense (Navigli et al, 2007).</S> | Reference Offset:  ['89','96'] | Reference Text:  <S sid = 89 ssid = >the system used the MFS as a backoff strategy; 3.</S><S sid = 96 ssid = >As expected, several systems used lexico-semantic information from the WordNet semantic networkand/or were trained on the SemCor semantically annotated corpus.Finally, we point out that all the systems perform ing better than the MFS baseline adopted it as a backoff strategy when they were not able to output a sense assignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-2006.txt | Citing Article:  N09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Currently supervised methods achieve the best disambiguation quality (about 80% precision and recall for coarse-grained WSD in the most recent WSD evaluation conference SemEval 2007 (Navigli et al, 2007)).</S> | Reference Offset:  ['0','101'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 101 ssid = >LCC-WSD ? ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-2006.txt | Citing Article:  N09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the most recent SemEval 2007 (Navigli et al, 2007), the best unsupervised systems only achieved about 70% precision and 50% recall.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-2006.txt | Citing Article:  N09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have evaluated our method using SemEval-2007 Task 07 (Coarse-grained English All-words Task) test set (Navigli et al, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-2006.txt | Citing Article:  N09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Two authors of (Navigli et al, 2007) independently and manually annotated part of the test set (710 word instances), and the pairwise agreement was 93.80%.</S> | Reference Offset:  ['49','50'] | Reference Text:  <S sid = 49 ssid = >A sec ond author independently annotated part of the test set (710 word instances).</S><S sid = 50 ssid = >The pairwise agreement between the two authors was 93.80%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-2006.txt | Citing Article:  P12-3012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We benchmark our API by performing knowledge based WSD with BabelNet on standard SemEval datasets, namely the SemEval-2007 coarse-grained all-words (Navigli et al, 2007, Coarse-WSD, hence forth) and the SemEval-2010 cross-lingual (Lefever and Hoste, 2010, CL-WSD) WSD tasks.</S> | Reference Offset:  ['101','114'] | Reference Text:  <S sid = 101 ssid = >LCC-WSD ? ?</S><S sid = 114 ssid = >UPV-WSD ? ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-2006.txt | Citing Article:  P12-3012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 1: Performance on SemEval-2007 coarse-grained all-words WSD (Navigli et al, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 07: Coarse-Grained English All-Words Task</S><S sid = 1 ssid = >This paper presents the coarse-grained En glish all-words task at SemEval-2007.</S> | Discourse Facet:  NA | Annotator: Automatic


