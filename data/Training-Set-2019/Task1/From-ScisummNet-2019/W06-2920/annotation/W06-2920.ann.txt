Citance Number: 1 | Reference Article:  W06-2920.txt | Citing Article:  D11-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The evaluation metric traditionally associated with dependency parsing is based on scoring labeled or unlabeled attachment decisions, whereby each correctly identified pair of head-dependent words is counted towards the success of the parser (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['18','60'] | Reference Text:  <S sid = 18 ssid = >One of the reasons is the lack of a de-facto standard for an evaluation metric (labeled or unlabeled, separate root accuracy?</S><S sid = 60 ssid = >The predicted values were compared to the gold standard HEAD and DEPREL.6 The official evaluation metric is the labeled attachment score (LAS), i.e. the percentage of “scoring” tokens for which the system has predicted the correct HEAD and DEPREL.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-2920.txt | Citing Article:  W12-0503.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For this paper since we are primarily concerned with the merging of tree structures we only evaluate UAS (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['125','183'] | Reference Text:  <S sid = 125 ssid = >This approach assumes projective dependency structures.</S><S sid = 183 ssid = >(2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-2920.txt | Citing Article:  D07-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently dependency parsing has received renewed interest, both in the parsing literature (Buchholz and Marsi, 2006) and in applications like translation (Quirk et al, 2005) and information extraction (Culotta and Sorensen, 2004).</S> | Reference Offset:  ['46','244'] | Reference Text:  <S sid = 46 ssid = >Nivre’s parser has been tested for Swedish (Nivre et al., 2004), English (Nivre and Scholz, 2004), Czech (Nivre and Nilsson, 2005), Bulgarian (Marinov and Nivre, 2005) and Chinese Cheng et al. (2005), while McDonald’s parser has been applied to English (McDonald et al., 2005a), Czech (McDonald et al., 2005b) and, very recently, Danish (McDonald and Pereira, 2006).</S><S sid = 244 ssid = >Even though McDonald et al. (2006) and Nivre et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-2920.txt | Citing Article:  E12-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >19.6% of the sentences in the corpus contain non-projective edges and 1.8% of the edges are non-projective, which is almost 5 times more frequent than in English and is the same as the Czech non-projectivity level (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['131','159'] | Reference Text:  <S sid = 131 ssid = >“ROOT”) for tokens with HEAD=0); percentage of scoring tokens with HEAD=0, a head that precedes or a head that follows the token (this nicely shows which languages are predominantly head-initial or head-final); the average number of scoring tokens with HEAD=0 per parse tree unit; the percentage of (scoring and non-scoring) non-projective relations and of parse tree units with at least one non-projective relation.</S><S sid = 159 ssid = >All data sets except the Chinese one contain some non-projective dependency arcs, although their proportion varies from 0.1% to 5.4%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-2920.txt | Citing Article:  C10-2135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The standard procedure for this purpose would be cross-validation. However, the popular data sets used for bench marking parsers, such as those that emerged 1176 from the CoNLL-X shared task on dependency parsing (Buchholz and Marsi, 2006), are typically based on monolingual text.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 2 ssid = >The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-2920.txt | Citing Article:  C10-2135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The treebank data used to train the German parser is the Tiger Treebank (Brants et al, 2002), in the version released with the CoNLL-X shared task (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['53','86'] | Reference Text:  <S sid = 53 ssid = >Some dependency grammars, and also some treebanks, allow tokens to have more than one head, although often there is a distinction between primary and optional secondary relations, e.g. in the Danish Dependency Treebank (Kromann, 2003), the Dutch Alpino Treebank (van der Beek et al., 2002b) and the German TIGER treebank (Brants et al., 2002).</S><S sid = 86 ssid = >We used the following five treebanks of this type: German: TIGER treebank17 (Brants et al., 2002); Japanese: Japanese Verbmobil treebank18 (Kawata and Bartels, 2000); Portuguese: The Bosque part of the Floresta sint´a(c)tica19 (Afonso et al., 2002); Dutch: Alpino treebank20 (van der Beek et al., 2002b; van der Beek et al., 2002a); Chinese: Sinica 17Many thanks to the TIGER team for allowing us to use the treebank for the shared task and to Amit Dubey for converting the treebank.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-2920.txt | Citing Article:  P10-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have used the 10 smallest data sets from CoNNL-X (Buchholz and Marsi, 2006) in our experiments.</S> | Reference Offset:  ['183','227'] | Reference Text:  <S sid = 183 ssid = >(2006).</S><S sid = 227 ssid = >It has the smallest training set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-2920.txt | Citing Article:  C08-1085.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Currently there are about a dozen input/output conversion filters available, covering various existing data formats including the TigerXML format, the for mats of the Penn Treebank (Marcus et al, 1994), the CoNLL-X shared task format (Buchholz and Marsi, 2006), and the formats of the Latin Dependency (Bamman and Crane, 2006), Sinica (Chu Ren et al, 2000), Slovene Dependency (D? zero ski et al, 2006) (SDT), and Alpino (van der Beek et al., 2002) tree banks.</S> | Reference Offset:  ['86','244'] | Reference Text:  <S sid = 86 ssid = >We used the following five treebanks of this type: German: TIGER treebank17 (Brants et al., 2002); Japanese: Japanese Verbmobil treebank18 (Kawata and Bartels, 2000); Portuguese: The Bosque part of the Floresta sint´a(c)tica19 (Afonso et al., 2002); Dutch: Alpino treebank20 (van der Beek et al., 2002b; van der Beek et al., 2002a); Chinese: Sinica 17Many thanks to the TIGER team for allowing us to use the treebank for the shared task and to Amit Dubey for converting the treebank.</S><S sid = 244 ssid = >Even though McDonald et al. (2006) and Nivre et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-2920.txt | Citing Article:  C08-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['97','262'] | Reference Text:  <S sid = 97 ssid = >For the Portuguese treebank, the conversion was complicated by the fact that a detailed specification existed which tokens should be the head of which other tokens, e.g. the finite verb must be the head of the subject and the complementzier but the main verb must be the head of the complements and adjuncts.23 Given that the Floresta sint´a(c)tica does not use traditional VP constituents but rather verbal chunks (consisting mainly of verbs), a simple MagermanCollins-style head table was not sufficient to derive the required dependency structure.</S><S sid = 262 ssid = >We hope that the resources created and lessons learned during this shared task will be valuable for many years to come but also that they will be extended and improved by others in the future, and that the shared task website will grow into an informational hub on multilingual dependency parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-2920.txt | Citing Article:  P07-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We evaluate all constraints and measures described in the previous section on 12 languages, whose treebanks were made available in the CoNLL-X shared task on dependency parsing (Buchholz and Marsi,2006).</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 2 ssid = >The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-2920.txt | Citing Article:  W09-1304.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Additionally, we converted the annotation about scope of negation into a token-per-token representation, following the standard format of the 2006 CoNLL Shared Task (Buchholz and Marsi, 2006), where sentences are separated by a blank line and fields are separated by a single tab character.</S> | Reference Offset:  ['48','50'] | Reference Text:  <S sid = 48 ssid = >All the sentences are in one text file and they are separated by a blank line after each sentence.</S><S sid = 50 ssid = >Each token is represented on one line, consisting of 10 fields.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-2920.txt | Citing Article:  P13-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Datasets and Evaluation Our experiments are run on five different languages: Chinese (ch), Danish (da), Dutch (nl), Portuguese (pt) and Swedish (sv) (da ,nl, pt and sv are free data sets distributed for the 2006 CoNLL Shared Tasks (Buchholz and Marsi, 2006)).</S> | Reference Offset:  ['183','251'] | Reference Text:  <S sid = 183 ssid = >(2006).</S><S sid = 251 ssid = >Other easy PoS are articles, with accuracies in the nineties for German, Dutch, Swedish, Portuguese and Spanish.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-2920.txt | Citing Article:  P09-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Multilingual parsers of participants in the CoNLL 2006 shared task (Buchholz and Marsi, 2006) can handle Japanese sentences.</S> | Reference Offset:  ['0','183'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 183 ssid = >(2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-2920.txt | Citing Article:  W09-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We find that partial correspondence projection gives rise to parsers that outperform parsers trained on aggressively filtered data sets, and achieve unlabeled attachment scores that are only 5% behind the aver age UAS for Dutch in the CoNLL-X Shared Task on supervised parsing (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 2 ssid = >The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-2920.txt | Citing Article:  W09-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Despite its simplicity, the partial correspondence approach proves very effective and leads to parsers that achieve unlabeled attachment scores that are only 5% behind the average UAS for Dutch in the CoNLL-X Shared Task (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['0','193'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 193 ssid = >In general, there is a high correlation between the best scores and the average scores.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-2920.txt | Citing Article:  W09-1104.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the CoNLL-X data format for dependency trees (Buchholz and Marsi, 2006) to encode partial structures.</S> | Reference Offset:  ['122','125'] | Reference Text:  <S sid = 122 ssid = >We will refer to this as “bottom-up-trees”.</S><S sid = 125 ssid = >This approach assumes projective dependency structures.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-2920.txt | Citing Article:  P09-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Penn Treebank (Marcus et al, 1993) the HPSG LinGo Redwoods Treebank (Oepen et al, 2002), and a smaller dependency treebank (Buchholz and Marsi, 2006).</S> | Reference Offset:  ['53','244'] | Reference Text:  <S sid = 53 ssid = >Some dependency grammars, and also some treebanks, allow tokens to have more than one head, although often there is a distinction between primary and optional secondary relations, e.g. in the Danish Dependency Treebank (Kromann, 2003), the Dutch Alpino Treebank (van der Beek et al., 2002b) and the German TIGER treebank (Brants et al., 2002).</S><S sid = 244 ssid = >Even though McDonald et al. (2006) and Nivre et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W06-2920.txt | Citing Article:  N12-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The CoNLL-X (Buchholz and Marsi, 2006) and CoNLL 2007 (Nivre et al, 2007) shared tasks focused on multilingual dependency parsing.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 2 ssid = >The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W06-2920.txt | Citing Article:  P12-2020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Parsing accuracy comparison and error analysis under the CoNLL-X dependency shared task data (Buchholz and Marsi, 2006) have been performed by McDonald and Nivre (2011).</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >CoNLL-X Shared Task On Multilingual Dependency Parsing</S><S sid = 2 ssid = >The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W06-2920.txt | Citing Article:  W09-1117.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Spanish corpus was parsed using the MST dependency parser (McDonald et al, 2005) trained using dependency trees generated from the the English Penn Treebank (Marcus et al, 1993) and Spanish CoNLL-X data (Buchholz and Marsi, 2006). So that we could directly compare against statistical translation models, our Spanish and English monolingual corpora were drawn from the Europarl parallel corpus (Koehn, 2005).</S> | Reference Offset:  ['46','244'] | Reference Text:  <S sid = 46 ssid = >Nivre’s parser has been tested for Swedish (Nivre et al., 2004), English (Nivre and Scholz, 2004), Czech (Nivre and Nilsson, 2005), Bulgarian (Marinov and Nivre, 2005) and Chinese Cheng et al. (2005), while McDonald’s parser has been applied to English (McDonald et al., 2005a), Czech (McDonald et al., 2005b) and, very recently, Danish (McDonald and Pereira, 2006).</S><S sid = 244 ssid = >Even though McDonald et al. (2006) and Nivre et al.</S> | Discourse Facet:  NA | Annotator: Automatic


