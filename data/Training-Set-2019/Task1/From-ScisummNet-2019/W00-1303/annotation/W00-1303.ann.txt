Citance Number: 1 | Reference Article:  W00-1303.txt | Citing Article:  N01-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The number of votes for the class obtained through the pairwise voting is used as the certain score for beam search with width 5 (Kudo and Matsumoto, 2000a).</S> | Reference Offset:  ['93','128'] | Reference Text:  <S sid = 93 ssid = >Table 2 shows the result of passing accuracy under the condition k = 5 (beam width), and d = 3 (dimension of the polynomial functions used for the kernel function).</S><S sid = 128 ssid = >We evaluate the relationship between the beam width and the parsing accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W00-1303.txt | Citing Article:  N01-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the CoNLL-2000 shared task, we achieved the accuracy of 93.48 using IOB2-F representation (Kudo and Matsumoto, 2000b).</S> | Reference Offset:  ['130','142'] | Reference Text:  <S sid = 130 ssid = >The best parsing accuracy is achieved at k = 5 and the best sentence accuracy is achieved at k = 5 and k = 7.</S><S sid = 142 ssid = >In our experiments, the accuracy of 89.09% is achieved using same training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W00-1303.txt | Citing Article:  P10-1037.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo and Matsumoto (2002) compare cascaded chunking with the CYK method (Kudo and Matsumoto, 2000).</S> | Reference Offset:  ['57','113'] | Reference Text:  <S sid = 57 ssid = >Generally, the optimal solution Db„t can be identified by using bottom-up algorithm such as CYK algorithm.</S><S sid = 113 ssid = >However, the SVMs method achieve a high accuracy not only on the training data but also on the test data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W00-1303.txt | Citing Article:  I05-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['52','168'] | Reference Text:  <S sid = 52 ssid = >— 1)} by D, where Dep(i) = j means that the chunk bi depends on (modifies) the chunk bi.</S><S sid = 168 ssid = >The result shows that Japanese dependency analysis can be effectively performed by use of SVMs due to its good generalization and nonoverfitting characteristics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W00-1303.txt | Citing Article:  W02-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo and Matsumoto (2000) used the sigmoid function to obtain pseudo probabilities in SVMs.</S> | Reference Offset:  ['56','81'] | Reference Text:  <S sid = 56 ssid = >We obtain Db„t taking into all the combination of these probabilities.</S><S sid = 81 ssid = >For the kernel function, we used the polynomial function (9).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W00-1303.txt | Citing Article:  W02-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To cope with this problem, Kudo and Matsumoto (2000) introduced a new type of feature called dynamic features, which are created dynamically during the parsing process.</S> | Reference Offset:  ['78','110'] | Reference Text:  <S sid = 78 ssid = >We refer to the features that are added incrementally during the parsing process as dynamic features.</S><S sid = 110 ssid = >This is due to a good characteristic of SVMs to cope with the data sparseness problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W00-1303.txt | Citing Article:  W02-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used a third degree polynomial kernel function, which is exactly the same setting in (Kudo and Matsumoto, 2000).</S> | Reference Offset:  ['49','81'] | Reference Text:  <S sid = 49 ssid = >Among the many kinds of Kernel functions available, we will focus on the d-th polynomial kernel: Use of d-th polynomial kernel function allows us to build an optimal separating hyperplane which takes into account all combination of features up to d. Using a Kernel function, we can rewrite the decision function as:</S><S sid = 81 ssid = >For the kernel function, we used the polynomial function (9).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W00-1303.txt | Citing Article:  W02-2016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results for the new cascaded chunking model as well as for the previous probabilistic model based on SVMs (Kudo and Matsumoto, 2000) are summarized in Table 2.</S> | Reference Offset:  ['143','147'] | Reference Text:  <S sid = 143 ssid = >Our model outperforms Uchimoto's model as far as the accuracies are compared.</S><S sid = 147 ssid = >We believe that our model is better than others from the viewpoints of coverage and consistency, since our model learns the combination of features without increasing the computational complexity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W00-1303.txt | Citing Article:  D07-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Haruno et al (1999) used Decision Trees, Sekine (2000) used Maximum Entropy Models, Kudo and Matsumoto (2000) used Support Vector Machines.</S> | Reference Offset:  ['16','140'] | Reference Text:  <S sid = 16 ssid = >Decision Trees(Haruno et al., 1998) and Maximum Entropy models(Ratnaparkhi, 1997; Uchimoto et al., 1999; Charniak, 2000) have been applied to dependency or syntactic structure analysis.</S><S sid = 140 ssid = >Uchimoto (Uchimoto et al., 1999) and Sekine (Sekine et al., 2000) report that using Kyoto University Corpus for their training and testing, they achieve around 87.2% accuracy by building statistical model based on Maximum Entropy framework.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W00-1303.txt | Citing Article:  D07-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, our methods analyze a sentence backwards as in Sekine (2000) and Kudo and Matsumoto (2000).</S> | Reference Offset:  ['58','123'] | Reference Text:  <S sid = 58 ssid = >Sekine suggests an efficient parsing technique for Japanese sentences that parses from the end of a sentence(Sekine et al., 2000).</S><S sid = 123 ssid = >Sekine (Sekine et al., 2000) gives an interesting report about the relationship between the beam width and the parsing accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W00-1303.txt | Citing Article:  D07-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['52','168'] | Reference Text:  <S sid = 52 ssid = >— 1)} by D, where Dep(i) = j means that the chunk bi depends on (modifies) the chunk bi.</S><S sid = 168 ssid = >The result shows that Japanese dependency analysis can be effectively performed by use of SVMs due to its good generalization and nonoverfitting characteristics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W00-1303.txt | Citing Article:  C04-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Deterministic methods for dependency parsing have now been applied to a variety of languages, including Japanese (Kudo and Matsumoto, 2000), English (Yamada and Matsumoto, 2003), Turkish (Oflazer, 2003), and Swedish (Nivre et al, 2004).</S> | Reference Offset:  ['16','58'] | Reference Text:  <S sid = 16 ssid = >Decision Trees(Haruno et al., 1998) and Maximum Entropy models(Ratnaparkhi, 1997; Uchimoto et al., 1999; Charniak, 2000) have been applied to dependency or syntactic structure analysis.</S><S sid = 58 ssid = >Sekine suggests an efficient parsing technique for Japanese sentences that parses from the end of a sentence(Sekine et al., 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W00-1303.txt | Citing Article:  W06-2920.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo and Matsumoto (2000) describe a dependency parser for Japanese and Yamada and Matsumoto (2003) an extension for English.</S> | Reference Offset:  ['0','109'] | Reference Text:  <S sid = 0 ssid = >Japanese Dependency Structure Analysis Based On Support Vector Machines</S><S sid = 109 ssid = >The parser achieves 86.52% accuracy for test data even with small training data (1172 sentences).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W00-1303.txt | Citing Article:  C02-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Therefore, SVMs have shown good performance for text categorization (Joachims, 1998), chunking (Kudo and Matsumoto, 2001), and dependency structure analysis (Kudo and Matsumoto, 2000).</S> | Reference Offset:  ['28','168'] | Reference Text:  <S sid = 28 ssid = >In this paper, we propose an application of SVMs to Japanese dependency structure analysis.</S><S sid = 168 ssid = >The result shows that Japanese dependency analysis can be effectively performed by use of SVMs due to its good generalization and nonoverfitting characteristics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W00-1303.txt | Citing Article:  C04-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kudo and Matsumoto (2000) also used the same backward beam search together with SVMs rather than ME.</S> | Reference Offset:  ['77','141'] | Reference Text:  <S sid = 77 ssid = >As we describe later we apply a beam search for parsing, and it is possible to keep several intermediate solutions while suppressing the combinatorial explosion.</S><S sid = 141 ssid = >For the training data, we used exactly the same data that they used in order to make a fair comparison.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W00-1303.txt | Citing Article:  C04-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['52','168'] | Reference Text:  <S sid = 52 ssid = >— 1)} by D, where Dep(i) = j means that the chunk bi depends on (modifies) the chunk bi.</S><S sid = 168 ssid = >The result shows that Japanese dependency analysis can be effectively performed by use of SVMs due to its good generalization and nonoverfitting characteristics.</S> | Discourse Facet:  NA | Annotator: Automatic


