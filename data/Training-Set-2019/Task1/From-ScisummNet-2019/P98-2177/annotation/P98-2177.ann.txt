Citance Number: 1 | Reference Article:  P98-2177.txt | Citing Article:  W99-0632.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We rely on Gsearch to provide moderately accurate information about verb frames in the same way that Hindle and Rooth (1993) relied on Fidditch to provide moderately accurate information about syntactic structure, and Ratnaparkhi (1998) relied on simple heuristics defined over part-of-speech tags to deliver information early as useful as that provided by Fidditch.</S> | Reference Offset:  ['2','13'] | Reference Text:  <S sid = 2 ssid = >Our unsupervised approach uses a heuristic based on attachment proximity and trains from raw text that is annotated with only part-of-speech tags and morphological base forms, as opposed to attachment information.</S><S sid = 13 ssid = >(Hindle and Rooth, 1993) describes a partially supervised approach in which the FIDDITCH partial parser was used to extract (v, n, p) tuples from raw text, where p is a preposition whose attachment is ambiguous between the head verb v and the head noun n. The extracted tuples are then used to construct a classifier, which resolves unseen ambiguities at around 80% accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P98-2177.txt | Citing Article:  W06-2112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Ratnaparkhi, 1998) first assumes noun attachment for all of-PPs and then applies his disambiguation methods to all remaining PPs.</S> | Reference Offset:  ['20','78'] | Reference Text:  <S sid = 20 ssid = >While we will be given the candidate attachment sites during testing, the training procedure assumes no a priori information about potential attachment sites.</S><S sid = 78 ssid = >Furthermore, we do not use the second noun n2, whereas the best supervised methods use this information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P98-2177.txt | Citing Article:  H05-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['34','94'] | Reference Text:  <S sid = 34 ssid = >Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.</S><S sid = 94 ssid = >We thank Dr. Lauri Kartunnen for lending us the Spanish natural language tools, and Mike Collins for helpful discussions on this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P98-2177.txt | Citing Article:  C02-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The most prominent unsupervised methods are the Lexical Association score by Hindle and Rooth (1993) and the co occurrence values by Ratnaparkhi (1998).</S> | Reference Offset:  ['32','34'] | Reference Text:  <S sid = 32 ssid = >This extraction heuristic loosely resembles a step in the bootstrapping procedure used to get training data for the classifier of (Hindle and Rooth, 1993).</S><S sid = 34 ssid = >Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P98-2177.txt | Citing Article:  C02-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The co occurrence values for verb V and noun N correspond to the probability estimates in (Ratnaparkhi, 1998) except that Ratnaparkhi includes a back-off to the uniform distribution for the zero denominator case.</S> | Reference Offset:  ['29','63'] | Reference Text:  <S sid = 29 ssid = >In the supervised case, both of the potential sites, namely the verb v and the noun n are known before the attachment is resolved.</S><S sid = 63 ssid = >This technique uses the bigram counts of the extracted head word tuples, and backs off to the uniform distribution when the denominator is zero. where 7) is the set of possible prepositions, where all the counts c(...) are from the extracted head word tuples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P98-2177.txt | Citing Article:  P00-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The current unsupervised state of the art achieves 81.9% attachment accuracy (Ratnaparkhi, 1998).</S> | Reference Offset:  ['1','79'] | Reference Text:  <S sid = 1 ssid = >several unsupervised statistical models for the prepositional phrase attachment task that approach the accuracy of the best supervised methods for this task.</S><S sid = 79 ssid = >Our result shows that the information in imperfect but abundant data from unambiguous attachments, as shown in Tables 2 and 3, is sufficient to resolve ambiguous prepositional phrase attachments at accuracies just under the supervised state-of-the-art accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P98-2177.txt | Citing Article:  P00-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in (Ratnaparkhi, 1998), we constructed a training data set consisting of only unambiguous.</S> | Reference Offset:  ['41','70'] | Reference Text:  <S sid = 41 ssid = >Also, the heuristic excludes examples with the verb to be from the training set (but not the test set) since we found them to be unreliable sources of evidence.</S><S sid = 70 ssid = >Furthermore, the extraction heuristic was developed and tuned on a &quot;development set&quot;, i.e., a set of annotated examples that did not overlap with either the test set or the training set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P98-2177.txt | Citing Article:  P00-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['34','94'] | Reference Text:  <S sid = 34 ssid = >Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.</S><S sid = 94 ssid = >We thank Dr. Lauri Kartunnen for lending us the Spanish natural language tools, and Mike Collins for helpful discussions on this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P98-2177.txt | Citing Article:  P00-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['34','94'] | Reference Text:  <S sid = 34 ssid = >Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.</S><S sid = 94 ssid = >We thank Dr. Lauri Kartunnen for lending us the Spanish natural language tools, and Mike Collins for helpful discussions on this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P98-2177.txt | Citing Article:  I05-1017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['34','94'] | Reference Text:  <S sid = 34 ssid = >Our procedure differs critically from (Hindle and Rooth, 1993) in that we do not iterate, we extract unambiguous attachments from unparsed input sentences, and we totally ignore the ambiguous cases.</S><S sid = 94 ssid = >We thank Dr. Lauri Kartunnen for lending us the Spanish natural language tools, and Mike Collins for helpful discussions on this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P98-2177.txt | Citing Article:  H05-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recently, Ratnaparkhi (1998) developed an unsupervised method that collects statistics from text annotated with part-of-speech tags and morphological base forms.</S> | Reference Offset:  ['2','23'] | Reference Text:  <S sid = 2 ssid = >Our unsupervised approach uses a heuristic based on attachment proximity and trains from raw text that is annotated with only part-of-speech tags and morphological base forms, as opposed to attachment information.</S><S sid = 23 ssid = >The tagger from (Ratnaparkhi, 1996) first annotates sentences of raw text with a sequence of partof-speech tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P98-2177.txt | Citing Article:  H05-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Ratnaparkhi (1998) notes that the test set contains errors, but does not correct them.</S> | Reference Offset:  ['70','88'] | Reference Text:  <S sid = 70 ssid = >Furthermore, the extraction heuristic was developed and tuned on a &quot;development set&quot;, i.e., a set of annotated examples that did not overlap with either the test set or the training set.</S><S sid = 88 ssid = >The Spanish test set has fewer ambiguous prepositions than the English test set, as shown by the accuracy of Cibaâ€ž.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P98-2177.txt | Citing Article:  H05-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Using an adaptation of the algorithm proposed by Ratnaparkhi (1998) for PP-attachment, she achieves P=72% (baseline P=64%), R=100.00%.</S> | Reference Offset:  ['3','90'] | Reference Text:  <S sid = 3 ssid = >It is therefore less resource-intensive and more portable than previous corpus-based algorithm proposed for this task.</S><S sid = 90 ssid = >The unsupervised algorithm for prepositional phrase attachment presented here is the only algorithm in the published literature that can significantly outperform the baseline without using data derived from a treebank or parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P98-2177.txt | Citing Article:  W01-0707.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A second model relevant to our discussion is the one proposed in (Ratnaparkhi,1998), addressing the problem of unsupervised learning for PP attachment resolution in VERB NOUN PP sequences.</S> | Reference Offset:  ['11','56'] | Reference Text:  <S sid = 11 ssid = >Previous work has framed the problem as a classification task, in which the goal is to predict N or V, corresponding to noun or verb attachment, given the head verb v, the head noun n, the preposition p, and optionally, the object of the preposition n2.</S><S sid = 56 ssid = >We approximate Pr(pla,v,n) as follows: The rationale behind these approximations is that when generating p given a noun (verb) attachment, only the counts involving the noun (verb) are relevant, assuming also that the noun (verb) has an attached prepositional phrase, i.e., 0 = true.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P98-2177.txt | Citing Article:  W01-0707.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The model proposed in (Ratnaparkhi, 1998) is similar to a version of our model based solely on equation (9), with no semantic information.</S> | Reference Offset:  ['3','15'] | Reference Text:  <S sid = 3 ssid = >It is therefore less resource-intensive and more portable than previous corpus-based algorithm proposed for this task.</S><S sid = 15 ssid = >Recently, (Stetina and Naga,o, 1997) have reported 88% accuracy by using a corpus-based model in conjunction with a semantic dictionary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P98-2177.txt | Citing Article:  W01-0707.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >equation (9) captures both the contribution from the random variable used in (Ratnaparkhi, 1998) to denote the presence or absence of any preposition that is unambiguously attached to the noun or the verb in question, and the contribution from the conditional probability that a particular preposition will occur as unambiguous attachment to the verb or to the noun.</S> | Reference Offset:  ['31','51'] | Reference Text:  <S sid = 31 ssid = >Therefore, there is only one possible attachment site for the preposition, and either the verb v or the noun n does not exist, in the case of noun-attached preposition or a verb-attached preposition, respectively.</S><S sid = 51 ssid = >Let the random variable 0 range over {true, false), and let it denote the presence or absence of any preposition that is unambiguously attached to the noun or verb in question.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P98-2177.txt | Citing Article:  P06-2029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Ratnaparkhi, 1998) solved this problem by regarding only prepositions in syntactically unambiguous configurations.</S> | Reference Offset:  ['10','88'] | Reference Text:  <S sid = 10 ssid = >Most of the previous successful approaches to this problem have been statistical or corpusbased, and they consider only prepositions whose attachment is ambiguous between a preceding noun phrase and verb phrase.</S><S sid = 88 ssid = >The Spanish test set has fewer ambiguous prepositions than the English test set, as shown by the accuracy of Cibaâ€ž.</S> | Discourse Facet:  NA | Annotator: Automatic


