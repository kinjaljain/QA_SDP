Citance Number: 1 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this paper, we find that the use of deep linguistic representations to predict these semantic labels are more effective than the generally more surface-syntax representations previously employed (Gildea and Palmer (2002)).</S> | Reference Offset:  ['3','49'] | Reference Text:  <S sid = 3 ssid = >In this paper, we quantify the effect of parser accuracy on these systems' performance, and examine the question of whether a flatter &quot;chunked&quot; representation of the input can be as effective for the purposes of semantic role identification.</S><S sid = 49 ssid = >In previous work using the FrameNet corpus, Gildea and Jurafsky (2002) developed a system to predict semantic roles from sentences and their parse trees as determined by the statistical parser of Collins (1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Gildea and Palmer (2002) show that semantic role labels can be predicted given syntactic features derived from the PTB with fairly high accuracy.</S> | Reference Offset:  ['12','14'] | Reference Text:  <S sid = 12 ssid = >We measure the effect of parser accuracy on semantic role prediction from parse trees, and determine whether a complete tree is indeed necessary for accurate role prediction.</S><S sid = 14 ssid = >The system first passed sentences through an automatic parser, extracted syntactic features from the parses, and estimated probabilities for semantic roles from the syntactic and lexical features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, in their inclusion of voice, Gildea and Palmer (2002) note that this deep syntax feature plays an important role in connecting semantic role with surface grammatical function.</S> | Reference Offset:  ['63','90'] | Reference Text:  <S sid = 63 ssid = >Voice: The distinction between active and passive verbs plays an important role in the connection between semantic role and grammatical function, since direct objects of active verbs correspond to subjects of passive verbs.</S><S sid = 90 ssid = >As a gauge of how closely the Propbank argument labels correspond to the path feature overall, we note that by always assigning the most common role for each path, for example always assigning ARG0 to the subject position, and using no other features, we obtain the correct role 69.4% of the time, vs. 82.3% for the complete system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We first experiment with the set of features described in Gildea and Palmer (2002): Pred HW, Arg HW, Phrase Type, Position, Path, Voice.</S> | Reference Offset:  ['51','69'] | Reference Text:  <S sid = 51 ssid = >Probabilities of a parse constituent belonging to a given semantic role were calculated from the following features: Phrase Type: This feature indicates the syntactic type of the phrase expressing the semantic roles: examples include noun phrase (NP), verb phrase (VP), and clause (S).</S><S sid = 69 ssid = >To predict argument roles in new data, we wish to estimate the probability of each role given these five features and the predicate p: P(rlpt, path, position, voice, hw, p).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The error rate, 10.0%, is lower than that reported by Gildea and Palmer (2002), 17.2%.</S> | Reference Offset:  ['78','94'] | Reference Text:  <S sid = 78 ssid = >The FrameNet data contained at least ten examples from each predicate, while 17% of the Propbank data had fewer than ten training examples.</S><S sid = 94 ssid = >It is also possible that this approach may be more robust to error than parsers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Note also that the transformations which are taken into account are a superset of the transformations taken into account by Gildea and Palmer (2002).</S> | Reference Offset:  ['13','53'] | Reference Text:  <S sid = 13 ssid = >Gildea and Jurafsky (2002) describe a statistical system trained on the data from the FrameNet project to automatically assign semantic roles.</S><S sid = 53 ssid = >The parse constituent spanning each set of words annotated as an argument was found, and the constituent's nonterminal label was taken as the phrase type.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These results are comparable to the results from Gildea and Palmer (2002), but only roughly because of differences in corpora.</S> | Reference Offset:  ['76','132'] | Reference Text:  <S sid = 76 ssid = >Results are shown in Tables 1 and 2.</S><S sid = 132 ssid = >In interpreting these results, it is important to keep in mind the differences between this task and other information extraction datasets.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P02-1031.txt | Citing Article:  W03-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Gildea and Palmer (2002) achieve a recall of 0.50, a precision of 0.58, and an F-measure of 0.54 when using the full parser of Collins (1999).</S> | Reference Offset:  ['115','118'] | Reference Text:  <S sid = 115 ssid = >In fact, this system achieves 27.6% precision and 22.0% recall.</S><S sid = 118 ssid = >With this scoring regime, the chunk-based system performs at 49.5% precision and 35.1% recall, still significantly lower than the 57.7% precision/50.0% recall for exact matches using automatically generated parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P02-1031.txt | Citing Article:  P13-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, much work has shown the usefulness of syntactic representations for subsequent tasks such as relation extraction, semantic role labeling (Gildea and Palmer, 2002) and paraphrase detection (CallisonBurch, 2008).</S> | Reference Offset:  ['10','49'] | Reference Text:  <S sid = 10 ssid = >Even for a single predicate, semantic arguments often have multiple syntactic realizations, as shown by the following paraphrases: Correctly identifying the semantic roles of the sentence constituents is a crucial part of interpreting text, and in addition to forming an important part of the information extraction problem, can serve as an intermediate step in machine translation or automatic summarization.</S><S sid = 49 ssid = >In previous work using the FrameNet corpus, Gildea and Jurafsky (2002) developed a system to predict semantic roles from sentences and their parse trees as determined by the statistical parser of Collins (1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P02-1031.txt | Citing Article:  W04-2610.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the last few years, many researchers (Blaheta and Charniak 2000), (Gildea and Jurafsky 2002), (Gildea and Palmer 2002), (Pradhan et al. 2003) have focused on the automatic prediction of semantic roles using statistical techniques.</S> | Reference Offset:  ['13','33'] | Reference Text:  <S sid = 13 ssid = >Gildea and Jurafsky (2002) describe a statistical system trained on the data from the FrameNet project to automatically assign semantic roles.</S><S sid = 33 ssid = >A more complete description of the FrameNet project can be found in (Baker et al., 1998; Johnson et al., 2001), and the ramifications for automatic classification are discussed more thoroughly in (Gildea and Jurafsky, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P02-1031.txt | Citing Article:  W04-2609.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >The core arguments of each predicate are simply numbered, while remaining arguments are given labels such as &quot;temporal&quot; or &quot;locative&quot;.</S><S sid = 146 ssid = >Acknowledgments This work was undertaken with funding from the Institute for Research in Cognitive Science at the University of Pennsylvania and from the Propbank project, DoD Grant MDA904-00C-2136.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P02-1031.txt | Citing Article:  W04-3211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first experiment compares the random forest classifier to three other classifiers, a statistical Bayesian approach with back off (Gildea and Palmer, 2002), a decision tree classifier (Surdeanu et al, 2003), and a Support Vector Machine (SVM) (Pradhan et al, 2003).</S> | Reference Offset:  ['5','33'] | Reference Text:  <S sid = 5 ssid = >Alshawi (1992)), to simpler finite-state or statistical systems such as Hobbs et al. (1997) and Miller et al.</S><S sid = 33 ssid = >A more complete description of the FrameNet project can be found in (Baker et al., 1998; Johnson et al., 2001), and the ramifications for automatic classification are discussed more thoroughly in (Gildea and Jurafsky, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P02-1031.txt | Citing Article:  W04-3211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >The core arguments of each predicate are simply numbered, while remaining arguments are given labels such as &quot;temporal&quot; or &quot;locative&quot;.</S><S sid = 146 ssid = >Acknowledgments This work was undertaken with funding from the Institute for Research in Cognitive Science at the University of Pennsylvania and from the Propbank project, DoD Grant MDA904-00C-2136.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P02-1031.txt | Citing Article:  N04-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Gildea and Palmer (2002) report F-score results in the 55% range for argument and boundary recognition based on automatic parses.</S> | Reference Offset:  ['0','109'] | Reference Text:  <S sid = 0 ssid = >The Necessity Of Parsing For Predicate Argument Recognition</S><S sid = 109 ssid = >This chunker-based result is only slightly lower than the 79.2% obtained using automatic parses in the known boundary condition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P02-1031.txt | Citing Article:  W05-1513.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, the tree-path feature has been shown to be valuable in semantic role labeling (Gildea and Palmer, 2002).</S> | Reference Offset:  ['56','90'] | Reference Text:  <S sid = 56 ssid = >It is defined as the path from the predicate through the parse tree to the constituent in question, represented as a string of parse tree nonterminals linked by symbols indicating upward or downward movement through the tree, as shown in Figure 2.</S><S sid = 90 ssid = >As a gauge of how closely the Propbank argument labels correspond to the path feature overall, we note that by always assigning the most common role for each path, for example always assigning ARG0 to the subject position, and using no other features, we obtain the correct role 69.4% of the time, vs. 82.3% for the complete system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P02-1031.txt | Citing Article:  N04-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Gildea and Palmer (2002) system uses the same features and the same classification mechanism used by G&J.</S> | Reference Offset:  ['33','45'] | Reference Text:  <S sid = 33 ssid = >A more complete description of the FrameNet project can be found in (Baker et al., 1998; Johnson et al., 2001), and the ramifications for automatic classification are discussed more thoroughly in (Gildea and Jurafsky, 2002).</S><S sid = 45 ssid = >However, the preliminary version of the data used in the experiments below are not tagged for word sense, or for the roleset used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P02-1031.txt | Citing Article:  N04-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >The core arguments of each predicate are simply numbered, while remaining arguments are given labels such as &quot;temporal&quot; or &quot;locative&quot;.</S><S sid = 146 ssid = >Acknowledgments This work was undertaken with funding from the Institute for Research in Cognitive Science at the University of Pennsylvania and from the Propbank project, DoD Grant MDA904-00C-2136.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P02-1031.txt | Citing Article:  P04-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >the accuracy on FrameNet (85.2%) is higher than the best result obtained in literature, i.e. 82.0% in (Gildea and Palmer, 2002).</S> | Reference Offset:  ['109','141'] | Reference Text:  <S sid = 109 ssid = >This chunker-based result is only slightly lower than the 79.2% obtained using automatic parses in the known boundary condition.</S><S sid = 141 ssid = >By using a gold-standard chunking representation, we have obtained higher performance over what could be expected from an entirely automatic system based on a flat representation of the data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P02-1031.txt | Citing Article:  W08-2219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More recent representative efforts includes that of Gildea and Jurafsky (2002), Gildea and Palmer (2002), and Punyakanok et al (2008).</S> | Reference Offset:  ['13','33'] | Reference Text:  <S sid = 13 ssid = >Gildea and Jurafsky (2002) describe a statistical system trained on the data from the FrameNet project to automatically assign semantic roles.</S><S sid = 33 ssid = >A more complete description of the FrameNet project can be found in (Baker et al., 1998; Johnson et al., 2001), and the ramifications for automatic classification are discussed more thoroughly in (Gildea and Jurafsky, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P02-1031.txt | Citing Article:  P03-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is in line with results in (Gildea and Palmer, 2002), who compare the effect of manual and automatic parsing on semantic predicate argument recognition.</S> | Reference Offset:  ['0','145'] | Reference Text:  <S sid = 0 ssid = >The Necessity Of Parsing For Predicate Argument Recognition</S><S sid = 145 ssid = >Our results using hand-annotated parse trees show that improvements in parsing should translate directly into better semantic interpretations.</S> | Discourse Facet:  NA | Annotator: Automatic


