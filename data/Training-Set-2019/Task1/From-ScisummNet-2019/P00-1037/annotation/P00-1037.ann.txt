Citance Number: 1 | Reference Article:  P00-1037.txt | Citing Article:  P02-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At ACL 2000, Brill and Moore (2000) introduced a new error model, allowing generic string-to-string edits.</S> | Reference Offset:  ['4','11'] | Reference Text:  <S sid = 4 ssid = >This paper describes a new channel model for spelling correction, based on generic string to string edits.</S><S sid = 11 ssid = >Our model works by learning generic string to string edits, along with the probabilities of each of these edits.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P00-1037.txt | Citing Article:  P02-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Moore (2000) present an improved error model for noisy channel spelling correction that goes beyond single insertions, deletions, substitutions, and transpositions.</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >An Improved Error Model For Noisy Channel Spelling Correction</S><S sid = 17 ssid = >We now have a noisy channel model for spelling correction, with two components, the source model P(w) and the channel model P(s  |w).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P00-1037.txt | Citing Article:  P02-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Moore (2000) showed that adding a source language model increases the accuracy significantly.</S> | Reference Offset:  ['81','128'] | Reference Text:  <S sid = 81 ssid = >When we allow generic edit operations, the complexity increases to O(|s|2*|w|2).</S><S sid = 128 ssid = >We see that while a language model improves results, using the better error model (Figure 1) still gives significantly better results.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P00-1037.txt | Citing Article:  P02-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The error model LTR was trained exactly as described originally by Brill and Moore (2000).</S> | Reference Offset:  ['21','129'] | Reference Text:  <S sid = 21 ssid = >In this paper, we will refer to the channel model as the error model.</S><S sid = 129 ssid = >Using a language model with our best error model gives a 73.6% error reduction compared to using a language model with the CG error model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P00-1037.txt | Citing Article:  P14-2028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In baseline speller we use a substring-based error model P dist (q0|q1) described in (Brill and Moore, 2000), the error model training method and the hypotheses generator are similar to (Duan and Hsu, 2011).</S> | Reference Offset:  ['21','129'] | Reference Text:  <S sid = 21 ssid = >In this paper, we will refer to the channel model as the error model.</S><S sid = 129 ssid = >Using a language model with our best error model gives a 73.6% error reduction compared to using a language model with the CG error model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P00-1037.txt | Citing Article:  P11-1038.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Moore (2000) characterise the error model by computing the product of operation probabilities on slice-by-slice string edits.</S> | Reference Offset:  ['11','31'] | Reference Text:  <S sid = 11 ssid = >Our model works by learning generic string to string edits, along with the probabilities of each of these edits.</S><S sid = 31 ssid = >The error probabilities are derived by first assuming all edits are equiprobable.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P00-1037.txt | Citing Article:  D10-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The next class of approaches applied the noisy channel model to correct single word spelling errors (Kernighan et al., 1990), (Brill and Moore, 2000).</S> | Reference Offset:  ['1','17'] | Reference Text:  <S sid = 1 ssid = >The noisy channel model has been applied to a wide range of problems, including spelling correction.</S><S sid = 17 ssid = >We now have a noisy channel model for spelling correction, with two components, the source model P(w) and the channel model P(s  |w).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P00-1037.txt | Citing Article:  D10-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Neither do we require pairs of misspelled names and their correct spellings for learning the error model unlike (Brill and Moore, 2000) or large-coverage general purpose lexicon for unlike (Cucerzan and Brill, 2004) or pronunciation dictionaries unlike (Toutanova and Moore, 2002).</S> | Reference Offset:  ['11','118'] | Reference Text:  <S sid = 11 ssid = >Our model works by learning generic string to string edits, along with the probabilities of each of these edits.</S><S sid = 118 ssid = >Then we mapped these words to the incorrect spellings they were paired with in the test set, and ran our spell checker to correct the misspellings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P00-1037.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Moore (2000) learn misspelled-word to correctly-spelled-word similarities for spelling correction.</S> | Reference Offset:  ['0','42'] | Reference Text:  <S sid = 0 ssid = >An Improved Error Model For Noisy Channel Spelling Correction</S><S sid = 42 ssid = >In addition, we condition on the position in the string that the edit occurs in, P( 4 1 PSN), where PSN = {start of word, middle of word, end of word}.2 The position is determined by the location of substring in the source (dictionary) word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P00-1037.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Brill and Moore (2000) combine a character-based alignment with the Expectation Maximization (EM) algorithm to develop an improved probabilistic error model for spelling correction.</S> | Reference Offset:  ['0','74'] | Reference Text:  <S sid = 0 ssid = >An Improved Error Model For Noisy Channel Spelling Correction</S><S sid = 74 ssid = >Essentially, we are doing one iteration of the Expectation-Maximization algorithm (Dempster, Laird et al. 1977).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P00-1037.txt | Citing Article:  D09-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The largest step towards an automatically trainable spelling system was the statistical model for spelling errors (Brill and Moore, 2000).</S> | Reference Offset:  ['10','97'] | Reference Text:  <S sid = 10 ssid = >This paper describes an improvement to noisy channel spelling correction via a more powerful model of spelling errors, be they typing mistakes or cognitive errors, than has previously been employed.</S><S sid = 97 ssid = >We ran experiments using a 10,000word corpus of common English spelling errors, paired with their correct spelling.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P00-1037.txt | Citing Article:  D09-1093.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Contrary to Brill and Moore (2000), we observe that user edits of ten have both left and right context, when editing a document.</S> | Reference Offset:  ['88','122'] | Reference Text:  <S sid = 88 ssid = >At every node in this trie, corresponding to a string , we point to a trie consisting of all strings that appear on the right hand side of a substitution in our parameter set with on the left hand side.</S><S sid = 122 ssid = >Because a spell checker is typically applied right after a word is typed, the language model only used left context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P00-1037.txt | Citing Article:  W10-0404.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The perfect score function calculates the probability of a suggestion given the misspelled word (Brill and Moore, 2000).</S> | Reference Offset:  ['76','78'] | Reference Text:  <S sid = 76 ssid = >Given a string s, where s o D , we want to return argmaxw P(w  |s)P(w  |context) .</S><S sid = 78 ssid = >We are given a dictionary D and a set of parameters P, where each parameter is P( 4 ) for some , E E * , meaning the probability that if a string is intended, the noisy channel will produce instead.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P00-1037.txt | Citing Article:  D09-1154.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition to the simple Levenshtein distance, we also use generalized string-to-string edit distance (Brill and Moore, 2000), which we trained on aligned katakana-English word pairs in the same manner as Brill et al (2001).</S> | Reference Offset:  ['35','80'] | Reference Text:  <S sid = 35 ssid = >Previous error models have all been based on Damerau-Levenshtein distance measures (Damerau 1964; Levenshtein 1966), where the distance between two strings is the minimum number of single character insertions, substitutions and deletions (and in some cases, character pair transpositions) necessary to derive one string from another.</S><S sid = 80 ssid = >For computing the Damerau-Levenshtein distance between two strings, this can be done in O(|s|*|w|) time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P00-1037.txt | Citing Article:  D09-1154.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One interesting future avenue to consider is to use the edit distance functions in our current model to select a subset of query-candidate pairs that are similar in terms of these functions, separately for the surface and Romanized forms, and use this subset to align the character strings in these query-candidate pairs as described in Brill and Moore (2000), and add the edit operations derived in this manner to the term variation identification classifier as features.</S> | Reference Offset:  ['26','39'] | Reference Text:  <S sid = 26 ssid = >Like Mayes, Damerau, et al. (1991), they consider as candidate source words only those words that are a single basic edit away from s, using the same edit set as above.</S><S sid = 39 ssid = >Our model allows all edit operations of the form 4 , where , E E * .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P00-1037.txt | Citing Article:  W11-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Brill and Moore (2000) introduced a model that worked on character sequences, not only on character level, and was conditioned on where in the word the sequences occurred.</S> | Reference Offset:  ['30','35'] | Reference Text:  <S sid = 30 ssid = >The probability of inserting or deleting a character is conditioned on the letter appearing immediately to the left of that character.</S><S sid = 35 ssid = >Previous error models have all been based on Damerau-Levenshtein distance measures (Damerau 1964; Levenshtein 1966), where the distance between two strings is the minimum number of single character insertions, substitutions and deletions (and in some cases, character pair transpositions) necessary to derive one string from another.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P00-1037.txt | Citing Article:  W11-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The approximate string matching algorithm we suggest is essentially that of Brill and Moore (2000), a modified weighted Levenshtein distance, where we allow error operations on character sequences as well as on single characters.</S> | Reference Offset:  ['35','81'] | Reference Text:  <S sid = 35 ssid = >Previous error models have all been based on Damerau-Levenshtein distance measures (Damerau 1964; Levenshtein 1966), where the distance between two strings is the minimum number of single character insertions, substitutions and deletions (and in some cases, character pair transpositions) necessary to derive one string from another.</S><S sid = 81 ssid = >When we allow generic edit operations, the complexity increases to O(|s|2*|w|2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P00-1037.txt | Citing Article:  W11-2159.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It would have been possible to use a fast trie implementation (Brill and Moore, 2000), however.</S> | Reference Offset:  ['84','93'] | Reference Text:  <S sid = 84 ssid = >We first precompile the dictionary into a trie, with each node in the trie corresponding to a vector of weights.</S><S sid = 93 ssid = >As we trace down the trie, if we encounter a terminal node, we follow the pointer to the corresponding trie, and then trace backwards from the position in s while tracing down the trie.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P00-1037.txt | Citing Article:  D07-1019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Brill and Moore, 2000) presented an improved error model over the one proposed by (Kernighan et al, 1990) by allowing generic string-to-string edit operations, which helps with modeling major cognitive errors such as the confusion between le and al.</S> | Reference Offset:  ['41','54'] | Reference Text:  <S sid = 41 ssid = >Note that the edit operations allowed in Church and Gale (1991), Mayes, Damerau et al. (1991) and Ristad and Yianilos (1997), are properly subsumed by our generic string to string substitutions.</S><S sid = 54 ssid = >Note that neither P(f  |ph) nor P(le  |al) are modeled directly in the previous approaches to error modeling.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P00-1037.txt | Citing Article:  H05-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The second is a slightly modified version of the spelling correction model of Brill and Moore (2000).</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >An Improved Error Model For Noisy Channel Spelling Correction</S><S sid = 17 ssid = >We now have a noisy channel model for spelling correction, with two components, the source model P(w) and the channel model P(s  |w).</S> | Discourse Facet:  NA | Annotator: Automatic


