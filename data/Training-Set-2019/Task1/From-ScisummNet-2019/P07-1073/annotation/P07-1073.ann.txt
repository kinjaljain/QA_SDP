Citance Number: 1 | Reference Article:  P07-1073.txt | Citing Article:  P08-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this section, we show that many relationships are consistently expressed using a compact set of relation-independent lexico-syntactic patterns, and quantify their frequency based on a sample of 500 sentences selected at random from an IE training corpus developed by (Bunescu and Mooney, 2007).</S> | Reference Offset:  ['54','56'] | Reference Text:  <S sid = 54 ssid = >The training bags consist of sentences extracted from online documents, using the methodology described in Section 6.</S><S sid = 56 ssid = >Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1073.txt | Citing Article:  P08-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first two datasets were collected from the Web, and made available by Bunescu and Mooney (2007).</S> | Reference Offset:  ['56','159'] | Reference Text:  <S sid = 56 ssid = >Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.</S><S sid = 159 ssid = >We have presented a new approach to relation extraction that leverages the vast amount of information available on the web.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1073.txt | Citing Article:  P14-2117.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To resolve this problem, Bunescu and Mooney (2007), Riedel et al (2010) and Yao et al (2010) relaxed the DS assumption to the at least-one assumption and employed multi-instance learning techniques to identify wrongly labeled instances.</S> | Reference Offset:  ['11','37'] | Reference Text:  <S sid = 11 ssid = >MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).</S><S sid = 37 ssid = >Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1073.txt | Citing Article:  D12-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Such data sets have been utilized successfully for relation extraction from the web (Bunescu and Mooney, 2007).</S> | Reference Offset:  ['21','138'] | Reference Text:  <S sid = 21 ssid = >Using a limited set of entity pairs (e.g. those in Table 1) and their associated bags as training data, the aim is to induce a relation extraction system that can reliably decide whether two entities mentioned in the same sentence exhibit the target relationship or not.</S><S sid = 138 ssid = >An interesting potential application of our approach is a web relation-extraction system similar to Google Sets, in which the user provides only a handful of pairs of entities known to exhibit or not to exhibit a particular relation, and the system is used to find other pairs of entities exhibiting the same relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1073.txt | Citing Article:  C10-2155.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bunescu and Mooney (2007) follow a classification-based approach to RE.</S> | Reference Offset:  ['12','35'] | Reference Text:  <S sid = 12 ssid = >We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.</S><S sid = 35 ssid = >When used for classification, the decision function computed by the learning algorithm is equivalent to a hyperplane in this feature space.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1073.txt | Citing Article:  P10-2023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms.</S> | Reference Offset:  ['11','149'] | Reference Text:  <S sid = 11 ssid = >MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).</S><S sid = 149 ssid = >A more recent IE system that works by bootstrapping relation extraction patterns from the web is KNOWITALL (Etzioni et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1073.txt | Citing Article:  E12-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We used the dataset by Bunescu and Mooney (2007), which we selected because it contains multiple realizations of an entity pair in a target semantic relation, unlike similar datasets such as the one by Roth and Yih (2002).</S> | Reference Offset:  ['77','145'] | Reference Text:  <S sid = 77 ssid = >In Figure 1, for inMIL problems: the training dataset contains very stance, sentence 53 contains two non-core frame elefew bags, and each bag can be very large.</S><S sid = 145 ssid = >Any pair of entities different from the relation pair is very likely to be a negative example for that relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1073.txt | Citing Article:  D10-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One heuristic is to assume that each candidate mention tuple of a training fact is indeed expressing the corresponding relation (Bunescu and Mooney, 2007).</S> | Reference Offset:  ['12','144'] | Reference Text:  <S sid = 12 ssid = >We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.</S><S sid = 144 ssid = >Alternatively, implicit negative evidence can be extracted from sentences in positive bags by exploiting the fact that, besides the two relation arguments, a sentence from a positive bag may contain other entity mentions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1073.txt | Citing Article:  E09-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Notable exceptions include Rosario and Hearst (2005) and Bunescu and Mooney (2007), who tackle relation classification and extraction tasks by considering the set of contexts in which the members of a candidate relation argument pair co-occur.</S> | Reference Offset:  ['145','155'] | Reference Text:  <S sid = 145 ssid = >Any pair of entities different from the relation pair is very likely to be a negative example for that relation.</S><S sid = 155 ssid = >Comparatively, the approach presented in this paper requires only a small number of queries: one query per relation pair, and one query for each relation argument.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1073.txt | Citing Article:  P12-2010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007).</S> | Reference Offset:  ['12','56'] | Reference Text:  <S sid = 12 ssid = >We have extended an existing approach to relation extraction using support vector machines and string kernels (Bunescu and Mooney, 2006) to handle this weaker form of MIL supervision.</S><S sid = 56 ssid = >Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1073.txt | Citing Article:  C08-1134.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bunescu and Mooney (2007) presented an approach to extract relations from the Web using minimal supervision.</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >Learning to Extract Relations from the Web using Minimal Supervision</S><S sid = 15 ssid = >We present experimental results demonstrating that our approach is able to accurately extract relations from the web by learning from such weak supervision.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1073.txt | Citing Article:  P11-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bunescu and Mooney (2007) connect weak supervision with multi-instance learning and extend their relational extraction kernel to this context.</S> | Reference Offset:  ['10','28'] | Reference Text:  <S sid = 10 ssid = >Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative.</S><S sid = 28 ssid = >As formulated above, the learning task can be seen as an instance of multiple instance learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1073.txt | Citing Article:  N12-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['60','164'] | Reference Text:  <S sid = 60 ssid = >The subsequence kernel induces a feature space where each dimension corresponds to a sequence of words.</S><S sid = 164 ssid = >This work was supported by grant IIS-0325116 from the NSF, and a gift from Google Inc.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1073.txt | Citing Article:  D12-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bunescu and Mooney (2007) and Riedel et al (2010) model distant supervision for relation extraction as a multi-instance single-label problem, which allows multiple mentions for the same tuple but disallows more than one label per object.</S> | Reference Offset:  ['11','37'] | Reference Text:  <S sid = 11 ssid = >MIL was originally introduced to solve a problem in biochemistry (Dietterich et al., 1997); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (Zhang et al., 2002), and text categorization (Andrews et al., 2003; Ray and Craven, 2005).</S><S sid = 37 ssid = >Gartner et al. (2002) adapted SVMs to the MIL setting using various multi-instance kernels.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1073.txt | Citing Article:  I08-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As pointed out by (Bunescu and Mooney, 2007), even though the same entities co-occur in multiple sentences, they are not necessarily linked by the same relationship in all of them.</S> | Reference Offset:  ['8','16'] | Reference Text:  <S sid = 8 ssid = >Although not all of the sentences for positive pairs will state the desired relationship, many of them will.</S><S sid = 16 ssid = >We address the task of learning a relation extraction system targeted to a fixed binary relationship R. The only supervision given to the learning algorithm is a small set of pairs of named entities that are known to belong (positive) or not belong (negative) to the given relationship.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1073.txt | Citing Article:  I08-1046.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One means of combating this is suggested by (Bunescu and Mooney, 2007).</S> | Reference Offset:  ['42','56'] | Reference Text:  <S sid = 42 ssid = >In a multi-instance kernel approach, only bags (and not instances) are considered as training examples, which means that the number of support vectors is going to be upper bounded by the number of training bags.</S><S sid = 56 ssid = >Therefore, for the initial experiments, we used a modified version of the subsequence kernel of Bunescu and Mooney (2006), which does not require syntactic information.</S> | Discourse Facet:  NA | Annotator: Automatic


