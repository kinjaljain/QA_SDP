Citance Number: 1 | Reference Article:  P99-1067.txt | Citing Article:  C02-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On the other hand, the alternative approach using comparable or unrelated text corpora were studied by Rapp (1999) and Fung et al (1998).</S> | Reference Offset:  ['31','151'] | Reference Text:  <S sid = 31 ssid = >It can be expected that this clue will work best with parallel corpora, second-best with comparable corpora, and somewhat worse with unrelated corpora.</S><S sid = 151 ssid = >On the one hand, their task was more difficult because they worked on a pair of unrelated languages (English/Japanese) using smaller corpora and a random selection of test words, many of which were multi-word terms.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P99-1067.txt | Citing Article:  W11-1205.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, good results are obtained from large corpora several million words for which the accuracy of the proposed translation is between 76% (Fung, 1998) and 89% (Rapp, 1999) for the first 20 candidates.</S> | Reference Offset:  ['124','149'] | Reference Text:  <S sid = 124 ssid = >Table 1 shows the results for 20 of the 100 German test words.</S><S sid = 149 ssid = >This was true in 89 cases.5 For comparison, Fung & McKeown (1997) report an accuracy of about 30% when only the top candidate is counted.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P99-1067.txt | Citing Article:  I08-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This can be accomplished as in Rapp (1999) and Schafer and Yarowsky (2002) by creating bag-of-words context vectors around both the source and target language words and then projecting the source vectors into the (English) target space via the current small translation dictionary.</S> | Reference Offset:  ['48','51'] | Reference Text:  <S sid = 48 ssid = >We translate all known words in this vector to the target language.</S><S sid = 51 ssid = >With the resulting vector, we now perform a similarity computation to all vectors in the co-occurrence matrix of the target language.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P99-1067.txt | Citing Article:  C04-1149.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Here, a standard technique of estimating bilingual term correspondences from com parable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed.</S> | Reference Offset:  ['35','121'] | Reference Text:  <S sid = 35 ssid = >After an attempt with a context heterogeneity measure (Fung, 1995) for identifying word translations, Fung based her later work also on the co-occurrence assumption (Fung & Yee, 1998; Fung & McKeown, 1997).</S><S sid = 121 ssid = >Another approach, as conducted by Fung & Yee (1998), would be to consider all possible translations listed in the lexicon and to give them equal (or possibly descending) weight.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P99-1067.txt | Citing Article:  C04-1149.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Rapp (1999) filtered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words.</S> | Reference Offset:  ['22','23'] | Reference Text:  <S sid = 22 ssid = >The third clue is generally limited to the identification of word pairs with similar spelling.</S><S sid = 23 ssid = >For all other pairs, it is usually used in combination with the first clue.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P99-1067.txt | Citing Article:  C10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The approach we investigate for identifying term translations in comparable corpora is similar to (Rapp, 1999) and many others.</S> | Reference Offset:  ['31','34'] | Reference Text:  <S sid = 31 ssid = >It can be expected that this clue will work best with parallel corpora, second-best with comparable corpora, and somewhat worse with unrelated corpora.</S><S sid = 34 ssid = >However, the co-occurrence clue when applied to comparable corpora is much weaker than the word-order clue when applied to parallel corpora, so larger corpora and well-chosen statistical methods are required.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P99-1067.txt | Citing Article:  C10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Complex linguistic tools such as terminological extractors (Daille and Morin,2005), parsers (Yu and Tsujii, 2009) or lemma tizers (Rapp, 1999) are sometimes used.</S> | Reference Offset:  ['9','72'] | Reference Text:  <S sid = 9 ssid = >Nevertheless, the results achieved with these algorithms have been found useful for the cornpilation of dictionaries, for checking the consistency of terminological usage in translations, for assisting the terminological work of translators and interpreters, and for example-based machine translation.</S><S sid = 72 ssid = >(According to Lezius, Rapp, & Wettler, 1998, 93% of the tokens of a German text had only one lemma.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P99-1067.txt | Citing Article:  C10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Context length can be based on a number of units, for instance 3 sentences (Daille and Morin, 2005), windows of 3 (Rapp, 1999) or 25 words (Prochasson et al, 2009), etc.</S> | Reference Offset:  ['6','82'] | Reference Text:  <S sid = 6 ssid = >Starting with the well-known paper of Brown et al. (1990) on statistical machine translation, there has been much scientific interest in the alignment of sentences and words in translated texts.</S><S sid = 82 ssid = >Instead, we combine the four vectors of length n into a single vector of length 4n.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P99-1067.txt | Citing Article:  C10-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As already noted, most authors use the log-likelihood ratio to measure the association between collocates; some, like (Rapp, 1999), informally compare the performance of a small number of association measures, or combine the results obtained with different association measures (Daille and Morin, 2005).</S> | Reference Offset:  ['96','105'] | Reference Text:  <S sid = 96 ssid = >To determine the English translation of an unknown German word, the association vector of the German word is computed and compared to all association vectors in the English association matrix.</S><S sid = 105 ssid = >It must be noted, however, that the other authors applied their similarity measures directly to the (log of the) co-occurrence vectors, whereas we applied the measures to the association vectors based on the log-likelihood ratio.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P99-1067.txt | Citing Article:  W12-0114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Expand the dictionary of step 3 using comparable corpora as proposed in a study by Rapp (1999).</S> | Reference Offset:  ['31','44'] | Reference Text:  <S sid = 31 ssid = >It can be expected that this clue will work best with parallel corpora, second-best with comparable corpora, and somewhat worse with unrelated corpora.</S><S sid = 44 ssid = >It is further assumed that there is a small dictionary available at the beginning, and that our aim is to expand this base lexicon.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P99-1067.txt | Citing Article:  W12-0114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >From a previous pilot study (Rapp, 1999) it can be expected that this methodology achieves an accuracy in the order of 70%, which means that only a relatively modest amount of manual post editing is required.</S> | Reference Offset:  ['71','120'] | Reference Text:  <S sid = 71 ssid = >However, this is a relatively rare case.</S><S sid = 120 ssid = >4 This means that alternative translations of a word were not considered.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P99-1067.txt | Citing Article:  P04-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus.</S> | Reference Offset:  ['2','30'] | Reference Text:  <S sid = 2 ssid = >However, only recently new approaches have been proposed to identify word translations from non-parallel or even unrelated texts.</S><S sid = 30 ssid = >The validity of the co-occurrence clue is obvious for parallel corpora, but — as empirically shown by Rapp — it also holds for non-parallel corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P99-1067.txt | Citing Article:  C10-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','165'] | Reference Text:  <S sid = 61 ssid = >Since our corpora are very large, to save disk space and processing time we decided to remove all function words from the texts.</S><S sid = 165 ssid = >I thank Manfred Wettler, Gisela Zunker-Rapp, Wolfgang Lezius, and Anita Todd for their support of this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P99-1067.txt | Citing Article:  C10-2055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To identify the context terms CT (WS) of a source word WS, as in (Rapp, 1999), we use log likelihood ratio (LL) Dunning (1993).</S> | Reference Offset:  ['105','106'] | Reference Text:  <S sid = 105 ssid = >It must be noted, however, that the other authors applied their similarity measures directly to the (log of the) co-occurrence vectors, whereas we applied the measures to the association vectors based on the log-likelihood ratio.</S><S sid = 106 ssid = >According to our observations, estimates based on the log-likelihood ratio are generally more reliable across different corpora and languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P99-1067.txt | Citing Article:  E12-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Using large, unrelated English and German corpora (with 163m and 135mwords) and a small German-English bilingual dictionary (with 22k entires), Rapp (1999) demonstrated that reasonably accurate translations could be learned for 100 German nouns that were not contained in the seed bilingual dictionary.</S> | Reference Offset:  ['0','58'] | Reference Text:  <S sid = 0 ssid = >Automatic Identification Of Word Translations From Unrelated English And German Corpora</S><S sid = 58 ssid = >Our German/English base lexicon is derived from the Collins Gem German Dictionary with about 22,300 entries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P99-1067.txt | Citing Article:  E12-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We extend the vector space approach of Rapp (1999) to compute similarity between phrases in the source and target languages.</S> | Reference Offset:  ['47','52'] | Reference Text:  <S sid = 47 ssid = >Using our source-language corpus, we compute a co-occurrence vector for this word.</S><S sid = 52 ssid = >The vector with the highest similarity is considered to be the translation of our source-language word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P99-1067.txt | Citing Article:  E12-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','165'] | Reference Text:  <S sid = 61 ssid = >Since our corpora are very large, to save disk space and processing time we decided to remove all function words from the texts.</S><S sid = 165 ssid = >I thank Manfred Wettler, Gisela Zunker-Rapp, Wolfgang Lezius, and Anita Todd for their support of this work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P99-1067.txt | Citing Article:  D09-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional co-locational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999).</S> | Reference Offset:  ['4','121'] | Reference Text:  <S sid = 4 ssid = >Whereas for parallel texts in some studies up to 99% of the word alignments have been shown to be correct, the accuracy for non-parallel texts has been around 30% up to now.</S><S sid = 121 ssid = >Another approach, as conducted by Fung & Yee (1998), would be to consider all possible translations listed in the lexicon and to give them equal (or possibly descending) weight.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P99-1067.txt | Citing Article:  D09-1040.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some successful combinations are cos CP (Schuetze and Pedersen, 1997), Lin PMI (Lin, 1998), City LL (Rapp, 1999), and Jensen Shannon divergence of conditional probabilities (JSD CP).</S> | Reference Offset:  ['89','155'] | Reference Text:  <S sid = 89 ssid = >They were based on mutual information (Church & Hanks, 1989), conditional probabilities (Rapp, 1996), or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio (Dunning, 1993).</S><S sid = 155 ssid = >It can also be considered as an extension from the monolingual to the bilingual case of the well-established methods for semantic or syntactic word clustering as proposed by Schiitze (1993), Grefenstette (1994), Ruge (1995), Rapp (1996), Lin (1998), and others.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P99-1067.txt | Citing Article:  P13-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The counts can be collected in positional (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window).</S> | Reference Offset:  ['75','84'] | Reference Text:  <S sid = 75 ssid = >For counting word co-occurrences, in most other studies a fixed window size is chosen and it is determined how often each pair of words occurs within a text window of this size.</S><S sid = 84 ssid = >However, the computational methods described below are in the same way applicable to window sizes of any length with or without consideration of word order.</S> | Discourse Facet:  NA | Annotator: Automatic


