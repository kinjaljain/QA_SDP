Citance Number: 1 | Reference Article:  C00-2136.txt | Citing Article:  W01-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On the one hand machine learning is used to automate as much as possible the tasks an IE expert would perform in application development (Cardie 1997) (Yangarber et al 2000).</S> | Reference Offset:  ['69','154'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >learned, otherwise go to step 4 Previous algorithms which use this approach include those described by Yangarber et al (2000) and Stevenson and Greenwood (2005).</S> | Reference Offset:  ['69','151'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 151 ssid = >use of extraction systenls.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The extraction patterns used by both Yangarber et al (2000) and Stevenson and Greenwood (2005) were based on SVO tuples extracted from dependency trees.</S> | Reference Offset:  ['69','197'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 197 ssid = >A non-t)rojectivc dependency parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  C00-2136.txt | Citing Article:  W06-0204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yangarber et al (2000) suggested a method where patterns were compared based on their distribution across documents in a corpus.</S> | Reference Offset:  ['69','132'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 132 ssid = >However, the review and augmenta- tion process took little time, as compared to the manual corpus analysis and development of the pattern base.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yangarber et al (2000) proposed an algorithm for learning extraction patterns for a small number of examples which greatly reduced the burden on the application developer and reduced the knowledge acquisition bottleneck.</S> | Reference Offset:  ['41','154'] | Reference Text:  <S sid = 41 ssid = >However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yangarber et al (2000) chose an approach motivated by the assumption that documents containing a large number of patterns already identified as relevant to a particular IE scenario are likely to contain further relevant patterns.</S> | Reference Offset:  ['57','58'] | Reference Text:  <S sid = 57 ssid = >We stm:t with a large, corlms of documents in the domain (which have not been anne- 941 tared or classified in any way) and an initial "seed" of scenario patterns selected by the user - -  a small set of patterns whose pres- ence reliably indicates thai; the document is relevant o the scenario.</S><S sid = 58 ssid = >The pattern set is used to divide the cor- tins U into a set of relewmt documents, R (which contain at; least one instance of one of the patterns), and a set of non-relevant documents R = U - R. 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  C00-2136.txt | Citing Article:  P05-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This approach has been shown to successfully acquire useful extraction patterns which, when added to an IE system, improved its performance (Yangarber et al, 2000).</S> | Reference Offset:  ['18','154'] | Reference Text:  <S sid = 18 ssid = >This approach as been evalu- ated on actual event extraction scenarios.</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  C00-2136.txt | Citing Article:  P07-1074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Architecture This architecture has been inspired by several existing seed-oriented minimally supervised ma chine learning systems, in particular by Snowball (Agichtein and Gravano, 2000) and ExDisco (Yangarber et al, 2000).</S> | Reference Offset:  ['69','143'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 143 ssid = >ExDIscO attains values within the range of the MUC participald;S, all of which were either heavily-supervised or m~mually coded systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  C00-2136.txt | Citing Article:  W03-1014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ExDisco (Yangarber et al,2000) uses a bootstrapping mechanism to find new extraction patterns using unannotated texts and some seed patterns as the initial input.</S> | Reference Offset:  ['59','115'] | Reference Text:  <S sid = 59 ssid = >Search tbr new candidate patterns: ?</S><S sid = 115 ssid = >These patterns were left in Proteus for all the runs, and they make some contribu- tion to the relatively high baseline scores obtained using just the seed event patterns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  C00-2136.txt | Citing Article:  W06-0202.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, the AutoSlog system (Riloff, 1993) uses pat terns which match certain grammatical categories, mainly nouns and verbs, in phrase chunked text while Yangarber et al (2000) use subject-verb object tuples derived from a dependency parse.</S> | Reference Offset:  ['76','81'] | Reference Text:  <S sid = 76 ssid = >3.3 General izat ion and Concept Classes Because tuples may not repeat with sufficient frequency to obtain reliable statistics, each tu- ple is reduced to a set of pints: e.g., a verb- object pair, a subject-object pair, etc.</S><S sid = 81 ssid = >ExDIsco  was seeded with lninimal pattern sets, namely: Subject Verb Direct Object C-Company C-At)point C-Person C-Person C-Resign ibr the Mmmgement task, and Subject Verb Direct Object * C-Buy C-Conlt)any C-Company merge * for Acquisitions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  C00-2136.txt | Citing Article:  N07-2043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To reduce the knowledge engineering burden on the user in constructing and porting an IE system, unsupervised learning has been utilized ,e.g. Riloff (1996), Yangarber et al (2000), and Sekine (2006).</S> | Reference Offset:  ['41','69'] | Reference Text:  <S sid = 41 ssid = >However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S><S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  C00-2136.txt | Citing Article:  W09-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bootstrapping approaches are employed in (Riloff, 1996), (Yangarber et al, 2000), (Yangarber, 2003), and (Stevenson and Greenwood, 2005) in order to find IE patterns for domain-specific event extraction.</S> | Reference Offset:  ['69','154'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  C00-2136.txt | Citing Article:  W06-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, EXDISCO (Yangarber et al., 2000) used Wall Street Journal articles for training.</S> | Reference Offset:  ['69','70'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 70 ssid = >We used a corlms of 9,224 articles from the Wall Street; Journal.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  C00-2136.txt | Citing Article:  P05-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >meets the density criterion (as defined in (Yangarber et al, 2000)).</S> | Reference Offset:  ['69','154'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >AutoSlog TS, does not require a pre-annotated corpus, but does require one that has been split into subsets that are relevant vs. non-relevant subsets to the scenario. (Yangarber et al, 2000) attempts to find extraction patterns, without a pre-classified corpus, starting from a set of seed patterns.</S> | Reference Offset:  ['41','64'] | Reference Text:  <S sid = 41 ssid = >However, the burden is still on the user to find the appropriate set of examples, which may require a painstaldng and expensive search of a large corpus.</S><S sid = 64 ssid = >Use the new pattern set; to induce a new split of the corpus into relevant and non- relevant documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We first present the basic algorithm for pattern acquisition, similar to that presented in (Yangarber et al., 2000).</S> | Reference Offset:  ['20','63'] | Reference Text:  <S sid = 20 ssid = >Sections 2 and 3 describe our algorithm for pattern dis- covery; section 4 describes our experimental re- sults.</S><S sid = 63 ssid = >(Optionally, at this point, we may present he pattern to the user for review.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['103','208'] | Reference Text:  <S sid = 103 ssid = >~ "~ I I  (1 - ~,.~,.c~(p))"", (5) ~c K(d) where t;11(, weights ,wp arc (tetint;d using the tel- ewm(:(: of the (loeuments, a,s the total  SUl)l)or(; which the pa, I;I;ern p receives: % = log ~ l;.d,(d) dE 11 (p) and ;,7 is (;11( largest weight.</S><S sid = 208 ssid = >Co~@ on Applied Nataral Langaage Process- tug (ANLP-NAACL), Seattle, WA.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  C00-2136.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For an indirect evaluation of the quality of the learned patterns, we employ the text-filtering evaluation strategy, as in (Yangarber et al, 2000).</S> | Reference Offset:  ['109','110'] | Reference Text:  <S sid = 109 ssid = >We have evaluated ExDIsco by manually incorporating the discovered pat- terns into the Proteus knowledge bases and run- ning a full MUC-style evaluation.</S><S sid = 110 ssid = >We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  C00-2136.txt | Citing Article:  D09-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Information Extraction (IE) systems typically use extraction patterns (e.g., Soderland et al (1995), Riloff (1996), Yangarber et al (2000), Califf and Mooney (2003)) or classifiers (e.g., Freitag (1998), Freitag and McCallum (2000), Chieu et al (2003), Bunescu and Mooney (2004)) to extract role fillers for events.</S> | Reference Offset:  ['69','154'] | Reference Text:  <S sid = 69 ssid = >The parser is used ibr reducing each clause or noun phrase to a tuple, consisting of the central ar- guments, ms described in detail in (Yangarber et al., 2000).</S><S sid = 154 ssid = >So lne  o f  th i s  work  has  en l - i)hasized il]teractive tools to (:onvert examples to extractioi~ t)atterlls (Yangarber and Grish- man, 1997); nmch ot: the re, search has focused on methods for automatically converting a cortms annotated with extraction examples into pat- terns (Lehnert et al., 1992; Fisher et al., 1995; Miller el; al., 1998).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  C00-2136.txt | Citing Article:  W06-2207.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have chosen this evaluation strategy because this indirect approach was shown to correlate well with a direct evaluation, where the learned patterns were used to customize an IE system (Yangarberet al, 2000).</S> | Reference Offset:  ['109','110'] | Reference Text:  <S sid = 109 ssid = >We have evaluated ExDIsco by manually incorporating the discovered pat- terns into the Proteus knowledge bases and run- ning a full MUC-style evaluation.</S><S sid = 110 ssid = >We started with our extraction system, Pro- tens, which was used in MUC-6 in 1995, and has undergone continual improvements since the MUC evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


