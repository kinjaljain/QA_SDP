Citance Number: 1 | Reference Article:  W07-2009.txt | Citing Article:  W07-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our systems consistently perform better when a mode exists, which makes sense because those are instances in which the annotators are in agreement (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['58','63'] | Reference Text:  <S sid = 58 ssid = >We want to emphasise test items with better agreement.</S><S sid = 63 ssid = >With 10 guesses there is a better chance that the systems find the responses of these 5 annotators.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-2009.txt | Citing Article:  C10-2074.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our evaluation framework is inspired by the lexical substitution task (McCarthy and Navigli, 2007), where a system attempts to generate a word (or a set of words) to replace a target word, such that the meaning of the sentence is preserved.</S> | Reference Offset:  ['2','83'] | Reference Text:  <S sid = 2 ssid = >In the task, annotators and systems find an alternative substitute word or phrase for a target word in context.</S><S sid = 83 ssid = >For mw detection and identification we used WordNet to detect if a multiword in WordNet which includes the target word occurs within a window of 2 words before and 2 words after the target word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-2009.txt | Citing Article:  W09-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(OOT) evaluation metrics defined by McCarthy and Navigli (2007).</S> | Reference Offset:  ['25','43'] | Reference Text:  <S sid = 25 ssid = >This optionwas envisaged for evaluation of multiword detection.</S><S sid = 43 ssid = >We have 3 separate subtasks 1) best 2) oot and 3) mw which we describe below.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-2009.txt | Citing Article:  W09-0208.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The first one, the LEXSUB-PARA dataset, is a small subset of the Lexical Substitution corpus (McCarthy and Navigli, 2007) that was specifically created for this task.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-2009.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While Dinu and Lapata (Dinu and Lapata, 2010b) did show improvement over context insensitive DIRT, this result was obtained on the verbs of the Lexical Substitution Task in SemEval (McCarthy and Navigli, 2007), which was manually created with a bias for context-sensitive substitutions.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-2009.txt | Citing Article:  P13-1131.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Then we will also be able to evaluate our model on the Lexical Substitution Task (McCarthy and Navigli, 2007), which has been commonly used in recent years as a benchmark for context-sensitive lexical similarity models.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-2009.txt | Citing Article:  P09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recently, McCarthy and Navigli (2007) proposed the English Lexical Substitution task (hereafter referred to as LEXSUB) under the auspices of SemEval-2007.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-2009.txt | Citing Article:  P09-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For more information on LEXSUB, see McCarthy and Navigli (2007).</S> | Reference Offset:  ['0','33'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 33 ssid = >The words included were se lected either manually (70 words) from examinationof a variety of lexical resources and corpora or au tomatically (131) using information in these lexical resources.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-2009.txt | Citing Article:  P09-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Within the scope of our paper, rule application is handled similarly to Lexical Substitution (McCarthy and Navigli, 2007), considering the contextual relationship between the text and the rule.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-2009.txt | Citing Article:  S10-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >SWAT-E is the best system for out often, as several of the items that were emphasized through duplication were also correct. The results are much higher than for LEXSUB (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['51','57'] | Reference Text:  <S sid = 51 ssid = >best measures This requires the best file produced by the system which gives as many guesses as the system believes are fitting, but where the credit for each correct guess is divided by the number of guesses.</S><S sid = 57 ssid = >This gives higher scores to items with less variation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-2009.txt | Citing Article:  P12-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The past work which is most similar to ours is derived from the lexical substitution track of SemEval 2007 (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-2009.txt | Citing Article:  C08-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In particular, this technique ranks a given list of synonyms according to a similarity metric based on the occurrences in the Web 1T 5-gram corpus, which specify n-grams frequencies in a large Web sample. This technique achieved the state-of-the-art performance on the English Lexical Substitution task at SemEval 2007 (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-2009.txt | Citing Article:  D11-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To evaluate the system's ability to come up with suitable substitutes from scratch, we use the measures designed to evaluate systems that took part in the original English lexical substitution task (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-2009.txt | Citing Article:  W09-2506.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We evaluate our model on a paraphrase ranking task on a subset of the SemEval 2007 lexical substitution task (McCarthy and Navigli, 2007) data, and compare it to a random baseline and E&P's state of the art model.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-2009.txt | Citing Article:  D11-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Instead, we automatically extract confusable candidates from a parallel corpus. Synonym extraction (Wu and Zhou, 2003), lexical substitution (McCarthy and Navigli, 2007) and paraphrasing (Madnani and Dorr, 2010) are related to collocation correction in the sense that they try to find semantically equivalent words or phrases.</S> | Reference Offset:  ['0','30'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 30 ssid = >The data set comprises 2010 sentences, 201 target words each with 10 sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-2009.txt | Citing Article:  W09-2412.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results are reported in McCarthy and Navigli (2007) and in more detail in McCarthy and Navigli (in press).</S> | Reference Offset:  ['92','101'] | Reference Text:  <S sid = 92 ssid = >Please refer to the task website for these results.</S><S sid = 101 ssid = >The dis tributional methods, especially lin, show promising results given that these methods are automatic and 5The task website is at http://www.informatics.sussex.ac.uk/ research/nlp/mccarthy/task10index.html.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-2009.txt | Citing Article:  P10-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our first experiment is carried out on the SemEval 2007 lexical substitution task dataset (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-2009.txt | Citing Article:  P10-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To evaluate the performance of our model, we use various subsets of the SemEval 2007 lexical substitution task (McCarthy and Navigli, 2007) dataset.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 1 ssid = >In this paper we describe the English Lexical Substitution task for SemEval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W07-2009.txt | Citing Article:  P10-1097.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use it because we want to compare our model with E&P. P10 measures the percentage of gold-standard paraphrases in the top-ten list of paraphrases as ranked by the system, and can be defined as follows (McCarthy and Navigli, 2007).</S> | Reference Offset:  ['58','120'] | Reference Text:  <S sid = 58 ssid = >We want to emphasise test items with better agreement.</S><S sid = 120 ssid = >Since a pre-defined inventory is not used, the task allows usto compare lexical resources as well as disambiguation techniques without a bias to any predefined inventory.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W07-2009.txt | Citing Article:  W10-0211.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We explore this suggestion, implementing a lexical substitution (McCarthy and Navigli,2007) approach to dialogue generation with sentiment, using the Valentino approach and associated resources.</S> | Reference Offset:  ['0','33'] | Reference Text:  <S sid = 0 ssid = >SemEval-2007 Task 10: English Lexical Substitution Task</S><S sid = 33 ssid = >The words included were se lected either manually (70 words) from examinationof a variety of lexical resources and corpora or au tomatically (131) using information in these lexical resources.</S> | Discourse Facet:  NA | Annotator: Automatic


