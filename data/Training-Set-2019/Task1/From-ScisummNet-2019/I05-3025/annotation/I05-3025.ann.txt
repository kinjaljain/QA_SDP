Citance Number: 1 | Reference Article:  I05-3025.txt | Citing Article:  W06-0121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In ME model, the following features (Jin Kiat Low et al, 2005) are selected: a) cn (n=-2, -1, 0, 1, 2) b) cncn+1 (n=-2, -1, 0, 1) c) c-1c+1 where cn indicates the character in the left or right position n relative to the current character c0.</S> | Reference Offset:  ['13','42'] | Reference Text:  <S sid = 13 ssid = >C0 denotes the current character, Cn(C?n ) denotes the character n positions to the right (left) of the current character.</S><S sid = 42 ssid = >When processing the current character C0 ??</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  I05-3025.txt | Citing Article:  P06-2056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track.</S> | Reference Offset:  ['82','91'] | Reference Text:  <S sid = 82 ssid = >The columns R, P, and F show the recall, precision, and F mea- sure, respectively.</S><S sid = 91 ssid = >4 Conclusion Using a maximum entropy approach, our Chi- nese word segmenter achieves state-of-the-art ac- curacy, when evaluated on all four corpora in the open track of the Second International Chinese Word Segmentation Bakeoff.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  I05-3025.txt | Citing Article:  D10-1077.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >3) New feature templates were added, such as the templates that were used in representing numbers, dates, letters etc. (Low et al., 2005).</S> | Reference Offset:  ['10','11'] | Reference Text:  <S sid = 10 ssid = >Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1 1.1 Basic Features The basic features of our word segmenter are similar to our previous work (Ng and Low, 2004): (a) Cn(n = ?2,?1, 0, 1, 2) (b) CnCn+1(n = ?2,?1, 0, 1) (c) C?1C1 (d) Pu(C0) (e) T (C?2)T (C?1)T (C0)T (C1)T (C2) In the above feature templates, C refers to a Chinese character.</S><S sid = 11 ssid = >Templates (a) ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  I05-3025.txt | Citing Article:  I08-4017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Those for the 4-tag set, adopted from (Xue, 2003) and (Low et al., 2005), include C−2, C−1, C0, C1, C2, C−2C−1, C−1C0, C−1C1, C0C1 and C1C2.</S> | Reference Offset:  ['10','22'] | Reference Text:  <S sid = 10 ssid = >Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1 1.1 Basic Features The basic features of our word segmenter are similar to our previous work (Ng and Low, 2004): (a) Cn(n = ?2,?1, 0, 1, 2) (b) CnCn+1(n = ?2,?1, 0, 1) (c) C?1C1 (d) Pu(C0) (e) T (C?2)T (C?1)T (C0)T (C1)T (C2) In the above feature templates, C refers to a Chinese character.</S><S sid = 22 ssid = >T (C2) = 11243 1http://maxent.sourceforge.net/ 161 will be set to 1 (???</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  I05-3025.txt | Citing Article:  W10-4141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Third, the post processing method (Low et al, 2005) is employed to enhance the unknown word segmentation.</S> | Reference Offset:  ['73','75'] | Reference Text:  <S sid = 73 ssid = >After word segmentation is done by the maxi- mum entropy classifier, a post-processing step is applied to correct inconsistently segmented words made up of 3 or more characters.</S><S sid = 75 ssid = >In the post-processing step, the segmentation of the characters of these consecutive words is changed so that they are segmented as a single word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  I05-3025.txt | Citing Article:  I08-4015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['102','103'] | Reference Text:  <S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S><S sid = 103 ssid = >In Proceedings of the Second SIGHAN Workshop on Chinese Lan- guage Processing, pages 176?179.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  I05-3025.txt | Citing Article:  I08-4015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We add a new feature, which also used in maximum entropy model for word segmentation task by (Low et al, 2005), to the feature templates for CRF model while keep the other features same as (Zhao et al, 2006).</S> | Reference Offset:  ['10','11'] | Reference Text:  <S sid = 10 ssid = >Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1 1.1 Basic Features The basic features of our word segmenter are similar to our previous work (Ng and Low, 2004): (a) Cn(n = ?2,?1, 0, 1, 2) (b) CnCn+1(n = ?2,?1, 0, 1) (c) C?1C1 (d) Pu(C0) (e) T (C?2)T (C?1)T (C0)T (C1)T (C2) In the above feature templates, C refers to a Chinese character.</S><S sid = 11 ssid = >Templates (a) ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  I05-3025.txt | Citing Article:  W10-4136.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >3) New feature templates were added, such as templates used in representing numbers, dates, letters etc. (Low et al., 2005).</S> | Reference Offset:  ['10','11'] | Reference Text:  <S sid = 10 ssid = >Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1 1.1 Basic Features The basic features of our word segmenter are similar to our previous work (Ng and Low, 2004): (a) Cn(n = ?2,?1, 0, 1, 2) (b) CnCn+1(n = ?2,?1, 0, 1) (c) C?1C1 (d) Pu(C0) (e) T (C?2)T (C?1)T (C0)T (C1)T (C2) In the above feature templates, C refers to a Chinese character.</S><S sid = 11 ssid = >Templates (a) ?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  I05-3025.txt | Citing Article:  W07-2054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Briefly, after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005).</S> | Reference Offset:  ['49','102'] | Reference Text:  <S sid = 49 ssid = >1.3 Additional Training Corpora The presence of different standards in Chinese word segmentation limits the amount of training corpora available for the community, due to dif- ferent organizations preparing training corpora in their own standards.</S><S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  I05-3025.txt | Citing Article:  W07-2010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Briefly, after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005).</S> | Reference Offset:  ['49','102'] | Reference Text:  <S sid = 49 ssid = >1.3 Additional Training Corpora The presence of different standards in Chinese word segmentation limits the amount of training corpora available for the community, due to dif- ferent organizations preparing training corpora in their own standards.</S><S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  I05-3025.txt | Citing Article:  D10-1090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the maximum entropy segmenter of (Low et al, 2005) to segment the Chinese part of the FBIS corpus.</S> | Reference Offset:  ['6','55'] | Reference Text:  <S sid = 6 ssid = >1 Chinese Word Segmenter The Chinese word segmenter we built is similar to the maximum entropy word segmenter we em- ployed in our previous work (Ng and Low, 2004).</S><S sid = 55 ssid = >Use the trained word segmenter to segment another corpus D annotated in a different segmentation standard.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  I05-3025.txt | Citing Article:  I08-4028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['102','103'] | Reference Text:  <S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S><S sid = 103 ssid = >In Proceedings of the Second SIGHAN Workshop on Chinese Lan- guage Processing, pages 176?179.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  I05-3025.txt | Citing Article:  W06-0133.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our Chinese word segmenter is a modification of the system described by Low et al (2005), which they entered in the 2005 Second International Chinese Word Segmentation Bakeoff.</S> | Reference Offset:  ['6','91'] | Reference Text:  <S sid = 6 ssid = >1 Chinese Word Segmenter The Chinese word segmenter we built is similar to the maximum entropy word segmenter we em- ployed in our previous work (Ng and Low, 2004).</S><S sid = 91 ssid = >4 Conclusion Using a maximum entropy approach, our Chi- nese word segmenter achieves state-of-the-art ac- curacy, when evaluated on all four corpora in the open track of the Second International Chinese Word Segmentation Bakeoff.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  I05-3025.txt | Citing Article:  W06-0133.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Much of this can be attributed to the value of using an external dictionary and additional training data, as illustrated by the experiments run by Low et al (2005) with their model.</S> | Reference Offset:  ['36','57'] | Reference Text:  <S sid = 36 ssid = >We ad- dress the problem of OOV words in two ways: using an external dictionary containing a list of predefined words, and using additional training corpora which are not segmented according to the same segmentation standard.</S><S sid = 57 ssid = >Add all such characters C as additional train- ing data to the original training corpus D0, and train a new word segmenter using the en- larged training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  I05-3025.txt | Citing Article:  W06-0133.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It should be noted that in our testing during development, even when we strove to create a system which matched as closely as possible the one described by Low et al (2005), we were unable to achieve scores for the 2005 bakeoff data as high as their system did.</S> | Reference Offset:  ['64','85'] | Reference Text:  <S sid = 64 ssid = >2 Testing During testing, the probability of a boundary tag sequence assignment t1 .</S><S sid = 85 ssid = >Our word segmenter achieved the high- est F measure for AS, CITYU, and PKU, and the second highest for MSR.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  I05-3025.txt | Citing Article:  W10-4130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Especially, character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005).</S> | Reference Offset:  ['96','102'] | Reference Text:  <S sid = 96 ssid = >word-based or character-based?</S><S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  I05-3025.txt | Citing Article:  W06-0141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We utilized four of the five basic feature templates suggested in (Low et al, 2005), described as follows: Cn (n=-2, -1, 0, 1, 2), CnCn+ 1 (n=-2, -1, 0, 1), Pu (C0)? T (C-2) T (C-1) T (C0) T (C1) T (C2) where C refers to a Chinese character.</S> | Reference Offset:  ['10','17'] | Reference Text:  <S sid = 10 ssid = >Our implementation used the opennlp maximum entropy package v2.1.0 from sourceforge.1 1.1 Basic Features The basic features of our word segmenter are similar to our previous work (Ng and Low, 2004): (a) Cn(n = ?2,?1, 0, 1, 2) (b) CnCn+1(n = ?2,?1, 0, 1) (c) C?1C1 (d) Pu(C0) (e) T (C?2)T (C?1)T (C0)T (C1)T (C2) In the above feature templates, C refers to a Chinese character.</S><S sid = 17 ssid = >The punctuation feature, Pu(C0), checks whether C0 is a punctuation symbol (such as ??</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  I05-3025.txt | Citing Article:  W06-0141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >See detail description and the example in (Low et al, 2005).</S> | Reference Offset:  ['20','27'] | Reference Text:  <S sid = 20 ssid = >For example, when considering the character ?#?</S><S sid = 27 ssid = >For example, comma ?,?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  I05-3025.txt | Citing Article:  W10-4122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Especially, the character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005).</S> | Reference Offset:  ['96','102'] | Reference Text:  <S sid = 96 ssid = >word-based or character-based?</S><S sid = 102 ssid = >Chinese word segmentation as LMR tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  I05-3025.txt | Citing Article:  D11-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Low et al (2005) introduce an external dictionary as features of a discriminative model.</S> | Reference Offset:  ['46','87'] | Reference Text:  <S sid = 46 ssid = >are found in the dictionary.</S><S sid = 87 ssid = >Version V1 used only the basic features (Section 1.1); Version V2 used the basic features and additional features de- rived from our external dictionary (Section 1.2); Version V3 used the basic features but with ad- ditional training corpora (Section 1.3); and Ver- sion V4 is our official submitted version combin- ing basic features, external dictionary, and addi- tional training corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


