Citance Number: 1 | Reference Article:  J03-3001.txt | Citing Article:  P10-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Early web-based models used search engines to collect N-gram counts, and thus could not use capitalization, punctuation, and annotations such as part-of-speech (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['77','121'] | Reference Text:  <S sid = 77 ssid = >Language identification algorithms (Beesley 1988; Grefenstette 1995), now widely used in Web search engines, were developed as NLP technology.</S><S sid = 121 ssid = >Many Web search engines allow the user to search for adjacent phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J03-3001.txt | Citing Article:  W06-1705.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In corpus linguistics building such mega corpora is beyond the scope of individual researchers, and they are not easily accessible (Kennedy, 1998: 56) unless the web is used as a corpus (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['140','187'] | Reference Text:  <S sid = 140 ssid = >Can they be used?</S><S sid = 187 ssid = >Where researchers use established corpora, such as Brown, the BNC, or the Penn Treebank, researchers and readers are willing to accept the corpus name as a label for the type of text occurring in it without asking critical questions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J03-3001.txt | Citing Article:  E06-2001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Web contains vast amounts of linguistic data for many languages (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['1','105'] | Reference Text:  <S sid = 1 ssid = >The Web, teeming as it is with language data, of all manner of varieties and languages, in vast quantity and freely available, is a fabulous linguists’ playground.</S><S sid = 105 ssid = >In fact, the text contains about 1,500 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J03-3001.txt | Citing Article:  W06-1704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In recent years, the Web has been increasingly used as a source of linguistic data (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['9','146'] | Reference Text:  <S sid = 9 ssid = >Language scientists and technologists are increasingly turning to the Web as a source of language data, because it is so big, because it is the only available source for the type of language in which they are interested, or simply because it is free and instantly available.</S><S sid = 146 ssid = >Much work in recent years has gone into developing language models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J03-3001.txt | Citing Article:  P06-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is now easy to gather machine-readable sentences in various domains because of the ease of publication and access via the Web (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['19','50'] | Reference Text:  <S sid = 19 ssid = >These may be considered under four main headings: sampling and representativeness, finite size, machine-readable form, a standard reference.</S><S sid = 50 ssid = >Mihalcea and Tchklovski complement this use of Web as corpus with Web technology to gather manual word sense annotations on the Word Expert Web site.3 Santamar´ia et al., in this issue, discuss how to link word senses to Web directory nodes, and thence to Web pages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J03-3001.txt | Citing Article:  W06-1206.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['67','216'] | Reference Text:  <S sid = 67 ssid = >They explore the performance of a number of machine learning algorithms (on a representative disambiguation task) as the size of the training corpus grows from a million to a billion words.</S><S sid = 216 ssid = >Various alternative embeddings are evaluated using the CLEF (Peters 2001) multilingual information retrieval test beds.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J03-3001.txt | Citing Article:  C08-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The web as a corpus has been successfully used for many areas in NLP (Kilgarriff and Grefenstette 2003) such as WSD (Mihalcea and Moldovan 1999), obtaining frequencies for bigrams (Keller and Lapata 2003) and noun compound bracketing (Nakov and Hearst 2005).</S> | Reference Offset:  ['43','140'] | Reference Text:  <S sid = 43 ssid = >Rada Mihalcea and Dan Moldovan (1999) used hit counts for carefully constructed search engine queries to identify rank orders for word sense frequencies, as an input to a word sense disambiguation engine.</S><S sid = 140 ssid = >Can they be used?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J03-3001.txt | Citing Article:  W06-1701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For Hungarian, the highest quality (4 % threshold) stratum of the corpus contains 1.22m unique pages for a total of 699m tokens, already exceeding the 500m predicted in (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['84','105'] | Reference Text:  <S sid = 84 ssid = >In 2003, Google claims to search four times this number of Web pages, which raises the number of bytes of text available just through this one Web server to over 20 terabytes from directly accessible Web pages.</S><S sid = 105 ssid = >In fact, the text contains about 1,500 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J03-3001.txt | Citing Article:  W09-0430.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For collecting bilingual text data for the two sets S1, S2, the Web is an ideal source as it is large, free and available (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['3','9'] | Reference Text:  <S sid = 3 ssid = >The Web is immense, free, and available by mouse click.</S><S sid = 9 ssid = >Language scientists and technologists are increasingly turning to the Web as a source of language data, because it is so big, because it is the only available source for the type of language in which they are interested, or simply because it is free and instantly available.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J03-3001.txt | Citing Article:  W07-1602.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is natural to question the appropriateness of web data for research purposes, because web data is inevitably noisy and search engines themselves can introduce certain idiosyncracies which can distort results (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['60','121'] | Reference Text:  <S sid = 60 ssid = >However, for some purposes, it is not large enough.</S><S sid = 121 ssid = >Many Web search engines allow the user to search for adjacent phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J03-3001.txt | Citing Article:  W08-1708.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The second corpus is a subset of the German part of the Wacky project (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['164','192'] | Reference Text:  <S sid = 164 ssid = >The problem with the second is that it is arbitrary.</S><S sid = 192 ssid = >The Open Directory Project (at (dmoz.org)) is a collaborative, volunteer project for classifying Web pages into a taxonomic hierarchy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J03-3001.txt | Citing Article:  W06-1707.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >So we have the Internet: it is immense, free, easily accessible and can be used for all manner of language research (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['3','4'] | Reference Text:  <S sid = 3 ssid = >The Web is immense, free, and available by mouse click.</S><S sid = 4 ssid = >It contains hundreds of billions of words of text and can be used for all manner of language research.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J03-3001.txt | Citing Article:  N09-1059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Many NLP tasks have successfully utilized very large corpora, most of which were acquired from the Web (Kilgarriff and Grefenstette, 2003).</S> | Reference Offset:  ['117','200'] | Reference Text:  <S sid = 117 ssid = >In October 1996 there How can these large numbers be used for other language-processing tasks?</S><S sid = 200 ssid = >They find that Web frequency counts are consistent with those for other large corpora.</S> | Discourse Facet:  NA | Annotator: Automatic


