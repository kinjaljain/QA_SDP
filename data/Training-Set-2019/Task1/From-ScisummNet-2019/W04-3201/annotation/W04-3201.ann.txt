Citance Number: 1 | Reference Article:  W04-3201.txt | Citing Article:  P05-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Taskar et al., 2004) suggested a method for maximal margin parsing which employs the dynamic programming approach to decoding and parameter estimation problems.</S> | Reference Offset:  ['14','16'] | Reference Text:  <S sid = 14 ssid = >Given sufficiently “local” features, the decoding and parameter estimation problems can be solved using dynamic programming algorithms.</S><S sid = 16 ssid = >In this paper, we describe a dynamic programming approach to discriminative parsing that is an alternative to maximum entropy estimation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W04-3201.txt | Citing Article:  P14-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous work has also used surface features in their parsers, but the focus has been on machine learning methods (Taskar et al, 2004), latent annotations (Petrov and Klein, 2008a; Petrov and Klein, 2008b), or implementation (Finkel et al, 2008).</S> | Reference Offset:  ['11','38'] | Reference Text:  <S sid = 11 ssid = >In reranking methods (Johnson et al., 1999; Collins, 2000; Shen et al., 2003), an initial parser is used to generate a number of candidate parses.</S><S sid = 38 ssid = >Recently, it has also been extended to graphical models (Taskar et al., 2003; Altun et al., 2003) and shown to outperform the standard maxlikelihood methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W04-3201.txt | Citing Article:  W06-2936.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the terminology in (Taskar et al, 2004) for a generic structured output prediction, and define a part.</S> | Reference Offset:  ['92','113'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 113 ssid = >Hence, in our experiments we use an online coordinate descent method analogous to the sequential minimal optimization (SMO) used for SVMs (Platt, 1999) and adapted to structured max-margin estimation in Taskar et al. (2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W04-3201.txt | Citing Article:  W06-3603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow Taskar et al (2004) and Turian and Melamed (2005) in training and testing on? 15word sentences in the English Penn Treebank (Taylor et al, 2003).</S> | Reference Offset:  ['92','115'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 115 ssid = >We used the Penn English Treebank for all of our experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W04-3201.txt | Citing Article:  W06-3603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on 15 word sentences.</S> | Reference Offset:  ['92','116'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 116 ssid = >We report results here for each model and setting trained and tested on only the sentences of length < 15 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W04-3201.txt | Citing Article:  W06-3603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','166'] | Reference Text:  <S sid = 61 ssid = >There is a major problem with both the primal and the dual formulations above: since each potential mistake must be ruled out, the number of variables or constraints is proportional to |G(x)|, the number of possible parse trees.</S><S sid = 166 ssid = >This work was supported in part by the Department of the Interior/DARPA under contract number NBCHD030010, a Microsoft Graduate Fellowship to the second author, and National Science Foundation grant 0347631 to the third author.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W04-3201.txt | Citing Article:  P07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','166'] | Reference Text:  <S sid = 61 ssid = >There is a major problem with both the primal and the dual formulations above: since each potential mistake must be ruled out, the number of variables or constraints is proportional to |G(x)|, the number of possible parse trees.</S><S sid = 166 ssid = >This work was supported in part by the Department of the Interior/DARPA under contract number NBCHD030010, a Microsoft Graduate Fellowship to the second author, and National Science Foundation grant 0347631 to the third author.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W04-3201.txt | Citing Article:  P07-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It is expensive to train the MF approximation on the whole WSJ corpus, so instead we use only sentences of length at most 15, as in (Taskar et al, 2004) and (Turian and Melamed, 2006).</S> | Reference Offset:  ['92','116'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 116 ssid = >We report results here for each model and setting trained and tested on only the sentences of length < 15 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W04-3201.txt | Citing Article:  W05-0407.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An other interesting model for parsing re-ranking based on tree kernel is presented in (Taskar et al, 2004).</S> | Reference Offset:  ['92','161'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 161 ssid = >We have presented a maximum-margin approach to parsing, which allows a discriminative SVM-like objective to be applied to the parsing problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W04-3201.txt | Citing Article:  W05-0407.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A refinement of such technique was presented in (Taskar et al, 2004).</S> | Reference Offset:  ['38','92'] | Reference Text:  <S sid = 38 ssid = >Recently, it has also been extended to graphical models (Taskar et al., 2003; Altun et al., 2003) and shown to outperform the standard maxlikelihood methods.</S><S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W04-3201.txt | Citing Article:  W08-2102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Taskar et al (2004) describe a max-margin approach; however, in this work training sentences were limited to be of 15 words or less.</S> | Reference Offset:  ['0','25'] | Reference Text:  <S sid = 0 ssid = >Max-Margin Parsing</S><S sid = 25 ssid = >The primary contribution of this paper is the extension of the max-margin approach of Taskar et al. (2003) to context free grammars.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W04-3201.txt | Citing Article:  P06-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Taskar et al (2004) took several months to train on the 15 word sentences in the English Penn Treebank (Dan Klein, p.c.).</S> | Reference Offset:  ['92','115'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 115 ssid = >We used the Penn English Treebank for all of our experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W04-3201.txt | Citing Article:  P06-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow Taskar et al (2004) in training and testing on 15 word sentences in the English Penn Treebank (Taylor et al, 2003).</S> | Reference Offset:  ['92','115'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 115 ssid = >We used the Penn English Treebank for all of our experiments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W04-3201.txt | Citing Article:  P06-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To situate our results in the literature, we compare our results to those reported by Taskar et al (2004) and Turian and Melamed (2005) for their discriminative parsers, which were also trained and tested on 15 word sentences.</S> | Reference Offset:  ['92','116'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 116 ssid = >We report results here for each model and setting trained and tested on only the sentences of length < 15 words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W04-3201.txt | Citing Article:  P06-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['61','166'] | Reference Text:  <S sid = 61 ssid = >There is a major problem with both the primal and the dual formulations above: since each potential mistake must be ruled out, the number of variables or constraints is proportional to |G(x)|, the number of possible parse trees.</S><S sid = 166 ssid = >This work was supported in part by the Department of the Interior/DARPA under contract number NBCHD030010, a Microsoft Graduate Fellowship to the second author, and National Science Foundation grant 0347631 to the third author.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W04-3201.txt | Citing Article:  P06-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Collins and Roark (2004) and Taskar et al (2004) beat the generative baseline only after using the standard trick of using the output from a generative model as a feature.</S> | Reference Offset:  ['148','163'] | Reference Text:  <S sid = 148 ssid = >The first feature was the prediction of the generative baseline; this feature added little information, but made the learning phase faster.</S><S sid = 163 ssid = >On a test set of ≤ 15 word sentences, the featurerich model outperforms both its own natural generative baseline and the Collins parser on Fl.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W04-3201.txt | Citing Article:  D08-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Additionally, we exploit the flexibility of the discriminative framework both to improve the treatment of unknown words as well as to include span features (Taskar et al, 2004), giving the benefit of some input features integrally in our dynamic program.</S> | Reference Offset:  ['81','127'] | Reference Text:  <S sid = 81 ssid = >For example, O could include features which identify the rule used in the production, or features which track the rule identity together with features of the words at positions s, m, e, and neighboring positions in the sentence x.</S><S sid = 127 ssid = >For a span (s, e) of a sentence x, the base lexical features were: These base features were conjoined with the span length for spans of length 3 and below, since short spans have highly distinct behaviors (see the examples below).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W04-3201.txt | Citing Article:  D08-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In re ranking, one can incorporate any such features, of course, but even in our dynamic programming approach it is possible to include features that decompose along the dynamic program structure, as shown by Taskar et al (2004).</S> | Reference Offset:  ['16','92'] | Reference Text:  <S sid = 16 ssid = >In this paper, we describe a dynamic programming approach to discriminative parsing that is an alternative to maximum entropy estimation.</S><S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W04-3201.txt | Citing Article:  D08-1091.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use non-local span features, which condition on properties of input spans (Taskar et al, 2004).</S> | Reference Offset:  ['92','127'] | Reference Text:  <S sid = 92 ssid = >As shown in Taskar et al. (2003), the dual in Eq.</S><S sid = 127 ssid = >For a span (s, e) of a sentence x, the base lexical features were: These base features were conjoined with the span length for spans of length 3 and below, since short spans have highly distinct behaviors (see the examples below).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W04-3201.txt | Citing Article:  D08-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is the approach taken by Taskar et al (2004), but their approach assumes that the loss function can be decomposed into local loss functions.</S> | Reference Offset:  ['17','82'] | Reference Text:  <S sid = 17 ssid = >Our method extends the maxmargin approach of Taskar et al. (2003) to the case of context-free grammars.</S><S sid = 82 ssid = >In addition, we assume that the loss function L(x, y, ˆy) also decomposes into a sum of local loss functions l(x, y, r) over parts, as follows: One approach would be to define l(x, y, r) to be 0 only if the non-terminal A spans words s ... e in the derivation y and 1 otherwise.</S> | Discourse Facet:  NA | Annotator: Automatic


