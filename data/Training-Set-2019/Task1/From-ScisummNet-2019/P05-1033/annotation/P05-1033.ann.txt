Citance Number: 1 | Reference Article:  P05-1033.txt | Citing Article:  W05-1506.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similarly, Chiang (2005) uses the k-best parsing algorithm described below in a CFG-based log-linear translation model in order to learn feature weights which maximize BLEU.</S> | Reference Offset:  ['56','78'] | Reference Text:  <S sid = 56 ssid = >This can result in nbest lists with very few different translations or feature vectors, which is problematic for the algorithm we use to tune the feature weights.</S><S sid = 78 ssid = >This makes the decoding algorithm asymptotically linear-time.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P05-1033.txt | Citing Article:  W05-1506.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['30','121'] | Reference Text:  <S sid = 30 ssid = >A move to synchronous CFG can be seen as a move towards syntax-based MT; however, we make a distinction here between formally syntax-based and linguistically syntax-based MT.</S><S sid = 121 ssid = >S. D. G.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P05-1033.txt | Citing Article:  W05-1506.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We also implemented Algorithms 2 and 3 in a parsing-based MT decoder (Chiang, 2005) and report results on decoding speed.</S> | Reference Offset:  ['30','81'] | Reference Text:  <S sid = 30 ssid = >A move to synchronous CFG can be seen as a move towards syntax-based MT; however, we make a distinction here between formally syntax-based and linguistically syntax-based MT.</S><S sid = 81 ssid = >This is faster than our Python implementation of a standard phrase-based decoder, so we expect that a future optimized implementation of the hierarchical decoder will run at a speed competitive with other phrase-based systems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P05-1033.txt | Citing Article:  W05-1506.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our second experiment was on a CKY-based decoder for a machine translation system (Chiang, 2005), implemented in Python 2.4 accelerated with Psyco 1.3 (Rigo, 2004).</S> | Reference Offset:  ['0','79'] | Reference Text:  <S sid = 0 ssid = >A Hierarchical Phrase-Based Model For Statistical Machine Translation</S><S sid = 79 ssid = >The decoder is implemented in Python, an interpreted language, with C++ code from the SRI Language Modeling Toolkit (Stolcke, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P05-1033.txt | Citing Article:  P14-1137.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Following this WSD reformulation for SMT, Chan et al (2007) integrate a state-of-the-art WSD system into a hierarchical phrase-based system (Chiang, 2005).</S> | Reference Offset:  ['83','110'] | Reference Text:  <S sid = 83 ssid = >We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al., 2003; Koehn, 2004a), against our system.</S><S sid = 110 ssid = >Hierarchical phrase pairs, which can be learned without any syntactically-annotated training data, improve translation accuracy significantly compared with a state-of-the-art phrase-based system.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P05-1033.txt | Citing Article:  D08-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Whenever we combine two dynamic programming items, we need to score the fluency of their concatentation by incorporating the score of any language model features which cross the target side boundaries of the two concatenated items (Chiang, 2005).</S> | Reference Offset:  ['69','98'] | Reference Text:  <S sid = 69 ssid = >Each cell contains all the items standing for X spanning fi/.</S><S sid = 98 ssid = >This suggests that the model will prefer serial combination of phrases, unless some other factor supports the use of hierarchical phrases (e.g., a better language model score).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P05-1033.txt | Citing Article:  N09-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For instance, Zollmann et al (2006) follow Chiang (2005) in disallowing adjacent non terminals.</S> | Reference Offset:  ['7','12'] | Reference Text:  <S sid = 7 ssid = >The basic phrase-based model is an instance of the noisy-channel approach (Brown et al., 1993),1 in which the translation of a French sentence f into an from position i to position j inclusive, and similarly for eji .</S><S sid = 12 ssid = >Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al., 2003), or not at all (Zens and Ney, 2004; Kumar et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P05-1033.txt | Citing Article:  N10-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Cherry, 2008) and (Marton and Resnik, 2008) introduce syntactic constraints into the standard phrase-based decoding (Koehn et al, 2003) and hierarchical phrase-based decoding (Chiang, 2005) respectively by using a counting feature which accumulates whenever hypotheses violate syntactic boundaries of source-side parse trees.</S> | Reference Offset:  ['83','103'] | Reference Text:  <S sid = 83 ssid = >We compared a baseline system, the state-of-the-art phrase-based system Pharaoh (Koehn et al., 2003; Koehn, 2004a), against our system.</S><S sid = 103 ssid = >Koehn et al. (2003) mention German (es gibt, there is) as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P05-1033.txt | Citing Article:  N10-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >More previously, (Chiang, 2005) rewards hypotheses whenever they exactly match constituent boundaries of parse trees on the source side.</S> | Reference Offset:  ['28','106'] | Reference Text:  <S sid = 28 ssid = >It translates the above example almost exactly as we have shown, the only error being that it omits the word ‘that’ from (6) and therefore (8).</S><S sid = 106 ssid = >This feature adds a factor to (17), { 1 if fij is a constituent 0 otherwise as determined by a statistical tree-substitutiongrammar parser (Bikel and Chiang, 2000), trained on the Penn Chinese Treebank, version 3 (250k words).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P05-1033.txt | Citing Article:  W10-2413.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['30','121'] | Reference Text:  <S sid = 30 ssid = >A move to synchronous CFG can be seen as a move towards syntax-based MT; however, we make a distinction here between formally syntax-based and linguistically syntax-based MT.</S><S sid = 121 ssid = >S. D. G.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P05-1033.txt | Citing Article:  P09-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To better leverage syntactic constraint yet still allow non-syntactic translations, Chiang (2005) introduces a count for each hypothesis and accumulates it whenever the hypothesis exactly matches syntactic boundaries on the source side.</S> | Reference Offset:  ['103','105'] | Reference Text:  <S sid = 103 ssid = >Koehn et al. (2003) mention German (es gibt, there is) as an example of a good phrase pair which is not a syntactic phrase pair, and report that favoring syntactic phrases does not improve accuracy.</S><S sid = 105 ssid = >Thus, favoring subtrees in our model that are syntactic phrases might provide a fairer way of testing the hypothesis that syntactic phrases are better phrases.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P05-1033.txt | Citing Article:  P08-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Chiang (2005)'s hierarchal phrase-based model achieves significant performance improvement.</S> | Reference Offset:  ['3','99'] | Reference Text:  <S sid = 3 ssid = >Thus it can be seen as shift to the of syntaxtranslation systems without any lin- In our experiments using BLEU as a metric, the hierarchical phrasebased model achieves a relative improvement of 7.5% over Pharaoh, a state-of-the-art phrase-based system.</S><S sid = 99 ssid = >We then tested our system, using the settings described above.4 Our system achieves an absolute improvement of 0.02 over the baseline (7.5% relative), without using any additional training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P05-1033.txt | Citing Article:  P08-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, no further significant improvement is achieved when the model is made sensitive to syntactic structures by adding a constituent feature (Chiang, 2005).</S> | Reference Offset:  ['102','109'] | Reference Text:  <S sid = 102 ssid = >The use of hierarchical structures opens the possibility of making the model sensitive to syntactic structure.</S><S sid = 109 ssid = >Although the feature improved accuracy on the development set (from 0.314 to 0.322), it gave no statistically significant improvement on the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P05-1033.txt | Citing Article:  P08-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, formal SCFG show much better performance in the formally syntax-based translation framework (Chiang, 2005).</S> | Reference Offset:  ['30','31'] | Reference Text:  <S sid = 30 ssid = >A move to synchronous CFG can be seen as a move towards syntax-based MT; however, we make a distinction here between formally syntax-based and linguistically syntax-based MT.</S><S sid = 31 ssid = >A system like that of Yamada and Knight (2001) is both formally and linguistically syntax-based: formally because it uses synchronous CFG, linguistically because the structures it is defined over are (on the English side) informed by syntactic theory (via the Penn Treebank).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P05-1033.txt | Citing Article:  P08-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This is because the formal syntax is learned from phrases directly without relying on any linguistic theory (Chiang, 2005).</S> | Reference Offset:  ['30','32'] | Reference Text:  <S sid = 30 ssid = >A move to synchronous CFG can be seen as a move towards syntax-based MT; however, we make a distinction here between formally syntax-based and linguistically syntax-based MT.</S><S sid = 32 ssid = >Our system is formally syntaxbased in that it uses synchronous CFG, but not necessarily linguistically syntax-based, because it induces a grammar from a parallel text without relying on any linguistic annotations or assumptions; the result sometimes resembles a syntactician’s grammar but often does not.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P05-1033.txt | Citing Article:  D07-1049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Standard ngram language models assign probabilities to translation hypotheses in the target language, typically as smoothed trigram models (Chiang, 2005).</S> | Reference Offset:  ['49','79'] | Reference Text:  <S sid = 49 ssid = >The word penalty is easy; the language model is integrated by intersecting the English-side CFG with the language model, which is a weighted finitestate automaton.</S><S sid = 79 ssid = >The decoder is implemented in Python, an interpreted language, with C++ code from the SRI Language Modeling Toolkit (Stolcke, 2002).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P05-1033.txt | Citing Article:  N09-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Hiero (Chiang, 2005) is a hierarchical, string-to-string translation system.</S> | Reference Offset:  ['0','35'] | Reference Text:  <S sid = 0 ssid = >A Hierarchical Phrase-Based Model For Statistical Machine Translation</S><S sid = 35 ssid = >In this paper we describe the design and implementation of our hierarchical phrase-based model, and report on experiments that demonstrate that hierarchical phrases indeed improve translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P05-1033.txt | Citing Article:  W06-3119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Recent work in machine translation has evolved from the traditional word (Brown et al, 1993) and phrase based (Koehn et al, 2003a) models to include hierarchical phrase models (Chiang, 2005) and bilingual synchronous grammars (Melamed, 2004).</S> | Reference Offset:  ['0','12'] | Reference Text:  <S sid = 0 ssid = >A Hierarchical Phrase-Based Model For Statistical Machine Translation</S><S sid = 12 ssid = >Above the phrase level, these models typically have a simple distortion model that reorders phrases independently of their content (Och and Ney, 2004; Koehn et al., 2003), or not at all (Zens and Ney, 2004; Kumar et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P05-1033.txt | Citing Article:  W06-3119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Chiang, 2005) generates synchronous context free grammar (SynCFG) rules from an existing phrase translation table.</S> | Reference Offset:  ['2','29'] | Reference Text:  <S sid = 2 ssid = >The model is formally a synchronous context-free grammar but is learned from a bitext without any syntactic information.</S><S sid = 29 ssid = >These hierarchical phrase pairs are formally productions of a synchronous context-free grammar (defined below).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P05-1033.txt | Citing Article:  W06-3119.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While (Chiang, 2005) uses only two nonterminal symbols in his grammar, we introduce multiple syntactic categories, taking advantage of a target language parser for this information.</S> | Reference Offset:  ['40','73'] | Reference Text:  <S sid = 40 ssid = >Note that we have used only a single nonterminal symbol X instead of assigning syntactic categories to phrases.</S><S sid = 73 ssid = >The parser only operates on the French-side grammar; the English-side grammar affects parsing only by increasing the effective grammar size, because there may be multiple rules with the same French side but different English sides, and also because intersecting the language model with the English-side grammar introduces many states into the nonterminal alphabet, which are projected over to the French side.</S> | Discourse Facet:  NA | Annotator: Automatic


