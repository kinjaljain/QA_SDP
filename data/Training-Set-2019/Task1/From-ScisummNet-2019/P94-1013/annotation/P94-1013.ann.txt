Citance Number: 1 | Reference Article:  P94-1013.txt | Citing Article:  P97-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['67','216'] | Reference Text:  <S sid = 67 ssid = >The initial step is to take a histogram of a corpus with accents and diacritics retained, and compute a table of accent pattern distributions as follows: De-accented Form Accent Pattern % Number cesse cesse 53% 669 cesse 47% 593 cout mut 100% 330 couta cofita 100% 41 coute colite 53% 107 mite 47% 96 cote cote 69% 2645 cote 28% 1040 cote 3% 99 cote <1% 15 cotiere cOtiere 100% 296 For words with multiple accent patterns, steps 2-5 are applied.</S><S sid = 216 ssid = >Finally, although the case study of accent restoration in Spanish and French was chosen for its diversity of ambiguity types and plentiful source of data for fully automatic and objective evaluation, the algorithm solves a worthwhile problem in its own right with promising commercial potential.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P94-1013.txt | Citing Article:  W03-0417.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Until now, many methods have been proposed for this problem including winnow-based algorithms (Golding and Roth, 1999), differential grammars (Powers, 1998), transformation based learning (Mangu and Brill, 1997), decision lists (Yarowsky, 1994).</S> | Reference Offset:  ['6','101'] | Reference Text:  <S sid = 6 ssid = >This paper presents a general-purpose statistical decision procedure for lexical ambiguity resolution based on decision lists (Rivest, 1987).</S><S sid = 101 ssid = >Several smoothing methods have been explored here, including those discussed in (Gale et al., 1992).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P94-1013.txt | Citing Article:  P06-2065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In cases like (Yarowsky, 1995), unsupervised methods offer accuracy results than rival supervised methods (Yarowsky,1994) while requiring only a fraction of the data preparation effort.</S> | Reference Offset:  ['101','199'] | Reference Text:  <S sid = 101 ssid = >Several smoothing methods have been explored here, including those discussed in (Gale et al., 1992).</S><S sid = 199 ssid = >In particular, precision seems to be at least as good as that achieved with Bayesian methods applied to the same evidence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P94-1013.txt | Citing Article:  W02-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Decision lists (Rivest, 1987) have been used for a variety of natural language tasks, including accent restoration (Yarowsky, 1994), word sense disambiguation (Yarowsky, 2000), finding the past tense of English verbs (Mooney and Califf, 1995), and several other problems.</S> | Reference Offset:  ['18','61'] | Reference Text:  <S sid = 18 ssid = >Accent restoration is merely an instance of a closelyrelated class of problems including word-sense disambiguation, word choice selection in machine translation, homograph and homophone disambiguation, and capitalization restoration.</S><S sid = 61 ssid = >The formal model of decision lists was presented in (Rivest, 1987).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P94-1013.txt | Citing Article:  W02-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The standard algorithm for learning decision lists (Yarowsky, 1994) is very simple.</S> | Reference Offset:  ['0','143'] | Reference Text:  <S sid = 0 ssid = >Decision Lists For Lexical Ambiguity Resolution: Application To Accent Restoration In Spanish And French</S><S sid = 143 ssid = >Step 7: Using the Decision Lists Once these decision lists have been created, they may be used in real time to determine the accent pattern for ambiguous words in new contexts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P94-1013.txt | Citing Article:  W02-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky (1994) suggests two improvements to the standard algorithm.</S> | Reference Offset:  ['19','206'] | Reference Text:  <S sid = 19 ssid = >The given algorithm may be used to solve each of these problems, and has been applied without modification to the case of homograph disambiguation in speech synthesis (Sproat, Hirschberg and Yarowsky, 1992).</S><S sid = 206 ssid = >In a comparative study (Yarowsky, 1994), the decision list algorithm outperformed both an N-Gram tagger and Bayesian classifier primarily because it could effectively integrate a wider range of available evidence types than its competitors.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P94-1013.txt | Citing Article:  W02-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Accent restoration (Yarowsky, 1994), word sense disambiguation (Yarowsky, 2000), and other problems all fall into this framework, and typically use similar feature types.</S> | Reference Offset:  ['18','37'] | Reference Text:  <S sid = 18 ssid = >Accent restoration is merely an instance of a closelyrelated class of problems including word-sense disambiguation, word choice selection in machine translation, homograph and homophone disambiguation, and capitalization restoration.</S><S sid = 37 ssid = >The distribution of ambiguity types in French is similar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P94-1013.txt | Citing Article:  P02-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They include those using Naive Bayes (Gale et al 1992a), Decision List (Yarowsky 1994), Nearest Neighbor (Ng and Lee 1996), Transformation Based Learning (Mangu and Brill 1997), Neural Network (Towell and 1 In this paper, we take English-Chinese translation as example; it is a relatively easy process, however, to extend the discussions to translations between other language pairs.</S> | Reference Offset:  ['55','101'] | Reference Text:  <S sid = 55 ssid = >This was expanded upon by (Gale et al., 1992), and in a class-based variant by (Yarowsky, 1992).</S><S sid = 101 ssid = >Several smoothing methods have been explored here, including those discussed in (Gale et al., 1992).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P94-1013.txt | Citing Article:  A97-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky (1994) notes that conceptual spelling correction is part of a closely related class of problems which include word sense disambiguation, word choice selection in machine translation, and accent and capitalization restoration.</S> | Reference Offset:  ['18','46'] | Reference Text:  <S sid = 18 ssid = >Accent restoration is merely an instance of a closelyrelated class of problems including word-sense disambiguation, word choice selection in machine translation, homograph and homophone disambiguation, and capitalization restoration.</S><S sid = 46 ssid = >Thus while accent restoration may not be be the prototypical member of the class of lexical-ambiguity resolution problems, it is an especially useful one for describing and evaluating a proposed solution to this class of problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P94-1013.txt | Citing Article:  C04-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Lemmatization allows for more compact and generalizable data by clustering all inflected forms of an ambiguous word together, an effect already commented on by Yarowsky (1994).</S> | Reference Offset:  ['75','194'] | Reference Text:  <S sid = 75 ssid = >For example, if lemmatization procedures are available, collocational measures for morphological roots will tend to yield more succinct and generalizable evidence than measuring the distributions for each of the inflected forms.</S><S sid = 194 ssid = >The incorporation of word (and optionally part-of-speech) trigrams allows the modeling of many local syntactic constraints, while collocational evidence in a wider context allows for more semantic distinctions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P94-1013.txt | Citing Article:  C04-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As has already been noted by Yarowsky (1994), using lemmas helps to produce more concise and generic evidence than inflected forms.</S> | Reference Offset:  ['77','84'] | Reference Text:  <S sid = 77 ssid = >Note that it's not necessary to determine the actual parts-of-speech of words in context; using only the most likely part of speech or a set of all possibilities will produce adequate, if somewhat diluted, distributional evidence.</S><S sid = 84 ssid = >Use of a morphological analyzer (developed by Tzoukermann and Liberman (1990)) allowed distributional measures to be computed for associations of lemmas (morphological roots), improving generalization to different inflected forms not observed in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P94-1013.txt | Citing Article:  C02-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky (1994) defined a basic set of features that has been widely used (with some variations) by other WSD systems.</S> | Reference Offset:  ['66','85'] | Reference Text:  <S sid = 66 ssid = >Basic corpus analysis will indicate which is the most common pattern for each word, and may be used in conjunction with or independent of dictionaries and other lexical resources.</S><S sid = 85 ssid = >Also, a basic lexicon with possible parts of speech (augmented by the morphological analyzer) allowed adjacent part-of-speech sequences to be used as disambiguating evidence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P94-1013.txt | Citing Article:  C02-1112.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Despite their simplicity, Decision Lists (Dlist for short) as defined in Yarowsky (1994) have been shown to be very effective for WSD (Kilgarriff & Palmer, 2000).</S> | Reference Offset:  ['0','143'] | Reference Text:  <S sid = 0 ssid = >Decision Lists For Lexical Ambiguity Resolution: Application To Accent Restoration In Spanish And French</S><S sid = 143 ssid = >Step 7: Using the Decision Lists Once these decision lists have been created, they may be used in real time to determine the accent pattern for ambiguous words in new contexts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P94-1013.txt | Citing Article:  D07-1026.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In general, the strategy adopted to model syntagmatic relations in WSD is to provide bigrams and trigrams of collocated words as features to describe local contexts (Yarowsky, 1994).</S> | Reference Offset:  ['9','124'] | Reference Text:  <S sid = 9 ssid = >Perhaps surprisingly, this strategy appears to yield the same or even slightly better precision than the combination of evidence approach when trained on the same features.</S><S sid = 124 ssid = >If a bigram is unambiguous, probability distributions for dependent trigrams will not even be generated, since they will provide no additional information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P94-1013.txt | Citing Article:  N01-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['67','216'] | Reference Text:  <S sid = 67 ssid = >The initial step is to take a histogram of a corpus with accents and diacritics retained, and compute a table of accent pattern distributions as follows: De-accented Form Accent Pattern % Number cesse cesse 53% 669 cesse 47% 593 cout mut 100% 330 couta cofita 100% 41 coute colite 53% 107 mite 47% 96 cote cote 69% 2645 cote 28% 1040 cote 3% 99 cote <1% 15 cotiere cOtiere 100% 296 For words with multiple accent patterns, steps 2-5 are applied.</S><S sid = 216 ssid = >Finally, although the case study of accent restoration in Spanish and French was chosen for its diversity of ambiguity types and plentiful source of data for fully automatic and objective evaluation, the algorithm solves a worthwhile problem in its own right with promising commercial potential.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P94-1013.txt | Citing Article:  P06-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky (1994 and 1995), Mihalcea and Moldovan (2000), and Mihalcea (2002) have made further research to obtain large corpus of higher quality from an initial seed corpus.</S> | Reference Offset:  ['176','186'] | Reference Text:  <S sid = 176 ssid = >Thus the following results must be interpreted as agreement rates with the corpus accent pattern; the true percent correct may be several percentage points higher.</S><S sid = 186 ssid = >It should be emphasized that the actual percent correct is higher than these agreement figures, due to errors in the original corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P94-1013.txt | Citing Article:  W06-2608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In general, the strategy adopted to model syntagmatic relations is to provide bigrams and trigrams of collocated words as features to describe local contexts (Yarowsky, 1994), and each word is regarded as a different instance to classify.</S> | Reference Offset:  ['62','124'] | Reference Text:  <S sid = 62 ssid = >I have restricted feature conjuncts to a much narrower complexity than allowed in the original model— namely to word and class trigrams.</S><S sid = 124 ssid = >If a bigram is unambiguous, probability distributions for dependent trigrams will not even be generated, since they will provide no additional information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P94-1013.txt | Citing Article:  W06-2608.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As baseline, we report the result of a standard approach consisting on explicit bigrams and trigrams of words and POS tags around the words to be disambiguated (Yarowsky, 1994).</S> | Reference Offset:  ['90','187'] | Reference Text:  <S sid = 90 ssid = >Such words were given a part-of-speech tag consisting of the union of the possibilities (eg ADJECTIVE-NOUN), as in Kupiec (1989).</S><S sid = 187 ssid = >The relatively low agreement rate on words with accented i's (1) is a result of this.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P94-1013.txt | Citing Article:  P01-1005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The more recent set of techniques includes multiplicative weight update algorithms (Golding and Roth, 1998), latent semantic analysis (Jones and Martin, 1997), transformation-based learning (Mangu and Brill, 1997), differential grammars (Powers, 1997), decision lists (Yarowsky, 1994), and a variety of Bayesian classifiers (Gale et al, 1993, Golding, 1995, Golding and Schabes, 1996).</S> | Reference Offset:  ['55','153'] | Reference Text:  <S sid = 55 ssid = >This was expanded upon by (Gale et al., 1992), and in a class-based variant by (Yarowsky, 1992).</S><S sid = 153 ssid = >This is done by Bayesian classifiers, neural nets, IR-based classifiers and N-gram part-of-speech taggers.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P94-1013.txt | Citing Article:  C04-1130.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yarowsky (1994) argued the optimal value is sensitive to the type of ambiguity.</S> | Reference Offset:  ['97','163'] | Reference Text:  <S sid = 97 ssid = >Sorting by this value will list the strongest and most reliable evidence first6.</S><S sid = 163 ssid = >Thus for this type of ambiguity resolution, there is no apparent detriment, and some apparent performance gain, from usit indicates the most likely accent pattern in cases where nothing matches.</S> | Discourse Facet:  NA | Annotator: Automatic


