Citance Number: 1 | Reference Article:  W03-1730.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Note that the top participant of CTBc (Zhang et al, 2003) used additional named entity knowledge/data in their word segmenter).</S> | Reference Offset:  ['30','60'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 60 ssid = >Except for some named entity corpus, we could not get any more sources related to CTB standard.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-1730.txt | Citing Article:  P14-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ICTCLAS Segmenter: this model, trained by Zhang et al (2003), is a hierarchicalHMM segmenter that incorporates parts-of speech (POS) information into the probability models and generates multiple HMM mod els for solving segmentation ambiguities.</S> | Reference Offset:  ['30','49'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 49 ssid = >According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-1730.txt | Citing Article:  W10-3703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging.</S> | Reference Offset:  ['11','62'] | Reference Text:  <S sid = 11 ssid = >ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.</S><S sid = 62 ssid = >Before the bakeoff, BIG5-coded word segmentation has never been researched in our institute.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-1730.txt | Citing Article:  P13-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Then we apply a hierarchical Hidden Markov Model (HMM) based Chinese lexical analyzer ICTCLAS (Zhang et al, 2003) to extract named entities, noun phrases and events.</S> | Reference Offset:  ['0','49'] | Reference Text:  <S sid = 0 ssid = >HHMM-Based Chinese Lexical Analyzer ICTCLAS</S><S sid = 49 ssid = >According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-1730.txt | Citing Article:  W08-0335.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >HMMsegmenter (Zhang et al, 2003) that uses the specifications of PKU.</S> | Reference Offset:  ['30','58'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 58 ssid = >Actually, PKU standard is very different from CTB one though they seemed similar.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-1730.txt | Citing Article:  W10-3708.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Most word-based segmenters in Chinese IR are either rule-based models, which rely on a lexicon, or statistical-based models, which are trained on manually segmented corpora (Zhang et al,2003).</S> | Reference Offset:  ['0','17'] | Reference Text:  <S sid = 0 ssid = >HHMM-Based Chinese Lexical Analyzer ICTCLAS</S><S sid = 17 ssid = >2 HHMM-based Chinese lexical analysis</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-1730.txt | Citing Article:  W10-3708.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Its segmentation model is a 3The query set and relevance judgements are available at http: //www.cs.ualberta.ca/ ?yx2/research.html 59 class-based hidden Markov model (HMM) model (Zhang et al, 2003).</S> | Reference Offset:  ['49','72'] | Reference Text:  <S sid = 49 ssid = >According to named entities in the given corpus, we could train both class-based segmentation HMM and rolebased HMM model for unknown word recognition.</S><S sid = 72 ssid = >As is shown in Table 1, It could also be concluded that class-based segmentation HMM is effective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-1730.txt | Citing Article:  P06-2123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (Max Ent) (Xue and Shen, 2003), support vector machine.</S> | Reference Offset:  ['26','72'] | Reference Text:  <S sid = 26 ssid = >In this HMM, the original symbol is observation while the atom is state.</S><S sid = 72 ssid = >As is shown in Table 1, It could also be concluded that class-based segmentation HMM is effective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-1730.txt | Citing Article:  P06-2056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Decrease in H (XjX n) for Chinese characters when n is increased software such as (Zhang et al, 2003) whose performance is also high.</S> | Reference Offset:  ['4','30'] | Reference Text:  <S sid = 4 ssid = >Evaluation on ICTCLAS shows that its performance is competitive.</S><S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-1730.txt | Citing Article:  W10-4125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Hence the need for automatic word segmentation systems (Zhang et al, 2003).</S> | Reference Offset:  ['30','66'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 66 ssid = >Then, the Compared with other systems, ICTCLAS especially GB-coded version is competitive.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-1730.txt | Citing Article:  I08-4033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Segmentation performance has been improved significantly, from the earliest maximal match (dictionary-based) approaches to HMM-based (Zhang et al, 2003) approaches and recent state-of-the-art machine learning approaches such as maximum entropy (MaxEnt) (Xue and Shen, 2003), support vector machine (SVM) (Kudo and Matsumoto, 2001), conditional random fields (CRF) (Peng and McCallum, 2004), and minimum error rate training (Gao et al, 2004).</S> | Reference Offset:  ['26','30'] | Reference Text:  <S sid = 26 ssid = >In this HMM, the original symbol is observation while the atom is state.</S><S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-1730.txt | Citing Article:  I05-3028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Then for every path of the N+1paths4 (N best paths and the atom path), we perform a process of Roles Tagging with HMM model (Zhang et al 2003).</S> | Reference Offset:  ['23','28'] | Reference Text:  <S sid = 23 ssid = >Any word is made up of an atom or more.</S><S sid = 28 ssid = >POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-1730.txt | Citing Article:  P05-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Chinese sentences in both the development and test corpus are segmented and POS tagged by ICTCLAS (Zhang et al, 2003).</S> | Reference Offset:  ['8','74'] | Reference Text:  <S sid = 8 ssid = >Through the first bakeoff, we could learn more about the development in Chinese word segmentation and become more confident on our HHMM-based approach.</S><S sid = 74 ssid = >Through the first bakeoff, we have learn more about the development in Chinese word segmentation and become more confident on our HHMMbased approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-1730.txt | Citing Article:  E09-1063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Both ICTCLAS and Stanford segmenters utilise machine learning techniques, with Hidden Markov Models for ICT (Zhang et al, 2003) and conditional random fields for the Stanford segmenter (Tseng et al, 2005).</S> | Reference Offset:  ['11','30'] | Reference Text:  <S sid = 11 ssid = >ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.</S><S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-1730.txt | Citing Article:  P14-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this work, we resort to ICTCLAS (Zhang et al, 2003), a widely used tool in the literature.</S> | Reference Offset:  ['0','30'] | Reference Text:  <S sid = 0 ssid = >HHMM-Based Chinese Lexical Analyzer ICTCLAS</S><S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-1730.txt | Citing Article:  P14-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The posts were then part-of speech tagged using a Chinese word segmentation tool named ICTCLAS (Zhang et al, 2003).</S> | Reference Offset:  ['30','43'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 43 ssid = >Hence the best choice W# of word segmentation is easy to find using Djikstra's algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-1730.txt | Citing Article:  P13-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Their system only does IWR, using the CWS and POS tagging output of the ICTCLAS segmenter (Zhang et al, 2003) as in put.</S> | Reference Offset:  ['28','30'] | Reference Text:  <S sid = 28 ssid = >POS tagging and role tagging using Viterbi are also skipped because they are classic application of HMM.</S><S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-1730.txt | Citing Article:  I08-7003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['20','81'] | Reference Text:  <S sid = 20 ssid = >Atom segmentation, the bottom level of HHMM, is an initial step.</S><S sid = 81 ssid = >We also thank Richard Sproat, Qing Ma, Fei Xia and other SIGHAN colleagues for their elaborate organization and enthusiastic help in the First International Chinese Word Segmentation Bakeoff.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-1730.txt | Citing Article:  I08-7003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >ICTCLAS is developed by Chinese Academy of Science, the precision of which is 97.58% on tagging general words (Huaping Zhang et al, 2003).</S> | Reference Offset:  ['11','73'] | Reference Text:  <S sid = 11 ssid = >ICT (Institute of Computing Technology, Chinese Academy of Sciences) participated the First International Chinese Word Segmentation Bakeoff.</S><S sid = 73 ssid = >Excepted for CTB, IV Recall is over 97%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-1730.txt | Citing Article:  P14-2139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The Chinese word segmentation tool is ICTCLAS (Zhang et al 2003) and Google Translator is the MT for the source language.</S> | Reference Offset:  ['30','42'] | Reference Text:  <S sid = 30 ssid = >Our previous papers (Zhang et al. 2003) gave more Given a word wi, classc i is defined in Figure 2.</S><S sid = 42 ssid = >After transformation through class-based HMM, word segmentation becomes single-source shortest paths problem.</S> | Discourse Facet:  NA | Annotator: Automatic


