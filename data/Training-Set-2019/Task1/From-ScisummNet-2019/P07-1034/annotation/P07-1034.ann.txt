Citance Number: 1 | Reference Article:  P07-1034.txt | Citing Article:  D08-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For evaluation we selected two domain adaptation datasets: spam (Jiang and Zhai, 2007) and sentiment (Blitzer et al, 2007).</S> | Reference Offset:  ['10','18'] | Reference Text:  <S sid = 10 ssid = >Following (Blitzer et al., 2006), we call the first the source domain, and the second the target domain.</S><S sid = 18 ssid = >Recently there have been some studies addressing domain adaptation from different perspectives (Roark and Bacchiani, 2003; Chelba and Acero, 2004; Florian et al., 2004; Daum´e III and Marcu, 2006; Blitzer et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1034.txt | Citing Article:  D08-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In a complimentary approach, Jiang and Zhai (2007) weighed training instances based on their similarity to unlabeled target domain data.</S> | Reference Offset:  ['153','184'] | Reference Text:  <S sid = 153 ssid = >However, based on our theoretical analysis, we can expect the labeled target instances to be more representative of the target domain than the source instances.</S><S sid = 184 ssid = >Indeed, all the above methods do not make use of the unlabeled instances in the target domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1034.txt | Citing Article:  D12-1068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >Our goal is to obtain a good estimate of θt that is optimized according to the target domain distribution pt(x, y).</S><S sid = 197 ssid = >We thank the anonymous reviewers for their valuable comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We show that, on the NER task, DAB outperforms supervised, transductive and standard bootstrapping algorithms, as well as a bootstrapping variant, called balanced bootstrapping (Jiang and Zhai, 2007), that has recently been proposed for domain adaptation.</S> | Reference Offset:  ['170','172'] | Reference Text:  <S sid = 170 ssid = >We call this second method the balanced bootstrapping method.</S><S sid = 172 ssid = >As we can see, while bootstrapping can generally improve the performance over the baseline where no unlabeled data is used, the balanced bootstrapping method performed slightly better than the standard bootstrapping method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Jiang and Zhai (2007) proposed an instance re-weighting framework that handles both the [S+T+] and [S+T] settings.</S> | Reference Offset:  ['4','96'] | Reference Text:  <S sid = 4 ssid = >We then propose a general instance weighting framework for domain adaptation.</S><S sid = 96 ssid = >We now formally define our instance weighting framework.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Jiang and Zhai (2007) recently proposed an instance re-weighting framework to take domain shift into account.</S> | Reference Offset:  ['4','32'] | Reference Text:  <S sid = 4 ssid = >We then propose a general instance weighting framework for domain adaptation.</S><S sid = 32 ssid = >In Section 3, we then propose a general instance weighting framework for domain adaptation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >Our goal is to obtain a good estimate of θt that is optimized according to the target domain distribution pt(x, y).</S><S sid = 197 ssid = >We thank the anonymous reviewers for their valuable comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Balanced bootstrapping has been shown to be more effective for domain adaptation than standard bootstrapping (Jiang and Zhai, 2007) for named entity classification on a subset of the dataset used here.</S> | Reference Offset:  ['170','172'] | Reference Text:  <S sid = 170 ssid = >We call this second method the balanced bootstrapping method.</S><S sid = 172 ssid = >As we can see, while bootstrapping can generally improve the performance over the baseline where no unlabeled data is used, the balanced bootstrapping method performed slightly better than the standard bootstrapping method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1034.txt | Citing Article:  D09-1158.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >It also outperforms balanced bootstrapping, an approach designed for domain adaptation (Jiang and Zhai, 2007).</S> | Reference Offset:  ['170','172'] | Reference Text:  <S sid = 170 ssid = >We call this second method the balanced bootstrapping method.</S><S sid = 172 ssid = >As we can see, while bootstrapping can generally improve the performance over the baseline where no unlabeled data is used, the balanced bootstrapping method performed slightly better than the standard bootstrapping method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1034.txt | Citing Article:  P11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This motivated the popular domain adaptation solution based on instance weighting, which assigns larger weights to those transferable instances so that the model trained on the source domain can adapt more effectively to the target domain (Jiang and Zhai, 2007).</S> | Reference Offset:  ['0','149'] | Reference Text:  <S sid = 0 ssid = >Instance Weighting for Domain Adaptation in NLP</S><S sid = 149 ssid = >A possible reason for this is that the set of labeled target instances we use is a biased sample from the target domain, and therefore the model trained on these instances is not always a good predictor of “misleading” source instances.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1034.txt | Citing Article:  P11-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Jiang and Zhai, 2007) used a small number of labeled data from target domain to weight source instances.</S> | Reference Offset:  ['133','141'] | Reference Text:  <S sid = 133 ssid = >In the first setting, we assume there are a small number of labeled target instances available.</S><S sid = 141 ssid = >In the first set of experiments, we gradually remove “misleading” labeled instances from the source domain, using the small number of labeled target instances we have.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1034.txt | Citing Article:  D10-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Among the previously mentioned work, (Jiang and Zhai, 2007) is a special case given that it discusses both aspects of adaptation algorithms.</S> | Reference Offset:  ['20','57'] | Reference Text:  <S sid = 20 ssid = >A detailed discussion on related work is given in Section 5.</S><S sid = 57 ssid = >Therefore, in this case, we still need domain adaptation, which we refer to as instance adaptation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1034.txt | Citing Article:  D10-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This highly effective approach is not directly applicable to the multinomial models used for core SMT components, which have no natural method for combining split features, so we rely on an instance-weighting approach (Jiangand Zhai, 2007) to down weight domain-specific examples in OUT.</S> | Reference Offset:  ['5','25'] | Reference Text:  <S sid = 5 ssid = >Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective.</S><S sid = 25 ssid = >Based on this analysis, we propose a general instance weighting method for domain adaptation, which can be regarded as a generalization of an existing approach to semi-supervised learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1034.txt | Citing Article:  D10-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We have already mentioned the closely related work by Matsoukas et al (2009) on discriminative corpus weighting, and Jiang and Zhai (2007) on (non discriminative) instance weighting.</S> | Reference Offset:  ['0','42'] | Reference Text:  <S sid = 0 ssid = >Instance Weighting for Domain Adaptation in NLP</S><S sid = 42 ssid = >In discriminative models, we are only concerned with p(y|x).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1034.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Blitzer et al (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution.</S> | Reference Offset:  ['10','186'] | Reference Text:  <S sid = 10 ssid = >Following (Blitzer et al., 2006), we call the first the source domain, and the second the target domain.</S><S sid = 186 ssid = >Blitzer et al. (2006) propose a domain adaptation method that uses the unlabeled target instances to infer a good feature representation, which can be regarded as weighting the features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1034.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The maintainer of the system may be notified that performance is suffering, labels can be obtained for a sample of instances from the stream for retraining, or large volumes of unlabeled instances can be used for instance reweighting (Jiang and Zhai, 2007).</S> | Reference Offset:  ['136','162'] | Reference Text:  <S sid = 136 ssid = >For spam filtering, we used 200 labeled target instances and 1800 unlabeled target instances.</S><S sid = 162 ssid = >Further removing source instances would push the emphasis more on the set of labeled target instances, which is only a biased sample of the whole target domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1034.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >Our goal is to obtain a good estimate of θt that is optimized according to the target domain distribution pt(x, y).</S><S sid = 197 ssid = >We thank the anonymous reviewers for their valuable comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1034.txt | Citing Article:  P12-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Jiang and Zhai (2007) introduce a general instance weighting framework for model adaptation.</S> | Reference Offset:  ['4','32'] | Reference Text:  <S sid = 4 ssid = >We then propose a general instance weighting framework for domain adaptation.</S><S sid = 32 ssid = >In Section 3, we then propose a general instance weighting framework for domain adaptation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1034.txt | Citing Article:  P09-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >Our goal is to obtain a good estimate of θt that is optimized according to the target domain distribution pt(x, y).</S><S sid = 197 ssid = >We thank the anonymous reviewers for their valuable comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1034.txt | Citing Article:  P09-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['73','197'] | Reference Text:  <S sid = 73 ssid = >Our goal is to obtain a good estimate of θt that is optimized according to the target domain distribution pt(x, y).</S><S sid = 197 ssid = >We thank the anonymous reviewers for their valuable comments.</S> | Discourse Facet:  NA | Annotator: Automatic


