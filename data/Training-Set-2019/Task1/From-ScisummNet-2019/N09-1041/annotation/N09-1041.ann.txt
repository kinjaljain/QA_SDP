Citance Number: 1 | Reference Article:  N09-1041.txt | Citing Article:  E12-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In TOPICSUM (Haghighi and Vanderwende, 2009), each word is generated by a single topic which can be a corpus-wide background distribution over common words, a distribution of document-specific words or a distribution of the core content of a given cluster.</S> | Reference Offset:  ['35','68'] | Reference Text:  <S sid = 35 ssid = >The KLSUM algorithm introduces a criterion for selecting a summary S given document collection D, where PS is the empirical unigram distribution of the candidate summary S and KL(P Q) represents the Kullback-Lieber (KL) divergence given by divergence between the true distribution P (here the document set unigram distribution) and the approximating distribution Q (the summary distribution).</S><S sid = 68 ssid = >As with TOPICSUM, each sentence has a distribution ψT over topics (BACKGROUND, DOCSPECIFIC, CONTENT).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N09-1041.txt | Citing Article:  E12-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Models that use more structure in the representation of documents have also been proposed for generating more coherent and less redundant summaries, such as HIERSUM (Haghighi and Vanderwende, 2009) and TTM (Celikyilmaz and Hakkani-Tur, 2011).</S> | Reference Offset:  ['2','128'] | Reference Text:  <S sid = 2 ssid = >Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.</S><S sid = 128 ssid = >On the whole, HIERSUM summaries appear to be significantly less redundant than PYTHY and moderately less redundant than SUMBASIC.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N09-1041.txt | Citing Article:  E12-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In our experiments, we follow the same approach as in (Haghighi and Vanderwende, 2009) by greedily adding sentences to a summary so long as they decrease KL divergence.</S> | Reference Offset:  ['35','85'] | Reference Text:  <S sid = 35 ssid = >The KLSUM algorithm introduces a criterion for selecting a summary S given document collection D, where PS is the empirical unigram distribution of the candidate summary S and KL(P Q) represents the Kullback-Lieber (KL) divergence given by divergence between the true distribution P (here the document set unigram distribution) and the approximating distribution Q (the summary distribution).</S><S sid = 85 ssid = >Since globally optimizing the KLSUM criterion in equation (equation (2)) is exponential in the total number of sentences in a document collection, we 21We choose σ = 0.75 in our experiments. opted instead for a simple approximation where sentences are greedily added to a summary so long as they decrease KL-divergence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N09-1041.txt | Citing Article:  E12-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Once this is done, one of the learned collections can be used to generate the summary that best approximates this collection, using the greedy algorithm described by Haghighiand Vanderwende (2009).</S> | Reference Offset:  ['26','78'] | Reference Text:  <S sid = 26 ssid = >The SUMBASIC algorithm, introduced in Nenkova and Vanderwende (2005), is a simple effective procedure for multi-document extractive summarization.</S><S sid = 78 ssid = >Each specific content distribution 0Ci is meant to model topics which are used in several documents but tend to be used in concentrated locations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N09-1041.txt | Citing Article:  E12-1022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The original implementations of SUMBASIC (Nenkova and Vanderwende, 2005) and TOPICSUM (Haghighiand Vanderwende, 2009) were defined over single words (unigrams).</S> | Reference Offset:  ['2','26'] | Reference Text:  <S sid = 2 ssid = >Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.</S><S sid = 26 ssid = >The SUMBASIC algorithm, introduced in Nenkova and Vanderwende (2005), is a simple effective procedure for multi-document extractive summarization.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N09-1041.txt | Citing Article:  P12-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This model is very similar to the one used by Haghighi and Vanderwende (2009) in the context of text summarization.</S> | Reference Offset:  ['56','78'] | Reference Text:  <S sid = 56 ssid = >Daum´e III and Marcu (2006) explore a topic model similar to ours for query-focused multidocument summarization.16 Crucially however, Daum´e III and Marcu (2006) selected sentences with the highest expected number of CONTENT words.17 We found that in our model using this extraction criterion yielded 5.3 R-2 without stop words, significantly underperforming our TOPICSUM model.</S><S sid = 78 ssid = >Each specific content distribution 0Ci is meant to model topics which are used in several documents but tend to be used in concentrated locations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N09-1041.txt | Citing Article:  P11-2086.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Effective ways of representing content and ensuring coverage are the subject of ongoing research in the field (e.g., Gillick et al 2009, Haghighi and Vanderwende 2009).</S> | Reference Offset:  ['26','134'] | Reference Text:  <S sid = 26 ssid = >The SUMBASIC algorithm, introduced in Nenkova and Vanderwende (2005), is a simple effective procedure for multi-document extractive summarization.</S><S sid = 134 ssid = >As Leuski et al. (2003) and Branavan et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N09-1041.txt | Citing Article:  D11-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The most relevant work is by (Haghighi and Vanderwende, 2009) on exploring content models for multi-document summarization.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Exploring Content Models for Multi-Document Summarization</S><S sid = 1 ssid = >We present an exploration of generative probabilistic models for multi-document summarization.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N09-1041.txt | Citing Article:  D11-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Entity-aspect model is similar with 'HIERSUM' content model proposed by Haghighi and Vanderwende (2009).</S> | Reference Offset:  ['3','56'] | Reference Text:  <S sid = 3 ssid = >Our model, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.</S><S sid = 56 ssid = >Daum´e III and Marcu (2006) explore a topic model similar to ours for query-focused multidocument summarization.16 Crucially however, Daum´e III and Marcu (2006) selected sentences with the highest expected number of CONTENT words.17 We found that in our model using this extraction criterion yielded 5.3 R-2 without stop words, significantly underperforming our TOPICSUM model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N09-1041.txt | Citing Article:  D11-1105.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this baseline, we directly compare our method with "HIERSUM" proposed by (Haghighi and Vanderwende, 2009).</S> | Reference Offset:  ['9','126'] | Reference Text:  <S sid = 9 ssid = >However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.</S><S sid = 126 ssid = >While it is difficult to qualitatively compare one summarization system over another, we can broadly characterize HIERSUM summaries compared to some of the other systems discussed.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N09-1041.txt | Citing Article:  N12-1018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One could also think of this as a version of the KLSum summarization system (Haghighi and Vanderwende, 2009) that stops after one sentence.</S> | Reference Offset:  ['40','87'] | Reference Text:  <S sid = 40 ssid = >It is worth noting however that KLSUM’s performance matches SUMFOCUS (Vanderwende et al., 2007), the highest R-2 performing system at DUC 2006.</S><S sid = 87 ssid = >All summary sentence ordering was determined as follows: each sentence in the proposed summary was assigned a number in [0, 1] reflecting its relative sentence position in its source document, and sorted by this quantity.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N09-1041.txt | Citing Article:  W11-1605.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In more recent work, Haghighi and Vanderwende (2009) built a summarization system based on topic models, where both topics at general document level as well as those at specific subtopic levels were learnt.</S> | Reference Offset:  ['0','10'] | Reference Text:  <S sid = 0 ssid = >Exploring Content Models for Multi-Document Summarization</S><S sid = 10 ssid = >In this work we examine a series of content models for multi-document summarization and argue that LDA-style probabilistic topic models (Blei et al., 2003) can offer state-of-the-art summarization quality as measured by automatic metrics (see section 5.1) and manual user evaluation (see section 5.2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N09-1041.txt | Citing Article:  N10-1012.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Such methods have been successfully applied to a myriad of tasks including word sense discrimination (Brody and Lapata, 2009), document summarisation (Haghighi and Vanderwende, 2009), areal linguistic analysis (Daume III, 2009) and text segmentation (Sun et al, 2008).</S> | Reference Offset:  ['7','134'] | Reference Text:  <S sid = 7 ssid = >In the common Document Understanding Conference (DUC) formulation of the task, a system takes as input a document set as well as a short description of desired summary focus and outputs a word length limited summary.1 To avoid the problem of generating cogent sentences, many systems opt for an extractive approach, selecting sentences from the document set which best reflect its core content.2 There are several approaches to modeling document content: simple word frequency-based methods (Luhn, 1958; Nenkova and Vanderwende, 2005), graph-based approaches (Radev, 2004; Wan and Yang, 2006), as well as more linguistically motivated techniques (Mckeown et al., 1999; Leskovec et al., 2005; Harabagiu et al., 2007).</S><S sid = 134 ssid = >As Leuski et al. (2003) and Branavan et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N09-1041.txt | Citing Article:  P11-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The following models are used as benchmark: (i) PYTHY (Toutanova et al, 2007): Utilizes human generated summaries to train a sentence ranking system using a classifier model; (ii) HIERSUM (Haghighi and Vanderwende, 2009): Based on hierarchical topic models.</S> | Reference Offset:  ['3','97'] | Reference Text:  <S sid = 3 ssid = >Our model, utilizes a hierarchical LDA-style model (Blei et al., 2004) to represent content specificity as a hierarchy of topic vocabulary distributions.</S><S sid = 97 ssid = >PYTHY uses humangenerated summaries in order to train a sentence ranking system which discriminatively maximizes ROUGE scores.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N09-1041.txt | Citing Article:  W11-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi and Vanderwende (2009) demonstrated that these models can improve the quality of generic multi-document summaries over simpler surface models.</S> | Reference Offset:  ['9','138'] | Reference Text:  <S sid = 9 ssid = >However, little has been done to directly compare the benefit of complex content models to simpler surface ones for generic multi-document summarization.</S><S sid = 138 ssid = >In this paper we have presented an exploration of content models for multi-document summarization and demonstrated that the use of structured topic models can benefit summarization quality as measured by automatic and manual metrics.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N09-1041.txt | Citing Article:  W11-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We re-implement the HIERSUM system from Haghighi and Vanderwende (2009), and show that using our objective dramatically improves the content of extracted summaries.</S> | Reference Offset:  ['13','94'] | Reference Text:  <S sid = 13 ssid = >The resulting model, HIERSUM (see section 3.4), can produce general summaries as well as summaries for any of the learned sub-topics.</S><S sid = 94 ssid = >We primarily evaluate the HIERSUM model, extracting a single summary from the general content distribution using the KLSUM criterion (see section 3.2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N09-1041.txt | Citing Article:  W11-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This idea was first presented by Daume and Marcu (2006) for their BAYESUM system for query-focused summarization, and later adapted for non-query summarization in the TOPICSUM system by Haghighi and Vanderwende (2009).</S> | Reference Offset:  ['56','133'] | Reference Text:  <S sid = 56 ssid = >Daum´e III and Marcu (2006) explore a topic model similar to ours for query-focused multidocument summarization.16 Crucially however, Daum´e III and Marcu (2006) selected sentences with the highest expected number of CONTENT words.17 We found that in our model using this extraction criterion yielded 5.3 R-2 without stop words, significantly underperforming our TOPICSUM model.</S><S sid = 133 ssid = >While many variants of the general summarization task have been proposed which utilize such information (Vanderwende et al., 2007; Nastase, 2008), this presupposes that a user knows enough of the content of a document collection in order to propose a query.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N09-1041.txt | Citing Article:  W11-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Haghighi and Vanderwende (2009) presented a version of HIERSUM that models documents as a bag of bigrams, and provides results comparable to PYTHY.</S> | Reference Offset:  ['104','108'] | Reference Text:  <S sid = 104 ssid = >In order to put HIERSUM and PYTHY on equalfooting with respect to R-2, we instead ran HIERSUM with each sentence consisting of a bag of bigrams instead of unigrams.24 All the details of the model remain the same.</S><S sid = 108 ssid = >We conclude that both PYTHY variants and HIERSUM bigram are comparable with respect to ROUGE performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N09-1041.txt | Citing Article:  W11-0507.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These are based on the manual evaluation questions from DUC 2007, and are the same questions asked in Haghighi and Vanderwende (2009).</S> | Reference Offset:  ['115','123'] | Reference Text:  <S sid = 115 ssid = >Users were presented with 4 questions drawn from the DUC manual evaluation guidelines:26 (1) Overall quality: Which summary was better overall?</S><S sid = 123 ssid = >As seen in table 5.2, HIERSUM outperforms PYTHY under all questions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N09-1041.txt | Citing Article:  D10-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Such models also provide a framework for adding additional structure to a summarization model (Haghighi and Vanderwende, 2009).</S> | Reference Offset:  ['2','11'] | Reference Text:  <S sid = 2 ssid = >Beginning with a simple word frequency based model (Nenkova and Vanderwende, 2005), we construct a sequence of models each injecting more structure into the representation of document set content and exhibiting ROUGE gains along the way.</S><S sid = 11 ssid = >We also contend that they provide convenient building blocks for adding more structure to a summarization model.</S> | Discourse Facet:  NA | Annotator: Automatic


