Citance Number: 1 | Reference Article:  W03-1017.txt | Citing Article:  H05-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 146 ssid = >Any opinions, findings, or recommendations are those of the authors and do not necessarily reflect ARDA’s views.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-1017.txt | Citing Article:  P09-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Yu and Hatzivassiloglou, 2003) discusses a necessary component for an opinion question answering system: separating opinions from fact at both the document and sentence level.</S> | Reference Offset:  ['0','2'] | Reference Text:  <S sid = 0 ssid = >Towards Answering Opinion Questions: Separating Facts From Opinions And Identifying The Polarity Of Opinion Sentences</S><S sid = 2 ssid = >In this paper, we discuss a necessary component for an opinion question answering system: separating opinions from fact, at both the document and sentence level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-1017.txt | Citing Article:  P09-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We extract several types of features, including a set of pattern features, and then design a classifier to identify sentiment polarity for each question (similar as (Yuand Hatzivassiloglou, 2003)).</S> | Reference Offset:  ['94','122'] | Reference Text:  <S sid = 94 ssid = >We mapped article types News and Business to facts, and article types Editorial and Letter to the Editor to opinions.</S><S sid = 122 ssid = >In general, the additional features helped the classifier; the best performance is achieved when words, bigrams, trigrams, part-of-speech, and polarity are included in the feature set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-1017.txt | Citing Article:  W12-3705.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our work is similar to Yu and Hatzivassiloglou (2003) and Wiebe et al (1999) in that we use lexical and POS features.</S> | Reference Offset:  ['23','24'] | Reference Text:  <S sid = 23 ssid = >Much of the earlier research in automated opinion detection has been performed by Wiebe and colleagues (Bruce and Wiebe, 1999; Wiebe et al., 1999; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2002), who proposed methods for discriminating between subjective and objective text at the document, sentence, and phrase levels.</S><S sid = 24 ssid = >Bruce and Wiebe (1999) annotated 1,001 sentences as subjective or objective, and Wiebe et al. (1999) described a sentence-level Naive Bayes classifier using as features the presence or absence of particular syntactic classes (pronouns, adjectives, cardinal numbers, modal verbs, adverbs), punctuation, and sentence position.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-1017.txt | Citing Article:  P06-2059.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Turney proposed the unsupervised method for sentiment classification (Turney, 2002), and similar method is utilized by many other researchers (Yu and Hatzivassiloglou, 2003).</S> | Reference Offset:  ['36','72'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 72 ssid = >We first discuss how such words are automatically found by our system, and then describe the method by which we aggregate this information across the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-1017.txt | Citing Article:  D07-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yu and Hatzivassiloglou (2003) identified the polarity of opinion sentences using semantically oriented words.</S> | Reference Offset:  ['57','73'] | Reference Text:  <S sid = 57 ssid = >In addition, the presence of semantically oriented (positive and negative) words in a sentence is an indicator that the sentence is subjective (Hatzivassiloglou and Wiebe, 2000).</S><S sid = 73 ssid = >To determine which words are semantically oriented, in what direction, and the strength of their orientation, we measured their co-occurrence with words from a known seed set of semantically oriented words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-1017.txt | Citing Article:  D09-1140.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yu and Hatzivassiloglou (2003) addressed three challenges in the news article domain: discriminating between objective documents and subjective documents such as editorials, detecting subjectivity at the sentence level, and determining polarity at the sentence level.</S> | Reference Offset:  ['3','50'] | Reference Text:  <S sid = 3 ssid = >We present a Bayesian classifier for discriminating between documents with a preponderance of opinions such as editorials from regular news stories, and describe three unsupervised, statistical techniques for the significantly harder task of detecting opinions at the sentence level.</S><S sid = 50 ssid = >To measure the overall similarity of a sentence to the opinion or fact documents, we first select the documents that are on the same topic as the sentence in question.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-1017.txt | Citing Article:  C10-2057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pang and Riloff (2005) and Yu and Hatzivassiloglou (2003) trained sentence-level subjectivity classifiers and proved that performing sentiment analysis targeting selected subjective sentences only gets higher results.</S> | Reference Offset:  ['34','57'] | Reference Text:  <S sid = 34 ssid = >Our sentence-level classifiers introduce additional criteria for detecting subjective material (opinions), including methods based on sentence similarity within a topic and an approach that relies on multiple classifiers.</S><S sid = 57 ssid = >In addition, the presence of semantically oriented (positive and negative) words in a sentence is an indicator that the sentence is subjective (Hatzivassiloglou and Wiebe, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-1017.txt | Citing Article:  W06-1642.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Yu and Hatzivassiloglou (2003) separated facts from opinions and assigned polarities only to opinions.</S> | Reference Offset:  ['95','135'] | Reference Text:  <S sid = 95 ssid = >We cannot automatically select a sentence-level gold standard discriminating between facts and opinions, or between positive and negative opinions.</S><S sid = 135 ssid = >We presented several models for distinguishing between opinions and facts, and between positive and negative opinions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-1017.txt | Citing Article:  P06-2079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >There have been attempt son tackling this so-called document-level subjectivity classification task, with very encouraging results (see Yu and Hatzivassiloglou (2003) and Wiebe et al (2004) for details).</S> | Reference Offset:  ['23','26'] | Reference Text:  <S sid = 23 ssid = >Much of the earlier research in automated opinion detection has been performed by Wiebe and colleagues (Bruce and Wiebe, 1999; Wiebe et al., 1999; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2002), who proposed methods for discriminating between subjective and objective text at the document, sentence, and phrase levels.</S><S sid = 26 ssid = >More recently, Wiebe et al. (2002) report on document-level subjectivity classification, using a k-nearest neighbor algorithm based on the total count of subjective words and phrases within each document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-1017.txt | Citing Article:  P06-2079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 146 ssid = >Any opinions, findings, or recommendations are those of the authors and do not necessarily reflect ARDA’s views.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-1017.txt | Citing Article:  P06-2079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Indeed, recent work has shown that benefits can be made by first separating facts from opinions in a document (e.g, Yu and Hatzivassiloglou (2003)) and classifying the polarity based solely on the subjective portions of the document (e.g., Pang and Lee (2004)).</S> | Reference Offset:  ['0','26'] | Reference Text:  <S sid = 0 ssid = >Towards Answering Opinion Questions: Separating Facts From Opinions And Identifying The Polarity Of Opinion Sentences</S><S sid = 26 ssid = >More recently, Wiebe et al. (2002) report on document-level subjectivity classification, using a k-nearest neighbor algorithm based on the total count of subjective words and phrases within each document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-1017.txt | Citing Article:  C08-1135.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Yu and Hatzivassiloglou (2003) use semantically oriented words for identification of polarity at the sentence level.</S> | Reference Offset:  ['57','73'] | Reference Text:  <S sid = 57 ssid = >In addition, the presence of semantically oriented (positive and negative) words in a sentence is an indicator that the sentence is subjective (Hatzivassiloglou and Wiebe, 2000).</S><S sid = 73 ssid = >To determine which words are semantically oriented, in what direction, and the strength of their orientation, we measured their co-occurrence with words from a known seed set of semantically oriented words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-1017.txt | Citing Article:  C10-2036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >At sentence level, Yu and Hatzivassiloglou (2003) propose to classify opinion sentences as positive or negative in terms of the main perspective being expressed in opinionated sentences.</S> | Reference Offset:  ['4','102'] | Reference Text:  <S sid = 4 ssid = >We also present a first model for classifying opinion sentences as positive or negative in terms of the main perspective being expressed in the opinion.</S><S sid = 102 ssid = >Each of ten human evaluators (all with graduate training in computational linguistics) was presented with one block and asked to select a label for each sentence among the following: “fact”, “positive opinion”, “negative opinion”, “neutral opinion”, “sentence contains both positive and negative opinions”, “opinion but cannot determine orientation”, and “uncertain”.5 Since we have one judgment for 300 sentences and two judgments for 100 sentences, we created two gold standards for sentence classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-1017.txt | Citing Article:  W06-0302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 146 ssid = >Any opinions, findings, or recommendations are those of the authors and do not necessarily reflect ARDA’s views.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-1017.txt | Citing Article:  W06-0302.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 146 ssid = >Any opinions, findings, or recommendations are those of the authors and do not necessarily reflect ARDA’s views.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-1017.txt | Citing Article:  W05-0308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['36','146'] | Reference Text:  <S sid = 36 ssid = >For determining whether an opinion sentence is positive or negative, we have used seed words similar to those produced by (Hatzivassiloglou and McKeown, 1997) and extended them to construct a much larger set of semantically oriented words with a method similar to that proposed by (Turney, 2002).</S><S sid = 146 ssid = >Any opinions, findings, or recommendations are those of the authors and do not necessarily reflect ARDA’s views.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-1017.txt | Citing Article:  W05-0308.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The annotations in Yu and Hatzivassiloglou (2003) are sentence-level subjective vs. objective and polarity judgments.</S> | Reference Offset:  ['33','57'] | Reference Text:  <S sid = 33 ssid = >Unlike the work cited above, we do not rely on human annotations for training but only on weak metadata provided at the document level.</S><S sid = 57 ssid = >In addition, the presence of semantically oriented (positive and negative) words in a sentence is an indicator that the sentence is subjective (Hatzivassiloglou and Wiebe, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-1017.txt | Citing Article:  W07-2022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >These approaches rely on presence and scores of sentiment-bearing words that have been acquired from dictionaries (Kim and Hovy, 2005) or corpora (Yu and Hatzivassiloglou, 2003).</S> | Reference Offset:  ['45','57'] | Reference Text:  <S sid = 45 ssid = >We developed three different approaches to classify opinions from facts at the sentence level.</S><S sid = 57 ssid = >In addition, the presence of semantically oriented (positive and negative) words in a sentence is an indicator that the sentence is subjective (Hatzivassiloglou and Wiebe, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-1017.txt | Citing Article:  C04-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Wiebe et al2001, Yu and Hatzivassiloglou 2003), a task that is not relevant for the processing of very brief pieces of direct customer feedback.</S> | Reference Offset:  ['1','23'] | Reference Text:  <S sid = 1 ssid = >Opinion question answering is a challenging task for natural language processing.</S><S sid = 23 ssid = >Much of the earlier research in automated opinion detection has been performed by Wiebe and colleagues (Bruce and Wiebe, 1999; Wiebe et al., 1999; Hatzivassiloglou and Wiebe, 2000; Wiebe, 2000; Wiebe et al., 2002), who proposed methods for discriminating between subjective and objective text at the document, sentence, and phrase levels.</S> | Discourse Facet:  NA | Annotator: Automatic


