Citance Number: 1 | Reference Article:  D08-1011.txt | Citing Article:  P09-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Translation Edit Rate (TER, Snover et al (2006)) based alignment proposed in Sim et al (2007) is often taken as the baseline, and a couple of other approaches, such as the Indirect Hidden Markov Model (IHMM, He et al (2008)) and the ITG-based alignment (Karakos et al. (2008)), were recently proposed with better results reported.</S> | Reference Offset:  ['7','107'] | Reference Text:  <S sid = 7 ssid = >Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).</S><S sid = 107 ssid = >Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D08-1011.txt | Citing Article:  P09-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Our incremental alignment approaches adopt the same heuristics for alignment normalization stated in He et al (2008).</S> | Reference Offset:  ['107','108'] | Reference Text:  <S sid = 107 ssid = >Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.</S><S sid = 108 ssid = >(2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D08-1011.txt | Citing Article:  P09-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The various parameters in the IHMM model are set as the optimal values found in He et al (2008).</S> | Reference Offset:  ['107','142'] | Reference Text:  <S sid = 107 ssid = >Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.</S><S sid = 142 ssid = >In the IHMM-based method, the smoothing factor for surface similarity model is set to ρ = 3, the interpolation factor of the overall similarity model is set to α = 0.3, and the controlling factor of the distance-based distortion parameters is set to K=2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D08-1011.txt | Citing Article:  P09-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The comparison between the two pair-wise alignment methods shows that IHMM gives a 0.7 BLEU point gain over TER, which is a bit smaller than the difference reported in He et al (2008).</S> | Reference Offset:  ['106','168'] | Reference Text:  <S sid = 106 ssid = >There have been other hypothesis alignment methods.</S><S sid = 168 ssid = >It shows that the IHMMbased method is still about 1 BLEU point better than the TER-based method.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D08-1011.txt | Citing Article:  D09-1125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.</S><S sid = 187 ssid = >The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D08-1011.txt | Citing Article:  D09-1125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To compute scores for word pairs, we perform pair-wise hypothesis alignment using the indirect HMM (He et al 2008) for every pair of input hypotheses.</S> | Reference Offset:  ['88','107'] | Reference Text:  <S sid = 88 ssid = >Matusov et al. (2006) proposed using GIZA++ to align words between different MT hypotheses, where all hypotheses of the test corpus are collected to create hypothesis pairs for GIZA++ training.</S><S sid = 107 ssid = >Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D08-1011.txt | Citing Article:  D09-1125.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The baselines include a pair-wise hypothesis alignment approach using the indirect HMM (IHMM) proposed by He et al (2008), and an incremental hypothesis alignment approach using the incremental HMM (IncHMM) proposed by Li et al (2009).</S> | Reference Offset:  ['107','108'] | Reference Text:  <S sid = 107 ssid = >Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al.</S><S sid = 108 ssid = >(2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D08-1011.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >He et al (2008) proposed an IHMM-based word alignment method which the parameters are estimated indirectly from a variety of sources.</S> | Reference Offset:  ['3','17'] | Reference Text:  <S sid = 3 ssid = >Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the of the IHMM are estimated a variety of sources including word semantic similarity, word surface similarity, and a distance-based distortion penalty.</S><S sid = 17 ssid = >Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the parameters of the IHMM are estimated indirectly from a variety of sources including word semantic similarity, word surface similarity, and a distancebased distortion penalty, without using large amount of training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D08-1011.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compute the association score from a linear combination of two clues: surface similarity computed as Equation (2) and position difference based distortion score by following (He et al, 2008).</S> | Reference Offset:  ['46','111'] | Reference Text:  <S sid = 46 ssid = >Since both words are in the same language, the similarity model can be derived based on both semantic similarity and surface similarity, and the overall similarity model is a linear interpolation of the two: where and reflect the semantic and surface similarity between and e; , respectively, and α is the interpolation factor.</S><S sid = 111 ssid = >In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D08-1011.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >IHMM-based: He et al (2008) propose an indirect hidden Markov model (IHMM) for hypothesis alignment.</S> | Reference Offset:  ['2','15'] | Reference Text:  <S sid = 2 ssid = >An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment.</S><S sid = 15 ssid = >In this paper, we propose an indirect hidden Markov model (IHMM) for MT hypothesis alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D08-1011.txt | Citing Article:  P09-1106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compute the distortion model by following (He et al, 2008) for IHMM and CLA-based methods.</S> | Reference Offset:  ['87','106'] | Reference Text:  <S sid = 87 ssid = >The two main hypothesis alignment methods for system combination in the previous literature are GIZA++ and TER-based methods.</S><S sid = 106 ssid = >There have been other hypothesis alignment methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D08-1011.txt | Citing Article:  D09-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compared our approach with the state-of-the-art confusion-network-based system (He et al, 2008) and achieved a significant absolute improvement of 1.23 BLEU points on the NIST 2005 Chinese-to-English test set and 0.93 BLEU point on the NIST 2008 Chinese-to-English test set.</S> | Reference Offset:  ['109','131'] | Reference Text:  <S sid = 109 ssid = >In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track of the 2008 NIST Open MT Evaluation (NIST, 2008).</S><S sid = 131 ssid = >The test set is the MT08 Chinese-to-English “current” test set, which includes 1357 sentences from both newswire and web-data genres.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D08-1011.txt | Citing Article:  D09-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Since the candidate hypotheses are aligned using Indirect-HMM-based (IHMM-based) alignment method (He et al, 2008) in both direction, we briefly review the IHMM-based alignment method first.</S> | Reference Offset:  ['148','182'] | Reference Text:  <S sid = 148 ssid = >Compared to the TER-based method, the IHMM-based method is about 1.5 BLEU points better.</S><S sid = 182 ssid = >In this paper, an IHMM-based method is proposed for hypothesis alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D08-1011.txt | Citing Article:  D09-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.</S><S sid = 187 ssid = >The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D08-1011.txt | Citing Article:  D09-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On NIST MT05 test set, the lattice-based system gave better results with an absolute improvement of 1.23 BLEU points over the confusion network-based system (He et al, 2008) and 3.73 BLEU points over the best single system.</S> | Reference Offset:  ['148','150'] | Reference Text:  <S sid = 148 ssid = >Compared to the TER-based method, the IHMM-based method is about 1.5 BLEU points better.</S><S sid = 150 ssid = >It outperformed the best single system by 4.7 BLEU points and the TER-based system combination by 1.0 BLEU points.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D08-1011.txt | Citing Article:  P11-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Aligning translation hypotheses can be challenging and has a substantial effect on combination performance (He et al, 2008).</S> | Reference Offset:  ['7','36'] | Reference Text:  <S sid = 7 ssid = >Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).</S><S sid = 36 ssid = >In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D08-1011.txt | Citing Article:  W09-0409.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['58','187'] | Reference Text:  <S sid = 58 ssid = >If the target language uses alphabetic orthography, as English does, we treat words as letter sequences and the similarity measure can be the length of the longest matched prefix (LMP) or the length of the longest common subsequence (LCS) between them.</S><S sid = 187 ssid = >The authors are grateful to Chris Quirk, Arul Menezes, Kristina Toutanova, William Dolan, Mu Li, Chi-Ho Li, Dongdong Zhang, Long Jiang, Ming Zhou, George Foster, Roland Kuhn, Jing Zheng, Wen Wang, Necip Fazil Ayan, Dimitra Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin Knight, Jens-Soenke Voeckler, Spyros Matsoukas, and Antti-Veikko Rosti for assistance with the MT systems and/or for the valuable suggestions and discussions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D08-1011.txt | Citing Article:  N10-1141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Aligning translation hypotheses accurately can be challenging, and has a substantial effect on combination performance (He et al, 2008).</S> | Reference Offset:  ['7','36'] | Reference Text:  <S sid = 7 ssid = >Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007).</S><S sid = 36 ssid = >In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D08-1011.txt | Citing Article:  W12-3124.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >He et al (2008) proposed using an indirect hidden Markov model (IHMM) for pairwise alignment of system outputs.</S> | Reference Offset:  ['2','15'] | Reference Text:  <S sid = 2 ssid = >An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment.</S><S sid = 15 ssid = >In this paper, we propose an indirect hidden Markov model (IHMM) for MT hypothesis alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


