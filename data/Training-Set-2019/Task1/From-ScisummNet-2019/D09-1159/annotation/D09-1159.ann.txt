Citance Number: 1 | Reference Article:  D09-1159.txt | Citing Article:  P14-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A previous work that used structured kernels in Sentiment Analysis is the approach of Wu et al (2009).</S> | Reference Offset:  ['9','165'] | Reference Text:  <S sid = 9 ssid = >Previous works on mining opinions can be divided into two directions: sentiment classification and sentiment related information extraction.</S><S sid = 165 ssid = >Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D09-1159.txt | Citing Article:  P14-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The results showed by Wu et al (2009) suggest that tree kernels on dependency trees are a good approach but we also plan to employ string kernels on this task.</S> | Reference Offset:  ['106','181'] | Reference Text:  <S sid = 106 ssid = >Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).</S><S sid = 181 ssid = >Experimental results show that our approach improved the performances of the mining task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D09-1159.txt | Citing Article:  P11-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compared our aspect identification approach against two baselines: a) the method proposed by Hu and Liu (2004), which was based on the association rule mining, and b) the method proposed by Wu et al (2009), which was based on a dependency parser.</S> | Reference Offset:  ['106','146'] | Reference Text:  <S sid = 106 ssid = >Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).</S><S sid = 146 ssid = >However, in other domains, directly adjacent method is better than the learning based methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D09-1159.txt | Citing Article:  P11-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Afterwards, Wu et al (2009) utilized the dependency parser to extract the noun phrases and verb phrases from the reviews as the aspect candidates.</S> | Reference Offset:  ['66','88'] | Reference Text:  <S sid = 66 ssid = >A phrase dependency tree is defined as T = (V , E ), where V is the set of phrases, E is the dependency relations among the phrases in V representing by direct edges.</S><S sid = 88 ssid = >While prepositional phrases (PPs) and adjectival phrases (ADJPs) are excluded.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D09-1159.txt | Citing Article:  D11-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Phrase dependency grammars have recently been used by Wu et al (2009) for feature extraction for opinion mining.</S> | Reference Offset:  ['0','164'] | Reference Text:  <S sid = 0 ssid = >Phrase Dependency Parsing for Opinion Mining</S><S sid = 164 ssid = >Opinion mining has recently received considerable attention.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D09-1159.txt | Citing Article:  D11-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For a monolingual task, Wu et al (2009) used a shallow parser to convert lexical dependencies from a dependency parser into phrase dependencies.</S> | Reference Offset:  ['65','78'] | Reference Text:  <S sid = 65 ssid = >To construct phrase dependency tree, we propose a method which combines results from an existing shallow parser and a lexical dependency parser.</S><S sid = 78 ssid = >Fig.2(a) is the result of the lexical dependency parser.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D09-1159.txt | Citing Article:  D11-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We compared our approach against two state-of-the art methods: a) the method proposed by Hu and Liu (2004), which is based on the association rule mining, and b) the method proposed by Wu et al (2009), which is based on the dependency parser.</S> | Reference Offset:  ['106','146'] | Reference Text:  <S sid = 106 ssid = >Dependency tree kernels has been proposed by (Culotta and Sorensen, 2004).</S><S sid = 146 ssid = >However, in other domains, directly adjacent method is better than the learning based methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D09-1159.txt | Citing Article:  D11-1013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, Wu et al (2009) identified aspects based on the features explored by dependency parser.</S> | Reference Offset:  ['10','165'] | Reference Text:  <S sid = 10 ssid = >The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S><S sid = 165 ssid = >Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D09-1159.txt | Citing Article:  D10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A wide spectrum of tasks have been studied under review mining, ranging from coarse-grained document-level polarity classification (Pang et al,2002) to fine-grained extraction of opinion expressions and their targets (Wu et al, 2009).</S> | Reference Offset:  ['10','165'] | Reference Text:  <S sid = 10 ssid = >The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S><S sid = 165 ssid = >Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D09-1159.txt | Citing Article:  D10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','183'] | Reference Text:  <S sid = 57 ssid = >The other phrase is called dependent, which modifies the head.</S><S sid = 183 ssid = >The authors would like to thank the reviewers for their useful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D09-1159.txt | Citing Article:  D10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For MaxEnt training, we tried three labeled data sets: one that was taken from the restaurant data set and manually annotated by us, and two from the annotated data set used in (Wu et al., 2009).</S> | Reference Offset:  ['129','143'] | Reference Text:  <S sid = 129 ssid = >Then for each product feature, they annotated the opinion expression which has relation with it.</S><S sid = 143 ssid = >The other domains are used as testing set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D09-1159.txt | Citing Article:  D10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To test this hypothesis, we tried two quite different training data sets, one from the cell phone domain and the other from the DVD player domain, both used in (Wu et al, 2009).</S> | Reference Offset:  ['125','142'] | Reference Text:  <S sid = 125 ssid = >Our corpus is selected from them, which contains customer reviews of 11 products belong to 5 categories(Diaper, Cell Phone, Digital Camera, DVD Player, and MP3 Player).</S><S sid = 142 ssid = >We use the digital camera and cell phone domain as training set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D09-1159.txt | Citing Article:  P14-1032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Wu et al (2009) proposed a phrase level dependency parsing for mining aspects and features of products.</S> | Reference Offset:  ['0','180'] | Reference Text:  <S sid = 0 ssid = >Phrase Dependency Parsing for Opinion Mining</S><S sid = 180 ssid = >The novelties of our work included: 1) we defined the phrase dependency parsing and proposed an approach to construct the phrase dependency trees; 2) we proposed a new tree kernel function to model the phrase dependency trees.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D09-1159.txt | Citing Article:  P14-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = ></S> | Reference Offset:  ['57','183'] | Reference Text:  <S sid = 57 ssid = >The other phrase is called dependent, which modifies the head.</S><S sid = 183 ssid = >The authors would like to thank the reviewers for their useful comments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D09-1159.txt | Citing Article:  P13-1173.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al, 2009) and CRFs (Li et al, 2010).</S> | Reference Offset:  ['10','165'] | Reference Text:  <S sid = 10 ssid = >The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S><S sid = 165 ssid = >Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D09-1159.txt | Citing Article:  P14-1030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They regarded it as a sequence labeling task, where several classical models were used, such as CRFs (Li et al, 2010) and SVM (Wu et al, 2009).</S> | Reference Offset:  ['10','165'] | Reference Text:  <S sid = 10 ssid = >The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S><S sid = 165 ssid = >Amount of works have been done on sentimental classification in different levels (Zhang et al., 2009; Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


