Citance Number: 1 | Reference Article:  J97-1003.txt | Citing Article:  P99-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The performance with respect to identifying sentence boundaries appears to be close to that of systems aimed at identifying only sentence boundaries (Palmer and Hearst, 1997), whose accuracy is in the range of 99%.</S> | Reference Offset:  ['22','135'] | Reference Text:  <S sid = 22 ssid = >The algorithm has three parts: tokenization into terms and sentence-sized units, determination of a score for each sentence-sized unit, and detection of the subtopic boundaries, which are assumed to occur at the largest valleys in the graph that results from plotting sentence-units against scores.</S><S sid = 135 ssid = >In contrast, TextTiling has the goal of identifying major subtopic boundaries, attempting only a linear segmentation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  J97-1003.txt | Citing Article:  P99-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This similarity is computed by applying in the style of Hearst (1997) a cosine-based metric on the morphed segments.</S> | Reference Offset:  ['325','361'] | Reference Text:  <S sid = 325 ssid = >The lexical score is computed as follows.</S><S sid = 361 ssid = >Any attempt to make an absolute cutoff, even one normalized for the length of the document, is problematic since there should be some relationship between the structure and style of the text and the number of segments assigned to it.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  J97-1003.txt | Citing Article:  N10-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Foltz et al's (1998) approach is in line with the earlier TextTiling method that identifies subtopic structure in text (Hearst, 1997).</S> | Reference Offset:  ['19','497'] | Reference Text:  <S sid = 19 ssid = >Because the goal is to partition texts into contiguous, nonoverlapping subtopic segments, I call the general approach TextTiling (Hearst, 1993, 1994a, 1994b).1 Subtopic discussions are assumed to occur within the scope of one or more overarching main topics, which span the length of the text.</S><S sid = 497 ssid = >In a line of work we call Mixed-Media access (Chen et al. 1994), textual subtopic structure is being integrated with other media types, such as images and speech.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  J97-1003.txt | Citing Article:  C10-2177.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Table 1 also presents the performance of a typical topic segmentation algorithm, TextTiling (Hearst, 1997).</S> | Reference Offset:  ['368','370'] | Reference Text:  <S sid = 368 ssid = >This section presents comparisons of the results of the algorithm against human judgments and against article boundaries.</S><S sid = 370 ssid = >As mentioned above, Hearst (1995) and Hearst and Plaunt (1993) show how to use TextTiles in information retrieval tasks, although this work does not show whether or not the results of these algorithms produce better performance than the results of some other segmentation strategy would.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  J97-1003.txt | Citing Article:  P13-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Many researchers have attempted to make use of cue phrases (Hirschberg and Litman, 1993), especially for segmentation both in prose (Hearst, 1997) and conversation (Galley et al, 2003).</S> | Reference Offset:  ['82','520'] | Reference Text:  <S sid = 82 ssid = >The results of Hearst and Plaunt (1993), Salton, Allan, and Buckley (1993) and Moffat et al. (1994) suggest that it is the nature of the intermediate size of the passages that matters.</S><S sid = 520 ssid = >The use of discourse cues for detection of segment boundaries and other discourse purposes has been extensively researched, although predominantly on spoken text (see Hirschberg and Litman [19931 for a summary of six research groups' treatments of 64 cue words).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  J97-1003.txt | Citing Article:  W06-3407.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The best known algorithm based on this idea is TextTiling (Hearst, 1997).</S> | Reference Offset:  ['203','259'] | Reference Text:  <S sid = 203 ssid = >Hearst (1993) posited that this argument should also apply to determining which words best distinguish one subtopic from another.</S><S sid = 259 ssid = >This variation of the TextTiling algorithm is explored and evaluated in Hearst (1994b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  J97-1003.txt | Citing Article:  N12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >reference segmentation from a coder should not be trusted, given that inter-annotator agreement is often reported to be rather poor (Hearst, 1997, p. 54).</S> | Reference Offset:  ['193','230'] | Reference Text:  <S sid = 193 ssid = >Results for this approach are reported in Section 6.</S><S sid = 230 ssid = >Results for this approach are reported in Section 6.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  J97-1003.txt | Citing Article:  N12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Siegel and Castellan, 1988) values for coders and automatic segmenters (Hearst, 1997, p. 56).</S> | Reference Offset:  ['346','392'] | Reference Text:  <S sid = 346 ssid = >Note that the depth scores are based only on relative score information, ignoring absolute values.</S><S sid = 392 ssid = >The kappa coefficients found in Isard and Carletta (1995) ranged from .43 to .68 for four coders placing transaction boundaries, and those found in (Rose 1995) ranged from .65 to .90 for four coders segmenting sentences.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  J97-1003.txt | Citing Article:  N12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pairwise mean kappa scores were calculated by comparing a coder's segmentation against a reference segmentation formulated by the majority opinion strategy used in Passonneau and Litman (1993, p. 150) (Hearst, 1997, pp. 53-54).</S> | Reference Offset:  ['124','367'] | Reference Text:  <S sid = 124 ssid = >(pp.</S><S sid = 367 ssid = >There are several ways to evaluate a segmentation algorithm, including comparing its segmentation against that of human judges, comparing its segmentation against author-specified orthographic information, and comparing its segmentation against other automated segmentation strategies in terms of how they effect the outcome of some computational task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  J97-1003.txt | Citing Article:  N12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Coders often disagree in segmentation tasks (Hearst, 1997, p. 56), making it improbable that a single, correct, reference segmentation could be identified from human codings.</S> | Reference Offset:  ['367','370'] | Reference Text:  <S sid = 367 ssid = >There are several ways to evaluate a segmentation algorithm, including comparing its segmentation against that of human judges, comparing its segmentation against author-specified orthographic information, and comparing its segmentation against other automated segmentation strategies in terms of how they effect the outcome of some computational task.</S><S sid = 370 ssid = >As mentioned above, Hearst (1995) and Hearst and Plaunt (1993) show how to use TextTiles in information retrieval tasks, although this work does not show whether or not the results of these algorithms produce better performance than the results of some other segmentation strategy would.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  J97-1003.txt | Citing Article:  N12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This category choice is similar to those chosen by Hearst (1997, p. 53), who computed chance agreement in terms of the probability that coders would say that a segment boundary exists (segt), and the probability that they would not (unsegt).</S> | Reference Offset:  ['282','389'] | Reference Text:  <S sid = 282 ssid = >Reynar (1994) describes an algorithm similar to that of Hearst (1993) and Hearst and Plaunt (1993) with a difference in the way in which the size of the blocks of adjacent regions are chosen.</S><S sid = 389 ssid = >According to Carletta (1996), K measures pairwise agreement among a set of coders making category judgments, correcting for expected chance agreement as follows: where P(A) is the proportion of times that the coders agree and P(E) is the proportion of times that they would be expected to agree by chance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  J97-1003.txt | Citing Article:  N06-2003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The best known algorithm based on this idea is TextTiling (Hearst, 1997).</S> | Reference Offset:  ['203','259'] | Reference Text:  <S sid = 203 ssid = >Hearst (1993) posited that this argument should also apply to determining which words best distinguish one subtopic from another.</S><S sid = 259 ssid = >This variation of the TextTiling algorithm is explored and evaluated in Hearst (1994b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  J97-1003.txt | Citing Article:  W04-2323.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Automatic segmentation of discourse forms the basis for many applications, from information retrieval and text summarisation to anaphora resolution (Hearst, 1997).</S> | Reference Offset:  ['39','44'] | Reference Text:  <S sid = 39 ssid = >Although most discourse segmentation work is done at a finer granularity than that suggested here, multi-paragraph segmentation has many potential applications.</S><S sid = 44 ssid = >There are also potential applications in some other areas, such as text summarization.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  J97-1003.txt | Citing Article:  W04-2323.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >While agreement among annotators regarding linear segmentation has been found to be higher than 80% (Hearst, 1997), with respect to hierarchical segmentation it has been observed to be as low as 60% (Flammia and Zue, 1995).</S> | Reference Offset:  ['135','367'] | Reference Text:  <S sid = 135 ssid = >In contrast, TextTiling has the goal of identifying major subtopic boundaries, attempting only a linear segmentation.</S><S sid = 367 ssid = >There are several ways to evaluate a segmentation algorithm, including comparing its segmentation against that of human judges, comparing its segmentation against author-specified orthographic information, and comparing its segmentation against other automated segmentation strategies in terms of how they effect the outcome of some computational task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  J97-1003.txt | Citing Article:  N10-2002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As in (Hearst, 1997), we segment each document into several 'mini-documents', each one devoted to a single topic, and then to perform location and topic-based clustering over the (now larger) set of mini-documents.</S> | Reference Offset:  ['86','501'] | Reference Text:  <S sid = 86 ssid = >This approach, called TileBars, allows the user to make informed decisions about which documents and which passages of those documents to view, based on the distributional behavior of the query terms in the documents.</S><S sid = 501 ssid = >When examining documents of all lengths, he finds that relevant documents tend to have more TextTiles than nonrelevant ones (95% significant by a Mann Whitney test).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  J97-1003.txt | Citing Article:  W08-2106.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >So far, it has been used mainly in the context of automatic text segmentation, where a change in vocabulary is often the mark of topic change (Hearst, 1997), and, to a lesser extent, in discourse studies (see, e.g., (Foltz et al, 1998)).</S> | Reference Offset:  ['144','462'] | Reference Text:  <S sid = 144 ssid = >This is not so much a change in setting or character as a change in subject matter.</S><S sid = 462 ssid = >This phenomenon occurs in some of the other texts as well, but to a much lesser extent.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  J97-1003.txt | Citing Article:  E06-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this study, we use Galley et al's (2003) LCSeg algorithm, a variant of TextTiling (Hearst, 1997).</S> | Reference Offset:  ['77','259'] | Reference Text:  <S sid = 77 ssid = >The results are that the small, artificial multi-paragraph groupings seemed to perform better than the author-supplied sectioning information (which usually consisted of many more paragraphs than Moffet et al. 's subdivision algorithm or TextTiling would create).</S><S sid = 259 ssid = >This variation of the TextTiling algorithm is explored and evaluated in Hearst (1994b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  J97-1003.txt | Citing Article:  E06-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To compute a baseline, we follow Kan (2003) and Hearst (1997) in using Monte Carlo simulated segments.</S> | Reference Offset:  ['70','71'] | Reference Text:  <S sid = 70 ssid = >This includes author-determined segments, marked orthographically (paragraphs, sections, and chapters) (Hearst and Plaunt 1993; Salton, Allan, and Buckley 1993; Moffat et al. 1994) and/or automatically derived units of text, including fixed-length blocks (Hearst and Flaunt 1993; Callan 1994), segments motivated by subtopic structure (TextTiles) (Hearst and Plaunt 1993), or segments motivated by properties of the query (Mittendorf and Schaible 1994).</S><S sid = 71 ssid = >Hearst and Plaunt (1993), in some early passage-based retrieval experiments, report improved results using passages over full-text documents, but do not find a significant difference between using motivated subtopic segments and arbitrarily chosen block lengths that approximated the average subtopic segment length.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  J97-1003.txt | Citing Article:  E06-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Compared to the task of segmenting expository texts reported in Hearst (1997) with a 39.1% chance of each paragraph end being a target topic boundary, the chance of each speaker turn being a top-level or sub-topic boundary in our ICSI corpus is just 2.2% and 0.69%.</S> | Reference Offset:  ['117','395'] | Reference Text:  <S sid = 117 ssid = >69-70) After many pages of attempting to pin the concept down, they suggest, as one alternative, investigating topic-shift markers instead: It has been suggested ... that instead of undertaking the difficult task of attempting to define 'what a topic is', we should concentrate on describing what we recognize as topic shift.</S><S sid = 395 ssid = >Thus the expected chance agreement P(E) is .524 (since P(Boundary) = .391 and P(Nonboundary) ----- .609, (.3912 + .6092) = .524).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  J97-1003.txt | Citing Article:  P07-1128.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, lexical cohesion-based algorithms, such as LCSEG (Galley et al, 2003), or its word frequency-based predecessor TextTile (Hearst, 1997) capture topic shifts by modeling the similarity of word repetition in adjacent windows.</S> | Reference Offset:  ['170','496'] | Reference Text:  <S sid = 170 ssid = >Stoddard (1991) creates cohesion maps by assigning to each word a location on a twodimensional grid corresponding to the word's position in the text.</S><S sid = 496 ssid = >For example, the algorithms described here should prove useful for topic-based segmentation of video transcripts (Christel et al. 1995).</S> | Discourse Facet:  NA | Annotator: Automatic


