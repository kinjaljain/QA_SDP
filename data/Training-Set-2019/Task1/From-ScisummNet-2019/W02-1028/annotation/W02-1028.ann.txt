Citance Number: 1 | Reference Article:  W02-1028.txt | Citing Article:  P03-1044.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, (Thelen and Riloff, 2002) did not focus on the issue of convergence, and on leveraging negative categories to achieve or improve convergence.</S> | Reference Offset:  ['58','93'] | Reference Text:  <S sid = 58 ssid = >To achieve this effect, we increment the value of N by one after each bootstrapping iteration.</S><S sid = 93 ssid = >Riloff and Jones acknowledged this issue and used a second level of bootstrapping (the “Meta” bootstrapping level) to alleviate this problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W02-1028.txt | Citing Article:  P10-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al, 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al, 2007), and concept lists (Katz et al, 2003).</S> | Reference Offset:  ['8','134'] | Reference Text:  <S sid = 8 ssid = >Semantic class information has proven to be useful for many natural language processing tasks, including information extraction (Riloff and Schmelzenbach, 1998; Soderland et al., 1995), anaphora resolution (Aone and Bennett, 1996), question answering (Moldovan et al., 1999; Hirschman et al., 1999), and prepositional phrase attachment (Brill and Resnik, 1994).</S><S sid = 134 ssid = >(2) If a word is hypothesized for both category A and category B during the same iteration, then it to the “one sense per discourse” observation (Gale et al., 1992)) that a word belongs to a single semantic category within a limited domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W02-1028.txt | Citing Article:  P10-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >(Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealistic assumption that a word cannot belong to more than one semantic category.</S> | Reference Offset:  ['17','18'] | Reference Text:  <S sid = 17 ssid = >Third, we explore the idea of learning multiple semantic categories simultaneously by adding this capability to Basilisk as well as another bootstrapping algorithm.</S><S sid = 18 ssid = >Finally, we present results showing that learning multiple semantic categories simultaneously improves performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W02-1028.txt | Citing Article:  W06-2919.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Previous approaches to context pattern induction were described by Riloff and Jones (1999), Agichtein and Gravano (2000), Thelen and Riloff (2002), Lin et al (2003), and Etzioni et al (2005), among others.</S> | Reference Offset:  ['8','90'] | Reference Text:  <S sid = 8 ssid = >Semantic class information has proven to be useful for many natural language processing tasks, including information extraction (Riloff and Schmelzenbach, 1998; Soderland et al., 1995), anaphora resolution (Aone and Bennett, 1996), question answering (Moldovan et al., 1999; Hirschman et al., 1999), and prepositional phrase attachment (Brill and Resnik, 1994).</S><S sid = 90 ssid = >The algorithm most closely related to Basilisk is meta-bootstrapping (Riloff and Jones, 1999), which also uses extraction pattern contexts for semantic lexicon induction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W02-1028.txt | Citing Article:  W12-4107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Over the years, researchers have successfully shown how to build ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al, 2007), and concept lists (Katz et al, 2003).</S> | Reference Offset:  ['8','134'] | Reference Text:  <S sid = 8 ssid = >Semantic class information has proven to be useful for many natural language processing tasks, including information extraction (Riloff and Schmelzenbach, 1998; Soderland et al., 1995), anaphora resolution (Aone and Bennett, 1996), question answering (Moldovan et al., 1999; Hirschman et al., 1999), and prepositional phrase attachment (Brill and Resnik, 1994).</S><S sid = 134 ssid = >(2) If a word is hypothesized for both category A and category B during the same iteration, then it to the “one sense per discourse” observation (Gale et al., 1992)) that a word belongs to a single semantic category within a limited domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W02-1028.txt | Citing Article:  D10-1008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Next, we applied the Basilisk bootstrapping algorithm (Thelen and Riloff, 2002) to learn PPVs.</S> | Reference Offset:  ['43','90'] | Reference Text:  <S sid = 43 ssid = >The patterns are then applied to the corpus and all of their extracted noun phrases are recorded.</S><S sid = 90 ssid = >The algorithm most closely related to Basilisk is meta-bootstrapping (Riloff and Jones, 1999), which also uses extraction pattern contexts for semantic lexicon induction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W02-1028.txt | Citing Article:  W11-0319.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar approaches are used among others in (Thelen and Riloff, 2002) for learning semantic lexicons, in (Collins and Singer, 1999) for named entity recognition, and in (Fagni and Sebastiani, 2007) for hierarchical text categorization.</S> | Reference Offset:  ['87','88'] | Reference Text:  <S sid = 87 ssid = >Several learning algorithms have also been developed for named entity recognition (e.g., (Collins and Singer, 1999; Cucerzan and Yarowsky, 1999)).</S><S sid = 88 ssid = >(Collins and Singer, 1999) used contextual information of a different sort than we do.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W02-1028.txt | Citing Article:  W04-2402.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thelen and Riloff (2002)'s bootstrapping method iteratively performs feature selection and word selection for each class.</S> | Reference Offset:  ['0','117'] | Reference Text:  <S sid = 0 ssid = >A Bootstrapping Method For Learning Semantic Lexicons Using Extraction Pattern Contexts</S><S sid = 117 ssid = >This hypothesis makes sense only if a word cannot belong to more than one semantic class.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W02-1028.txt | Citing Article:  W04-2402.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In Section 5, we report experiments using syntactic features shown to be useful by the above studies, and compare performance with Thelen and Riloff (2002)'s bootstrapping method.</S> | Reference Offset:  ['0','104'] | Reference Text:  <S sid = 0 ssid = >A Bootstrapping Method For Learning Semantic Lexicons Using Extraction Pattern Contexts</S><S sid = 104 ssid = >So we implemented the meta-bootstrapping algorithm ourselves to directly compare its performance with that of Basilisk.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W02-1028.txt | Citing Article:  W04-2402.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the following algorithms as baseline: EM, co training, and co-EM, as established techniques for learning from unlabeled data in general; the bootstrapping method proposed by Thelen and Riloff (2002) (hereafter, TRB and TR) as a state-of-the-art bootstrapping method designed for semantic lexicon construction.</S> | Reference Offset:  ['0','44'] | Reference Text:  <S sid = 0 ssid = >A Bootstrapping Method For Learning Semantic Lexicons Using Extraction Pattern Contexts</S><S sid = 44 ssid = >Figure 2 shows the bootstrapping process that follows, which we explain in the following sections.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W02-1028.txt | Citing Article:  P06-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The extraction of large sets of candidate facts opens the possibility of fast-growth iterative extraction, as opposed to the de-facto strategy of conservatively growing the seed set by as few as five items (Thelen and Riloff, 2002) after each iteration.</S> | Reference Offset:  ['29','94'] | Reference Text:  <S sid = 29 ssid = >The input to Basilisk is a text corpus and a set of seed words.</S><S sid = 94 ssid = >While meta-bootstrapping trusts individual extraction patterns to make unilateral decisions, Basilisk gathers collective evidence from a large set of extraction patterns.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W02-1028.txt | Citing Article:  P06-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Pattern generalization is disabled, and the ranking of patterns and facts follows strictly the criteria and scoring functions from (Thelen and Riloff, 2002), which are also used in slightly different form in (Lita and Carbonell, 2004) and (Agichtein and Gravano,2000).</S> | Reference Offset:  ['31','62'] | Reference Text:  <S sid = 31 ssid = >These seed words form the initial semantic lexicon.</S><S sid = 62 ssid = >All extraction patterns are used during this step, not just the patterns in the pattern pool.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W02-1028.txt | Citing Article:  P06-1102.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >As a more realistic compromise over overly-cautious acquisition, the baseline run retains as many of the top candidate facts as the size of the current seed, whereas (Thelen and Riloff, 2002) only add the top five candidate facts to the seed set after each iteration.</S> | Reference Offset:  ['29','60'] | Reference Text:  <S sid = 29 ssid = >The input to Basilisk is a text corpus and a set of seed words.</S><S sid = 60 ssid = >The next step is to score the candidate words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W02-1028.txt | Citing Article:  P09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Multi-category algorithms out perform MLB (Thelen and Riloff, 2002), and we focus on these algorithms in our experiments.</S> | Reference Offset:  ['86','132'] | Reference Text:  <S sid = 86 ssid = >None of these previous algorithms used extraction patterns or similar contexts to infer semantic class associations.</S><S sid = 132 ssid = >For both algorithms, the conflict resolution procedure works as follows.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W02-1028.txt | Citing Article:  P09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In BASILISK (Thelen and Riloff, 2002), candidate terms are ranked highly if they have strong evidence for a category and little or no evidence for other categories.</S> | Reference Offset:  ['144','147'] | Reference Text:  <S sid = 144 ssid = >We modified Basilisk’s scoring function to prefer words that have strong evidence for one category but little or no evidence for competing categories.</S><S sid = 147 ssid = >A word is ranked highly only if it has a high score for the targeted category and there is little evidence that it belongs to a different category.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W02-1028.txt | Citing Article:  P09-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To improve the seeds, the frequency of the potential seeds in the corpora is often considered, on the assumption that highly frequent seeds are better (Thelen and Riloff, 2002).</S> | Reference Offset:  ['30','53'] | Reference Text:  <S sid = 30 ssid = >We generated seed words by sorting the words in the corpus by frequency and manually identifying the 10 most frequent nouns that belong to each category.</S><S sid = 53 ssid = >Only these nouns are considered for addition to the lexicon.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W02-1028.txt | Citing Article:  E12-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >This kind of supervision is similar to the seeding in bootstrapping literature (Thelen and Riloff, 2002) or prototype-based learning (Haghighi and Klein, 2006).</S> | Reference Offset:  ['0','45'] | Reference Text:  <S sid = 0 ssid = >A Bootstrapping Method For Learning Semantic Lexicons Using Extraction Pattern Contexts</S><S sid = 45 ssid = >The first step in the bootstrapping process is to score the extraction patterns based on their tendency to extract known category members.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W02-1028.txt | Citing Article:  E12-1021.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Seed-based supervision is closely related to the idea of seeding in the bootstrapping literature for learning semantic lexicons (Thelen and Riloff, 2002).</S> | Reference Offset:  ['17','90'] | Reference Text:  <S sid = 17 ssid = >Third, we explore the idea of learning multiple semantic categories simultaneously by adding this capability to Basilisk as well as another bootstrapping algorithm.</S><S sid = 90 ssid = >The algorithm most closely related to Basilisk is meta-bootstrapping (Riloff and Jones, 1999), which also uses extraction pattern contexts for semantic lexicon induction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W02-1028.txt | Citing Article:  P06-2022.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Thelen and Riloff (2002) use a bootstrapping algorithm to learn semantic lexicons of nouns for six semantic categories, one of which is EVENTS.</S> | Reference Offset:  ['19','98'] | Reference Text:  <S sid = 19 ssid = >Basilisk (Bootstrapping Approach to SemantIc Lexicon Induction using Semantic Knowledge) is a weakly supervised bootstrapping algorithm that automatically generates semantic lexicons.</S><S sid = 98 ssid = >We used Basilisk to learn semantic lexicons for six semantic categories: BUILDING, EVENT, HUMAN, LOCATION, TIME, and WEAPON.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W02-1028.txt | Citing Article:  D10-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Multi-category bootstrapping algorithms, such as Basilisk (Thelen and Riloff, 2002), NOMEN (Yangarber et al, 2002), and WMEB (McIntosh and Curran, 2008), aim to reduce semantic drift by extracting multiple semantic categories simultaneously.</S> | Reference Offset:  ['17','159'] | Reference Text:  <S sid = 17 ssid = >Third, we explore the idea of learning multiple semantic categories simultaneously by adding this capability to Basilisk as well as another bootstrapping algorithm.</S><S sid = 159 ssid = >Basilisk’s bootstrapping algorithm exploits two ideas: (1) collective evidence from extraction patterns can be used to infer semantic category associations, and (2) learning multiple semantic categories simultaneously can help constrain the bootstrapping process.</S> | Discourse Facet:  NA | Annotator: Automatic


