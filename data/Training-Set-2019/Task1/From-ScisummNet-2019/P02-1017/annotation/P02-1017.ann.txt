Citance Number: 1 | Reference Article:  P02-1017.txt | Citing Article:  P04-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A number of studies are related to the work we presented, most specifically work on parallel-text based "information projection" for parsing (Hwa et al., 2002), but also grammar induction work based on constituent/distituent information (Klein and Manning, 2002) and (language-internal) alignment based learning (van Zaanen, 2000).</S> | Reference Offset:  ['7','22'] | Reference Text:  <S sid = 7 ssid = >In previous work, we presented a conditional model over trees which gave the best published results for unsupervised parsing of the ATIS corpus (Klein and Manning, 2001b).</S><S sid = 22 ssid = >To the extent that such approaches work, they work because good local heuristics have been engineered (Klein and Manning, 2001a; Clark, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Empirically, our algorithm performs favorably compared to the constituent context model of Klein and Manning (2002) without the need for careful initialization.</S> | Reference Offset:  ['0','30'] | Reference Text:  <S sid = 0 ssid = >A Generative Constituent-Context Model For Improved Grammar Induction</S><S sid = 30 ssid = >First, random initialization is not always good, or necessary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We primarily compare our method to the constituent-context model (CCM) of Klein and Manning (2002).</S> | Reference Offset:  ['0','110'] | Reference Text:  <S sid = 0 ssid = >A Generative Constituent-Context Model For Improved Grammar Induction</S><S sid = 110 ssid = >CCM is our system, as described above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >CCM is used with the initializer proposed in Klein and Manning (2002).</S> | Reference Offset:  ['94','110'] | Reference Text:  <S sid = 94 ssid = >This distribution was not used in the model itself, however.</S><S sid = 110 ssid = >CCM is our system, as described above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The EM algorithm with the CCM requires very careful initialization, which is described in Klein and Manning (2002).</S> | Reference Offset:  ['30','110'] | Reference Text:  <S sid = 30 ssid = >First, random initialization is not always good, or necessary.</S><S sid = 110 ssid = >CCM is our system, as described above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P02-1017.txt | Citing Article:  P14-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Empirically, our algorithm performs favorably to the CCM of Klein and Manning (2002) without the need for careful initialization.</S> | Reference Offset:  ['30','110'] | Reference Text:  <S sid = 30 ssid = >First, random initialization is not always good, or necessary.</S><S sid = 110 ssid = >CCM is our system, as described above.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P02-1017.txt | Citing Article:  N06-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, there are "unsupervised" strategies where no data is labeled and all annotations (including the grammar itself) must be discovered (Klein and Manning, 2002).</S> | Reference Offset:  ['7','76'] | Reference Text:  <S sid = 7 ssid = >In previous work, we presented a conditional model over trees which gave the best published results for unsupervised parsing of the ATIS corpus (Klein and Manning, 2001b).</S><S sid = 76 ssid = >On the right, sequences have been labeled according to whether their occurrences are constituents more or less of the time than a cutoff (of 0.2).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P02-1017.txt | Citing Article:  P07-1049.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >When Klein and Manning induce the parts-of-speech, they do so from a much larger corpus containing the full WSJ tree bank together with additional WSJ newswire (Klein and Manning,2002).</S> | Reference Offset:  ['15','57'] | Reference Text:  <S sid = 15 ssid = >Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = 57 ssid = >We will induce trees by inducing tree-equivalent bracketings.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >An excellent recent result is by Klein and Manning (2002).</S> | Reference Offset:  ['15','69'] | Reference Text:  <S sid = 15 ssid = >Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = 69 ssid = >The distituents must necessarily outnumber the constituents, and so such distributional clustering will result in mostly distituent classes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We refer readers to Klein and Manning (2002) or Cover and Thomas (1991, p. 72) for details; computing expected counts for a sentence is a closed form operation.</S> | Reference Offset:  ['34','85'] | Reference Text:  <S sid = 34 ssid = >This grammar, which we refer to as DEP-PCFG will be evaluated in more detail in section 4.</S><S sid = 85 ssid = >The completions (bracketings) cannot be efficiently enumerated, and so a cubic dynamic program similar to the inside-outside algorithm is used to calculate the expected counts of each yield and context, both as constituents and distituents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P02-1017.txt | Citing Article:  P04-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The third line corresponds to the setup reported by Klein and Manning (2002).</S> | Reference Offset:  ['15','55'] | Reference Text:  <S sid = 15 ssid = >Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = 55 ssid = >A bracketing is binary if it corresponds to a binary tree.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We implement the baseline system, which Klein and Manning (2002) use for their grammar induction experiments with induced part-of-speech tags.</S> | Reference Offset:  ['16','164'] | Reference Text:  <S sid = 16 ssid = >We followed this for most experiments, but in section 4.3, we use distributionally induced tags as input.</S><S sid = 164 ssid = >Figure 8 shows the performance with induced tags compared to correct tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We follow Klein and Manning (2002) in using K means to cluster the d dimensional word vectors into parts-of-speech.</S> | Reference Offset:  ['15','161'] | Reference Text:  <S sid = 15 ssid = >Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = 161 ssid = >The resulting vectors were clustered into 200 word classes by a weighted k-means algorithm, and then grammar induction operated over these classes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We chose the baseline system primarily to match previous evaluations of grammar induction using induced tags (Klein and Manning, 2002).</S> | Reference Offset:  ['163','164'] | Reference Text:  <S sid = 163 ssid = >Nevertheless, using these tags as input still gave induced structure substantially above right-branching.</S><S sid = 164 ssid = >Figure 8 shows the performance with induced tags compared to correct tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Klein and Manning (2002) present a generative model for inducing constituent boundaries from part-of-speech tagged text.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >A Generative Constituent-Context Model For Improved Grammar Induction</S><S sid = 1 ssid = >We present a generative distributional model for the unsupervised induction of natural language syntax which explicitly models constituent yields and contexts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P02-1017.txt | Citing Article:  C08-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We evaluate induced constituency trees against those of the Penn Treebank using the versions of unlabeled precision, recall, and F-score used by Klein and Manning (2002).</S> | Reference Offset:  ['36','101'] | Reference Text:  <S sid = 36 ssid = >By the F1 measure used in the experiments in section 4, an induced dependency PCFG scores 48.2, compared to a score of 82.1 for a supervised PCFG read from local trees of the treebank.</S><S sid = 101 ssid = >Evaluation was done by measuring unlabeled precision, recall, and their harmonic mean F1 against the treebank parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P02-1017.txt | Citing Article:  P07-3008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Evaluation of the algorithm is done according to PARSEVAL, except for a few changes that are also proposed by Klein and Manning (2002).</S> | Reference Offset:  ['82','101'] | Reference Text:  <S sid = 82 ssid = >We now essentially have our induction algorithm.</S><S sid = 101 ssid = >Evaluation was done by measuring unlabeled precision, recall, and their harmonic mean F1 against the treebank parses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P02-1017.txt | Citing Article:  P07-3008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Still, Klein and Manning (2002) and Bod (2006) stick to tag-based models.</S> | Reference Offset:  ['15','180'] | Reference Text:  <S sid = 15 ssid = >Klein and Manning (2001b) and Clark (2001) take treebank part-of-speech sequences as input.</S><S sid = 180 ssid = >The induction algorithm combines the benefits of EM-based parameter search and distributional clustering methods.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P02-1017.txt | Citing Article:  P06-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary stengths: it identifies brackets but does not label them.</S> | Reference Offset:  ['9','121'] | Reference Text:  <S sid = 9 ssid = >Here, we improve on that model in several ways.</S><S sid = 121 ssid = >The top row of figure 8 shows the recall of nontrivial brackets, split according the brackets’ labels in the treebank.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P02-1017.txt | Citing Article:  P06-1111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Finally, we intersect the feature-augmented PCFG with the CCM model of Klein and Manning (2002), a high quality bracketing model.</S> | Reference Offset:  ['114','168'] | Reference Text:  <S sid = 114 ssid = >Especially since the CCM does not model recursive structure explicitly, one might be concerned that the high overall accuracy is due to a high accuracy on short-span constituents.</S><S sid = 168 ssid = >The conditional model of Klein and Manning (2001b) had the drawback that the variance of final F1, and qualitative grammars found, was fairly high, depending on small differences in first-round random parses.</S> | Discourse Facet:  NA | Annotator: Automatic


