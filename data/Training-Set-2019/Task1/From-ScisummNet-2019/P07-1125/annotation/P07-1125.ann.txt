Citance Number: 1 | Reference Article:  P07-1125.txt | Citing Article:  W08-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Medlock and Briscoe (2007) proposed a weakly supervised setting for hedge classification in scientific texts where the aim is to minimise human supervision needed to obtain an adequate amount of training data.</S> | Reference Offset:  ['0','111'] | Reference Text:  <S sid = 0 ssid = >Weakly Supervised Learning for Hedge Classification in Scientific Literature</S><S sid = 111 ssid = >In many cases hedge classification is challenging even for a human annotator.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1125.txt | Citing Article:  W08-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The authors are only aware of the following related corpora: the Hedge classification corpus (Medlock and Briscoe, 2007), which has been annotated for hedge cues (at the sentence level) and consists of five full biological research papers (1537 sentences).</S> | Reference Offset:  ['3','40'] | Reference Text:  <S sid = 3 ssid = >We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.</S><S sid = 40 ssid = >We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1125.txt | Citing Article:  W08-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >5 articles from FlyBase (the same data were used by Medlock and Briscoe (2007) for evaluating sentence-level hedge classifiers) and 4 articles from the open access BMC Bioinformatics website were downloaded and annotated for negations, uncertainty and their scopes.</S> | Reference Offset:  ['44','85'] | Reference Text:  <S sid = 44 ssid = >Relative F1 (Frel 1 ) and Cohen’s Kappa (n) were then used to quantify the level of agreement.</S><S sid = 85 ssid = >After each learning iteration, we compute the precision/recall BEP for the spec class using both classifiers trained on the current labelled data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1125.txt | Citing Article:  D11-1070.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Solving the sentence level task, Medlock and Briscoe (2007) used single words as input features in order to classify sentences from biological articles as speculative or non speculative.</S> | Reference Offset:  ['19','76'] | Reference Text:  <S sid = 19 ssid = >Riloff et al. Given a collection of sentences, S, the task is to (2003) explore bootstrapping techniques to identify label each sentence as either speculative or nonsubjective nouns and subsequently classify subjec- speculative (spec or nspec henceforth).</S><S sid = 76 ssid = >As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1125.txt | Citing Article:  W10-3003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >A misinterpretation of the BioScope paper (Szarvas et al, 2008) led us to believe that five of the nine full articles in the training data were annotated using the guidelines of Medlock and Briscoe (2007).</S> | Reference Offset:  ['25','43'] | Reference Text:  <S sid = 25 ssid = >This idea was for- Light et al. (item 1) and introduce a set of further malised by Blum and Mitchell (1998) in their guidelines to help elucidate various ‘grey areas’ and presentation of co-training.</S><S sid = 43 ssid = >The two annotators labelled the data independently using the guidelines outlined in section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1125.txt | Citing Article:  D09-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Medlock and Briscoe (2007) extended the work of Light et al (2004) by refining their annotation guidelines and creating a publicly available data set (FlyBase data set) for speculative sentence classification.</S> | Reference Offset:  ['22','25'] | Reference Text:  <S sid = 22 ssid = >prove annotation consistency, we have developed a 2.2 Weakly Supervised Learning new set of guidelines, building on the work of Light Recent years have witnessed a significant growth et al. (2004).</S><S sid = 25 ssid = >This idea was for- Light et al. (item 1) and introduce a set of further malised by Blum and Mitchell (1998) in their guidelines to help elucidate various ‘grey areas’ and presentation of co-training.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1125.txt | Citing Article:  D09-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Szarvas (2008) extended the weakly supervised machine learning methodology of Medlock and Briscoe (2007) by applying feature selection to reduce the number of candidate keywords, by using limited manual supervision to filter the features, and by extending the feature representation with bigrams and trigrams.</S> | Reference Offset:  ['1','72'] | Reference Text:  <S sid = 1 ssid = >We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.</S><S sid = 72 ssid = >The class priors can be estimated based on the relative distribution sizes derived from the current training sets: where |S |is the number of samples in training set S. If we assume feature independence, which as we will see for our task is not as gross an approximation as it may at first seem, we can simplify the classconditional likelihood in the well known manner: and then (estimate the likelihood for each feature: where f(x, S) is the number of samples in training set S in which feature x is present, and a is a universal smoothing constant, scaled by the class prior.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1125.txt | Citing Article:  D09-1145.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In addition, by following the annotation guidelines of Medlock and Briscoe (2007), Szarvas (2008) made available the BMC Bioinformatics data set, by annotating four full text papers from the open access BMC Bioinformatics website.</S> | Reference Offset:  ['40','43'] | Reference Text:  <S sid = 40 ssid = >We annotated six of the papers to form a test set with a total of 380 spec sentences and 1157 nspec sentences, and randomly selected 300,000 sentences from the remaining papers as training data for the weakly supervised learner.</S><S sid = 43 ssid = >The two annotators labelled the data independently using the guidelines outlined in section 3.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1125.txt | Citing Article:  W10-3023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In related work, Szarvas (2008) extended the methodology of Medlock and Briscoe (2007), and presented a hedge detection method in biomedical texts with a weakly supervised selection of keywords.</S> | Reference Offset:  ['0','1'] | Reference Text:  <S sid = 0 ssid = >Weakly Supervised Learning for Hedge Classification in Scientific Literature</S><S sid = 1 ssid = >We investigate automatic classification of speculative language (‘hedging’), in biomedical text using weakly supervised machine learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1125.txt | Citing Article:  W10-3005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For speculative sentences detection, Medlock and Briscoe (2007) report their approach based on weakly supervised learning.</S> | Reference Offset:  ['0','68'] | Reference Text:  <S sid = 0 ssid = >Weakly Supervised Learning for Hedge Classification in Scientific Literature</S><S sid = 68 ssid = >In this section, we derive a simple probabilistic model for acquiring training data for a given learning task, and use it to motivate our approach to weakly supervised hedge classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1125.txt | Citing Article:  W10-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Medlock and Briscoe (2007) also used single words as input features in order to classify sentences from scientific articles in biomedical domain as speculative or non-speculative.</S> | Reference Offset:  ['19','76'] | Reference Text:  <S sid = 19 ssid = >Riloff et al. Given a collection of sentences, S, the task is to (2003) explore bootstrapping techniques to identify label each sentence as either speculative or nonsubjective nouns and subsequently classify subjec- speculative (spec or nspec henceforth).</S><S sid = 76 ssid = >As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1125.txt | Citing Article:  W10-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Medlock and Briscoe (2007) use a similar baseline as the one adopted by Light et al (2004), i.e. a naive algorithm based on substring matching, but with a different list of terms to match against.</S> | Reference Offset:  ['16','96'] | Reference Text:  <S sid = 16 ssid = >Banko and Brill (2001) use ‘bagging’ and agreeThe most clearly relevant study is Light et al. ment to measure confidence on unlabelled samples, (2004) where the focus is on introducing the prob- and more recently McClosky et al.</S><S sid = 96 ssid = >As a baseline classifier we use the substring matching technique of (Light et al., 2004), which labels a sentence as spec if it contains one or more of the following: suggest, potential, likely, may, at least, in part, possibl, further investigation, unlikely, putative, insights, point toward, promise and propose.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1125.txt | Citing Article:  W10-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However Medlock and Briscoe (2007) note that their model is unsuccessful in identifying assertive statements of knowledge paucity which are generally marked rather syntactically than lexically.</S> | Reference Offset:  ['35','108'] | Reference Text:  <S sid = 35 ssid = >Statement of knowledge paucity. ture selection procedure.</S><S sid = 108 ssid = >For example, the learning models were unsuccessful in identifying assertive statements of knowledge paucity, eg: There is no clear evidence for cytochrome c release during apoptosis in C elegans or Drosophila.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1125.txt | Citing Article:  W10-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Kilicoglu and Bergler (2008) did experiments on the same dataset as Medlock and Briscoe (2007) and their experimental results proved that the classification accuracy can be improved by approximately 9% (from an F-score of 76% to an F-score of 85%) if syntactic and semantic information are incorporated.</S> | Reference Offset:  ['101','103'] | Reference Text:  <S sid = 101 ssid = >The baseline classifier achieves a BEP of 0.60 while both classifiers using our learning model reach approximately 0.76 BEP with little to tell between them.</S><S sid = 103 ssid = >These results suggest that performance may be enhanced when the learning and classification tasks are carried out by different models.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1125.txt | Citing Article:  W10-3004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The experiments run by Medlock (2008) on the same dataset as Medlock and Briscoe (2007) show that adding features based on part-of speech tags to a bag-of-words input representation can slightly improve the accuracy, but the improvements are marginal and not statistically significant.</S> | Reference Offset:  ['57','79'] | Reference Text:  <S sid = 57 ssid = >In this study we use single terms as features, based on the intuition that many hedge cues are single terms (suggest, likely etc.) and due to the success of ‘bag of words’ representations in many classification tasks to date.</S><S sid = 79 ssid = >This has the dual benefit of removing irrelevant features and also reducing dependence between features, as the selected features will often be nonlocal and thus not too tightly correlated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1125.txt | Citing Article:  W10-3017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Other early work focused on semi supervised learning due to a lack of annotated datasets (Medlock and Briscoe, 2007).</S> | Reference Offset:  ['0','15'] | Reference Text:  <S sid = 0 ssid = >Weakly Supervised Learning for Hedge Classification in Scientific Literature</S><S sid = 15 ssid = >Early work direct relevance to the task of classifying speculative by Yarowsky (1995) falls within this framework. language from an NLP/ML perspective.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1125.txt | Citing Article:  W10-3017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We can then use the large amounts of unannotated sentences that are available to extract n-gram features that have high uncertainty class conditional probability and add them to our training set with those features labeled as hedges as described in Medlock and Briscoe (2007).</S> | Reference Offset:  ['60','79'] | Reference Text:  <S sid = 60 ssid = >Firstly, due to the relative sparsity of hedge cues, most samples contain large numbers of irrelevant features.</S><S sid = 79 ssid = >This has the dual benefit of removing irrelevant features and also reducing dependence between features, as the selected features will often be nonlocal and thus not too tightly correlated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1125.txt | Citing Article:  W10-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Medlock and Briscoe (2007) used single words as input feature sin order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples.</S> | Reference Offset:  ['19','76'] | Reference Text:  <S sid = 19 ssid = >Riloff et al. Given a collection of sentences, S, the task is to (2003) explore bootstrapping techniques to identify label each sentence as either speculative or nonsubjective nouns and subsequently classify subjec- speculative (spec or nspec henceforth).</S><S sid = 76 ssid = >As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1125.txt | Citing Article:  W10-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Szarvas (2008) extended the methodology of Medlock and Briscoe (2007) to use n-gram features and a semi-supervised selection of the keyword features.</S> | Reference Offset:  ['79','90'] | Reference Text:  <S sid = 79 ssid = >This has the dual benefit of removing irrelevant features and also reducing dependence between features, as the selected features will often be nonlocal and thus not too tightly correlated.</S><S sid = 90 ssid = >We use m=5 based on the intuition that five is a rough upper bound on the number of hedge cue features likely to occur in any one sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1125.txt | Citing Article:  W12-3805.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Early work on speculative language detection tried to classify a sentence either as speculative or non-speculative (see, for example, Medlock and Briscoe (2007)).</S> | Reference Offset:  ['15','76'] | Reference Text:  <S sid = 15 ssid = >Early work direct relevance to the task of classifying speculative by Yarowsky (1995) falls within this framework. language from an NLP/ML perspective.</S><S sid = 76 ssid = >As discussed earlier, the speculative/non-speculative distinction hinges on the presence or absence of a few hedge cues within the sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


