<PAPER>
  <S sid="0">Optimal Reduction of Rule Length in Linear Context-Free Rewriting Systems</S>
  <ABSTRACT>
    <S sid="1" ssid="1">Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation.</S>
    <S sid="2" ssid="2">The parsing complexity of an is exponential in both the of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, In this paper, we present an algorithm that transforms an LCFRS into a strongly equivalent form in which productions have rank at most and has minimal fan-out.</S>
    <S sid="3" ssid="3">Our results generalize previous work on Synchronous Context-Free Grammar, and are particularly relevant for machine translation from or to languages that require syntactic analyses with discontinuous constituents.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="4" ssid="1">There is currently considerable interest in syntaxbased models for statistical machine translation that are based on the extraction of a synchronous grammar from a corpus of word-aligned parallel texts; see for instance Chiang (2007) and the references therein.</S>
    <S sid="5" ssid="2">One practical problem with this approach, apart from the sheer number of the rules that result from the extraction procedure, is that the parsing complexity of all synchronous formalisms that we are aware of is exponential in the rank of a rule, defined as the number of nonterminals on the righthand side.</S>
    <S sid="6" ssid="3">Therefore, it is important that the rules of the extracted grammar are transformed so as to minimise this quantity.</S>
    <S sid="7" ssid="4">Not only is this beneficial in terms of parsing complexity, but smaller rules can also improve a translation model&#8217;s ability to generalize to new data (Zhang et al., 2006).</S>
    <S sid="8" ssid="5">Optimal algorithms exist for minimising the size of rules in a Synchronous Context-Free Grammar (SCFG) (Uno and Yagiura, 2000; Zhang et al., 2008).</S>
    <S sid="9" ssid="6">However, the SCFG formalism is limited to modelling word-to-word alignments in which a single continuous phrase in the source language is aligned with a single continuous phrase in the target language; as defined below, this amounts to saying that SCFG have a fan-out of 2.</S>
    <S sid="10" ssid="7">This restriction appears to render SCFG empirically inadequate.</S>
    <S sid="11" ssid="8">In particular, Wellington et al. (2006) find that the coverage of a translation model can increase dramatically when one allows a bilingual phrase to stretch out over three rather than two continuous substrings.</S>
    <S sid="12" ssid="9">This observation is in line with empirical studies in the context of dependency parsing, where the need for formalisms with higher fan-out has been observed even in standard, single language texts (Kuhlmann and Nivre, 2006).</S>
    <S sid="13" ssid="10">In this paper, we present an algorithm that computes optimal decompositions of rules in the formalism of Linear Context-Free Rewriting Systems (LCFRS) (Vijay-Shanker et al., 1987).</S>
    <S sid="14" ssid="11">LCFRS was originally introduced as a generalization of several so-called mildly context-sensitive grammar formalisms.</S>
    <S sid="15" ssid="12">In the context of machine translation, LCFRS is an interesting generalization of SCFG because it does not restrict the fan-out to 2, allowing productions with arbitrary fan-out (and arbitrary rank).</S>
    <S sid="16" ssid="13">Given an LCFRS, our algorithm computes a strongly equivalent grammar with rank 2 and minimal increase in fan-out.1 In this context, strong equivalence means that the derivations of the original grammar can be reconstructed using some simple homomorphism (c.f.</S>
    <S sid="17" ssid="14">Nijholt, 1980).</S>
    <S sid="18" ssid="15">Our contribution is significant because the existing algorithms for decomposing SCFG, based on Uno and Yagiura (2000), cannot be applied to LCFRS, as they rely on the crucial property that components of biphrases are strictly separated in the generated string: Given a pair of synchronized nonterminal symbols, the material derived from the source nonterminal must precede the material derived from the target nonterminal, or vice versa.</S>
    <S sid="19" ssid="16">The problem that we solve has been previously addressed by Melamed et al. (2004), but in contrast to our result, their algorithm does not guarantee an optimal (minimal) increase in the fanout of the resulting grammar.</S>
    <S sid="20" ssid="17">However, this is essential for the practical applicability of the transformed grammar, as the parsing complexity of LCFRS is exponential in both the rank and the fan-out.</S>
    <S sid="21" ssid="18">Structure of the paper The remainder of the paper is structured as follows.</S>
    <S sid="22" ssid="19">Section 2 introduces the terminology and notation that we use for LCFRS.</S>
    <S sid="23" ssid="20">In Section 3, we present the technical background of our algorithm; the algorithm itself is discussed in Section 4.</S>
    <S sid="24" ssid="21">Section 5 concludes the paper by discussing related work and open problems.</S>
    <S sid="25" ssid="22">General notation The set of non-negative integers is denoted by N. For i, j &#8712; N, we write [i, j] to denote the interval { k &#8712; N  |i &#8804; k &#8804; j }, and use [i] as a shorthand for [1, i].</S>
    <S sid="26" ssid="23">Given an alphabet V , we write V * for the set of all (finite) strings over V .</S>
  </SECTION>
  <SECTION title="2 Preliminaries" number="2">
    <S sid="27" ssid="1">We briefly summarize the terminology and notation that we adopt for LCFRS; for detailed definitions, see Vijay-Shanker et al. (1987).</S>
    <S sid="28" ssid="2">Let V be an alphabet.</S>
    <S sid="29" ssid="3">For natural numbers r &#8805; 0 and f, f1, ... , fr &#8805; 1, a function is called a linear, non-erasing function over V of type f1 &#215; &#183; &#183; &#183; &#215; fr &#8594; f, if it can be defined by an equation of the form where Qg = h&#945;g,1, ... , &#945;g,fi is an f-tuple of strings over the variables on the left-hand side of the equation and symbols in V that contains exactly one occurrence of each variable.</S>
    <S sid="30" ssid="4">We call the value r the rank of g, the value f its fan-out, and write &#961;(g) and co(g), respectively, to denote these quantities.</S>
    <S sid="31" ssid="5">Note that, if we assume the variables on the lefthand side of the defining equation of g to be named according to the specific schema given above, then g is uniquely determined by Qg.</S>
    <S sid="32" ssid="6">A linear context-free rewriting system (LCFRS) is a construct G = (VN, VT, P, 5), where: VN is an alphabet of nonterminal symbols in which each symbol A &#8712; VN is associated with a value co(A), called its fan-out; VT is an alphabet of terminal symbols; 5 &#8712; N is a distinguished start symbol with co(5) = 1; and P is a set of productions of the form where A, B1, ... , Br &#8712; VN, and g is a linear, nonerasing function over the terminal alphabet VT of type co(B1) &#215; &#183; &#183; &#183; &#215; co(Br) &#8594; co(A).</S>
    <S sid="33" ssid="7">In a derivation of an LCFRS, the production p can be used to transform a sequence of r tuples of strings, generated by the nonterminals B1, ... , Br, into a single co(A)-tuple of strings, associated with the nonterminal A.</S>
    <S sid="34" ssid="8">The values &#961;(g) and co(g) are called the rank and fan-out of p, respectively, and we write &#961;(p) and co(p), respectively, to denote these quantities.</S>
    <S sid="35" ssid="9">The rank and fan-out of G, written &#961;(G) and co(G), respectively, are the maximum rank and fan-out among all of its productions.</S>
    <S sid="36" ssid="10">Given that co(5) = 1, a derivation will associate 5 with a set of one-component tuples of strings over VT; this forms the string language generated by G. Example 1 The following LCFRS generates the string language { anbncndn  |n &#8712; N}.</S>
    <S sid="37" ssid="11">We only specify the set of productions; the remaining components of the grammar are obvious from that.</S>
    <S sid="38" ssid="12">The functions g1 and g2 have rank 1; the function g3 has rank 0.</S>
    <S sid="39" ssid="13">The functions g2 and g3 have fan-out 2; the function g1 has fan-out 1.</S>
    <S sid="40" ssid="14">&#10065;</S>
  </SECTION>
  <SECTION title="3 Technical background" number="3">
    <S sid="41" ssid="1">The general idea behind our algorithm is to replace each production of an LCFRS with a set of &#8220;shorter&#8221; productions that jointly are equivalent to the original production.</S>
    <S sid="42" ssid="2">Before formalizing this idea, we first introduce a specialized representation for the productions of an LCFRS.</S>
    <S sid="43" ssid="3">We distinguish between occurrences of symbols within a string by exploiting two different notations.</S>
    <S sid="44" ssid="4">Let &#945; = a1a2 &#183; &#183; &#183; an be a string.</S>
    <S sid="45" ssid="5">The occurrence ai in &#945; can be denoted by means of its position index i &#8712; [n], or else by means of its two (left and right) endpoints, i &#8722;1 and i; here, the left (right) endpoint denotes a boundary between occurrence ai and the previous (subsequent) occurrence, or the beginning (end) of the string &#945;.</S>
    <S sid="46" ssid="6">Similarly, a substring ai &#183; &#183; &#183; aj of &#945; with i &#8804; j can be denoted by the positions i, i + 1, ... , j of its occurrences, or else by means of its left and right endpoints, i &#8722; 1 and j.</S>
    <S sid="47" ssid="7">For the remainder of this section, let us fix an Let $ be a fresh symbol that does not occur in G. We define the characteristic string of the production p as and the variable string of p as the string &#963;N(p) obtained from &#963;(p) by removing all the occurrences of symbols in VT.</S>
    <S sid="48" ssid="8">Example 2 We will illustrate the concepts introduced in this section using the concrete production Let I be an index set, I &#8838; [r].</S>
    <S sid="49" ssid="9">Consider the set B of occurrences Bi in the right-hand side of p such that i &#8712; I.2 We define the position set of B, denoted by &#928;B, as the set of all positions 1 &#8804; j &#8804; |&#963;N(p)| such that the jth symbol in &#963;N(p) is a variable of the form xi,h, for i &#8712; I and some h &#8805; 1.</S>
    <S sid="50" ssid="10">Example 3 Some position sets of p0 are A position set &#928;B can be uniquely expressed as the union of f &#8805; 1 intervals [l1 + 1, r1], ... , [lf + 1, rf] such that ri&#8722;1 &lt; li for every 1 &lt; i &#8804; f. Thus we define the set of endpoints of &#928;B as The quantity f is called the fan-out of &#928;B, written &#981;(&#928;B).</S>
    <S sid="51" ssid="11">Notice that the fan-out of a position set &#928;{B} does not necessarily coincide with the fan-out of the non-terminal B in the underlying LCFRS.</S>
    <S sid="52" ssid="12">A set with 2f endpoints always corresponds to a position set of fan-out f. Example 4 For our running example, we have &#916;{B1} = {0,1, 2, 3}, &#916;{B2} = {1, 2}, &#916;{B3} = {4, 6}.</S>
    <S sid="53" ssid="13">Consequently, the fan-out of &#916;{B1} is 2, and the fan-out of &#916;{B2} and &#916;{B3} is 1.</S>
    <S sid="54" ssid="14">Notice that the fan-out of the non-terminal B3 is 2.</S>
    <S sid="55" ssid="15">&#10065; We drop B from &#928;B and &#916;B whenever this set is understood from the context or it is not relevant.</S>
    <S sid="56" ssid="16">Given a set of endpoints &#916; = {i1,... , i2f} with i1 &lt; &#183; &#183; &#183; &lt; i2f, we obtain its corresponding position set by calculating the closure of &#916;, defined as 2To avoid clutter in our examples, we abuse the notation by not making an explicit distinction between nonterminals and occurrences of nonterminals in productions.</S>
    <S sid="57" ssid="17">Assume that r &gt; 2.</S>
    <S sid="58" ssid="18">The reduction of p by the nonterminal occurrences Br&#8722;1, Br is the ordered pair of productions (p1, p2) that is defined as follows.</S>
    <S sid="59" ssid="19">Let &#947;1, ... ,&#947;n be the maximal substrings of &#963;(p) that contain only variables xi,j with r&#8212; 1 G i G r and terminal symbols, and at least one variable.</S>
    <S sid="60" ssid="20">Then where X is a fresh nonterminal symbol, the characteristic string &#963;(p1) is the string obtained from &#963;(p) by replacing each substring &#947;i by the variable xr&#8722;1,i, and the characteristic string &#963;(p2) is the string &#947;1$ &#183;&#183;&#183; $&#947;n.</S>
    <S sid="61" ssid="21">Note that the defining equations of neither g1 nor g2 are in the specific form discussed in Section 2.1; however, they can be brought into this form by a consistent renaming of the variables.</S>
    <S sid="62" ssid="22">We will silently assume this renaming to take place.</S>
    <S sid="63" ssid="23">Example 5 The reduction of p0 by the nonterminal occurrences B2 and B3 has p1 : A &#8212;* g1(B1, X) and p2 : X &#8212;* g2(B2, B3) with or, after renaming and in standard notation, It is easy to check that a reduction provides us with a pair of productions that are equivalent to the original production p, in terms of generative capacity, since for all tuples of strings generated from the nonterminals B1, ... , Br, respectively.</S>
    <S sid="64" ssid="24">Note also that the fanout of production p1 equals the fan-out of p. However, the fan-out of p2 (the value n) may be greater than the fan-out of p, depending on the way variables are arranged in &#963;(p).</S>
    <S sid="65" ssid="25">Thus, a reduction does not necessarily preserve the fan-out of the original production.</S>
    <S sid="66" ssid="26">In the worst case, the fan-out of p2 can be as large as &#981;(Br&#8722;1) + &#981;(Br).</S>
    <S sid="67" ssid="27">We have defined reductions only for the last two occurrences of nonterminals in the right-hand side of a production p. However, it is easy to see that we can also define the concept for two arbitrary (not necessarily adjacent) occurrences of nonterminals, at the cost of making the notation more complicated.</S>
  </SECTION>
  <SECTION title="4 The algorithm" number="4">
    <S sid="68" ssid="1">Let G be an LCFRS with &#981;(G) = f and &#961;(G) = r, and let f0 &gt; f be a target fan-out.</S>
    <S sid="69" ssid="2">We will now present an algorithm that computes an equivalent LCFRS G0 of fan-out at most f0 whose rank is at most 2, if such an LCFRS exists in the first place.</S>
    <S sid="70" ssid="3">The algorithm works by exhaustively reducing all productions in G. Given an LCFRS production p, a naive algorithm to compute an equivalent set of productions whose rank is at most 2 is given in Figure 1.</S>
    <S sid="71" ssid="4">By applying this algorithm to all the productions in the LCFRS G, we can obtain an equivalent LCFRS with rank 2.</S>
    <S sid="72" ssid="5">We will call such an LCFRS a binarization of G. The fan-out of the obtained LCFRS will depend on the nonterminals that we choose for the reductions in line 5.</S>
    <S sid="73" ssid="6">It is not difficult to see that, in the worst case, the resulting fan-out can be as high as Fr2] &#183; f. This occurs when we choose Fr2] nonterminals with fan-out f that have associated variables in the string &#963;N(p) that do not occur at consecutive positions.</S>
    <S sid="74" ssid="7">The algorithm that we develop in Section 4.3 improves on the naive algorithm in that it can be exploited to find a sequence of reductions that results in a binarization of G that is optimal, i.e., leads to an LCFRS with minimal fan-out.</S>
    <S sid="75" ssid="8">The algorithm is based on a technical concept called adjacency.</S>
    <S sid="76" ssid="9">Let p be some production in the LCFRS G, and let &#916;1, &#916;2 be sets of endpoints, associated with some sets of nonterminal occurrences in p. We say that &#916;1 and &#916;2 overlap if the intersection of their closures is nonempty, that is, if [&#916;1]&#8745;[&#916;2] =6 &#8709;.</S>
    <S sid="77" ssid="10">Overlapping holds if and only if the associated sets of nonterminal occurrences are not disjoint.</S>
    <S sid="78" ssid="11">If &#916;1 and &#916;2 do not overlap, we define their merge as It is easy to see that [&#8853;(&#916;1, &#916;2)] = [&#916;1] &#8746; [&#916;2].</S>
    <S sid="79" ssid="12">We say that &#916;1 and &#916;2 are adjacent for a given fanout f, written &#916;1 &#8596;f &#916;2, if &#916;1 and &#916;2 do not overlap, and co([&#8853;(&#916;1, &#916;2)]) &#8804; f. Example 6 For the production p0 from Example 2, we have &#8853;(&#916;{B1}, &#916;{B2}) = {0, 3}, showing that &#916;{B1} &#8596;1 &#916;{B2}.</S>
    <S sid="80" ssid="13">Similarly, we have &#8853;(&#916;{B1}, &#916;{B3}) = {0, 1, 2, 3, 4, 6} , showing that &#916;{B1} &#8596;3 &#916;{B3}, but that neither &#916;{B1} &#8596;2 &#916;{B3} nor &#916;{B1} &#8596;1 &#916;{B3} holds.</S>
    <S sid="81" ssid="14">&#10039; The adjacency-based binarization algorithm is given in Figure 2.</S>
    <S sid="82" ssid="15">It starts with a working set containing the endpoint sets corresponding to each nonterminal occurrence in the input production p. Reductions of p are only explored for nonterminal occurrences whose endpoint sets are adjacent for the target fan-out f0, since reductions not meeting this constraint would produce productions with fan-out greater than f0.</S>
    <S sid="83" ssid="16">Each reduction explored by the algorithm produces a new endpoint set, associated to the fresh nonterminal that it introduces, and this new endpoint set is added to the working set and potentially used in further reductions.</S>
    <S sid="84" ssid="17">From the definition of the adjacency relation &#8596;f, it follows that at lines 9 and 10 of BOUNDEDBINARIZATION we only pick up reductions for p that do not exceed the fan-out bound of f0.</S>
    <S sid="85" ssid="18">This implies soundness for our algorithm.</S>
    <S sid="86" ssid="19">Completeness means that the algorithm fails only if there exists no binarization for p of fan-out not greater than f0.</S>
    <S sid="87" ssid="20">This property is intuitive if one observes that our algorithm is a specialization of standard algorithms for the computation of the closure of binary relations.</S>
    <S sid="88" ssid="21">A formal proof of this fact is rather long and tedious, and will not be reported here.</S>
    <S sid="89" ssid="22">We notice that there is a very close similarity between algorithm BOUNDED-BINARIZATION and the deduction procedure proposed by Shieber et al. (1995) for parsing.</S>
    <S sid="90" ssid="23">We discuss this more at length in Section 5.</S>
    <S sid="91" ssid="24">Note that we have expressed the algorithm as a decision function that will return true if there exists a binarization of p with fan-out not greater than f0, and false otherwise.</S>
    <S sid="92" ssid="25">However, the algorithm can easily be modified to return a reduction producing such a binarization, by adding to each endpoint set &#916; &#8712; workingSet two pointers to the adjacent endpoint sets that were used to obtain it.</S>
    <S sid="93" ssid="26">If the algorithm is successful, the tree obtained by following these pointers from the final endpoint set &#916;{B1,...,B&#961;(p)} &#8712; workingSet gives us a tree of reductions that will produce a binarization of p with fan-out not greater than f0, where each node labeled with the set &#916;{Bi} corresponds to the nonterminal BZ, and nodes labeled with other endpoint sets correspond to the fresh nonterminals created by the reductions.</S>
    <S sid="94" ssid="27">In order to implement BOUNDED-BINARIZATION, we can represent endpoint sets in a canonical way as 2f0-tuples of integer positions in ascending order, and with some special null value used to fill positions for endpoint sets with fan-out strictly smaller than f0.</S>
    <S sid="95" ssid="28">We will assume that the concrete null value is larger than any other integer.</S>
    <S sid="96" ssid="29">We also need to provide some appropriate representation for the set workingSet, in order to guarantee efficient performance for the membership test and the insertion operation.</S>
    <S sid="97" ssid="30">Both operations can be implemented in constant time if we represent workingSet as an (2&#215;f0)-dimensional table with Boolean entries.</S>
    <S sid="98" ssid="31">Each dimension is indexed by values in [0, n] plus our special null value; here n is the length of the string &#963;N(p), and thus n = O(|p|).</S>
    <S sid="99" ssid="32">However, this has the disadvantage of using space &#920;(n2f0), even in case workingSet is sparse, and is affordable only for quite small values of f0.</S>
    <S sid="100" ssid="33">Alternatively, we can more compactly represent workingSet as a trie data structure.</S>
    <S sid="101" ssid="34">This representation has size certainly smaller than 2f0 &#215; q, where q is the size of the set workingSet.</S>
    <S sid="102" ssid="35">However, both membership and insertion operations take now an amount of time O(2f0).</S>
    <S sid="103" ssid="36">We now analyse the time complexity of algorithm BOUNDED-BINARIZATION for inputs p and f0.</S>
    <S sid="104" ssid="37">We first focus on the while-loop at lines 7 to 13.</S>
    <S sid="105" ssid="38">As already observed, the number of possible endpoint sets is bounded by O(n2f0).</S>
    <S sid="106" ssid="39">Furthermore, because of the test at line 11, no endpoint set is ever inserted into the agenda variable more than once in a single run of the algorithm.</S>
    <S sid="107" ssid="40">We then conclude that our while-loop cycles a number of times O(n2f0).</S>
    <S sid="108" ssid="41">We now focus on the choice of the endpoint set &#916;1 in the inner for-loop at lines 9 to 13.</S>
    <S sid="109" ssid="42">Let us fix &#916; as in line 8.</S>
    <S sid="110" ssid="43">It is not difficult to see that any &#916;1 with This means that, for each &#916; coming out of the agenda, at line 9 we can choose all endpoint sets &#916;1 such that &#916;1 &#8596;f0 &#916; by performing the following steps: We claim that, in the above steps, the number of involved endpoints does not exceed 3f0.</S>
    <S sid="111" ssid="44">To see this, we observe that from (2) we can derive |I |&#8805; &#981;(&#916;) + &#981;(&#916;1) &#8722; f0.</S>
    <S sid="112" ssid="45">The total number of (distinct) endpoints in a single iteration step is as claimed.</S>
    <S sid="113" ssid="46">Since each endpoint takes values in the set [0, n], we have a total of O(n3f0) different choices.</S>
    <S sid="114" ssid="47">For each such choice, we need to classify an endpoint as belonging to either &#916;\I, &#916;1\I, or I.</S>
    <S sid="115" ssid="48">This amounts to an additional O(33f0) different choices.</S>
    <S sid="116" ssid="49">Overall, we have a total number of O((3n)3f0) different choices.</S>
    <S sid="117" ssid="50">For each such choice, the test for membership in workingSet for &#916;1 takes constant time in case we use a multi-dimensional table, or else O(|p|) in case we use a trie.</S>
    <S sid="118" ssid="51">The adjacency test and the merge operations can easily be carried out in time O(|p|).</S>
    <S sid="119" ssid="52">Putting all of the above observations together, and using the already observed fact that n = O(|p|), we can conclude that the total amount of time required by the while-loop at lines 7 to 13 is bounded by O(|p |&#183; (3|p|)3f0), both under the assumption that workingSet is represented as a multi-dimensional table or as a trie.</S>
    <S sid="120" ssid="53">This is also a bound on the running time of the whole algorithm.</S>
    <S sid="121" ssid="54">The algorithm defined in Section 4.3 can be used to binarize an LCFRS in such a way that each rule in the resulting binarization has the minimum possible fan-out.</S>
    <S sid="122" ssid="55">This can be done by applying the BOUNDED-BINARIZATION algorithm to each production p, until we find the minimum value for the bound f' for which this algorithm finds a binarization.</S>
    <S sid="123" ssid="56">For a production with rank r and fan-out f, we know that this optimal value of f' must be in the interval [f, Fr2] &#183; f] because binarizing a production cannot reduce its fan-out, and the NAIVEBINARIZATION algorithm seen in Section 4.1 can binarize any production by increasing fan-out to Fr] &#183; f in the worst case.</S>
    <S sid="124" ssid="57">2 The simplest way of finding out the optimal value of f' for each production is by a sequential search starting with co(p) and going upwards, as in the algorithm in Figure 3.</S>
    <S sid="125" ssid="58">Note that the upper bound Fr2] &#183; f that we have given for f' guarantees that the whileloop in this algorithm always terminates.</S>
    <S sid="126" ssid="59">In the worst case, we may need f &#183; (Fr2] &#8722; 1) + 1 executions of the BOUNDED-BINARIZATION algorithm to find the optimal binarization of a production in G. This complexity can be reduced by changing the strategy to search for the optimal f': for example, we can perform a binary search within the interval [f, Fr2] &#183; f], rization in Llog(f &#183;(Fr2]&#8722;1)+1)]+1 executions of BOUNDED-BINARIZATION.</S>
    <S sid="127" ssid="60">However, this will not result in a practical improvement, since BOUNDEDBINARIZATION is exponential in the value of f' and the binary search will require us to run it on values of f' larger than the optimal in most cases.</S>
    <S sid="128" ssid="61">An intermediate strategy between the two is to apply exponential backoff to try the sequence of values f &#8722;1+2i (for i = 0, 1, 2 ...).</S>
    <S sid="129" ssid="62">When we find the first i such that BOUNDED-BINARIZATION does not fail, if i &gt; 0, we apply the same strategy to the interval [f&#8722;1+2i&#8722;1, f&#8722;2+2i], and we repeat this method to shrink the interval until BOUNDED-BINARIZATION does not fail for i = 0, giving us our optimal f'.</S>
    <S sid="130" ssid="63">With this strategy, the amount of executions of the algorithm that we need in the worst case is where w = f &#183; (Fr2] &#8722; 1) + 1, but we avoid using unnecessarily large values of f'.</S>
  </SECTION>
  <SECTION title="5 Discussion" number="5">
    <S sid="131" ssid="1">To conclude this paper, we now discuss a number of aspects of the results that we have presented, including various other pieces of research that are particularly relevant to this paper.</S>
    <S sid="132" ssid="2">The algorithm introduced in this paper can be used to transform an LCFRS into an equivalent form with rank 2.</S>
    <S sid="133" ssid="3">This will result into a more efficiently parsable LCFRS, since rank exponentially affects parsing complexity.</S>
    <S sid="134" ssid="4">However, we must take into account that parsing complexity is also influenced by fan-out.</S>
    <S sid="135" ssid="5">Our algorithm guarantees a minimal increase in fan-out.</S>
    <S sid="136" ssid="6">In practical cases it seems such an increase is quite small.</S>
    <S sid="137" ssid="7">For example, in the context of dependency parsing, both G&#180;omezRodr&#180;&#305;guez et al. (2009) and Kuhlmann and Satta (2009) show that all the structures in several wellknown non-projective dependency treebanks are binarizable without any increase in their fan-out.</S>
    <S sid="138" ssid="8">More in general, it has been shown by Seki et al. (1991) that parsing of LCFRS can be carried out in time 0(n|pM|), where n is the length of the input string and pM is the production in the grammar with largest size.3 Thus, there may be cases in which one has to find an optimal tradeoff between rank and fanout, in order to minimize the size of pM.</S>
    <S sid="139" ssid="9">This requires some kind of Viterbi search over the space of all possible binarizations, constructed as described at the end of Subsection 4.3, for some appropriate value of the fan-out f'.</S>
    <S sid="140" ssid="10">This paper has focussed on string-based LCFRS.</S>
    <S sid="141" ssid="11">As discussed in Vijay-Shanker et al. (1987), LCFRS provide a more general framework where the productions are viewed as generating a set of abstract derivation trees.</S>
    <S sid="142" ssid="12">These trees can be used to specify how structures other than tuples of strings are composed.</S>
    <S sid="143" ssid="13">For example, LCFRS derivation trees can be used to specify how the elementary trees of a Tree Adjoining Grammar can be composed to produced derived tree.</S>
    <S sid="144" ssid="14">However, the results in this paper also apply to non-string-based LCFRS, since by limiting attention to the terminal string yield of whatever structures are under consideration, the composition operations can be defined using the string-based version of LCFRS that is discussed here.</S>
    <S sid="145" ssid="15">The NAIVE-BINARIZATION algorithm given in Figure 1 is not novel to this paper: it is similar to an algorithm developed in Melamed et al. (2004) for generalized multitext grammars, a formalism weakly equivalent to LCFRS that has been introduced for syntax-based machine translation.</S>
    <S sid="146" ssid="16">However, the grammar produced by our algorithm has optimal (minimal) fan-out.</S>
    <S sid="147" ssid="17">This is an important improvement over the result in (Melamed et al., 2004), as this quantity enters into the parsing complexity of both multitext grammars and LCFRS as an exponential factor, and therefore must be kept as low as possible to ensure practically viable parsing.</S>
    <S sid="148" ssid="18">Rank reduction is also investigated in Nesson et al. (2008) for synchronous tree-adjoining grammars, a synchronous rewriting formalism based on tree-adjoining grammars Joshi and Schabes (1992).</S>
    <S sid="149" ssid="19">In this case the search space of possible reductions is strongly restricted by the tree structures specified by the formalism, resulting in simplified computation for the reduction algorithms.</S>
    <S sid="150" ssid="20">This feature is not present in the case of LCFRS.</S>
    <S sid="151" ssid="21">There is a close parallel between the technique used in the MINIMAL-BINARIZATION algorithm and deductive parsing techniques as proposed by Shieber et al. (1995), that are usually implemented by means of tabular methods.</S>
    <S sid="152" ssid="22">The idea of exploiting tabular parsing in production factorization was first expressed in Zhang et al. (2006).</S>
    <S sid="153" ssid="23">In fact, the particular approach presented here has been used to improve efficiency of parsing algorithms that use discontinuous syntactic models, in particular, nonprojective dependency grammars, as discussed in G&#180;omez-Rodr&#180;&#305;guez et al. (2009).</S>
    <S sid="154" ssid="24">The bounded binarization algorithm that we have presented has exponential run-time in the value of the input fan-out bound f'.</S>
    <S sid="155" ssid="25">It remains an open question whether the bounded binarization problem for LCFRS can be solved in deterministic polynomial time.</S>
    <S sid="156" ssid="26">Even in the restricted case of f' = cp(p), that is, when no increase in the fan-out of the input production is allowed, we do not know whether p can be binarized using only deterministic polynomial time in the value of p&#8217;s fan-out.</S>
    <S sid="157" ssid="27">However, our bounded binarization algorithm shows that the latter problem can be solved in polynomial time when the fan-out of the input LCFRS is bounded by some constant.</S>
    <S sid="158" ssid="28">Whether the bounded binarization problem can be solved in polynomial time in the value of the input bound f' is also an open problem in the restricted case of synchronous context-free grammars, a special case of an LCFRS of fan-out two with a strict separation between the two components of each nonterminal in the right-hand side of a production, as discussed in the introduction.</S>
    <S sid="159" ssid="29">An interesting analysis of this restricted problem can be found in Gildea and Stefankovic (2007).</S>
    <S sid="160" ssid="30">Acknowledgements The work of Carlos G&#180;omezRodr&#180;&#305;guez was funded by Ministerio de Educaci&#180;on y Ciencia and FEDER (HUM2007-66607-C04) and Xunta de Galicia (PGIDIT07SIN005206PR, INCITE08E1R104022ES, INCITE08ENA305025ES, INCITE08PXIB302179PR and Rede Galega de Procesamento da Linguaxe e Recuperaci&#180;on de Informaci&#180;on).</S>
    <S sid="161" ssid="31">The work of Marco Kuhlmann was funded by the Swedish Research Council.</S>
    <S sid="162" ssid="32">The work of Giorgio Satta was supported by MIUR under project PRIN No.</S>
    <S sid="163" ssid="33">2007TJNZRE 002.</S>
    <S sid="164" ssid="34">We are grateful to an anonymous reviewer for a very detailed review with a number of particularly useful suggestions.</S>
  </SECTION>
</PAPER>
