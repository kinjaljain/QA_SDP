<PAPER>
	<S sid="0">Heterogeneous Parsing via Collaborative Decoding</S><ABSTRACT>
		<S sid="1" ssid="1">There often exist multiple corpora for the same natural language processing (NLP)tasks.</S>
		<S sid="2" ssid="2">However, such corpora are generally used independently due to distinctions in annotation standards.</S>
		<S sid="3" ssid="3">For the purpose of full use of readily available human annotations, it is significant to simultaneously utilize multiple corpora of different annotation standards.</S>
		<S sid="4" ssid="4">In this paper, we focus on the challenge of con stituent syntactic parsing with treebanksof different annotations and propose a collaborative decoding (or co-decoding) ap proach to improve parsing accuracy byleveraging bracket structure consensus be tween multiple parsing decoders trainedon individual treebanks.</S>
		<S sid="5" ssid="5">Experimental results show the effectiveness of the proposed approach, which outperforms state of-the-art baselines, especially on long sentences.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="6" ssid="6">Recent years have seen extensive applications of machine learning methods to natural language processing problems.</S>
			<S sid="7" ssid="7">Typically, increase in the scale of training data boosts the performance ofmachine learning methods, which in turn en hances the quality of learning-based NLP systems (Banko and Brill, 2001).</S>
			<S sid="8" ssid="8">However, annotating data by human is expensive in time and labor.</S>
			<S sid="9" ssid="9">Forthis reason, human-annotated corpora are consid ered as the most valuable resource for NLP.In practice, there often exist more than one cor pus for the same NLP tasks.</S>
			<S sid="10" ssid="10">For example, forconstituent syntactic parsing (Collins, 1999; Charniak, 2000; Petrov et al, 2006) in Chinese, in addition to the most popular treebank Chinese Tree bank (CTB) (Xue et al, 2002), there are alsoother treebanks such as Tsinghua Chinese Tree bank (TCT) (Zhou, 1996).</S>
			<S sid="11" ssid="11">For the purpose of full use of readily available human annotationsfor the same tasks, it is significant if such corpora can be used jointly.</S>
			<S sid="12" ssid="12">At first sight, a di rect combination of multiple corpora is a way to this end.</S>
			<S sid="13" ssid="13">However, corpora created for the sameNLP tasks are generally built by different organizations.</S>
			<S sid="14" ssid="14">Thus such corpora often follow dif ferent annotation standards and/or even different linguistic theories.</S>
			<S sid="15" ssid="15">We take CTB and TCT as a case study.</S>
			<S sid="16" ssid="16">Although both CTB and TCT are Chomskian-style treebanks, they have annotation divergences in at least two dimensions: a) CTBand TCT have dramatically different tag sets, in cluding parts-of-speech and grammar labels, and the tags cannot be mapped one to one; b) CTB and TCT have distinct hierarchical structures.</S>
			<S sid="17" ssid="17">Forexample, the words ???</S>
			<S sid="18" ssid="18">(Chinese) ??</S>
			<S sid="19" ssid="19">(tradi tional) ??</S>
			<S sid="20" ssid="20">(culture)?</S>
			<S sid="21" ssid="21">are grouped as a flat noun phrase according to the CTB standard (right sidein Fig.</S>
			<S sid="22" ssid="22">1), but in TCT, the last two words are in stead grouped together beforehand (left side in Fig.</S>
			<S sid="23" ssid="23">1).</S>
			<S sid="24" ssid="24">The differences cause such treebanksof different annotations to be generally used in dependently.</S>
			<S sid="25" ssid="25">This paper is dedicated to solvingthe problem of how to use jointly multiple dis parate treebanks for constituent syntactic parsing.</S>
			<S sid="26" ssid="26">Hereafter, treebanks of different annotations are 1344called heterogeneous treebanks, and correspondingly, the problem of syntactic parsing with heterogeneous treebanks is referred to as heteroge neous parsing.Previous work on heterogeneous parsing is of ten based on treebank transformation (or treebank conversion) (Wang et al, 1994; Niu et al, 2009).</S>
			<S sid="27" ssid="27">The basic idea is to transform annotations of one treebank (source treebank) to fit the standard ofanother treebank (target treebank).</S>
			<S sid="28" ssid="28">Due to divergences of treebank annotations, such transforma tion is generally achieved in an indirect way by selecting transformation results from the output ofa parser trained on the target treebank.</S>
			<S sid="29" ssid="29">A com mon property of all the work mentioned above is that transformation accuracy is heavily dependenton the performance of parsers trained on the tar get treebank.</S>
			<S sid="30" ssid="30">Sometimes transformation accuracy is not so satisfactory that techniques like instancepruning are needed in order to refine transforma tion results (Niu et al, 2009).</S>
			<S sid="31" ssid="31">We claim there exists another way, interesting but less studied for heterogeneous parsing.</S>
			<S sid="32" ssid="32">The basic idea is that, although there are annotationdivergences between heterogenous treebanks, ac tually we can also find consensus in annotations of bracket structures.</S>
			<S sid="33" ssid="33">Thus we would like to train parsers on individual heterogeneous treebanks and guide the parsers to gain output with consensus in bracket structures as much as possible when they are parsing the same sentences.To realize this idea, we propose a generic col laborative decoding (or co-decoding) frameworkwhere decoders trained on heterogeneous treebanks can exchange consensus information between each other during the decoding phase.</S>
			<S sid="34" ssid="34">The oretically the framework is able to incorporate a large number of treebanks and various functions that formalize consensus statistics.</S>
			<S sid="35" ssid="35">Our contributions can be summarized: 1) wepropose a co-decoding approach to directly uti lizing heterogeneous treebanks; 2) we propose anovel function to measure parsing consensus between multiple decoders.</S>
			<S sid="36" ssid="36">We also conduct ex periments on two Chinese treebanks: CTB and TCT.</S>
			<S sid="37" ssid="37">The results show that our approach achieves promising improvements over baseline systems which make no use of consensus information.</S>
			<S sid="38" ssid="38">np nS ??</S>
			<S sid="39" ssid="39">np a ??</S>
			<S sid="40" ssid="40">n ??</S>
			<S sid="41" ssid="41">NP NR ??</S>
			<S sid="42" ssid="42">NN ??</S>
			<S sid="43" ssid="43">NN ??</S>
			<S sid="44" ssid="44">(Chinese) (traditional) (culture) Figure 1: Example tree fragments with TCT (left) and CTB (right) annotations</S>
	</SECTION>
	<SECTION title="Collaborative Decoding-based. " number="2">
			<S sid="45" ssid="1">Heterogeneous Parsing 2.1 Motivation.</S>
			<S sid="46" ssid="2">This section describes the motivation to use co-decoding for heterogeneous parsing.</S>
			<S sid="47" ssid="3">We firstuse the example in Fig.</S>
			<S sid="48" ssid="4">1 to illustrate what con sensus information exists between heterogenous treebanks and why such information might help to improve parsing accuracy.</S>
			<S sid="49" ssid="5">This figure contains two partial parse trees corresponding to the words ???</S>
			<S sid="50" ssid="6">(Chinese) ??</S>
			<S sid="51" ssid="7">(traditional) ??</S>
			<S sid="52" ssid="8">(culture)?, annotated according to the TCT (left side) and CTB (right side) standards respectively.</S>
			<S sid="53" ssid="9">Despite the distinctions in tag sets and bracket structures, these parse trees actually have partial agreements in bracket structures.</S>
			<S sid="54" ssid="10">That is, not all bracket structures in the parse trees are different.</S>
			<S sid="55" ssid="11">Specifically put, although the internal structures of the parse trees are different, both CTB and TCT agree to take ???</S>
			<S sid="56" ssid="12">as a noun phrase.</S>
			<S sid="57" ssid="13">Motivated by this observation, we would like to guide parsers that are trained on CTB andTCT respectively to verify their output interac tively by using consensus information implicitly contained in these treebanks.</S>
			<S sid="58" ssid="14">Better performance is expected when such information is considered.</S>
			<S sid="59" ssid="15">A feasible framework to make use of consensus information is n-best combination (Henderson and Brill, 1999; Sagae and Lavie, 2006; Zhang et al., 2009; Fossum and Knight, 2009).</S>
			<S sid="60" ssid="16">In contrast 1345 to previous work on n-best combination where multiple parsers, say, Collins parser (Collins, 1999) and Berkeley parser (Petrov et al, 2006) are trained on the same training data, n-best combination for heterogeneous parsing is instead allowed to use either a single parser or multiple parsers which are trained on heterogeneoustreebanks.</S>
			<S sid="61" ssid="17">Consensus information can be incor porated during the combination of the output (n-best list of full parse trees following distinctannotation standards) of individual parsers.</S>
			<S sid="62" ssid="18">How ever, despite the success of n-best combination methods, they suffer from the limited scope of n-best list.</S>
			<S sid="63" ssid="19">Taking this into account, we prefer to apply the co-decoding approach such that consensus information is expected to affect the entire procedure of searching hypothesis space.</S>
			<S sid="64" ssid="20">2.2 System Overview.</S>
			<S sid="65" ssid="21">The idea of co-decoding is recently extensively studied in the literature of SMT (Li et al, 2009; Liu et al, 2009).</S>
			<S sid="66" ssid="22">As the name shows, co-decodingrequires multiple decoders be combined and pro ceed collaboratively.</S>
			<S sid="67" ssid="23">As with n-best combination,there are at least two ways to build multiple de coders: we can either use multiple parsers trainedon the same training data (use of diversity of mod els), or use a single parser on different training data (use of diversity of datasets) 1.</S>
			<S sid="68" ssid="24">Both wayscan build multiple decoders which are to be inte grated into co-decoding.</S>
			<S sid="69" ssid="25">For the latter case, onemethod to get diverse training data is to use dif ferent portions of the same training set.</S>
			<S sid="70" ssid="26">In this study we extend the case to an extreme situation where heterogeneous treebanks are used to build multiple decoders.Fig.</S>
			<S sid="71" ssid="27">2 represents a basic flow chart of heteroge neous parsing via co-decoding.</S>
			<S sid="72" ssid="28">Note that here wediscuss the case of co-decoding with only two decoders, but the framework is generic enough to in tegrate more than two decoders.</S>
			<S sid="73" ssid="29">For convenienceof reference, we call a decoder without incorpo rating consensus information as baseline decoder 1To make terminologies clear, we use parser as its regular sense, including training models (ex.</S>
			<S sid="74" ssid="30">Collins model 2) and parsing algorithms (ex.</S>
			<S sid="75" ssid="31">the CKY algorithm used in Collins parser), and we use decoder to represent parsing algorithms with specified parameter values treebank1 treebank2 decoder1 decoder2 co-decoding test data Figure 2: Basic flow chart of co-decoding and correspondingly refer to a decoder augmented with consensus information as member decoder.So the basic steps of co-decoding for heteroge neous parsing is to first build baseline decoders on heterogeneous treebanks and then use the baselinedecoders to parse sentences with consensus infor mation exchanged between each other.</S>
			<S sid="76" ssid="32">To complete co-decoding for heterogeneousparsing, three key components should be consid ered in the system:?</S>
			<S sid="77" ssid="33">Co-decoding model.</S>
			<S sid="78" ssid="34">A co-decoder con sists of multiple member decoders which arebaseline decoders augmented with consensus information.</S>
			<S sid="79" ssid="35">Co-decoding model de fines how baseline decoders and consensusinformation are correlated to get member de coders.?</S>
			<S sid="80" ssid="36">Decoder coordination.</S>
			<S sid="81" ssid="37">Decoders in the codecoding model cannot proceed indepen dently but should have interactions betweeneach other in order to exchange consensus in formation.</S>
			<S sid="82" ssid="38">A decoder coordination strategydecides on when, where, and how the inter actions happen.?</S>
			<S sid="83" ssid="39">Consensus-based score function.</S>
			<S sid="84" ssid="40">Consensus based score functions formalize consensusinformation between member decoders.</S>
			<S sid="85" ssid="41">Taking time complexity into consideration, consensus statistics should be able to be com puted efficiently.</S>
			<S sid="86" ssid="42">1346 In the following subsections, we first present the generic co-decoding model and then describein detail how member decoders collaborate.</S>
			<S sid="87" ssid="43">Fi nally we introduce a novel consensus-based scorefunction which is used to quantify consensus in formation exchanged between member decoders.</S>
			<S sid="88" ssid="44">2.3 Generic Co-decoding Model.</S>
			<S sid="89" ssid="45">The generic co-decoding model described here is also used in (Li et al, 2009) for co-decoding of machine translators.</S>
			<S sid="90" ssid="46">For a given sentence S, a parsing algorithm (decoder) seeks a parse tree T ? which is optimal in the sense that it maximizes some score function F (T ), as shown in Eq.</S>
			<S sid="91" ssid="47">1.</S>
			<S sid="92" ssid="48">T ? = argmax Ts.t.S=yield(T ) F (T ) (1) where Ts.t.S = yield(T ) represents the set of parse trees that yield the input sentence S. For baseline decoders, the score function F (T ) is generally just the inside probability P (T ) 2 ofa tree T , defined as the product of probabili ties of grammar rules appearing in parse tree T :?</S>
			<S sid="93" ssid="49">r?R(T ) P (r).</S>
			<S sid="94" ssid="50">In the co-decoding framework,F (T ) is extended so as to integrate consensus based score functions which measure consensus information between member decoders, as shown in Eq.</S>
			<S sid="95" ssid="51">2.</S>
			<S sid="96" ssid="52">Fm(T ) = Pm(T ) + n?</S>
			<S sid="97" ssid="53">k,k 6=m ?k(Hk(S), T ) (2) We use dk to denote the kth decoder and useHk(S) to denote corresponding parsing hypoth esis space of decoder dk.</S>
			<S sid="98" ssid="54">Moreover, Pm(T ) is referred to as baseline score given by baseline decoders and ?k(Hk(S), T ) is consensus score between decoders dm and dk, which is defined as a linear combination of consensus-based score functions, as shown in Eq.</S>
			<S sid="99" ssid="55">3.</S>
			<S sid="100" ssid="56">?k(Hk(S), T ) = ? l ?k,lfk,l(Hk(S), T ) (3)where fk,l(Hk(S), T ) represents a consensus based score function between T and Hk(S), and ?k,l is the corresponding weight.</S>
			<S sid="101" ssid="57">Index l 2Actually, the joint probability P(S,T) of sentence S and parse tree T is used, but we can prove that P (S, T ) = P (T ).</S>
			<S sid="102" ssid="58">ranges over all consensus-based score functions in Eq.</S>
			<S sid="103" ssid="59">3.</S>
			<S sid="104" ssid="60">Theoretically we can define a variety of consensus-based score functions.</S>
			<S sid="105" ssid="61">For the simplest case where there are only two member decoders and one consensus-based score function, Eq.</S>
			<S sid="106" ssid="62">2 and Eq.</S>
			<S sid="107" ssid="63">3 can be combined and simplified into the equation Fi(T ) = Pi(T ) + ?1?if(H1?i(S), T ) (4) where index i is set to the value of either 1 or 0.</S>
			<S sid="108" ssid="64">This simplified version is used in the experiments of this study.</S>
			<S sid="109" ssid="65">2.4 Decoder Coordination.</S>
			<S sid="110" ssid="66">This subsection discusses the problem of decoder coordination.</S>
			<S sid="111" ssid="67">Note that although Eq.</S>
			<S sid="112" ssid="68">2 is definedat sentence level, the co-decoding model actu ally should be applied to the parsing procedure of any subsequence (word span) of sentence S.So it is natural to render member decoders col laborate when they are processing the same wordspans.</S>
			<S sid="113" ssid="69">To this end, we would like to adopt bestfirst CKY-style parsing algorithms as baseline decoders, since CKY-style decoders have the property that they process word spans in the ascending order of span sizes.</S>
			<S sid="114" ssid="70">Moreover, the hypotheses 3 spanning the same range of words are readily stacked together in a chart cell before CKY style decoders move on to process other spans.</S>
			<S sid="115" ssid="71">Thus, member decoders can process the same word spans collaboratively from small ones to big ones until they finally complete parsing the entire sentence.A second issue in Eq.</S>
			<S sid="116" ssid="72">2 is that consensusbased score functions are dependent on hypothesis space Hk(S).</S>
			<S sid="117" ssid="73">Unfortunately, the whole hy pothesis space is not available most of the time.</S>
			<S sid="118" ssid="74">To address this issue, one practical method is to approximate Hk(S) with a n-best hypothesis list.</S>
			<S sid="119" ssid="75">For best-first CKY parsing, we actually retain all unpruned partial hypotheses over the same spanas the approximation.</S>
			<S sid="120" ssid="76">Hereafter, the approxima tion is denoted as H?k(S) Finally, we notice in Eq.</S>
			<S sid="121" ssid="77">2 that consensus score 3In the literature of syntactic parsing, especially in chart parsing, hypotheses is often called edges.</S>
			<S sid="122" ssid="78">This paper willcontinue to use the terminology hypothesis when no ambigu ity exists.</S>
			<S sid="123" ssid="79">1347?k(Hk(S), T ) and Hk(S) form a circular dependency: searching for Hk(S) requires both base line score and consensus score; on the other hand,calculating consensus score needs Hk(S) (its ap proximation in practice) to be known beforehand.Li et al (2009) solves this dilemma with a boot strapping method.</S>
			<S sid="124" ssid="80">It starts with seedy n-best listsgenerated by baseline decoders and then alter nates between calculating consensus scores andupdating n-best hypothesis lists.</S>
			<S sid="125" ssid="81">Such bootstrap ping method is a natural choice to break down the circular dependency, but multi-pass re-decoding might dramatically reduce decoding efficiency.</S>
			<S sid="126" ssid="82">Actually, Li et al (2009) restricts the iteration number to two in their experiments.</S>
			<S sid="127" ssid="83">In this paper, we instead use an alternative to the bootstrapping method.</S>
			<S sid="128" ssid="84">The process is described as follows.</S>
			<S sid="129" ssid="85">1.</S>
			<S sid="130" ssid="86">In traditional best-first CKY-style parsing al-.</S>
			<S sid="131" ssid="87">gorithms, hypotheses over the same wordspans are grouped according to some crite rion of hypothesis equivalence 4.</S>
			<S sid="132" ssid="88">Among equivalent hypotheses, only a single optimalhypothesis is retained.</S>
			<S sid="133" ssid="89">In this paper, we in stead keep top k of equivalent hypotheses in a data structure called best-first cache.</S>
			<S sid="134" ssid="90">2.</S>
			<S sid="135" ssid="91">Use hypotheses in best-first caches to ap-.</S>
			<S sid="136" ssid="92">proximate Hk(S), and calculate consensus score ?k(Hk(S), T ) between decoders.</S>
			<S sid="137" ssid="93">cally rerank hypotheses in best-first caches.</S>
			<S sid="138" ssid="94">Then remove hypotheses in caches except the top one hypothesis.</S>
			<S sid="139" ssid="95">In this study, we choose the best-first CKY-style parsing algorithm used in Collins parser (Collins,1999).</S>
			<S sid="140" ssid="96">Algorithm 1 extends this algorithm for co decoding.</S>
			<S sid="141" ssid="97">The first two steps initialize baselinedecoders and assign appropriate POS tags to sentence St. Since baseline decoders are built on heterogeneous treebanks, POS taggers correspond ing to each baseline decoder are demanded, unless gold POS tags are provided.</S>
			<S sid="142" ssid="98">The third step is thecore of the co-decoding algorithm.</S>
			<S sid="143" ssid="99">Here the complete procedure invokes baseline decoders to com4the simplest criterion of equivalence is whether hypothe ses have the same grammar labels.</S>
			<S sid="144" ssid="100">Algorithm 1 CKY-style Co-decoding Argument: dk{the set of baseline decoders} St{a sentence to be parsed} Begin Steps: 1.</S>
			<S sid="145" ssid="101">assign POS tags to sentence St 2.</S>
			<S sid="146" ssid="102">initialize baseline decoders dk 3.</S>
			<S sid="147" ssid="103">for span from 2 to sentence length do for start from 1 to (sentence length-span+1) do end := (start + span - 1) for each base decoder dk do complete(dk , start, end) do co-decoding(start, end) End Subroutine: complete(dk, start, end): base decoder dk generateshypotheses over the span (begin.end), and fills in best first caches.</S>
			<S sid="148" ssid="104">co-decoding(start, end): calculate consensus score and rerank hypotheses in best-first caches.</S>
			<S sid="149" ssid="105">The top 1 is chosen to be the best-first hypothesis.plete parsing on the span [start, end] and gener ates H?k(s).</S>
			<S sid="150" ssid="106">The co-decoding procedure calculates consensus score and locally reranks hypotheses in best-first caches.</S>
			<S sid="151" ssid="107">2.5 Consensus-based Score Function.</S>
			<S sid="152" ssid="108">There are at least two feasible ways to mea sure consensus between constituency parse trees.</S>
			<S sid="153" ssid="109">By viewing parse trees from diverse perspectives, we can either use functions on bracket structures of parse trees, as in (Wang et al, 1994), or use functions on head-dependent relations by first transforming constituency trees into dependencytrees, as in (Niu et al, 2009).</S>
			<S sid="154" ssid="110">Although the codecoding model is generic enough to integrate var ious consensus-based score functions in a uniform way, this paper only uses a bracket structure-based function.</S>
			<S sid="155" ssid="111">As mentioned above, the function proposed in(Wang et al, 1994) is based on bracket structures.</S>
			<S sid="156" ssid="112">Unfortunately, that function is not appli cable in the situation of this paper.</S>
			<S sid="157" ssid="113">The reason isthat, the function in (Wang et al, 1994) is de fined to work on two parse trees, but this paper instead needs a function on a tree T and a set of trees (the approximation H?k(S)).</S>
			<S sid="158" ssid="114">To this end, we first introduce the concept of constituent set (CS) of a parse tree.</S>
			<S sid="159" ssid="115">Conceptually, CS of a parse tree isa set of word spans corresponding to all the sub 1348 64 1 5 2 3 [1,3],[2,3],[1,1] [1,1] [2,3],[2,2],[3,3] [1,1] [2,2] [3,3] Figure 3: Constituent set of a synthetic parse treetrees of the tree, as illustrated in Fig.</S>
			<S sid="160" ssid="116">3.</S>
			<S sid="161" ssid="117">For exam ple, the constituent set of the tree rooted at node 6 has three elements: [1, 1], [1, 3], and [1, 2].</S>
			<S sid="162" ssid="118">For H?k(S), the constituent set is defined as the union of constituent sets of all elements it contains.</S>
			<S sid="163" ssid="119">CS(H?k(S)) = ? T?H?k(S) CS(T ) In practice, we need to cut off elements in CS(H?k(S)) in order to retain most confident word spans.</S>
			<S sid="164" ssid="120">With the concept of constituent set, a consensus-based score function on T and H?k(S) can be defined as follows.</S>
			<S sid="165" ssid="121">f(H?k(S), T ) = ? c?CS(T ) I(c, CS(H?k(S))) |CS(T )| (5) where I(c, CS(H?k(S))) is an indicator function which returns one if c ? CS(T ) is compatiblewith all the elements in CS(H?k(S)), zero oth erwise.</S>
			<S sid="166" ssid="122">Two spans, [a, b] and [i, j] are said to be compatible if they satisfy one of the following conditions: 1) i &gt; b; 2) a &gt; j; 3) a ? i ? b and j ? b; 4) i ? a ? j and b ? j. Fig 4 uses two example to illustrate the concept of compatibility.</S>
	</SECTION>
	<SECTION title="Experiments. " number="3">
			<S sid="167" ssid="1">3.1 Data and Performance Metric.</S>
			<S sid="168" ssid="2">The most recent version of the CTB corpus, CTB6.0 and the CIPS ParsEval data are used as hetero geneous treebanks in the experiments.</S>
			<S sid="169" ssid="3">Followingthe split utilized in (Huang et al, 2007), we di vided the dataset into blocks of 10 files.</S>
			<S sid="170" ssid="4">For each w1 w2 w3 w4 w1 w2 w3 w4 Figure 4: left) two spans conflict; right) two spans are compatibleblock, the first file was added to the CTB develop ment data, the second file was added to the CTB testing data, and the remaining 8 files were added to the CTB training data.</S>
			<S sid="171" ssid="5">For the sake of parsing efficiency, we randomly sampled 1,000 sentences of no more than 40 words from the CTB test set.</S>
			<S sid="172" ssid="6">CTB-Partitions Train Dev Test #Sentences 22,724 2,855 1,000 #Words 627,833 78,653 25,100 Ave-Length 30.1 30.0 20.3 TCT-Partitions Train Dev Test #Sentences 32,771 N/A 1,000 #Words 354,767 N/A 10,400 Ave-Length 10.6 N/A 10.4 Table 1: Basic statistics on the CTB and TCT data CIPS-ParsEval data is publicly available for thefirst Chinese syntactic parsing competition, CIPS ParsEval 2009.</S>
			<S sid="173" ssid="7">Compared to CTB, sentences in CIPS-ParsEval data are much shorter in length.</S>
			<S sid="174" ssid="8">We removed sentences which have words lessthan three.</S>
			<S sid="175" ssid="9">CIPS-ParsEval test set has 7,995 sen tences after sentence pruning.</S>
			<S sid="176" ssid="10">As with the CTB test set, we randomly sampled 1,000 sentences for evaluating co-decoding performance.</S>
			<S sid="177" ssid="11">Since CIPS-ParsEval data is actually a portion of the TCT corpus, for convenience of reference, we willrefer to CIPS-ParsEval data as TCT in the follow ing sections.</S>
			<S sid="178" ssid="12">Table 1 contains statistics on CTB and TCT.</S>
			<S sid="179" ssid="13">The two training sets are used individually to build baseline decoders.</S>
			<S sid="180" ssid="14">With regard to the test sets, each sentence in the test sets should have two kinds of POS tags, according to the CTB andTCT standards respectively.</S>
			<S sid="181" ssid="15">To this end, we ap plied a HMM-based method for POS annotation transformation (Zhu and Zhu, 2009).</S>
			<S sid="182" ssid="16">During thePOS transformation, the divergences of word seg mentation are omitted.</S>
			<S sid="183" ssid="17">For all experiments, bracketing F1 is used as the performance metric, provided by EVALB 5.</S>
			<S sid="184" ssid="18">5http://nlp.cs.nyu.edu/evalb 1349 3.2 Baseline Decoders.</S>
			<S sid="185" ssid="19">As already mentioned above, we apply Collins parser in this paper.</S>
			<S sid="186" ssid="20">Specifically speaking, twoCKY-style baseline decoders to participate co decoding are built on CTB and TCT respectivelywith Collins model two.</S>
			<S sid="187" ssid="21">For the CTB-based de coder, we use the CTB training data with slightmodifications: we replaced POS tags of punctua tions with specific punctuation symbols.To get the TCT-based decoder, we made follow ing modifications.</S>
			<S sid="188" ssid="22">Firstly, TCT is available withmanually annotated head indices for all the con stituents in parse trees.</S>
			<S sid="189" ssid="23">For example, a grammar label, say, np-1, means that the constituent is a noun phrase with the second child being its headchild.</S>
			<S sid="190" ssid="24">In order to relax context independence assumptions made in PCFG, we appended head indices to grammar labels to get new labels, for ex ample np1.</S>
			<S sid="191" ssid="25">Secondly, since Collins parser is a lexicalized parser, head rules specific to the TCTcorpus were manually created, which are used to gether with readily available head indices.</S>
			<S sid="192" ssid="26">Such adaptation is also used in (Chen et al, 2009); 3.3 Parsing Results.</S>
			<S sid="193" ssid="27">We conduct experiments on both CTB and TCTtest sets.</S>
			<S sid="194" ssid="28">Two parameters need to be set: the cut off threshold for constructing constituent set of H?k(S) and the weight ? 6 of consensus score inEq.</S>
			<S sid="195" ssid="29">4.</S>
			<S sid="196" ssid="30">We tuned the parameters on the CTB de velopment set and finally set them to 5 and 20 respectively in the experiments.</S>
			<S sid="197" ssid="31">Table 2 presents bracketing F1 scores of baseline systems and the co-decoding approach.</S>
			<S sid="198" ssid="32">Here, the row of baseline represents the performance of individual baselinedecoders, and the comparison of baseline and co decoding on a test set, say CTB, demonstrates how much boosting the other side, say TCT, can supply.</S>
			<S sid="199" ssid="33">For the co-decoding approach, the size of best-first cache is set to 5 which achieves thebest result among the cache sizes we have experi mented.</S>
			<S sid="200" ssid="34">As the results show, co-decoding achieves promising improvements over baseline systems on both test sets.</S>
			<S sid="201" ssid="35">Interestingly, we see that the improvement on the TCT test set is larger than 6We use the same ? for both member decoders.</S>
			<S sid="202" ssid="36">Test Set CTB TCT Baseline 79.82 81.02 Co-decoding 80.33 81.77 Table 2: Baseline and Co-decoding on the CTB and TCT test sets that on the CTB test set.</S>
			<S sid="203" ssid="37">In general, a relativelystrong decoder can improve co-decoding perfor mance more than a relatively weak decoder does.</S>
			<S sid="204" ssid="38">At the first sight, the TCT-based decoder seems tohave better performance than the CTB-based decoder.</S>
			<S sid="205" ssid="39">But if taking sentence length into consid eration, we can find that the TCT-based decoder is actually relatively weak.</S>
			<S sid="206" ssid="40">Table 3 shows the performance of the CTB-based decoder on short sentences.</S>
			<S sid="207" ssid="41">3.4 Analysis.</S>
			<S sid="208" ssid="42">Fig.</S>
			<S sid="209" ssid="43">5 shows the bracketing F1 on the CTB test set at different settings of the best-first cache size C . F1 scores reach the peak before C increases to 6.</S>
			<S sid="210" ssid="44">As a result, we set C to 5 in all our experiments.</S>
			<S sid="211" ssid="45">79 79.5 80 80.5 81 0 1 2 3 4 5 6 br ac ke tin g F1 size of best-first cache CTB Figure 5: Bracketing F1 with varying best-first cache sizeTo evaluate the effect of sentence length on co decoding, Table 3 presents F1 scores on portionsof the CTB test set, partitioned according to sen tence length.</S>
			<S sid="212" ssid="46">From the results we can see that co-decoding performs better on long sentences.</S>
			<S sid="213" ssid="47">One possible reason is that member decoders havemore consensus on big spans.</S>
			<S sid="214" ssid="48">Taking this obser vation into consideration, one enhancement to the co-decoding approach is to enable co-decodingonly on long sentences.</S>
			<S sid="215" ssid="49">This way, parsing ef 1350 Partitions [0,10] (10,20] (20,30] (30,40] # Sentence 276 254 266 204 Ave-Length 6.07 15.64 25.43 35.20 Baseline 92.83 84.34 78.98 76.69 Co-decoding 92.84 84.36 79.43 77.65 Table 3: Effect of sentence length on co-decoding performance ficiency of co-decoding can be improved.</S>
			<S sid="216" ssid="50">It isworth emphasizing that co-decoding is still helpful for parsers whose performance on short sen tences is not satisfactory, as shown in Table 2.</S>
			<S sid="217" ssid="51">Another interesting analysis is to check how many parsing results are affected by co-decoding, compared to baseline decoders.</S>
			<S sid="218" ssid="52">Table 4 shows the statistics.</S>
			<S sid="219" ssid="53">Test Set # All # Improved # Decreased CTB 1000 225 109 TCT 1000 263 92 Table 4: Statistics on sentences of test data As the table shows, although overall accuracy isincreased, we find that on some sentences, co decoding instead worsens parsing accuracy.</S>
			<S sid="220" ssid="54">Inorder to get insights on error sources, we manu ally analyzed 20 sentences on which co-decodingachieves negative results.</S>
			<S sid="221" ssid="55">We find a large por tion (14 of 20) of sentences are short sentences(of words less than 20).</S>
			<S sid="222" ssid="56">Actually, due to high accuracy of the CTB-based decoder on short sentences, co-decoding is indifferent when this de coder is processing short sentences.</S>
			<S sid="223" ssid="57">And we also find that some errors are derived from differencesin annotation standards.</S>
			<S sid="224" ssid="58">Fortunately, the diver gence of annotations mainly exists in relatively small spans.</S>
			<S sid="225" ssid="59">So one solution to the problem is to enable co-decoding on relatively big spans.</S>
			<S sid="226" ssid="60">These will be done in our future work.</S>
	</SECTION>
	<SECTION title="Related Work. " number="4">
			<S sid="227" ssid="1">4.1 System Combination.</S>
			<S sid="228" ssid="2">In the literature of syntactic parsing, n-best combination methods include parse selection, constituent recombination, production recombina tion, and n-best reranking.</S>
			<S sid="229" ssid="3">Henderson and Brill (1999) performs parse selection by maximizingthe expected precision of selected parse with re spect to the set of parses to be combined.</S>
			<S sid="230" ssid="4">Sagaeand Lavie (2006) proposes to recombine con stituents from the output of individual parsers.</S>
			<S sid="231" ssid="5">More recently, Fossum and Knight (2009) studies a combination method at production level.</S>
			<S sid="232" ssid="6">Zhang et al (2009) reranks n-best list of one parser with scores derived from another parser.</S>
			<S sid="233" ssid="7">Compared to n-best combination, co-decoding(Li et al, 2009; Liu et al, 2009) combines systems during decoding phase.</S>
			<S sid="234" ssid="8">Theoretically, system combination during decoding phase helps decoders to select better approximation to hypothe sis space, since pruning is practically unavoidable.To the best of our knowledge, co-decoding meth ods have not been applied to syntactic parsing.</S>
			<S sid="235" ssid="9">4.2 Treebank Transformation.</S>
			<S sid="236" ssid="10">The focus of this study is heterogeneous parsing.</S>
			<S sid="237" ssid="11">Previous work on this challenge is generally based on treebank transformation.</S>
			<S sid="238" ssid="12">Wang et al (1994) describes a method for transformation between constituency treebanks.</S>
			<S sid="239" ssid="13">The basic idea is to train a parser on a target treebank and generate a n-best list for each sentence in source treebank(s).</S>
			<S sid="240" ssid="14">Then,a matching metric which is a function on the num ber of the same word spans between two trees is defined to select a best parse from each n-best list.Niu et al (2009) applies a closely similar frame work as with (Wang et al, 1994) to transform a dependency treebank to a constituency one.</S>
	</SECTION>
	<SECTION title="Conclusions. " number="5">
			<S sid="241" ssid="1">This paper proposed a co-decoding approach tothe challenge of heterogeneous parsing.</S>
			<S sid="242" ssid="2">Compared to previous work on this challenge, co decoding is able to directly utilize heterogeneous treebanks by incorporating consensus informationbetween partial output of individual parsers dur ing the decoding phase.</S>
			<S sid="243" ssid="3">Experiments demonstratethe effectiveness of the co-decoding approach, es pecially the effectiveness on long sentences.</S>
			<S sid="244" ssid="4">Acknowledgments This work was supported in part by the National Science Foundation of China (60873091).</S>
			<S sid="245" ssid="5">We would like to thank our anonymous reviewers for their comments.</S>
			<S sid="246" ssid="6">1351</S>
	</SECTION>
</PAPER>
