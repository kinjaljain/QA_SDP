<PAPER>
  <S sid="0">Combining Rule-Based and Statistical Syntactic Analyzers</S>
  <ABSTRACT>
    <S sid="1" ssid="1">This paper presents the results of a set of preliminary experiments combining two knowledge-based partial dependency analyzers with two statistical parsers, applied to the Basque Dependency Treebank.</S>
    <S sid="2" ssid="2">The general idea will be to apply a stacked scheme where the output of the rule-based partial parsers will be given as input to MaltParser and MST, two state of the art statistical parsers.</S>
    <S sid="3" ssid="3">The results show a modest improvement over the baseline, although they also present interesting lines for further research.</S>
  </ABSTRACT>
  <SECTION title="1." number="1">
    <S sid="4" ssid="1">In this paper we present a set of preliminary experiments on the combination of two knowledge-based partial syntactic analyzers with two state of the art data-driven statistical parsers.</S>
    <S sid="5" ssid="2">The experiments have been performed on the Basque Dependency Treebank (Aduriz et al., 2003).</S>
    <S sid="6" ssid="3">In the last years, many attempts have been performed trying to combine different parsers (Surdeanu and Manning, 2010), with significant improvements over the best individual parser&#8217;s baseline.</S>
    <S sid="7" ssid="4">The two most successful approaches have been stacking (Martins et al., 2008) and voting (Sagae and Lavie, 2006, Nivre and McDonald, 2008, McDonald and Nivre, 2011).</S>
    <S sid="8" ssid="5">In this paper we will experiment the use of the stacking technique, giving the tags obtained by the rulebased syntactic partial parsers as input to the statistical parsers.</S>
    <S sid="9" ssid="6">Morphologically rich languages present new challenges, as the use of state of the art parsers for more configurational and non-inflected languages like English does not reach similar performance levels in languages like Basque, Greek or Turkish (Nivre et al., 2007a).</S>
    <S sid="10" ssid="7">As it was successfully done on part of speech (POS) tagging, where the use of rule-based POS taggers (Tapanainen and Voutilainen, 1994) or a combination of a rulebased POS tagger with a statistical one (Aduriz et al., 1997, Ezeiza et al., 1998) outperformed purely statistical taggers, we think that exploring the combination of knowledge-based and data-driven systems in syntactic processing can be an interesting line of research.</S>
    <S sid="11" ssid="8">Most of the experiments on combined parsers have relied on different types of statistical parsers (Sagae and Lavie, 2006, Martins et al., 2008, McDonald and Nivre, 2011), trained on an automatically annotated treebank.</S>
    <S sid="12" ssid="9">Yeh (2000) used the output of several baseline diverse parsers to increase the performance of a second transformation-based parser.</S>
    <S sid="13" ssid="10">In our work we will study the use of two partial rule-based syntactic analyzers together with two data-driven parsers: set of predefined tags to each word, where each tag gives both the name of a dependency relation (e.g. subject) together with the direction of its head (left or right).</S>
    <S sid="14" ssid="11">In the rest of this paper, section 2 will first present the corpus and the different parsers we will combine, followed by the experimental results in section 3, and the main conclusions of the work.</S>
  </SECTION>
  <SECTION title="2." number="2">
    <S sid="15" ssid="1">This section will describe the main resources that have been used in the experiments.</S>
    <S sid="16" ssid="2">First, subsection 2.1 will describe the Basque Dependency Treebank, and then subsection 2.2 will explain the main details of the analyzers that have been employed.</S>
    <S sid="17" ssid="3">The analyzers are a rulebased chunker, a rule-based shallow dependency parser and two state of the art data-driven dependency parsers, MaltParser and MST.</S>
    <S sid="18" ssid="4">Our work will make use the second version of the Basque dependency Treebank (BDT II, Aduriz et al., 2003), containing 150,000 tokens (11,225 sentences).</S>
    <S sid="19" ssid="5">Figure 1 presents an example of a syntactically annotated sentence.</S>
    <S sid="20" ssid="6">Each word contains its form, lemma, category or coarse part of speech (CPOS), POS, morphosyntactic features such as case, number of subordinate relations, and the dependency relation (headword + dependency).</S>
    <S sid="21" ssid="7">The information in figure 1 has been simplified due to space reasons, as typically each word contains many morphosyntactic features (case, number, type of subordinated sentence, ...), which are relevant for parsing.</S>
    <S sid="22" ssid="8">The last two lines of the sentence in figure 1 do not properly correspond to the treebank, but are the result of the rule-based partial syntactic analyzers (see subsection 2.2).</S>
    <S sid="23" ssid="9">For evaluation, we divided the treebank in three sets, corresponding to training, development, and test (80%, 10%, and 10%, respectively).</S>
    <S sid="24" ssid="10">The experiments were performed on the development set, leaving the best system for the final test.</S>
    <S sid="25" ssid="11">This subsection will present the four types of analyzers that have been used.</S>
    <S sid="26" ssid="12">The rule-based analyzers are based on the Contraint Grammar (CG) formalism (Karlsson et al., 1995), based on the assignment of morphosyntactic tags to words using a formalism that has the capabilities of finite state automata or regular expressions, by means of a set of rules that examine mainly local contexts of words to determine the correct tag assignment.</S>
    <S sid="27" ssid="13">The rule-based chunker (RBC henceforth, Aranzabe et al., 2009) uses 560 rules, where 479 of the rules deal with noun phrases and the rest with verb phrases.</S>
    <S sid="28" ssid="14">The chunker delimits the chunks with three tags, using a standard IOB marking style (see figure 1).</S>
    <S sid="29" ssid="15">The first one is to mark the beginning of the phrase (B-VP if it is a verb phrase and B-NP whether it's a noun phrase) and the other one to mark the continuation of the phrase (I-NP or I-VP, meaning that the word is inside an NP or VP).</S>
    <S sid="30" ssid="16">The last tag marks words that are outside a chunk.</S>
    <S sid="31" ssid="17">The evaluation of the chunker on the BDT gave a result of 87% precision and 85% recall over all chunks.</S>
    <S sid="32" ssid="18">We must take into account that this evaluation was performed on the gold POS tags, rather than on automatically assigned POS tasks, as in the present experiment.</S>
    <S sid="33" ssid="19">For that reason, the results can serve as an upper bound on the real results.</S>
    <S sid="34" ssid="20">The rule-based dependency analyzer (RBDA, Aranzabe et al., 2004) uses a set of 505 CG rules that try to assign dependency relations to wordforms.</S>
    <S sid="35" ssid="21">As the CG formalism only allows the assignment of tags, the rules only aim at marking the name of the dependency relation together with the direction of the head (left or right).</S>
    <S sid="36" ssid="22">For example, this analyzer assigns tags of the form &amp;NCSUBJ&gt; (see figure 1), meaning that the corresponding wordform is a non-clausal syntactic subject and that its head is situated to its right (the &#8220;&gt;&#8221; or &#8220;&lt;&#8221; symbols mark the direction of the head).</S>
    <S sid="37" ssid="23">This means that the result of this analysis is on the one hand a partial analysis and, on the other hand, it does not define a dependency tree, and can also be seen as a set of constraints on the shape of the tree.</S>
    <S sid="38" ssid="24">The system was evaluated on the BDT, obtaining f-scores between 90% for the auxmod dependency relation between the auxiliary and the main verb and 52% for the subject dependency relation, giving a (macro) average of 65%.</S>
    <S sid="39" ssid="25">Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al., 2007b) and MST Parser (McDonald et al., 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and treebanks (McDonald and Nivre, 2007).</S>
    <S sid="40" ssid="26">MaltParser (Nivre, 2006) is a representative of local, greedy, transition-based dependency parsing models, where the parser obtains deterministically a dependency tree in a single pass over the input using two data structures: a stack of partially analyzed items and the remaining input sequence.</S>
    <S sid="41" ssid="27">To determine the best action at each step, the parser uses history-based feature models and discriminative machine learning.</S>
    <S sid="42" ssid="28">The learning configuration can include any kind of information (such as word-form, lemma, category, subcategory or morphological features).</S>
    <S sid="43" ssid="29">Several variants of the parser have been implemented, and we will use one of its standard versions (MaltParser version 1.4).</S>
    <S sid="44" ssid="30">In our experiments, we will use the StackLazy algorithm with the liblinear classifier.</S>
    <S sid="45" ssid="31">The MST Parser can be considered a representative of global, exhaustive graph-based parsing (McDonald et al., 2005, 2006).</S>
    <S sid="46" ssid="32">This algorithm finds the highest scoring directed spanning tree in a dependency graph forming a valid dependency tree.</S>
    <S sid="47" ssid="33">To learn arc scores, it uses large-margin structured learning algorithms, which optimize the parameters of the model to maximize the score margin between the correct dependency graph and all incorrect dependency graphs for every sentence in a training set.</S>
    <S sid="48" ssid="34">The learning procedure is global since model parameters are set relative to classifying the entire dependency graph, and not just over single arc attachments.</S>
    <S sid="49" ssid="35">This is in contrast to the local but richer contexts used by transition-based parsers.</S>
    <S sid="50" ssid="36">We use the freely available version of MSTParser1.</S>
    <S sid="51" ssid="37">In the following experiments we will make use of the second order non-projective algorithm.</S>
  </SECTION>
  <SECTION title="3." number="3">
    <S sid="52" ssid="1">We will experiment the effect of using the output of the knowledge-based analyzers as input to the data-driven parsers in a stacked learning scheme.</S>
    <S sid="53" ssid="2">Figure 1 shows how the two last lines of the example sentence contain the tags assigned by the rule-based chunker (B-NP, I-NP, B-VP and I-VP) and the rule-based partial dependency analyzer (&amp;NCSUBJ, &amp;&lt;NCMOD, &amp;&lt;AUXMOD, &amp;CCOMP_OBJ and &amp;MAINV) .</S>
    <S sid="54" ssid="3">The first step consisted in applying the complete set of text processing tools for Basque, including: properties, such as case, number, tense, or different types of subordination for verbs.</S>
    <S sid="55" ssid="4">Consequently, the morphological analyzer for Basque (Aduriz et al. 2000) gives a high ambiguity.</S>
    <S sid="56" ssid="5">If only categorial (POS) ambiguity is taken into account, there is an average of 1.55 interpretations per wordform, which rises to 2.65 when the full morphosyntactic information is taken into account, giving an overall 64% of ambiguous word-forms. can pose an important problem, as determining the correct interpretation for each word-form requires in many cases the inspection of local contexts, and in some others, as the agreement of verbs with subject, object or indirect object, it could also suppose the examination of elements which can be far from each other, added to the free constituent order of the main sentence elements in Basque.</S>
    <S sid="57" ssid="6">The erroneous assignment of incorrect part of speech or morphological features can difficult the work of the parser.</S>
    <S sid="58" ssid="7">When performing this task, we found the problem of matching the treebank tokens with those obtained from the analyzers, as there were divergences on the treatment of multiword units, mostly coming from Named Entities, verb compounds and complex postpositions (formed with morphemes appearing at two different words).</S>
    <S sid="59" ssid="8">For that reason, we performed a matching process trying to link the multiword units given by the morphological analysis module and the treebank, obtaining a correct match for 99% of the sentences.</S>
    <S sid="60" ssid="9">Regarding the data-driven parsers, they are trained using two kinds of tags as input: syntactic analyzers (two last lines of the example in figure 1).</S>
    <S sid="61" ssid="10">These tags contain errors of the CG-based syntactic taggers.</S>
    <S sid="62" ssid="11">As the analyzers are applied after morphological processing, the errors can be propagated and augmented.</S>
    <S sid="63" ssid="12">Table 1 shows the results of using the output of the knowledge-based analyzers as input to the statistical parsers.</S>
    <S sid="64" ssid="13">We have performed three experiments for each statistical parser, trying with the chunks provided by the chunker, the partial dependency parser, and both.</S>
    <S sid="65" ssid="14">The table shows modest gains, suggesting that the rule-based analyzers help the statistical ones, giving slight increases over the baseline, which are statistically significant when applying MaltParser to the output of the rule-based dependency parser and a combination of the chunker and rule-based parsers.</S>
    <S sid="66" ssid="15">As table 1 shows, the parser type is relevant, as MaltParser seems to be sensitive when using the stacked features, while the partial parsers do not seem to give any significant improvement to MST.</S>
    <S sid="67" ssid="16">Looking with more detail at the errors made by the different versions of the parsers, we observe significant differences in the results for different dependency relations, seeing that the statistical parsers behave in a different manner regarding to each relation, as shown in table 2.</S>
    <S sid="68" ssid="17">The table shows the differences in f-score2 corresponding to five local dependency relations, (determination of verbal modifiers, such as subject, object and indirect object).</S>
    <S sid="69" ssid="18">McDonald and Nivre (2007) examined the types of errors made by the two data-driven parsers used in this work, showing how the greedy algorithm of MaltParser performed better with local dependency relations, while the graph-based algorithm of MST was more accurate for global relations.</S>
    <S sid="70" ssid="19">As both the chunker and the partial dependency analyzer are based on a set of local rules in the CG formalism, we could expect that the stacked parsers could benefit mostly on the local dependency relations.</S>
    <S sid="71" ssid="20">2 f-score = 2 * precision * recall / (precision + recall) (ncmod = non-clausal modifier, ncobj = non-clausal object, ncpred = non-clausal predicate, ncsubj = non-clausal subject, nciobj = non-clausal indirect object) Table 2 shows how the addition of the rule-based parsers&#8217; tags performs in accord with this behavior, as MaltParser gets f-score improvements for the local relations.</S>
    <S sid="72" ssid="21">Although not shown in Table 2, we also inspected the results on the long distance relations, where we did not observe noticeable improvements with respect to the baseline on any parser.</S>
    <S sid="73" ssid="22">For that reason, MaltParser, seems to mostly benefit of the local nature of the stacked features, while MST does not get a significant improvement, except for some local dependency relations, such as ncobj and ncsubj.</S>
    <S sid="74" ssid="23">We performed an additional test using the partial dependency analyzer&#8217;s gold dependency relations as input to MaltParser.</S>
    <S sid="75" ssid="24">As could be expected, the gold tags gave a noticeable improvement to the parser&#8217;s results, reaching 95% LAS.</S>
    <S sid="76" ssid="25">However, when examining the scores for the output dependency relations, we noticed that the gold partial dependency tags are beneficial for some relations, although negative for some others.</S>
    <S sid="77" ssid="26">For example the non-clausal modifier (ncmod) relation&#8217;s f-score increases 3.25 points, while the dependency relation for clausal subordinate sentences functioning as indirect object decreases 0.46 points, which is surprising in principle.</S>
    <S sid="78" ssid="27">For all those reasons, the relation between the input dependency tags and the obtained results seems to be intricate, and we think that it deserves new experiments in order to determine their nature.</S>
    <S sid="79" ssid="28">As each type of syntactic information can have an important influence on the results on specific relations, their study can shed light on novel schemes of parser combination.</S>
  </SECTION>
  <SECTION title="4." number="4">
    <S sid="80" ssid="1">We have presented a preliminary effort to integrate different syntactic analyzers, with the objective of getting the best from each system.</S>
    <S sid="81" ssid="2">Although the potential gain is in theory high, the experiments have shown very modest improvements, which seem to happen in the set of local dependency relations.</S>
    <S sid="82" ssid="3">We can point out some avenues for further research: schemes, such as voting, trying to get the best from each type of parser.</S>
    <S sid="83" ssid="4">Finally, we must also take into account that the rule-based analyzers were developed mainly having linguistic principles in mind, such as coverage of diverse linguistic phenomena or the treatment of specific syntactic constructions (Aranzabe et al., 2004), instead of performanceoriented measures, such as precision and recall.</S>
    <S sid="84" ssid="5">This means that there is room for improvement in the first-stage knowledge-based parsers, which will have, at least in theory, a positive effect on the second-phase statistical parsers, allowing us to test whether knowledge-based and machine learningbased systems can be successfully combined.</S>
  </SECTION>
  <SECTION title="Acknowledgements" number="5">
    <S sid="85" ssid="1">This research was supported by the Department of Industry of the Basque Government (IT344-10, SPE11UN114), the University of the Basque Country (GIU09/19) and the Spanish Ministry of Science and Innovation (MICINN, TIN201020218).</S>
  </SECTION>
</PAPER>
