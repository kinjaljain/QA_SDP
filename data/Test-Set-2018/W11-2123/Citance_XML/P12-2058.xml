<PAPER>
  <S sid="0">Heuristic Cube Pruning in Linear Time</S>
  <ABSTRACT>
    <S sid="1" ssid="1">We propose a novel heuristic algorithm for Cube Pruning running in linear time in the beam size.</S>
    <S sid="2" ssid="2">Empirically, we show a gain in running time of a standard machine translation system, at a small loss in accuracy.</S>
  </ABSTRACT>
  <SECTION title="1 Introduction" number="1">
    <S sid="3" ssid="1">Since its first appearance in (Huang and Chiang, 2005), the Cube Pruning (CP) algorithm has quickly gained popularity in statistical natural language processing.</S>
    <S sid="4" ssid="2">Informally, this algorithm applies to scenarios in which we have the k-best solutions for two input sub-problems, and we need to compute the kbest solutions for the new problem representing the combination of the two sub-problems.</S>
    <S sid="5" ssid="3">CP has applications in tree and phrase based machine translation (Chiang, 2007; Huang and Chiang, 2007; Pust and Knight, 2009), parsing (Huang and Chiang, 2005), sentence alignment (Riesa and Marcu, 2010), and in general in all systems combining inexact beam decoding with dynamic programming under certain monotonic conditions on the definition of the scores in the search space.</S>
    <S sid="6" ssid="4">Standard implementations of CP run in time O(k log(k)), with k being the size of the input/output beams (Huang and Chiang, 2005).</S>
    <S sid="7" ssid="5">Gesmundo and Henderson (2010) propose Faster CP (FCP) which optimizes the algorithm but keeps the O(k log(k)) time complexity.</S>
    <S sid="8" ssid="6">Here, we propose a novel heuristic algorithm for CP running in time O(k) and evaluate its impact on the efficiency and performance of a real-world machine translation system.</S>
  </SECTION>
  <SECTION title="2 Preliminaries" number="2">
    <S sid="9" ssid="1">Let G = (x0, ... , xk&#8722;1) be a list over R, that is, an ordered sequence of real numbers, possibly with repetitions.</S>
    <S sid="10" ssid="2">We write |G |= k to denote the length of G. We say that G is descending if xi &gt; xj for every i, j with 0 &lt; i &lt; j &lt; k. Let G1 = (x0, ... , xk&#8722;1) and G2 = (y0, ... , yk&#8242;&#8722;1) be two descending lists over R. We write G1 &#174; G2 to denote the descending list with elements xi + yj for every i, j with 0 &lt; i &lt; k and 0 &lt; j &lt; k&#8242;.</S>
    <S sid="11" ssid="3">In cube pruning (CP) we are given as input two descending lists G1, G2 over R with |G1 |= |G2 |= k, and we are asked to compute the descending list consisting of the first k elements of G1 &#174; G2.</S>
    <S sid="12" ssid="4">A problem related to CP is the k-way merge problem (Horowitz and Sahni, 1983).</S>
    <S sid="13" ssid="5">Given descending lists Gi for every i with 0 &lt; i &lt; k, we write mergek&#8722;1 i=0 Gi to denote the &#8220;merge&#8221; of all the lists Gi, that is, the descending list with all elements from the lists Gi, including repetitions.</S>
    <S sid="14" ssid="6">For A E R we define shift(G, A) = G &#174; (A).</S>
    <S sid="15" ssid="7">In words, shift(G, A) is the descending list whose elements are obtained by &#8220;shifting&#8221; the elements of G by A, preserving the order.</S>
    <S sid="16" ssid="8">Let G1, G2 be descending lists of length k, with G2 = (y0, .</S>
    <S sid="17" ssid="9">.</S>
    <S sid="18" ssid="10">.</S>
    <S sid="19" ssid="11">, yk&#8722;1).</S>
    <S sid="20" ssid="12">Then we can express the output of CP on G1, G2 as the list truncated after the first k elements.</S>
    <S sid="21" ssid="13">This shows that the CP problem is a particular instance of the k-way merge problem, in which all input lists are related by k independent shifts.</S>
    <S sid="22" ssid="14">Computation of the solution of the k-way merge problem takes time O(q log(k)), where q is the size of the output list.</S>
    <S sid="23" ssid="15">In case each input list has length k this becomes O(k2 log(k)), and by restricting the computation to the first k elements, as required by the CP problem, we can further reduce to O(k log(k)).</S>
    <S sid="24" ssid="16">This is the already known upper bound on the CP problem (Huang and Chiang, 2005; Gesmundo and Henderson, 2010).</S>
    <S sid="25" ssid="17">Unfortunately, there seems to be no way to achieve an asymptotically faster algorithm by exploiting the restriction that the input lists are all related by some shifts.</S>
    <S sid="26" ssid="18">Nonetheless, in the next sections we use the above ideas to develop a heuristic algorithm running in time linear in k.</S>
  </SECTION>
  <SECTION title="3 Cube Pruning With Constant Slope" number="3">
    <S sid="27" ssid="1">Consider lists L1, L2 defined as in section 2.</S>
    <S sid="28" ssid="2">We say that L2 has constant slope if yi&#8722;1 &#8722; yi = 0 &gt; 0 for every i with 0 &lt; i &lt; k. Throughout this section we assume that L2 has constant slope, and we develop an (exact) linear time algorithm for solving the CP problem under this assumption. all elements from L1 that belong to Ii.</S>
    <S sid="29" ssid="3">Thus, moving down one segment in L1 is the closest equivalent to moving down one element in L2.</S>
    <S sid="30" ssid="4">Let t = min{k, s}; we define descending lists Mi, 0 &lt; i &lt; t, as follows.</S>
    <S sid="31" ssid="5">We set M0 = shift(Q0, y0), and for 1 &lt; i &lt; t we let as the descending sublist consisting of all elements of that column that belong to shift(Ii, yj).</S>
    <S sid="32" ssid="6">Then we have Qi,j = shift(Qi, yj).</S>
    <S sid="33" ssid="7">For any d with 0 &lt; d &lt; t, consider now all segments Qi,j with i + j = d, forming a subantidiagonal in L. We observe that these segments contain all and only those elements of L that belong to the interval Id.</S>
    <S sid="34" ssid="8">It is not difficult to show by induction that these elements are exactly the elements that appear in descending order in the list Mi defined in (2).</S>
    <S sid="35" ssid="9">We can then directly use relation (2) to iteratively compute CP on two lists of length k, under our assumption that one of the two lists has constant slope.</S>
    <S sid="36" ssid="10">Using the fact that the merge of two lists as in (2) can be computed in time linear in the size of the output list, it is not difficult to implement the above algorithm to run in time O(k).</S>
  </SECTION>
  <SECTION title="4 Linear Time Heuristic Solution" number="4">
    <S sid="37" ssid="1">In this section we further elaborate on the exact algorithm of section 3 for the constant slope case, and develop a heuristic solution for the general CP problem.</S>
    <S sid="38" ssid="2">Let L1, L2, L and k be defined as in sections 2 and 3.</S>
    <S sid="39" ssid="3">Despite the fact that L2 does not have a constant slope, we can still split each column of L into segments, as follows.</S>
    <S sid="40" ssid="4">Let eIi, 0 &lt; i &lt; k &#8722; 1, be the left-open interval (x0 + yi+1, x0 + yi] of R. Note that, unlike the case of section 3, intervals eIi&#8217;s are not all of the same size now.</S>
    <S sid="41" ssid="5">Let also eIk&#8722;1 = [xk&#8722;1 + yk&#8722;1, x0 + yk&#8722;1].</S>
    <S sid="42" ssid="6">For each i, j with 0 &lt; j &lt; k and 0 &lt; i &lt; k &#8722; j, we define segment eQi,j as the descending sublist consisting of all elements of the j-th column of L that belong to eIi+j.</S>
    <S sid="43" ssid="7">In this way, the j-th column We claim that the ordered concatenation of M0, M1, ... , Mt&#8722;1 truncated after the first k elements is exactly the output of CP on input L1, L2.</S>
    <S sid="44" ssid="8">To prove our claim, it helps to visualize the descending list L1 &#8853; L2 (of size k2) as a k x k matrix L whose j-th column is shift(L1, yj), 0 &lt; j &lt; k. For an interval I = (x, x&#8242;], we define shift(I, y) = (x + y, x&#8242; + y].</S>
    <S sid="45" ssid="9">Similarly to what we have done with L1, we can split each column of L into s segments.</S>
    <S sid="46" ssid="10">For each i, j with 0 &lt; i &lt; s and 0 &lt; j &lt; k, we define the i-th segment of the j-th column, written Qi,j, we have a variable number of segments per column.</S>
    <S sid="47" ssid="11">Note that segments eQi,j with a constant value of i+j contain all and only those elements of L that belong to the left-open interval eIi+j.</S>
    <S sid="48" ssid="12">Similarly to section 3, we define descending lists fMi, 0 &lt; i &lt; k, by setting fM0 = eQ0,0 and, for 1 &lt; i &lt; k, by letting Note that the function path( Mi&#8722;1, L) should not return shift(fMi&#8722;1, &#8722;0), for some value 0, as in the case of (2).</S>
    <S sid="49" ssid="13">This is because input list L2 does not have constant slope in general.</S>
    <S sid="50" ssid="14">In an exact algorithm, path(fMi&#8722;1, L) should return the descending list L&#8902; i&#8722;1 = mergeij=1 e&#65533;i&#8722;j,j: Unfortunately, we do not know how to compute such a i-way merge without introducing a logarithmic factor.</S>
    <S sid="51" ssid="15">Our solution is to define path(fMi&#8722;1, L) in such a way that it computes a list Li&#8722;1 which is a permutation of the correct solution L&#8902; i&#8722;1.</S>
    <S sid="52" ssid="16">To do this, we consider the &#8220;relative&#8221; path starting at x0 +yi&#8722;1 that we need to follow in L in order to collect all the elements of fMi&#8722;1 in the given order.</S>
    <S sid="53" ssid="17">We then apply such a path starting at x0 + yi and return the list of collected elements.</S>
    <S sid="54" ssid="18">Finally, we compute the output list eL&#8902; as the concatenation of all lists fMi up to the first k elements.</S>
    <S sid="55" ssid="19">It is not difficult to see that when L2 has constant slope we ehave Mi = Mi for all i with 0 &#8804; i &lt; k, and list L&#8902; is the exact solution to the CP problem.</S>
    <S sid="56" ssid="20">When L2 does not have a constant slope, list eL&#8902; might depart from the exact solution in two respects: it might not be a descending list, because of local variations in the ordering of the elements; and it might not be a permutation of the exact solution, because of local variations at the end of the list.</S>
    <S sid="57" ssid="21">In the next section we evaluate the impact that referColumn =0 We encode a relative path (mentioned above) as a sequence of elements, called displacements, each of the form [i, S].</S>
    <S sid="58" ssid="22">Here i is the index of the next row, and S represents the relative displacement needed to reach the next column, to be summed to a variable called referColumn denoting the index of the column of the first element of the path.</S>
    <S sid="59" ssid="23">The reason why only the second coordinate is a relative value is that we shift paths only horizontally (row indices are preserved).</S>
    <S sid="60" ssid="24">The relative path is stored in a circular list C, with displacement [0, 1] marking the starting point (paths are always shifted one element to the right).</S>
    <S sid="61" ssid="25">When merging the list obtained through the path for Mi&#8722;1 with segment e&#65533;i,0, as specified in (3), we update C accordingly, so that the new relative path can be used at the next round for fMi.</S>
    <S sid="62" ssid="26">The merge operator is implemented by the while cycle at lines 8 to 19 of algorithm 1.</S>
    <S sid="63" ssid="27">The if statement at line 9 tests whether the next step should follow the relative path for fMi&#8722;1 stored in C (lines 10 to 14) or LCP speed gain over CP LCP speed gain over FCP else depart visiting an element from Qi,0 in the first column of L (lines 16 to 19).</S>
    <S sid="64" ssid="28">In the latter case, we update C with the new displacement (line 18), where the function insert() inserts a new element before the one currently pointed to.</S>
    <S sid="65" ssid="29">The function next() at line 13 moves the iterator to the next element and then returns its value.</S>
    <S sid="66" ssid="30">A running example of algorithm 1 is reported in Figure 1.</S>
    <S sid="67" ssid="31">The input lists are L1 = (12, 7, 5, 0), L2 = (9, 6, 3, 0).</S>
    <S sid="68" ssid="32">Each of the picture in the sequence represents the state of the algorithm when the test at line 9 is executed.</S>
    <S sid="69" ssid="33">The value in the shaded cell in the first column is xdeviate, while the value in the other shaded cell is xfollow.</S>
  </SECTION>
  <SECTION title="5 Experiments" number="5">
    <S sid="70" ssid="1">We implement Linear CP (LCP) on top of Cdec (Dyer et al., 2010), a widely-used hierarchical MT system that includes implementations of standard CP and FCP algorithms.</S>
    <S sid="71" ssid="2">The experiments were executed on the NIST 2003 Chinese-English parallel corpus.</S>
    <S sid="72" ssid="3">The training corpus contains 239k sentence pairs.</S>
    <S sid="73" ssid="4">A binary translation grammar was extracted using a suffix array rule extractor (Lopez, 2007).</S>
    <S sid="74" ssid="5">The model was tuned using MERT (Och, 2003).</S>
    <S sid="75" ssid="6">The algorithms are compared on the NIST-03 test set, which contains 919 sentence pairs.</S>
    <S sid="76" ssid="7">The features used are basic lexical features, word penalty and a 3-gram Language Model (Heafield, 2011).</S>
    <S sid="77" ssid="8">Since we compare decoding algorithms on the same search space, the accuracy comparison is done in terms of search score.</S>
    <S sid="78" ssid="9">For each algorithm we compute the average score of the best translation found for the test sentences.</S>
    <S sid="79" ssid="10">In Figure 2 we plot the score-loss relative to standard CP average score.</S>
    <S sid="80" ssid="11">Note that the FCP loss is always &lt; 3%, and the LCP loss is always &lt; 7%.</S>
    <S sid="81" ssid="12">The dotted line plots the loss of a baseline linear time heuristic algorithm which assumes that both input lists have constant slope, and that scans L along parallel lines whose steep is the ratio of the average slope of each input list.</S>
    <S sid="82" ssid="13">The baseline greatly deteriorates the accuracy: this shows that finding a reasonable linear time heuristic algorithm is not trivial.</S>
    <S sid="83" ssid="14">We can assume a bounded loss in accuracy, because for larger beam size all the algorithms tend to converge to exhaustive search.</S>
    <S sid="84" ssid="15">We found that these differences in search score resulted in no significant variations in BLEU score (e.g. with k = 30, CP reaches 32.2 while LCP 32.3).</S>
    <S sid="85" ssid="16">The speed comparison is done in terms of algorithm run-time.</S>
    <S sid="86" ssid="17">Figure 3 plots the relative speed gain of LCP over standard CP and over FCP.</S>
    <S sid="87" ssid="18">Given the log-scale used for the beam size k, the linear shape of the speed gain over FCP (and CP) in Figure 3 empirically confirms that LCP has a log(k) asymptotic advantage over FCP and CP.</S>
    <S sid="88" ssid="19">In addition to Chinese-English, we ran experiments on translating English to French (from Europarl corpus (Koehn, 2005)), and find that the LCP score-loss relative to CP is &lt; 9% while the speed relative advantage of LCP over CP increases in average by 11.4% every time the beam size is multiplied by 10 (e.g. with k = 1000 the speed advantage is 34.3%).</S>
    <S sid="89" ssid="20">These results confirm the bounded accuracy loss and log(k) speed advantage of LCP.</S>
  </SECTION>
</PAPER>
