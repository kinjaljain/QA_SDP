<PAPER>
	<S sid="0">Unsupervised All-words Word Sense Disambiguation with Grammatical Dependencies</S><ABSTRACT>
		<S sid="1" ssid="1">We present experiments that analyze the necessity of using a highly interconnectedword/sense graph for unsupervised all words word sense disambiguation.</S>
		<S sid="2" ssid="2">We show that allowing only grammatically related words to influence each other?s senses leads to disambiguation results on a par with thebest graph-based systems, while greatly reducing the computation load.</S>
		<S sid="3" ssid="3">We also com pare two methods for computing selectional preferences between the senses of every two grammatically related words: one using a Lesk-based measure on WordNet, the other using dependency relations from the British National Corpus.</S>
		<S sid="4" ssid="4">The best configurationuses the syntactically-constrained graph, se lectional preferences computed from thecorpus and a PageRank tie-breaking algo rithm.</S>
		<S sid="5" ssid="5">We especially note good performancewhen disambiguating verbs with grammati cally constrained links.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="6" ssid="6">It has long been believed that being able to detectthe correct sense of a word in a given context ? per forming word sense disambiguation (WSD) ? will lead to improved performance of systems tackling high end applications such as machine translation (Chan et al, 2007) and summarization(Elhadad et al., 1997).</S>
			<S sid="7" ssid="7">In order for WSD methods to be useful,they must be robust, portable, scalable, and there fore preferably not reliant on manually tagged data.</S>
			<S sid="8" ssid="8">These desiderata have lead to an increased interest in developing unsupervised WSD methods, flexiblerelative to the word sense inventory, and which dis ambiguate all open-class words in a given context as opposed to a selected few.</S>
			<S sid="9" ssid="9">Particularly appropriate from this point of view are graph-based methods (Navigli and Lapata, 2007), which map the open-class words in a given context onto a highly interconnected graph.</S>
			<S sid="10" ssid="10">Each node in this graph represents a word sense, and weighted edges will connect every pair of senses (corresponding to different words).</S>
			<S sid="11" ssid="11">The topologyof the graph and the weights of the edges can con tribute in a variety of ways to determine the best sense combination for the words in the considered context.</S>
			<S sid="12" ssid="12">This approach leads to large and highly interconnected graphs, in which distant, unrelated (in the context) words, are nonetheless connected,and allowed to influence each other?s sense preferences.</S>
			<S sid="13" ssid="13">We study the impact on disambiguation per formance when connections are restricted to pairs ofword senses corresponding to words that are gram matically linked in the considered context.</S>
			<S sid="14" ssid="14">The benefits of using grammatical information for automatic WSD were first explored by Yarowsky(1995) and Resnik (1996), in unsupervised ap proaches to disambiguating single words in context.Sussna (1993) presents a first approach to disambiguating together words within a context.</S>
			<S sid="15" ssid="15">The focus is on nouns, and the sense combination that min imizes the overall distance in the WordNet nouns network is chosen.Stetina et al (1998) present the first approach, su pervised, to disambiguating all words in a sentence with sense association (or selectional) preferences computed from a sense-tagged corpus.</S>
			<S sid="16" ssid="16">An untagged grammatically linked word pair will have associated a matrix of sense combination scores, based on theanalyzed sense-tagged corpus, and similarities be tween the current words and those in tagged pairswith the same grammatical relation.</S>
			<S sid="17" ssid="17">Once such ma trices are computed for all grammatically related word pairs, the sense preferences are propagated from the bottom of the parse tree towards the top,and the sense selection starts from the top and prop agates downward.McCarthy and Carroll (2003) also use an unsuper vised approach and grammatical relations to learnselectional preferences for word classes.</S>
			<S sid="18" ssid="18">In an ap proach inspired by the works of Li and Abe (1998) and Clark and Weir (2002), McCarthy and Carroll use grammatically connected words from a corpus to induce a distribution of senses over subtrees in the WordNet hierarchy.</S>
			<S sid="19" ssid="19">McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentencewill be connected through directed edges.</S>
			<S sid="20" ssid="20">We ex periment with graph edge weights computed usingWordNet, and weights computed using grammati cal collocation information from a corpus.</S>
			<S sid="21" ssid="21">These 757 weights are used to induce an initial scoring of thegraph vertices, starting from the leaves and propa gating upwards.</S>
			<S sid="22" ssid="22">The disambiguation process starts with choosing a sense for the head of the sentence,and moves towards the leaves, propagating down ward the chosen senses at each step, and using the edge weights and vertex scores to guide the sense selection process.</S>
			<S sid="23" ssid="23">We investigate two issues: (i) whether using in disambiguation only syntactically connected words leads to results on a par with, or better than, using allword-sense combinations, (ii) whether sense association strength induced from a sense-unlabeled cor pus can rival relatedness measures induced from a lexical resource - in our case, WordNet.We evaluate this approach on the Senseval 2(Palmer et al, 2001) and Senseval-3(Snyder and Palmer, 2004) English all-words test data.</S>
			<S sid="24" ssid="24">On the Senseval-2 data we obtain results on a par with thebest unsupervised WSD systems, on the Senseval 3 data, the results are lower overall, but for verbs higher than those obtained with other graph-basedmethods.</S>
			<S sid="25" ssid="25">In both situations, using only grammatically motivated edges leads to improved disam biguation of verbs compared to disambiguating in a graph with unrestricted connections.</S>
	</SECTION>
	<SECTION title="Disambiguation Algorithm. " number="2">
			<S sid="26" ssid="1">The disambiguation method described here uses grammatical information from the sentential context to constrain word pairs that are allowed to influence each other?s sense choice.</S>
			<S sid="27" ssid="2">Edge weights in the graph are relatedness scores computed based on WordNetand, in a second set-up, selectional preferences estimated from an (sense-)untagged corpus, for disambiguating together all words in the sentence.</S>
			<S sid="28" ssid="3">Grammatical information for the sentential context is ob tained using the dependency relation output of theStanford Parser (de Marneffe et al, 2006).</S>
			<S sid="29" ssid="4">Selec tional preferences are estimated using grammatical collocation information from the British NationalCorpus (BNC), obtained with the Word Sketch En gine (WSE) (Kilgarriff et al, 2004).</S>
			<S sid="30" ssid="5">2.1 Extracting grammatical relation.</S>
			<S sid="31" ssid="6">information We parse the Senseval test data using the Stanford Parser(Klein and Manning, 2003) generating the output in dependency relation format (de Marneffe et al, 2006).</S>
			<S sid="32" ssid="7">Edges that do not connect open-class words are filtered out, words are lemmatized, and we reintroduce the copula (it is bypassed as a predicate) because the verb be must be disambiguated as well.To estimate selectional preferences from a sense untagged corpus, for each grammatically related pairof words in a sentence we extract evidence consist Dependency relation WSE relation nsubj(verb,noun) subject(verb,noun) subject of(noun,verb) dobj(verb,noun) object(verb,noun) object of(noun,verb) amod(noun,adj) a modifier(noun,adj) modifies(adj,noun) nn(noun1,noun2) n modifier(noun1,noun2)modifies(noun2,noun1)prep of(verb,noun) pp of(verb,noun) pp-obj of(noun,verb) Table 1: Mapping of grammatical relations from the Stanford Parser onto the WSE relation set ? a sample.</S>
			<S sid="33" ssid="8">ing of pairs with the same grammatical relation and either the same head or dependent, using the Word Sketch Engine.</S>
			<S sid="34" ssid="9">To obtain such pairs we map the grammatical relations used by the Stanford Parser onto the set of grammatical relations used by the WSE.</S>
			<S sid="35" ssid="10">Table 1 shows a sample of this mapping.</S>
			<S sid="36" ssid="11">We denote by GR?1 the inverse of grammatical relationGR ? for example subject of is the inverse of sub ject.</S>
			<S sid="37" ssid="12">The result of this processing is illustrated in Figure 1, for the following sentence from the Senseval2 test data: The art of change-ringing is peculiar to the English, and, like most English peculiarities, unintelligible to the rest of the world.</S>
			<S sid="38" ssid="13">pp_like pp?obj_likeadj_comp_of peculiarity most a_modifier English modifies a_modifier modifies unintelligible world pp_of pp_to pp?obj_to pp?obj_of rest subject subject_of adj_comp be English pp?obj_to pp_to adj_comp_of adj_comp peculiar art change?ringing pp_of pp?obj_of Figure 1: Dependency graph with grammatical relations mapped onto the WSE set The dependency between two connected wordsis represented by two asymmetric grammatical re lations.</S>
			<S sid="39" ssid="14">2.2 Computing sense selectional preference.</S>
			<S sid="40" ssid="15">scores The selectional preference scores can be computed using the lexical resource that provides the inventory of senses, or using a corpus.Sense-selectional preferences based on depen dency relations in a corpus For each pair of words in a grammatical relation (w1, w2, GR) from a sentence, we compute a score for each sense siw2of w2, that shows the strength of the association 758 between siw2 and w1.</S>
			<S sid="41" ssid="16">The strength of the associ-ation will come from collocation information fromthe BNC, combined with sense similarity or related ness between siw2 and collocates of w1 in grammat-ical relation GR.</S>
			<S sid="42" ssid="17">Let us take an example ?</S>
			<S sid="43" ssid="18">(rest,world,pp of) from the example sentence presented before.</S>
			<S sid="44" ssid="19">We want to estimate the preferences of rest for senses of world.</S>
			<S sid="45" ssid="20">world has the following senses in WordNet 1.71: world%1:17:02::2, world%1:17:00::, world%1:17:01::, world%1:14:02::, world%1:14:01::, world%1:14:00::, world%1:09:01::, world%1:09:00:: .From the BNC we obtain the following colloca tion information (the formatting of the list is w1-POS GR wx-POS:co-occurrence frequency): rest-n pp of life-n:639, world-n:518, Europe-n:211, cast-n:44, season-n:90, day-n:253,country-n:158, family-n:134, evening n:60, Kingdom-n:42, chapter-n:55, team-n:96, week-n:93, society-n:89, afternoon-n:34, population-n:56, ...The list of grammatical collocates with rest in re lation pp of are: GCpp?ofrest = { life, world, Europe,case, season, day, country, family, evening, Kingdom, chapter, team, week, society, afternoon, popu lation,...</S>
			<S sid="46" ssid="21">} Based on relatedness scores between senses of these collocates and senses of world we compute selectional preference scores for each of world?s senses: world%1:17:02::?1 world%1:17:00::?2 world%1:17:01::?3 world%1:14:02::?2 world%1:14:01::?3 world%1:14:00::?4 world%1:09:01::?1 world%1:09:00::?1 The same procedure is applied to compute the sense selectional preference scores of world for each of rest?s senses, in the grammatical relation pp-obj of (the inverse of pp of in WSE).</S>
			<S sid="47" ssid="22">Formally, for the tuple (w1, w2, GR), we extract from the BNC all pairs (w1, wx, GR)3.</S>
			<S sid="48" ssid="23">The set GCGRw1 = {wx|(w1, wx, GR) ? corpus} gives w1?s grammatical collocations.</S>
			<S sid="49" ssid="24">To estimatethe sense association strength between w1 and senses of w2, for each wx ? GCGRw1 we computerelatedness between the senses of wx and the senses of w2.</S>
			<S sid="50" ssid="25">As i w2 w1|GR, the association strength between w1 and sense siw2 of word w2 under relation GR, is the 1WordNet 1.7 is the sense inventory for Senseval2, WordNet 1.7.1 is the sense inventory for Senseval 3.</S>
			<S sid="51" ssid="26">2Unique sense identifier from the WN lexicographer files.</S>
			<S sid="52" ssid="27">3Only wx collocates that have the same part of speech as w2are considered.</S>
			<S sid="53" ssid="28">sum of these relatedness scores: As i w2 w1|GR = ? wx?GCGRw1 ? sjwx?Swx rel(siw2 , s j wx) where Swx is the set of senses for word wx.</S>
			<S sid="54" ssid="29">If this value is 0, then As i w2 w1|GR = 1 nw2 , where nw2 is the number of senses of w2.</S>
			<S sid="55" ssid="30">rel(siw2 , sjwx) can be computed as a similarity orrelatedness measure (Budanitsky and Hirst, 2006).</S>
			<S sid="56" ssid="31">Because the sense inventory for the Senseval data comes from WordNet and we work at the sense level, we use relatedness measures based on WordNet, as opposed to corpus-based ones.</S>
			<S sid="57" ssid="32">In the experimentspresented further in the paper, we have used a relat edness measure based on hypernym and hyponym information, in the following manner: rel(siw2 , s j wx) = ? ?</S>
			<S sid="58" ssid="33">1 : siw2 is a hypernym of sjwx 1 : siw2 is a hyponym of sjwxand path length(siw2 , sjwx) ? 2 1 : siw2 similar to/antonym of sjwx0 : otherwiseIn other words, if the sense siw2 of w2 is a hy pernym of the sense sjwx or a close hyponym (dis-tance at most 2) or connected through a similar to/antonym of relation, we consider the two senses related and relatedness gets a score of 1.</S>
			<S sid="59" ssid="34">Otherwise, we consider the two senses unrelated.The motivation for using this relatedness measure is that it allows fast computations ? essential when dealing with a large amount of informa tion from a corpus ? and it clusters closely relatedsenses based on WordNet?s hypernym/hyponym re lations.</S>
			<S sid="60" ssid="35">By clustering together related senses, we gather more evidence for the selectional preferences of w2?s senses, which also helps partly with the datasparseness problem.</S>
			<S sid="61" ssid="36">Because at this point it is not determined to whichof wx?s senses the selectional preference is due, allof wx?s senses will have the same selectional prefer ence to a sense j of wy: As j wy siwx |GR = As j wy wx|GR, for all senses siwx of wx.</S>
			<S sid="62" ssid="37">Sense-selectional preferences based on a lexicalresource When using the lexical resource, because we have pairs that connect words under differ ent parts of speech, we opt for a Lesk-based measure (Banerjee and Pedersen, 2003).</S>
			<S sid="63" ssid="38">Relatedness scoresare computed for each pair of senses of the gram matically linked pair of words (w1, w2, GR), usingthe WordNet-Similarity-1.03 package and the lesk 759option (Pedersen et al, 2004).</S>
			<S sid="64" ssid="39">To maintain the nota tion from above, we denote by Asiwx sjwythe lesk relat edness score between sense i of wx and sense j of wy. These scores are symmetric: As i wx sjwy = As j wy siwx , and independent of grammatical relations GR.</S>
			<S sid="65" ssid="40">2.3 The sense-enhanced dependency tree.</S>
			<S sid="66" ssid="41">After computing the sense association strength scores for w1 and w2 in grammatical relation GRin the sentence, we expand the edge (wx, wy, GR)from the dependency tree to the two sets of directed edges: {(siwx ? sjwy , GR)|i = 1, n; j = 1, m}, {(sjwy ? siwx , GR?1)|i = 1, n; j = 1, m}.</S>
			<S sid="67" ssid="42">The weight of an edge (siwx ? sjwy , GR) is As j wy siwx |GR . Figure 2 shows one sense-enhanced edge..</S>
			<S sid="68" ssid="43">%1:17:00::%1:17:02:: %1:14:02:: %1:10:00:: %1:06:00:: %1:24:00 world%... rest | pp_ofA A rest%... world | pp?obj_of rest world pp_of pp?obj_of world rest ...</S>
			<S sid="69" ssid="44">2 2 1 2 1 1 1 4 1 4 1 2 1 1 4 1 2 2 ...</S>
			<S sid="70" ssid="45">Figure 2: A sense enhanced edge, with weights induced from corpus collocations.</S>
			<S sid="71" ssid="46">2.4 Word sense disambiguation.</S>
			<S sid="72" ssid="47">We first compute a score for each vertex (word sense) using the estimated sense preferences, traversing the dependency graph from the bottom up4.</S>
			<S sid="73" ssid="48">Each leaf is given a score of 1nw , where nwis the number of senses of the word w to which theleaf pertains.</S>
			<S sid="74" ssid="49">The score of the other vertices are theweighted sum of the scores of their grammatical de pendents in the sentence under analysis: Score(siwx) = ?</S>
			<S sid="75" ssid="50">(wx,wy ,GR) ? sjwy ?Swy A sjwy siwx |GR ? Score(sjwy ) The word sense disambiguation process starts from the root node of the dependency tree.</S>
			<S sid="76" ssid="51">The highest ranked score for the root is chosen, and the nodescorresponding to the other senses and their edges are deleted from the graph.</S>
			<S sid="77" ssid="52">For each of its dependents4The up-down orientation of the graph is given by the de pendency tree from which it was expanded.we add the sense preferences imposed by the cho sen sense to the vertex?s score, and proceed with the sense selection in the same way down through the graph.</S>
			<S sid="78" ssid="53">Score(sjwy ) = Score(s j wy ) + A sjwy siwx |GR?1 where (wx, wy, GR) ((wy, wx, GR?1)) is in thecurrent sentence.Because of data sparseness, there may be not enough evidence in the corpus to produce a clear winner, and several senses are tied.</S>
			<S sid="79" ssid="54">All senses arethen kept, and disambiguation proceeds further.</S>
			<S sid="80" ssid="55">If more than one word has multiple senses left afterthe top-down traversal of the tree, we use two meth ods: random choosing from the tied senses or the sequence labeling method described in (Mihalcea,2005).</S>
			<S sid="81" ssid="56">The graph?s vertices are the senses that remain to be disambiguated, and its edges connect every pair of these senses (provided that they corre spond to different words).</S>
			<S sid="82" ssid="57">The score of each vertex is initially set to 1, and the edge weights are Lesk similarity scores.</S>
			<S sid="83" ssid="58">The vertices are scored using aPage Rank algorithm, in which the rank at every it eration step is computed with the formula: WP (a) = (1?</S>
			<S sid="84" ssid="59">d) + d ? b?In(a) wba ? c?Out(b) wbc WP (b) where: a, b, c are vertices in the graph; WP (a) is the weighted PageRank score of node a; d is the probability that there will be a jump from a given vertex to another in the graph.</S>
			<S sid="85" ssid="60">We use d = 0.85, the value set by (Brin and Page, 1998) for Google?s PageRank model.</S>
			<S sid="86" ssid="61">In(a) is the set of a?s predecessors; Out(a) is the set of a?s successors.</S>
			<S sid="87" ssid="62">When the vertex scores converge5, the highestranking vertex for each word will give the sense pre diction for that word.</S>
			<S sid="88" ssid="63">For multi-term expressions that are split during parsing (such as come back), for which there is no prediction since they do not appear as such in the parse tree, the system randomly picks one of the WordNet senses.</S>
	</SECTION>
	<SECTION title="Experiments and Results. " number="3">
			<S sid="89" ssid="1">The WSD algorithm proposed is evaluated on the Senseval-2 and Senseval-3 English-all-words tasktest data.</S>
			<S sid="90" ssid="2">Table 2 shows the results obtained for fine grained scoring.</S>
			<S sid="91" ssid="3">Because for each target there is a prediction, precision and recall have the same value.</S>
			<S sid="92" ssid="4">5An aperiodic, irreducible graph is guaranteed to converge (Grimmett and Stirzaker, 1989).</S>
			<S sid="93" ssid="5">For every graph we built that has more than 3 nodes, the aperiodicity condition is met ? it has cycles of length 2 and 3, therefore the greatest common divisor of its cycle lengths is 1.</S>
			<S sid="94" ssid="6">The graph is also irreducible ? it has no leaves because it is highly interconnected.</S>
			<S sid="95" ssid="7">760 POS Rand.</S>
			<S sid="96" ssid="8">Seq.</S>
			<S sid="97" ssid="9">GRWN GRPRWN GRBNC GRPRBNCSenseval 2 noun 41.1% 63.0% 58.9% 62.4% 54.2% 63.3% verb 22.0% 31.6% 31.0% 33.0% 30.9% 32.7% adjective 38.9% 56.8% 52.9% 56.8% 40.4% 56.8% adverb 53.2% 57.5% 53.2% 58.8% 53.2% 59.1% all 36.7% 52.1% 49.0% 52.4% 44.6% 52.7% Senseval 3 noun 42.5% 58.2% 53.2% 55.4% 40.3% 58.6% verb 19.4% 40.4% 40.3% 42.3% 19.9% 40.0% adjective 45.0% 56.7% 53.4% 54.5% 46.0% 57.5% adverb 92.9% 92.9% 92.9% 92.9% 92.9% 92.9% all 34.4% 50.8% 48.2% 50.1% 33.8% 51.2%Table 2: Precision ( = Recall) disambiguation results for Sen seval English-all-words test dataColumn Random (Rand.)</S>
			<S sid="98" ssid="10">shows a simple ran dom baseline, and column Sequence (Seq.)</S>
			<S sid="99" ssid="11">shows the sequence data labelling method (Mihalcea, 2005) ? one of the best performing graph-methods (Navigli and Lapata, 2007).</S>
			<S sid="100" ssid="12">The results presented were obtained using word similarities computed with the WordNet-Similarity-1.03 package, on a sense graph built using the marked targets in thetest set.</S>
			<S sid="101" ssid="13">These results are not the same as those re ported in (Mihalcea, 2005) for the Senseval 2 data(nouns 57.5%, verbs: 36.5%, adjective: 56.7%, adverb: 70.9%, for an average precision of 54.2%), because of the difference in computing word similarities.</S>
			<S sid="102" ssid="14">The other 4 columns show results obtained us ing grammatical relation information between words as identified by the parser.</S>
			<S sid="103" ssid="15">GRWN includes the re-sults obtained using the Lesk-based similarity withthe syntactically-based graph and breaking ties randomly, GRPRWN presents results obtained in a simi-lar configuration ? only the tie breaking is done us ing PageRank.</S>
			<S sid="104" ssid="16">GRBNC and GRPRBNC are similarwith the previous two columns, only in this case the edge weights are the selectional preference scores induced from the BNC.</S>
			<S sid="105" ssid="17">The performance of GRWN is close to that ofSeq.</S>
			<S sid="106" ssid="18">When ties are broken randomly, the compu tation is much faster, since we do two traversals ofa small graph, while PageRank iterates until conver gence (approx.</S>
			<S sid="107" ssid="19">15 iterations) on graphs of average size of 1500 edges and 52 vertices (on Senseval 2data).</S>
			<S sid="108" ssid="20">When PageRank is used to solve ties the per formance on GRPRWN surpasses that of Seq whilestill being faster, having to iterate over graphs withan average of 1074 edges and 40 vertices.</S>
			<S sid="109" ssid="21">The computation load is not only lighter during disambigua tion, but also in the data preparation stage, when similarities must be computed between every sense pair corresponding to every pair of words within a sentence (or a window of a given size).</S>
			<S sid="110" ssid="22">There are other important differences.</S>
			<S sid="111" ssid="23">While the syntactic structure of the sentence plays no role in the Sequence method, it is crucial for the other methods.</S>
			<S sid="112" ssid="24">In the Senseval data not all words in a sentence were tagged as targets, and the Sequence method works only on them.</S>
			<S sid="113" ssid="25">This is not the case for the GR methods, which work with the full syntactic tree ? and will disambiguate more words at a time.Also, the targets tagged in the data contain ?satel lites?</S>
			<S sid="114" ssid="26">information (e.g. turn out, set up), which may change the part of speech of the main target (e.g. at the same time (adv) for target time (noun), out of print (adj) for target print (noun)).</S>
			<S sid="115" ssid="27">Multi-wordexpressions are themselves the subject of ample re search, and we could not incorporate them into our corpus-based approach.</S>
			<S sid="116" ssid="28">Verb particles in particular pose a problem, as most parsers will interpret the particle as a preposition or adverb.</S>
			<S sid="117" ssid="29">This was the case for the Senseval data, as well.</S>
			<S sid="118" ssid="30">On the other hand, this is a more realistic set-up, with no reliance on previously marked targets.</S>
			<S sid="119" ssid="31">Selectional preferences induced from a corpus without sense annotations perform well for verbs, but overall do not perform very well by themselves.The reasons for this are multiple.</S>
			<S sid="120" ssid="32">The most important is data sparseness.</S>
			<S sid="121" ssid="33">Many sense selection prefer ences are 0.</S>
			<S sid="122" ssid="34">In order to improve this approach, we will look into more flexible methods for computing dependency pair similarities (without fixing one ofthe vertices as we did in this paper).</S>
			<S sid="123" ssid="35">Previous re search in inducing sense rankings from an untaggedcorpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other appli cations) (Erk, 2007) will provide the starting point for research in this direction.</S>
	</SECTION>
	<SECTION title="Comparison with Related Work. " number="4">
			<S sid="124" ssid="1">The most similar approach to the one we describe,that has been tested on Senseval-2, is the one de scribed in (McCarthy and Carroll, 2003).</S>
			<S sid="125" ssid="2">The bestresults reported are 51.1% precision and 23.2% recall.</S>
			<S sid="126" ssid="3">This implementation also used grammatical in formation and selectional preferences induced froma corpus to determine a disjoint partition ? deter mined by a cut in the WordNet is-a tree ? over which it computes a probability distribution conditioned by the grammatical context and a verb or adjective class.</S>
			<S sid="127" ssid="4">McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derivessense ranking based on word similarity and distribu tional analysis in a corpus.</S>
			<S sid="128" ssid="5">Mihalcea (2005) reports the highest results on theSenseval-2 data obtained with a graph-based algorithm ? 54.2% precision and recall.</S>
			<S sid="129" ssid="6">The results ob tained with a PageRank algorithm applied to a sense graph built from a words within a context of a given 761size are also the highest for a completely unsuper vised WSD6 system in Senseval-2.The best result obtained by an unsupervised system on the Senseval-3 data is reported by Strappa rava et al (2004) ? 58.3%.</S>
			<S sid="130" ssid="7">This implementationuses WordNet-Domains, a version of WordNet enhanced with domain information (e.g. economy, geography).</S>
			<S sid="131" ssid="8">The domain of a given text is automat ically detected, and this information will constrain the possible senses of words in the given text.</S>
			<S sid="132" ssid="9">For Senseval 3 data, using a graph method with the Key Player Problem to measure vertex relevance, Navigli and Lapata (2007) report very close results to (Strapparava et al, 2004) on nouns and adjectives, and lower scores for verbs (F1-scores: 61.9% fornouns, 62.8% for adjectives, 36.1% for verbs com pared with 62.2% for nouns, 66.9% for adjectives,50.4% for verbs).</S>
			<S sid="133" ssid="10">Mihalcea (2005) reports an over all score of 52.2% for this data.</S>
			<S sid="134" ssid="11">It is interesting to look at the dependency tree we used for WSD from the point of view of graph connectivity measures (Navigli and Lapata, 2007).</S>
			<S sid="135" ssid="12">To determine the importance of a node in a graph, whether it represents the words and their senses in a given context, or people in a social network, one can use different measures.</S>
			<S sid="136" ssid="13">According to grammatical theories, the importance of a node in the sentence parse tree is given by the phrase type it heads, and the number of words it thus dominates.</S>
			<S sid="137" ssid="14">From this point of view, the top-down propagation of senses traverses and disambiguates the tree in order of the decreasing importance of nodes.</S>
			<S sid="138" ssid="15">Other methods could be used as well, such as disambiguating first the most highly connected nodes ? the ones with the most sense constraints.</S>
	</SECTION>
	<SECTION title="Conclusions. " number="5">
			<S sid="139" ssid="1">We have studied the impact of grammatical in formation for constraining and guiding the word sense disambiguation process in an unsupervised all-words setup.</S>
			<S sid="140" ssid="2">Compared with graph methods, the approach we described is computationally lighter, while performing at the same level on Senseval-2and Senseval-3 all-words tasks test data.</S>
			<S sid="141" ssid="3">Grammat ical constraints serve both to limit the number of word-senses pair similarities necessary, and also to estimate selectional preferences from an untagged corpus.</S>
			<S sid="142" ssid="4">Using only grammatically motivated connections leads to better disambiguation of verbs for both Senseval-2 and Senseval-3 test data, but while thedifference is consistent (1.4%, 1.9%) it is not statis tically significant.</S>
			<S sid="143" ssid="5">6As opposed to other unsupervised approaches, the sense frequency information from WordNet was not used.</S>
			<S sid="144" ssid="6">We explored a new method for estimating sense association strength from a sense-untagged corpus.Disambiguation when using sense relatedness com puted from WordNet is very close in performance with disambiguation based on sense association strength computed from the British National Corpus,and on a par with state-of-the-art unsupervised systems on Senseval-2.</S>
			<S sid="145" ssid="7">This indicates that grammatical relations and automatically derived sense association preference scores from a corpus have high potential for unsupervised all-word sense disambigua tion.</S>
	</SECTION>
</PAPER>
