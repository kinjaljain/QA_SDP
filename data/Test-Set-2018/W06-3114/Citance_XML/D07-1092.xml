<PAPER>
	<S sid="0">Translating Unknown Words by Analogical Learning</S><ABSTRACT>
		<S sid="1" ssid="1">Unknown words are a well-known hindranceto natural language applications.</S>
		<S sid="2" ssid="2">In particular, they drastically impact machine transla tion quality.</S>
		<S sid="3" ssid="3">An easy way out commercial translation systems usually offer their users is the possibility to add unknown wordsand their translations into a dedicated lex icon.</S>
		<S sid="4" ssid="4">Recently, Stroppa and Yvon (2005) have shown how analogical learning alone deals nicely with morphology in differentlanguages.</S>
		<S sid="5" ssid="5">In this study we show that ana logical learning offers as well an elegant andeffective solution to the problem of identify ing potential translations of unknown words.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number="1">
			<S sid="6" ssid="6">Analogical reasoning has received some attention in cognitive science and artificial intelligence (Gentneret al, 2001).</S>
			<S sid="7" ssid="7">It has been for a long time a faculty as sessed in the so-called SAT Reasoning tests used in the application process to colleges and universities in the United States.</S>
			<S sid="8" ssid="8">Turney (2006) has shown that it is possible to compute relational similarities in a corpus in order to solve 56% of typical analogical tests quizzed in SAT exams.</S>
			<S sid="9" ssid="9">The interested readercan find in (Lepage, 2003) a particularly dense treat ment of analogy, including a fascinating chapter on the history of the notion of analogy.</S>
			<S sid="10" ssid="10">The concept of proportional analogy, denoted [A : B = C : D ], is a relation between four entities which reads: ?A is to B as C is to D?.Among proportional analogies, we distinguish formal analogies, that is, ones that arise at the graph ical level, such as [fournit : fleurit = fournie : fleurie] in French or [believer : unbelievable = doer : undoable] in English.</S>
			<S sid="11" ssid="11">Formal analogies are often good indices for deeper analogies (Stroppa and Yvon, 2005).Lepage and Denoual (2005) presented the sys tem ALEPH, an intriguing example-based systementirely built on top of an automatic formal analogy solver.</S>
			<S sid="12" ssid="12">This system has achieved state-of-the art performance on the IWSLT task (Eck and Hori, 2005), despite its striking purity.</S>
			<S sid="13" ssid="13">As a matter offact, ALEPH requires no distances between exam ples, nor any threshold.1 It does not even rely on a tokenization device.</S>
			<S sid="14" ssid="14">One reason for its success probably lies in the specificity of the BTEC corpus: short and simple sentences of a narrow domain.</S>
			<S sid="15" ssid="15">It is doubtful that ALEPH would still behave adequately on broader tasks, such as translating news articles.Stroppa and Yvon (2005) propose a very help ful algebraic description of a formal analogy and describe the theoretical foundations of analogical learning which we will recap shortly.</S>
			<S sid="16" ssid="16">They showboth its elegance and efficiency on two morphologi cal analysis tasks for three different languages.Recently, Moreau et al (2007) showed that formal analogies of a simple kind (those involving suf fixation and/or prefixation) offer an effective way to extend queries for improved information retrieval.</S>
			<S sid="17" ssid="17">In this study, we show that analogical learning can be used as an effictive method for translatingunknown words or phrases.</S>
			<S sid="18" ssid="18">We found that our approach has the potential to propose a valid transla tion for 80% of ordinary unknown words, that is, words that are not proper names, compound words, or numerical expressions.</S>
			<S sid="19" ssid="19">Specific solutions have been proposed for those token types (Chen et al, 1998; Al-Onaizan and Knight, 2002; Koehn and Knight, 2003).</S>
			<S sid="20" ssid="20">The paper is organized as follows.</S>
			<S sid="21" ssid="21">We first recall 1Some heuristics are applied for speeding up the system.</S>
			<S sid="22" ssid="22">877 in Section 2 the principle of analogical learning anddescribe how it can be applied to the task of enrich ing a bilingual lexicon.</S>
			<S sid="23" ssid="23">In Section 3, we present the corpora we used in our experiments.</S>
			<S sid="24" ssid="24">We evaluate our approach over two translation tasks in Section 4.We discuss related work in Section 5 and give per spectives of our work in Section 6.</S>
	</SECTION>
	<SECTION title="Analogical Learning. " number="2">
			<S sid="25" ssid="1">2.1 Principle.</S>
			<S sid="26" ssid="2">Our approach to bilingual lexical enrichment is an instance of analogical learning described in (Stroppa and Yvon, 2005).</S>
			<S sid="27" ssid="3">A learning set L = {L1, . . .</S>
			<S sid="28" ssid="4">, LN} gathers N observations.</S>
			<S sid="29" ssid="5">A set of features computed on an incomplete observation X defines an input space.</S>
			<S sid="30" ssid="6">The inference task consists in predicting the missing features which belong to an output space.</S>
			<S sid="31" ssid="7">We denote I(X) (resp.</S>
			<S sid="32" ssid="8">O(X)) the projection of X into the input (resp.</S>
			<S sid="33" ssid="9">output) space.</S>
			<S sid="34" ssid="10">The inference procedure involves three steps: 1.</S>
			<S sid="35" ssid="11">Building EI(X) = {(A,B,C) ? L3 | [I(A) :.</S>
			<S sid="36" ssid="12">I(B) = I(C) : I(X)]}, the set of input stems2 of X , that is the set of triplets (A,B,C) which form with X an analogical equation.</S>
			<S sid="37" ssid="13">2.</S>
			<S sid="38" ssid="14">Building EO(X) = {Y | [O(A) : O(B) =.</S>
			<S sid="39" ssid="15">O(C) : Y ] ,?(A,B,C) ? EI(X)} the set of solutions to the analogical equations obtainedby projecting the stems of EI(X) into the out put space.</S>
	</SECTION>
	<SECTION title="Selecting O(X) among the elements of. " number="3">
			<S sid="40" ssid="1">EO(X).</S>
			<S sid="41" ssid="2">This inference procedure shares similarities withthe K-nearest-neighbor (k-NN) approach.</S>
			<S sid="42" ssid="3">In particular, since no model of the training material is be ing learned, the training corpus needs to be stored in order to be queried.</S>
			<S sid="43" ssid="4">On the contrary to k-NN, however, the search for closest neighbors does not require any distance, but instead relies on relational similarities.</S>
			<S sid="44" ssid="5">This purity has a cost: while in k-NN inference, neighbors can be found in time linear tothe training size, in analogical learning, this oper ation requires a computation time cubic in N , the 2In Turney?s work (Turney, 2006), a stem designates the first two words of a proportional analogy.number of observations.</S>
			<S sid="45" ssid="6">In many applications of interest, including the one we tackle here, this is sim ply impractical and heuristics must be applied.The first and second steps of the inference proce dure rely on the existence of an analogical solver,which we sketch in the next section.</S>
			<S sid="46" ssid="7">One impor tant thing to note at this stage, is that an analogicalequation may have several solutions, some being legitimate word-forms in a given language, others be ing not.</S>
			<S sid="47" ssid="8">Thus, it is important to select wisely the generated solutions, therefore Step 3.</S>
			<S sid="48" ssid="9">In practice, the inference procedure involves the computation of many analogical equations, and a statistic as simpleas the frequency of a solution often suffices to sepa rate good from spurious solutions.</S>
			<S sid="49" ssid="10">2.2 Analogical Solver.</S>
			<S sid="50" ssid="11">Lepage (1998) proposed an algorithm for comput ing the solutions of a formal analogical equation [A : B = C : ? ].</S>
			<S sid="51" ssid="12">We implemented a variant ofthis algorithm which requires to compute two editdistance tables, one between A and B and one between A and C. Since we are looking for subse quences of B and C not present in A, insertion costis null.</S>
			<S sid="52" ssid="13">Once this is done, the algorithm synchronizes the alignments defined by the paths of minimum cost in each table.</S>
			<S sid="53" ssid="14">Intuitively, the synchro nization of two alignments (one between A and B, and one between A and C) consists in composing in the correct order subsequences of the strings B andC that are not in A. We refer the reader to (Lep age, 1998) for the intricacies of this process which is illustrated in Figure 1 for the analogical equation[even : usual = unevenly : ? ].</S>
			<S sid="54" ssid="15">In this exam ple, there are 681 different paths that align even and usual (with a cost of 4), and 1 path which aligns even with unevenly (with a cost of 0).</S>
			<S sid="55" ssid="16">This results in 681synchronizations which generate 15 different solu tions, among which only unusually is a legitimate word-form.</S>
			<S sid="56" ssid="17">In practice, since the number of minimum-cost paths may be exponential in the size of the strings being aligned, we consider the synchronization of a maximum of M best paths in each edit-distance table.</S>
			<S sid="57" ssid="18">The worst-case complexity of our analogical solver is O([|A| ?</S>
			<S sid="58" ssid="19">(|B| + |C|)] + [M2 ?</S>
			<S sid="59" ssid="20">(|A| + ins(B,C))]), where the first term corresponds to the computation of the two edit-distance tables, 878 3 3 3 3 3 3 e 3 3 3 2 1 0 0 0 0 2 2 2 2 2 2 v 2 2 2 1 0 0 0 0 0 1 1 1 1 1 1 e 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 l a u s u / . u n e v e n l y e v e n e v e n u s u a l u n e v e n l y ?usua-un-l-ly e v e n e v e n u s u a l u n e v e n l y ?un-usu-a-l-lyFigure 1: The top table reports the edit-distance ta bles computed between even and usual (left part), and even and unevenly (right part).</S>
			<S sid="60" ssid="21">The bottompart of the figure shows 2 of the 681 synchroniza tions computed while solving the equation [even : usual = unevenly : ? ].</S>
			<S sid="61" ssid="22">The first one corresponds tothe path marked in bold italics and leads to a spurious solution; the second leads to a legitimate solu tion and corresponds to the path shown as squares.</S>
			<S sid="62" ssid="23">and the second one corresponds to the maximum time needed to synchronize them.</S>
			<S sid="63" ssid="24">|X| denotes the length, counted in characters of the string X , whilst ins(B,C) stands for the number of characters of B and C not belonging to A. Given the typical length of the strings we consider in this study, our solver is quite efficient.3Stroppa and Yvon (2005) described a generalization of this algorithm which can solve a formal analogical equation by composing two finite-state trans ducers.</S>
			<S sid="64" ssid="25">2.3 Application to Lexical Enrichment.</S>
			<S sid="65" ssid="26">Analogical inference can be applied to the task of extending an existing bilingual lexicon (or transfer table) with new entries.</S>
			<S sid="66" ssid="27">In this study, we focus on a particular enrichment task: the one of translating valid words or phrases that were not encountered at training time.</S>
			<S sid="67" ssid="28">A simple example of how our approach translatesunknown words is illustrated in Figure 2 for the (un 3Several thousands of equations solved within one second.</S>
			<S sid="68" ssid="29">Step 1 source (French) stems [activite?s : activite?</S>
			<S sid="69" ssid="30">= futilite?s : futilite?]</S>
			<S sid="70" ssid="31">[hostilite?s : hostilite?</S>
			<S sid="71" ssid="32">= futilite?s : futilite?]</S>
			<S sid="72" ssid="33">Step 2a projection by lexicon look-up activite?s?actions hostilite??hostility hostilite?s?hostilities activite??action futilite?s?trivialities,gimmicks . . .</S>
			<S sid="73" ssid="34">Step 2b target (English) resolution [actions : action = gimmicks : ? ] ? gimmick [hostilities : hostility = trivialities : ? ] ? triviality [hobbies : hobby = trivialities : ? ] ? triviality Step 3 selection of target candidates ?triviality, 2?, ?gimmick , 1?, . . .Figure 2: Illustration of the analogical inference pro cedure applied to the translation of the unknown French word futilite?.known) French word futilite?.</S>
			<S sid="74" ssid="35">In this example, trans lations is inferred by commuting plural and singular words.</S>
			<S sid="75" ssid="36">The inference process lazily captures the factthat English plural nouns ending in -ies usually cor respond to singular nouns ending in -y.</S>
			<S sid="76" ssid="37">Formally, we are given a training corpus L ={?S1, T1?, . . .</S>
			<S sid="77" ssid="38">, ?SN , TN ?} which consists of a col lection of N bilingual lexicon entries ?Si, Ti?.</S>
			<S sid="78" ssid="39">The input space is in our case the space of possible source words, while the output space is the set of possible target words.</S>
			<S sid="79" ssid="40">We define: ?X ? ?S ,T?, I(X) = S and O(X) = T Given an unknown source word-form S, Step 1 of the inference process consists in identifying source stems which have S as a solution:4 EI(S) = {?i, j, k?</S>
			<S sid="80" ssid="41">[1, N ] 3 | [Si : Sj = Sk : S]}.</S>
			<S sid="81" ssid="42">During Step 2a, each source stem belonging to EI(S) is projected form by form into (potentiallyseveral) stems in the output space, thanks to an op erator proj that will be defined shortly: E?i ,j ,k ?(S) = {T | [U : V = W : T ]} where (U, V,W ) ?</S>
			<S sid="82" ssid="43">(projL(Si)?</S>
			<S sid="83" ssid="44">projL(Sj)?</S>
			<S sid="84" ssid="45">projL(Sk)).</S>
			<S sid="85" ssid="46">4All strings in a stem must be different, otherwise, it can be shown that all source words would be considered.</S>
			<S sid="86" ssid="47">879 During Step 2b, each solution to those output stems is collected in EO(S) along with its associated frequency: EO(S) = ? ?i ,j ,k ??EI(S) E?i ,j ,k ?(S).Step 3 selects from EO(S) one or several solutions.</S>
			<S sid="87" ssid="48">We use frequency as criteria to sort the gener ated solutions.</S>
			<S sid="88" ssid="49">The projection mechanism we resort to in this study simply is a lexicon look-up: projL(S) = {T | ?S, T ? ?</S>
			<S sid="89" ssid="50">L}.</S>
			<S sid="90" ssid="51">There are several situations where this inference procedure will introduce noise.</S>
			<S sid="91" ssid="52">First, both sourceand target analogical equations can lead to spuri ous solutions.</S>
			<S sid="92" ssid="53">For instance, [show : showing =eating : ? ] will erroneously produce eatinging.</S>
			<S sid="93" ssid="54">Sec ond, an error in the original lexicon may introduce as well erroneous target word-forms.</S>
			<S sid="94" ssid="55">For instance, when translating the German word proklamierung, by making use of the analogy [formalisiert : formalisierung = proklamiert : proklamierung], the English equation [formalised : formalized = sets : ? ] will be considered if it happens that proklamiert?sets belongs to L; in which case, zets will be erroneously produced.</S>
			<S sid="95" ssid="56">We control noise in several ways.</S>
			<S sid="96" ssid="57">The source word-forms we generate are filtered by imposing that they belong to the input space.</S>
			<S sid="97" ssid="58">We also use a(large) target vocabulary to eliminate spurious tar get word-forms (see Section 3).</S>
			<S sid="98" ssid="59">More importantly, since we consider many analogical equations whentranslating a word-form, spurious analogical solu tions tend to appear less frequently than ones arising from paradigmatic commutations.</S>
			<S sid="99" ssid="60">2.4 Practical Considerations.</S>
			<S sid="100" ssid="61">Searching for EI(S) is an operation which requires solving a number of (source) analogical equations cubic in the size of the input space.</S>
			<S sid="101" ssid="62">In many settingsof interest, including ours, this is simply not practi cal. We therefore resort to two strategies to reduce computation time.</S>
			<S sid="102" ssid="63">The first one consists in using the analogical equations in a generative mode.</S>
			<S sid="103" ssid="64">Instead of searching through the set of stems ?Si, Sj , Sk?that have for solution the unknown source wordform S, we search for all pairs (Si, Sj) to the so lutions of [Si : Sj = S :?]</S>
			<S sid="104" ssid="65">that are valid word-forms of the input space.</S>
			<S sid="105" ssid="66">Note that this is an exact method which follows from the property (Lepage, 1998): [A : B = C : D ] ? [B : A = D : C ] This leaves us with a quadratic computation time which is still intractable in our case.</S>
			<S sid="106" ssid="67">Therefore,we apply a second strategy which consists in com puting the analogical equations [Si : Sj = S :?]</S>
			<S sid="107" ssid="68">for the only words Si and Sj close enough to S. More precisely, we enforce that Si ? v?(S) and that Sj ? v?(Si) for a neighborhood function v?(A) of the form: v?(A) = {B | f(B,A) ? ?}</S>
			<S sid="108" ssid="69">where f is a distance; we used the edit-distance in this study (Levenshtein, 1966).</S>
			<S sid="109" ssid="70">Note that the second strategy we apply is only a heuristic.</S>
			<S sid="110" ssid="71">3 Resources.</S>
			<S sid="111" ssid="72">In this work, we are concerned with one concrete problem a machine translation system must face:the one of translating unknown words.</S>
			<S sid="112" ssid="73">We are fur ther focusing on the shared task of the workshop on Statistical Machine Translation, which took place last year (Koehn and Monz, 2006) and consisted in translating Spanish, German, and French texts fromand to English.</S>
			<S sid="113" ssid="74">For some reasons, we restricted our selves to translating only into English.</S>
			<S sid="114" ssid="75">The trainingmaterial available is coming from the Europarl cor pus.</S>
			<S sid="115" ssid="76">The test material was divided into two parts.5The first one (hereafter called test-in) is com posed of 2 000 sentences from European parliamentdebates.</S>
			<S sid="116" ssid="77">The second part (called test-out) gath ers 1 064 sentences6 collected from editorials of theProject Syndicate website.7 The main statistics per tinent to our study are summarized in Table 1.</S>
			<S sid="117" ssid="78">A rough analysis of the 441 different unknown words encountered in the French test sets reveals that 54 (12%) of them contain at least one digit (years, page numbers, law numbers, etc.), 83 (20%) are proper names, 37 (8%) are compound words, 18 (4%) are foreign words (often Latin or Greek 5The participants were not aware of this.</S>
			<S sid="118" ssid="79">6We removed 30 sentences which had encoding problems.</S>
			<S sid="119" ssid="80">7http://www.project-syndicate.com 880 French Spanish German test- in out in out in out |unknown| 180 265 233 292 469 599 oov% 0.26 1.22 0.38 1.37 0.84 2.87 Table 1: Number of different (source) test words notseen at training time, and out-of-vocabulary rate ex pressed as a percentage (oov%).words), 7 words are acronyms, and 4 are tokenization problems.</S>
			<S sid="120" ssid="81">The 238 other words (54%) are ordi nary words.</S>
			<S sid="121" ssid="82">We considered different lexicons for testing our approach.</S>
			<S sid="122" ssid="83">These lexicons were derived from the training material of the shared task by training with GIZA++ (Och and Ney, 2000) ?default settings?</S>
			<S sid="123" ssid="84">two transfer tables (source-to-target and the reverse) that we intersected to remove some noise.</S>
			<S sid="124" ssid="85">In order to investigate how sensitive our approach is to the amount of training material available, wevaried the size of our lexicon LT by considering dif ferent portions of the training corpus (T = 5 000,10 000, 100 000, 200 000, and 500 000 pairs of sentences).</S>
			<S sid="125" ssid="86">The lexicon trained on the full training material (688 000 pairs of sentences), called Lref here after, is used for validation purposes.</S>
			<S sid="126" ssid="87">We kept (at most) the 20 best associations of each source word in these lexicons.</S>
			<S sid="127" ssid="88">In practice, because we intersect two models, the average number of translations kept for each source word is lower (see Table 2).Last, we collected from various target texts (En glish here) we had at our disposal, a vocabulary set V gathering 466 439 words, that we used to filter out spurious word-forms generated by our approach.</S>
	</SECTION>
	<SECTION title="Experiments. " number="4">
			<S sid="128" ssid="1">4.1 Translating Unknown Words.</S>
			<S sid="129" ssid="2">For the three translation directions (from Spanish, German, and French into English), we applied the analogical reasoning to translate the (non numerical) source words of the test material, absentfrom LT . Examples of translations produced by ana logical inference are reported in Figure 3, sorted by decreasing order of times they have been generated.</S>
			<S sid="130" ssid="3">anti-agricole  (anti-farm,5) (anti-agricultural,3) (anti-rural,3) (anti-farming,3) (anti-farmer,3) fleurie  (flourishing,5) (flourished,4) (flourish,1) futilite?</S>
			<S sid="131" ssid="4"> (trivialities,27) (triviality,14) (futile,9) (meaningless,9) (futility,4) (meaninglessness,4) (superfluous,2) (unwieldy,2) (unnecessary,2) (uselessness,2) (trivially,1) (tie,1) (trivial,1) butoir  (deadline,42) (deadlines,33) (blows,1) court-circuitant  (bypassing,13) (bypass,12) (bypassed,5) (bypasses,1) xviie  (xvii,18) (sixteenth,3) (eighteenth,1) Figure 3: Candidate translations inferred fromL200 000 and their frequency.</S>
			<S sid="132" ssid="5">The candidates re ported are those that have been intersected with V . Translations in bold are clearly erroneous.</S>
			<S sid="133" ssid="6">4.1.1 BaselinesWe devised two baselines against which we com pared our approach (hereafter ANALOG).</S>
			<S sid="134" ssid="7">The firstone, BASE1, simply proposes as translations the target words in the lexicon LT which are the most simi lar (in the sense of the edit-distance) to the unknownsource word.</S>
			<S sid="135" ssid="8">Naturally, this approach is only appropriate for pairs of languages that share many cognates (i.e., docteur ? doctor).</S>
			<S sid="136" ssid="9">The second baseline, BASE2, is more sensible and more closely cor responds to our approach.</S>
			<S sid="137" ssid="10">We first collect a set of source words that are close-enough (according to the edit-distance) to the unknown word.</S>
			<S sid="138" ssid="11">Those source words are then projected into the output space by simple bilingual lexicon look-up.</S>
			<S sid="139" ssid="12">So for instance, the French word demanda will be translated into the English word request if the French word demande isin LT and that request is one of its sanctioned trans lations.</S>
			<S sid="140" ssid="13">Each of these baselines is tested in two variants.</S>
			<S sid="141" ssid="14">The first one (id), which allows a direct comparison, proposes as many translations as ANALOG does.</S>
			<S sid="142" ssid="15">The second one (10) proposes the first 10 translations of each unknown word.</S>
			<S sid="143" ssid="16">4.1.2 Automatic Evaluation Evaluating the quality of translations requires to inspect lists of words each time we want to test a variant of our approach.</S>
			<S sid="144" ssid="17">This cumbersome process not only requires to understand the source language, 881 LT 5 000 10 000 50 000 100 000 200 000 500 000 p% r% p% r% p% r% p% r% p% r% p% r% test-in ANALOG 51.4 30.7 55.3 44.4 58.8 64.3 58.2 65.1 59.4 65.2 30.4 67.6 BASE1id 31.6 30.7 32.3 44.4 24.7 64.3 20.3 65.1 20.9 65.2 8.7 67.6 BASE2id 34.5 30.7 37.1 44.4 39.0 64.3 37.8 65.1 34.4 65.2 56.5 67.6 BASE110 26.7 100.0 28.3 100.0 23.9 100.0 20.0 100.0 16.6 100.0 11.8 100.0 BASE210 26.3 100.0 30.8 100.0 29.3 100.0 27.6 100.0 24.9 100.0 55.9 100.0 unk [3 171 , 9.1] [2 245 , 7.7] [754 , 4.0] [456 , 2.9] [253 , 2.0] [34 , 1.2] test-out ANALOG 52.8 28.9 55.3 42.5 52.9 68.8 54.7 74.6 55.7 81.0 43.3 88.2 BASE1id 28.0 28.9 29.0 42.5 27.3 68.8 23.1 74.6 26.8 81.0 22.7 88.2 BASE2id 32.9 28.9 35.0 42.5 32.5 68.8 35.9 74.6 40.8 81.0 59.1 88.2 BASE110 24.7 100.0 25.9 100.0 25.1 100.0 20.9 100.0 25.2 100.0 25.0 100.0 BASE210 21.7 100.0 26.4 100.0 27.2 100.0 29.4 100.0 33.6 100.0 57.9 100.0 unk [2 270 , 8.2] [1 701 , 6.9] [621 , 3.4] [402 , 2.4] [226 , 1.8] [76 , 1.4] Table 2: Performance of the different approaches on the French-to-English direction as a function of the number T of pairs of sentences used for training LT . A pair [n , t] in lines labeled by unk stands for the number of words to translate, and the average number of their translations in Lref . but happens to be in practice a delicate task.</S>
			<S sid="145" ssid="18">Wetherefore decided to resort to an automatic evaluation procedure which relies on Lref , a bilingual lex icon which entries are considered correct.</S>
			<S sid="146" ssid="19">We translated all the words of Lref absent fromLT . We evaluated the different approaches by com puting response and precision rates.</S>
			<S sid="147" ssid="20">The response rate is measured as the percentage of words for which we do have at least one translation produced (correct or not).</S>
			<S sid="148" ssid="21">The precision is computed in our case as the percentage of words for which at least one translation is sanctioned by Lref . Note that this way of measuring response and precision is clearlybiased toward translation systems that can hypoth esize several candidate translations for each word, as statistical systems usually do.</S>
			<S sid="149" ssid="22">The reason of this choice was however guided by a lack of precision of the reference we anticipated, a point we discuss in Section 4.1.3.</S>
			<S sid="150" ssid="23">The figures for the French-to-English direction are reported in Table 2.</S>
			<S sid="151" ssid="24">We observe that the ratioof unknown words that get a translation by ANA LOG is clearly impacted by the size of the lexicon LT we use for computing analogies: the larger the better.</S>
			<S sid="152" ssid="25">This was expected since the larger a lexicon is, the higher the number of source analogies thatcan be made and consequently, the higher the number of analogies that can be projected onto the out put space.</S>
			<S sid="153" ssid="26">The precision of ANALOG is rather stable across variants and ranges between 50% to 60%.The second observation we make is that the base lines perform worse than ANALOG in all but theL500 000 cases.</S>
			<S sid="154" ssid="27">Since our baselines propose trans lations to each source word, their response rate is maximum.</S>
			<S sid="155" ssid="28">Their precision, however, is an issue.</S>
			<S sid="156" ssid="29">Expectedly, BASE1 is the worst of the two baselines.</S>
			<S sid="157" ssid="30">If we arbitrarily fix the response rate of BASE2 to the one of ANALOG, the former approach shows a far lower precision (e.g., 34.4 against 59.4 for L200 000).</S>
			<S sid="158" ssid="31">This not only indicates that analogical learning is handling unknown words better than BASE2, but as well, that a combination of both approaches could potentially yield further improvements.</S>
			<S sid="159" ssid="32">A last observation concerns the fact that ANALOG performs equally well on the out-domain material.</S>
			<S sid="160" ssid="33">This is very important from a practical point of view and contrasts with some related work we discuss in Section 5.</S>
			<S sid="161" ssid="34">At first glance, the fact that BASE2 outperformsANALOG on the larger training size is disappoint ing.</S>
			<S sid="162" ssid="35">After investigations, we came to the conclusionthat this is mainly due to two facts.</S>
			<S sid="163" ssid="36">First, the num 882 ber of unknown words on which both systems were tested is rather low in this particular case (e.g., 34for the in-domain corpus).</S>
			<S sid="164" ssid="37">Second, we noticed a de ficiency of the reference lexicon Lref for many of those words.</S>
			<S sid="165" ssid="38">After all, this is not surprising since the words unseen in the 500 000 pairs of trainingsentences, but encountered in the full training cor pus (688 000 pairs) are likely to be observed only afew times, therefore weakening the associations au tomatically acquired for these entries.</S>
			<S sid="166" ssid="39">We evaluate that a third of the reference translations were wrong in this setting, which clearly raises some doubts on our automatic evaluation procedure in this case.The performance of ANALOG across the three lan guage pairs are reported in Table 3.</S>
			<S sid="167" ssid="40">We observe adrop of performance of roughly 10% (both in precision and response) for the German-to-English translation direction.</S>
			<S sid="168" ssid="41">This is likely due to the heuris tic procedure we apply during the search for stems,which is not especially well suited for handling com pound words that are frequent in German.We observe that for Spanish- and German-to English translation directions, the precision ratetends to decrease for larger values of T . One ex planation for that is that we consider all analogies equally likely in this work, while we clearly noted that some are spurious ones.</S>
			<S sid="169" ssid="42">With larger training material, spurious analogies become more likely.</S>
			<S sid="170" ssid="43">French Spanish German T p% r% p% r% p% r% 10 55.3 44.4 52.0 45.2 47.6 33.3 50 58.8 64.3 54.0 66.5 44.6 53.2 100 58.2 65.1 53.9 69.1 45.8 55.6 200 59.4 65.2 46.4 71.8 43.0 59.2Table 3: Performance across language pairs measured on test-in.</S>
			<S sid="171" ssid="44">The number T of pairs of sen tences used for training LT is reported in thousands.</S>
			<S sid="172" ssid="45">We measured the impact the translations produced by ANALOG have on a state-of-the-art phrase-based translation engine, which is described in (Patry etal., 2006).</S>
			<S sid="173" ssid="46">For that purpose, we extended a phrase table with the first translation proposed by ANALOGor BASE2 for each unknown word of the test ma terial.</S>
			<S sid="174" ssid="47">Results in terms of word-error-rate (WER) and BLEU score (Papineni et al, 2002) are reported in Table 4 for those sentences that contain at leastone unknown word.</S>
			<S sid="175" ssid="48">Small but consistent improve ments are observed for both metrics with ANALOG.This was expected, since the original system sim ply leaves the unknown words untranslated.</S>
			<S sid="176" ssid="49">What is more surprising is that the BASE2 version slightly underperforms the baseline.</S>
			<S sid="177" ssid="50">The reason is that some unknown words that should appear unmodified in a translation, often get an erroneous translation by BASE2.</S>
			<S sid="178" ssid="51">Forcing BASE2 to propose a translation for the same words for which ANALOG found one, slightly improves the figures (BASE2id).</S>
			<S sid="179" ssid="52">French Spanish German WER BLEU WER BLEU WER BLEU base 61.8 22.74 54.0 27.00 69.9 18.15 +BASE2 61.8 22.72 54.2 26.89 70.3 18.05 +BASE2id 61.7 22.81 54.1 27.01 70.1 18.14 +ANALOG 61.6 22.90 53.7 27.27 69.7 18.30 sentences 387 452 814Table 4: Translation quality produced by our phrase based SMT engine (base) with and without the first translation produced by ANALOG, BASE2, or BASE2id for each unknown word.</S>
			<S sid="180" ssid="53">4.1.3 Manual Evaluation As we already mentioned, the lexicon used as a reference in our automatic evaluation procedure is not perfect, especially for low frequency words.</S>
			<S sid="181" ssid="54">Wefurther noted that several words receive valid trans lations that are not sanctioned by Lref . This is for instance the case of the examples in Figure 4, where circumventing and fellow are arguably legitimate translations of the French words contournant andconcitoyen, respectively.</S>
			<S sid="182" ssid="55">Note that in the second ex ample, the reference translation is in the plural form while the French word is not.</S>
			<S sid="183" ssid="56">Therefore, we conducted a manual evaluation ofthe translations produced from L100 000 by ANA LOG and BASE2 on the 127 French words of the corpus test-in8 unknown of Lref . Those arethe non-numerical unknown words the participat ing systems in the shared task had to face in the 8We did not notice important differences between test-in and test-out.</S>
			<S sid="184" ssid="57">883 contournant (49 candidates) ANALOG  (circumventing,55) (undermining,20) (evading,19) (circumvented,17) (overturning,16) (circumvent,15) (circumvention,15) (bypass,13) (evade,13) (skirt,12) Lref  skirting, bypassing, by-pass, overcoming concitoyen (24 candidates)ANALOG  (citizens,26) (fellow,26) (fellowcitizens,26) (people,26) (citizen,23) (fellowcitizen,21) (fellows,5) (peoples,3) (civils,3) (fel lowship,2) Lref  fellow-citizensFigure 4: 10 best ranked candidate translations pro duced by ANALOG from L200 000 for two unknown words and their sanctioned translations in Lref . Words in bold are present in both the candidate and the reference lists.</S>
			<S sid="185" ssid="58">in-domain part of the test material.</S>
			<S sid="186" ssid="59">75 (60%) of those words received at least one valid translation by ANALOG while only 63 (50%) did by BASE2.</S>
			<S sid="187" ssid="60">Among those words that received (at least) one validtranslation, 61 (81%) were ranked first by ANALOG against only 22 (35%) by BASE2.</S>
			<S sid="188" ssid="61">We fur ther observed that among the 52 words that did not receive a valid translation by ANALOG, 38 (73%)did not receive a translation at all.</S>
			<S sid="189" ssid="62">Those untrans lated words are mainly proper names (bush), foreignwords (munere), and compound words (rhe?nanie du-nord-westphalie), for which our approach is not especially well suited.</S>
			<S sid="190" ssid="63">We conclude from this informal evaluation that 80% of ordinary unknown words received a valid translation in our French-to-English experiment, andthat roughly the same percentage had a valid trans lation proposed in the first place by ANALOG.</S>
			<S sid="191" ssid="64">4.2 Translating Unknown Phrases.</S>
			<S sid="192" ssid="65">Our approach is not limited to translate solely un known words, but might serve as well to enrichexisting entries in a lexicon.</S>
			<S sid="193" ssid="66">For instance, low frequency words, often poorly handled by current statistical methods, could receive useful translations.</S>
			<S sid="194" ssid="67">This is illustrated in Figure 5 where we report the best candidates produced by ANALOG for the French word invite?es, which appears 7 times in the 200 000 invite?e (61 candidates)ANALOG  (invited,135) (requested,92) (called,77) (urged,75) (guest,72) (asked,47) (re quest,43) (invites,27) (invite,26) (urge,26) L200 000  asked, generate, urged Figure 5: 10 best candidates produced by ANALOG for the low-frequency French word invite?es and its translations in L200 000.first pairs of the training corpus.</S>
			<S sid="195" ssid="68">Interestingly, ANALOG produced the candidate guest which corre sponds to a legitimate meaning of the French word that was absent in the training data.Because it can treat separators as any other char acter, ANALOG is not bounded to translate only words.</S>
			<S sid="196" ssid="69">As a proof of concept, we applied analogical reasoning to translate those source sequences of atmost 5 words in the test material that contain an un known word.</S>
			<S sid="197" ssid="70">Since there are many more sequencesthan there are words, the input space in this exper iment is far larger, and we had to resort to a much more aggressive pruning technique to find the stems of the sequences to be translated.expulsent  (expelling,36) (expel,31) (are ex pelling,23) (are expel,10)focaliserai  (focus,10) (focus solely,9) (concen trate all,9) (will focus,9) (will placing,9) de?passeront  (will exceed,4) (exceed,3) (will be exceed,3) (we go beyond,2) (will be exceeding,2) non-re?ussite de  (lack of success for,4) (lack of success of,4) (lack of success,4) que vous subissez  (you are experiencing,2) Figure 6: Examples of translations produced by ANALOG where the input (resp.</S>
			<S sid="198" ssid="71">output) space isdefined by the set of source (resp.</S>
			<S sid="199" ssid="72">target) word se quences.</S>
			<S sid="200" ssid="73">Words in bold are unknown.</S>
			<S sid="201" ssid="74">We applied the automatic evaluation procedure described in Section 4.1.2 for the French-to-English translation direction, with a reference lexicon beingthis time the phrase table acquired on the full train ing material.9 The response rate in this experiment is particularly low since only a tenth of the sequences 9This model contains 1.5 millions pairs of phrases.</S>
			<S sid="202" ssid="75">884 received (at least) a translation by ANALOG.</S>
			<S sid="203" ssid="76">Those are short sequences that contain at most three words,which clearly indicates the limitation of our prun ing strategy.</S>
			<S sid="204" ssid="77">Among those sequences that received at least one translation, the precision rate is 55%, which is consistent with the rate we measured while translating words.</S>
			<S sid="205" ssid="78">Examples of translations are reported in Figure 6.We observe that single words are not contrived any more to be translated by a single word.</S>
			<S sid="206" ssid="79">This allows to capture 1:n relations such as de?passeront?will exceed, where the future tense of the French word is adequately rendered by the modal will in English.</S>
	</SECTION>
	<SECTION title="Related Work. " number="5">
			<S sid="207" ssid="1">We are not the first to consider the translation of un known words or phrases.</S>
			<S sid="208" ssid="2">Several authors have for instance proposed approaches for translating propernames and named entities (Chen et al, 1998; AlOnaizan and Knight, 2002).</S>
			<S sid="209" ssid="3">Our approach is com plementary to those ones.</S>
			<S sid="210" ssid="4">Recently and more closely related to the approach we described, Callison-Burch et al (2006) proposed to replace an unknown phrase in a source sentenceby a paraphrase.</S>
			<S sid="211" ssid="5">Paraphrases in their work are ac quired thanks to a word alignment computed overa large external set of bitexts.</S>
			<S sid="212" ssid="6">One important difference between their work and ours is that our approach does not require additional material.10 Indeed, they used a rather idealistic set of large, ho mogeneous bitexts (European parliament debates) toacquire paraphrases from.</S>
			<S sid="213" ssid="7">Therefore we feel our ap proach is more suited for translating ?low density?</S>
			<S sid="214" ssid="8">languages and languages with a rich morphology.</S>
			<S sid="215" ssid="9">Several authors considered as well the translationof new words by relying on distributional colloca tional properties computed from a huge non-parallel corpus (Rapp, 1999; Fung and Yee, 1998; Takaaki and Matsuo, 1999; Koehn and Knight, 2002).</S>
			<S sid="216" ssid="10">Evenif admittedly non-parallel corpora are easier to ac quire than bitexts, this line of work is still heavily dependent on huge external resources.</S>
			<S sid="217" ssid="11">Most of the analogies made at the word level in our study are capturing morphological information.</S>
			<S sid="218" ssid="12">10We do use a target vocabulary list to filter out spurious analogies, but we believe we could do without.</S>
			<S sid="219" ssid="13">The frequency with which we generate a string could serve to decide upon its legitimacy.</S>
			<S sid="220" ssid="14">The use of morphological analysis in (statistical) machine translation has been the focus of severalstudies, (Nie?en, 2002) among the first.</S>
			<S sid="221" ssid="15">Depend ing on the pairs of languages considered, gains havebeen reported when the training material is of modest size (Lee, 2004; Popovic and Ney, 2004; Gold water and McClosky, 2005).</S>
			<S sid="222" ssid="16">Our approach does not require any morphological knowledge of the source, the target, or both languages.</S>
			<S sid="223" ssid="17">Admittedly, severalunsupervised morphological induction methodolo gies have been proposed, e.g., the recent approach in Freitag (2005).</S>
			<S sid="224" ssid="18">In any case, as we have shown, ANALOG is not bounded to treat only words, which we believe to be at our advantage.</S>
	</SECTION>
	<SECTION title="Discussion and Future Work. " number="6">
			<S sid="225" ssid="1">In this paper, we have investigated the appropri ateness of analogical learning to handle unknown words in machine translation.</S>
			<S sid="226" ssid="2">On the contrary to several lines of work, our approach does not rely on massive additional resources but capitalizes instead on an information which is inherently pertaining tothe language.</S>
			<S sid="227" ssid="3">We measured that roughly 80% of or dinary unknown French words can receive a valid translation into English with our approach.</S>
			<S sid="228" ssid="4">This work is currently being developed in severaldirections.</S>
			<S sid="229" ssid="5">First, we are investigating why our ap proach remains silent for some words or phrases.This will allow us to better characterize the limitations of ANALOG and will hopefully lead us to de sign a better strategy for identifying the stems of agiven word or phrase.</S>
			<S sid="230" ssid="6">Second, we are investigat ing how a systematic enrichment of a phrase-transfer table will impact a phrase-based statistical machine translation engine.</S>
			<S sid="231" ssid="7">Last, we want to investigate the training of a model that can learn regularities from the analogies we are making.</S>
			<S sid="232" ssid="8">This would relieve usfrom requiring the training material while translat ing, and would allow us to compare our approachwith other methods proposed for unsupervised mor phology acquisition.Acknowledgement We are grateful to the anony mous reviewers for their useful suggestions and to Pierre Poulin for his fruitful comments.</S>
			<S sid="233" ssid="9">This study has been partially funded by NSERC.</S>
			<S sid="234" ssid="10">885</S>
	</SECTION>
</PAPER>
